{
  "/docs/introduction-new-relic-mobile-unity": [
    {
      "sections": [
        "Security for mobile apps",
        "Data collection",
        "Secure data endpoints",
        "Unique identifiers",
        "No remote updates",
        "Data storage",
        "Instrumentation added to your code",
        "User's IP address"
      ],
      "title": "Security for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile",
        "Get started"
      ],
      "external_id": "c1f31e708e4710eb4823467a43ab30af1f29243c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/get-started/security-mobile-apps/",
      "published_at": "2021-05-05T05:08:34Z",
      "updated_at": "2021-05-05T05:08:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To protect your mobile application's security and your users' data privacy, New Relic only records performance data, as described in this document. We do not collect any data used or stored by the monitored app. For more information about New Relic's security measures, see our security and data privacy documentation, or visit the New Relic security website. Data collection When you install New Relic, our mobile monitoring capabilities become part of your iOS or Android app. These capabilities live within your application's \"sandbox,\" so they cannot access anything other than performance data from your mobile app. We do not collect performance data about the device itself, such as battery level. Our mobile SDK agent collects and sends specific data to the New Relic collector, including: Mobile data collected Comments Devices Length of application session Wireless carrier's name The device's model name and manufacturer, and its operating system version Certain package, class, method, and thread names A unique instance identifier Requests and responses URLs of HTTP requests, along with HTTP status code, response time, and size of the request and response body Operating system error code for network failures (HTTP requests that fail to complete) The first 2KB of the response body when the HTTP request receives a 4xx or 5xx response status code Android only: A stack trace when the HTTP request receives a 4xx or 5xx response status code The agent sends all data using HTTPS encryption and validates the collector's SSL certificate. This prevents common data sniffing and server spoofing attacks. The agent also removes the query string, fragment identifier, username, and password from each URL before sending the data. Secure data endpoints Our mobile SDK agent sends harvested data to the collectors for processing. You can redirect those data posts to proxy or delegate servers for secure data handling. Android: You can use APIs to specify the URI authority of harvest and crash collector data endpoints. For more information, see the Android agent configuration and feature flags documentation. iOS: For more information, see the iOS agent configuration and feature flags documentation. Unique identifiers Our mobile SDK agent assigns a unique identifier to each installed app instance in order to track discrete installs, identify recurring sessions, and correlate performance over time. Mobile agent Identifiers Android Our Android agent generates a cryptographically strong UUID and stores it in the app's SharedPreferences. For more information, see our Android compatibility and requirements documentation. iOS The security measures used for iOS depend on the agent version. In versions 5.3.5 or higher, the iOS agent uses the IdentifierForVendor property to provide a unique device ID. In versions 5.3.4 or lower, the iOS agent used the SecureUDID open source library. SecureUDID is used by many third party libraries and is an accepted industry standard that does not violate Apple App store guidelines. SecureUDID does not use device hardware identifiers such as IMEI. Note that our mobile SDK does not collect IDFA (Identity For Advertisers). For more information, see our iOS compatibility and requirements documentation. No remote updates New Relic does not have the ability to update mobile agents remotely. Using the agent will not introduce any code into your mobile app without your knowledge. Data storage Our mobile SDK agent stores configuration information using your app's normal preferences or settings API on the mobile device. This configuration includes your: Application token Application version number Android or iOS SDK agent version number Settings such as the maximum number of HTTP requests to track per minute Performance data is buffered in memory. It is never written to the device's storage. Server-side data storage for mobile apps is handled in the same way as all other applications monitored by New Relic. For more information, see our security documentation about hosting and data storage. In general, we retain performance data according to the more generous time period of either your web or your mobile subscription. We also retain aggregate records of the number of active instances of your application. Instrumentation added to your code Our mobile SDK agent injects code into certain method calls within your application in order to collect performance data. This can have the effect of adding stack frames to your application's call graph where our code executes. This allows us to time and monitor the inputs and outputs of various APIs. This added code has been reviewed and tested for security-related flaws, and it incorporates best practices related to secure coding. Because our code runs within your application's process, it is subject to the same rights and restrictions as your own code. In addition, our iOS agent registers an NSURLProtocol handler to track NSURLConnection-based networking activity. This instrumentation is compatible with other custom NSURLProtocol handlers your application may register. The handler is registered within a single application process, so it is unable to monitor networking requests originating from other applications or the underlying operating system. User's IP address Our mobile SDK agent captures the user's IP address to enrich data for additional user information. The IP address is used as a lookup value that maps to additional details and allows our customers to diagnose performance issues. IP address lookup values include: App name Country code Region Postal code Latitude Longitude Area code For more information about events and attributes for mobile monitoring, see our data dictionary. New Relic does not retain the user's IP address after the attributes have been mapped. The IP address value is cached in memory for up to six hours before being discarded. If you have questions or concerns about this use of IP addresses with regards to your own regulatory obligations for notice and consent, please contact your privacy or legal teams.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.31267,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for <em>mobile</em> apps",
        "sections": "Security for <em>mobile</em> apps",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em>",
        "body": "To protect your <em>mobile</em> application&#x27;s security and your users&#x27; data privacy, <em>New</em> <em>Relic</em> only records performance data, as described in this document. We do not collect any data used or stored by the monitored app. For more information about <em>New</em> <em>Relic</em>&#x27;s security measures, see our security and data"
      },
      "id": "603eb1c564441fa7e44e88a5"
    },
    {
      "sections": [
        "Introduction to New Relic APIs",
        "Tip",
        "NerdGraph (GraphQL)",
        "REST APIs by capability",
        "Alerts",
        "APM",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Synthetic monitoring",
        "Telemetry APIs for core data types",
        "Account management, admin, and usage APIs",
        "Other APIs",
        "Insights",
        "Plugins",
        "See APIs in action"
      ],
      "title": "Introduction to New Relic APIs",
      "type": "docs",
      "tags": [
        "APIs",
        "Get started",
        "Intro to APIs"
      ],
      "external_id": "a8978f1c0acce16e111b6680fa02b8f2b0fd4b04",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/get-started/intro-apis/introduction-new-relic-apis/",
      "published_at": "2021-05-04T15:46:20Z",
      "updated_at": "2021-04-22T10:21:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a variety of APIs and SDKs you can use to: Retrieve data from New Relic. Send data to New Relic. Adjust settings. This document provides examples and reference information for our API endpoints. For developer-focused content on how to use and customize New Relic, see developer.newrelic.com. Tip To use APIs and SDKs, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. NerdGraph (GraphQL) NerdGraph is New Relic's GraphQL-format API, an efficient and flexible query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph is the preferred API for querying New Relic data and making a range of feature configurations. To get started, see Introduction to NerdGraph. REST APIs by capability New Relic capabilities, like APM, infrastructure monitoring, or alerts, are often used together, and sometimes they overlap in functionality. This is why multiple APIs may be relevant to each area. Some API functionality will depend on your access to features and data. Tip To learn more about different API key types, see Understand New Relic API keys. Alerts Use the REST API for alerts and the API Explorer to: Create and manage policies, conditions, and notification channels. Create alert conditions based on NRQL queries. Create alert conditions based on data from other New Relic capabilities. APM API resources for application monitoring include: Resource Details REST API REST API features include: Retrieve APM data, including metrics, Apdex, error rates, and host data. Report deployments. Change the app name in the UI. Agent APIs Every APM language agent has an API that lets you customize the agent's default behavior, including reporting custom data. APM agent APIs include: C SDK API Go agent API Java agent API .NET agent API Node.js agent API PHP agent API Python agent API Ruby agent API Query API To query APM data, use the Query API. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Browser monitoring The Browser API resources include: Resource Details Browser agent API Use the Browser agent API for tasks such as: Report custom end user data to browser monitoring. Monitor asynchronous browser activity using SPA API calls. Insert custom data into New Relic dashboards . Manage source maps. REST API With the REST API you can: Retrieve page load timing data and throughput. Add or list apps monitored by browser monitoring. Manage alerts conditions for your browser data. Query API To retrieve browser monitoring data, use the Query API. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Infrastructure monitoring The Infrastructure API resources include: Resource Details Query API To retrieve infrastructure data, use the Query API. This API can also be used to retrieve subscription usage data. Infrastructure alert API To manage your infrastructure alerts, use the Infrastructure alert API. Integrations SDK To make your own custom integrations for reporting data to infrastructure monitoring, use the Integrations SDK. NerdGraph You can use NerdGraph (our GraphQL API) to query your cloud integration data and make changes to cloud integration settings. Mobile monitoring Mobile API resources include: Resource Details Mobile agent APIs Mobile APIs let you custom instrument your own code and send events to New Relic. See the platform-specific documentation: iOS Android Unity REST API Use the REST API for such tasks as: Retrieve a list of monitored apps. Get subscription usage data. Get metric names and data. Get crash count and crash rate data. Manage New Relic alerts conditions for your mobile apps. Query API To retrieve Mobile data from New Relic, use the Query API. Account management APIs For account-related APIs, see Account APIs. Synthetic monitoring Synthetics API resources include: Resource Details Synthetics REST API The Synthetics REST API functionality includes: Create and manage synthetics monitors. Manage synthetics alert notifications. Add labels to monitors, and retrieve monitors with specific labels. Query API To retrieve synthetics event data, use the Query API. Alerts API To create and manage alert conditions that target synthetics monitors, use the Alerts API. Telemetry APIs for core data types We offer several APIs that allow you to get our core data types (metrics, logs, traces, and events) into New Relic without the use of an installed agent. Data type Description Trace API Send distributed tracing data to New Relic. Event API Send event data to New Relic. Metric API Send metrics to New Relic from any source (including other telemetry monitoring services). Log API Send your log data to New Relic. Account management, admin, and usage APIs Like any other New Relic product or service, you want to be confident that your APIs protect you and your customers' data privacy. The following are API resources related to New Relic account administration and usage. For more information about API capabilities, see the specific New Relic API. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. Resource Details REST API REST API features include: Find your API keys, account ID, and information needed to use the REST API. Return a list of account users (original user model only). Get SLA report data for browser and application monitoring. Subscription usage You can use the Query API to retrieve subscription usage data. This can be helpful to see how usage compares to your current subscription level, or for doing departmental chargebacks. Partner API To retrieve information about your New Relic partner account, sub-accounts, and users, use the Partner API. Other APIs Insights API resources for Insights include: Resource Details Insert events API To report custom data use the Event insertion API. Query API To query your Insights data using NRQL-formatted queries, use the Query API. This API can also be used to retrieve subscription usage data. Dashboard API To create, read, update, and delete dashboards, use the Dashboard API. Other New Relic product APIs You can also report custom data from other New Relic features. For more information, see the API sections for other products. NerdGraph You can use NerdGraph (our GraphQL API) to query data with NRQL. Plugins Use the REST API for New Relic plugins and the API Explorer to: Get a list of plugins, including their names, IDs, and GUIDs. List one or more plugin components, their output, and their metric timeslice data. Developers and New Relic partners can also use New Relic's Plugin API to write an agent in any language that can work directly with the API for plugins. This allows you to send your own metric data to our plugins and view data received from the API in New Relic. See APIs in action For more on how you as a developer can optimize your ability to solve problems using New Relic, go to developer.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 88.654564,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> <em>to</em> <em>New</em> <em>Relic</em> APIs",
        "sections": "<em>Introduction</em> <em>to</em> <em>New</em> <em>Relic</em> APIs",
        "tags": "Intro <em>to</em> APIs",
        "body": " documentation: iOS Android <em>Unity</em> REST API Use the REST API for such tasks as: Retrieve a list of monitored apps. Get subscription usage data. Get metric names and data. Get crash count and crash rate data. Manage <em>New</em> <em>Relic</em> alerts conditions for your <em>mobile</em> apps. Query API To retrieve <em>Mobile</em> data from"
      },
      "id": "6043a36e64441f965e378ef4"
    },
    {
      "sections": [
        "No data appears (Android)",
        "Problem",
        "Solution"
      ],
      "title": "No data appears (Android)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Troubleshoot"
      ],
      "external_id": "cab2851a6f3c8bfddb1ed445f8722b3dddff7442",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/troubleshoot/no-data-appears-android/",
      "published_at": "2021-05-04T17:40:35Z",
      "updated_at": "2021-03-16T09:51:07Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After installing New Relic Mobile for Android and waiting at least 5 minutes, no data appears in New Relic UI. Solution If no data appears after you wait at least five minutes, use New Relic Diagnostics to automatically detect common problems and suggest troubleshooting. If that does not solve your issue, try the following: Make sure your system meets the compatibility and requirements. Make sure that you are calling the New Relic Mobile for Android agent on the first line of onCreate() in the MainActivity class and that you are running the agent on the main thread. New Relic Mobile for Android does not support starting the agent in another class. Check whether your Android app exceeds the 64k multidex limit. Increase the logging level and examine your logs for errors: Increase the New Relic logging level to AUDIT using withLogLevel: NewRelic.withApplicationToken(\"YOUR_APP_TOKEN\") .withLogLevel(AgentLog.AUDIT) .start(this.getApplication()); Copy Generate a few minutes of activity in your app. Examine your device log and your application build logs for issues. Confirm the device can reach the New Relic Mobile endpoint at mobile-collector.newrelic.com. If you need additional help, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 79.43175,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> Android",
        "body": "Problem After installing <em>New</em> <em>Relic</em> <em>Mobile</em> for Android and waiting at least 5 minutes, no data appears in <em>New</em> <em>Relic</em> UI. Solution If no data appears after you wait at least five minutes, use <em>New</em> <em>Relic</em> Diagnostics to automatically detect common problems and suggest troubleshooting. If that does"
      },
      "id": "603e8eb6196a67b64ea83d81"
    }
  ],
  "/docs/ios-device-id-obfuscation": [
    {
      "sections": [
        "Security for mobile apps",
        "Data collection",
        "Secure data endpoints",
        "Unique identifiers",
        "No remote updates",
        "Data storage",
        "Instrumentation added to your code",
        "User's IP address"
      ],
      "title": "Security for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile",
        "Get started"
      ],
      "external_id": "c1f31e708e4710eb4823467a43ab30af1f29243c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/get-started/security-mobile-apps/",
      "published_at": "2021-05-05T05:08:34Z",
      "updated_at": "2021-05-05T05:08:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To protect your mobile application's security and your users' data privacy, New Relic only records performance data, as described in this document. We do not collect any data used or stored by the monitored app. For more information about New Relic's security measures, see our security and data privacy documentation, or visit the New Relic security website. Data collection When you install New Relic, our mobile monitoring capabilities become part of your iOS or Android app. These capabilities live within your application's \"sandbox,\" so they cannot access anything other than performance data from your mobile app. We do not collect performance data about the device itself, such as battery level. Our mobile SDK agent collects and sends specific data to the New Relic collector, including: Mobile data collected Comments Devices Length of application session Wireless carrier's name The device's model name and manufacturer, and its operating system version Certain package, class, method, and thread names A unique instance identifier Requests and responses URLs of HTTP requests, along with HTTP status code, response time, and size of the request and response body Operating system error code for network failures (HTTP requests that fail to complete) The first 2KB of the response body when the HTTP request receives a 4xx or 5xx response status code Android only: A stack trace when the HTTP request receives a 4xx or 5xx response status code The agent sends all data using HTTPS encryption and validates the collector's SSL certificate. This prevents common data sniffing and server spoofing attacks. The agent also removes the query string, fragment identifier, username, and password from each URL before sending the data. Secure data endpoints Our mobile SDK agent sends harvested data to the collectors for processing. You can redirect those data posts to proxy or delegate servers for secure data handling. Android: You can use APIs to specify the URI authority of harvest and crash collector data endpoints. For more information, see the Android agent configuration and feature flags documentation. iOS: For more information, see the iOS agent configuration and feature flags documentation. Unique identifiers Our mobile SDK agent assigns a unique identifier to each installed app instance in order to track discrete installs, identify recurring sessions, and correlate performance over time. Mobile agent Identifiers Android Our Android agent generates a cryptographically strong UUID and stores it in the app's SharedPreferences. For more information, see our Android compatibility and requirements documentation. iOS The security measures used for iOS depend on the agent version. In versions 5.3.5 or higher, the iOS agent uses the IdentifierForVendor property to provide a unique device ID. In versions 5.3.4 or lower, the iOS agent used the SecureUDID open source library. SecureUDID is used by many third party libraries and is an accepted industry standard that does not violate Apple App store guidelines. SecureUDID does not use device hardware identifiers such as IMEI. Note that our mobile SDK does not collect IDFA (Identity For Advertisers). For more information, see our iOS compatibility and requirements documentation. No remote updates New Relic does not have the ability to update mobile agents remotely. Using the agent will not introduce any code into your mobile app without your knowledge. Data storage Our mobile SDK agent stores configuration information using your app's normal preferences or settings API on the mobile device. This configuration includes your: Application token Application version number Android or iOS SDK agent version number Settings such as the maximum number of HTTP requests to track per minute Performance data is buffered in memory. It is never written to the device's storage. Server-side data storage for mobile apps is handled in the same way as all other applications monitored by New Relic. For more information, see our security documentation about hosting and data storage. In general, we retain performance data according to the more generous time period of either your web or your mobile subscription. We also retain aggregate records of the number of active instances of your application. Instrumentation added to your code Our mobile SDK agent injects code into certain method calls within your application in order to collect performance data. This can have the effect of adding stack frames to your application's call graph where our code executes. This allows us to time and monitor the inputs and outputs of various APIs. This added code has been reviewed and tested for security-related flaws, and it incorporates best practices related to secure coding. Because our code runs within your application's process, it is subject to the same rights and restrictions as your own code. In addition, our iOS agent registers an NSURLProtocol handler to track NSURLConnection-based networking activity. This instrumentation is compatible with other custom NSURLProtocol handlers your application may register. The handler is registered within a single application process, so it is unable to monitor networking requests originating from other applications or the underlying operating system. User's IP address Our mobile SDK agent captures the user's IP address to enrich data for additional user information. The IP address is used as a lookup value that maps to additional details and allows our customers to diagnose performance issues. IP address lookup values include: App name Country code Region Postal code Latitude Longitude Area code For more information about events and attributes for mobile monitoring, see our data dictionary. New Relic does not retain the user's IP address after the attributes have been mapped. The IP address value is cached in memory for up to six hours before being discarded. If you have questions or concerns about this use of IP addresses with regards to your own regulatory obligations for notice and consent, please contact your privacy or legal teams.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.92755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Unique <em>identifiers</em>",
        "body": " version. In versions 5.3.5 or higher, the <em>iOS</em> agent uses the IdentifierForVendor property to provide a unique <em>device</em> <em>ID</em>. In versions 5.3.4 or lower, the <em>iOS</em> agent used the SecureUDID open source library. SecureUDID is used by many third party libraries and is an accepted industry standard that does"
      },
      "id": "603eb1c564441fa7e44e88a5"
    },
    {
      "sections": [
        "recordMetric (iOS SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples",
        "Objective-C",
        "Swift"
      ],
      "title": "recordMetric (iOS SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "iOS SDK API"
      ],
      "external_id": "c4094cef25b7e8b3438eb4d46f19d77ff1e45b9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/ios-sdk-api/recordmetric-ios-sdk-api/",
      "published_at": "2021-05-05T05:26:41Z",
      "updated_at": "2021-03-16T09:57:51Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic recordMetricWithName:(NSString *)name category:(NSString *)category value:(NSNumber *)value]; NewRelic.recordMetric(withName: String!, category: String!, value: NSNumber!) Copy Record custom metrics (arbitrary numerical data). Requirements Compatible with all agent versions. Description With this method, you can record arbitrary custom metrics to give more detail about app activity that is not tracked by New Relic automatically. The call accepts several sets of parameters for optional levels of detail. This method will record a metric of the form Custom/[Category]/[Name], with a count of 1 and a total value equal to the value passed in. Multiple calls will aggregate the count and value according to standard metric aggregation rules for New Relic Mobile. To get the most out of your metrics, follow these guidelines to create clear, concise metric names: Use case and whitespace characters appropriate for display in the user interface. Metric names are rendered as-is. Capitalize the metric name. Avoid using the characters / ] [ | * when naming metrics. Avoid multi-byte characters. The category is also required; it is displayed in the UI and is useful for organizing custom metrics if you have many of them. It can be a custom category or it can be a predefined category using the MetricCategory enum. To view your custom metrics, use Insights Metric Explorer to search metrics, create customizable charts, and add those charts to Insights dashboards. For variations that accept additional arguments and give you more control over the metrics you record, see NewRelic.h. For more information about using this API, see the iOS SDK API usage guide. Parameters Parameter Description $name string Required. The name for the custom metric. $category string Required. The metric category name, either custom or using a predefined metric category. Value double Required. The value of the metric. Examples Objective-C Method: [NewRelic recordMetricWithName:(NSString *)name category:(NSString *)category value:(NSNumber *)value]; Copy Example (metrics in milliseconds): [NewRelic recordMetricWithName:(NSString *)@\"My Important Metric\" category:(NSString *)@\"Important Metrics\" value:(NSNumber *)145.67]; Copy Swift Method: NewRelic.recordMetric(withName: String!, category: String!, value: NSNumber!) Copy Example (metrics in milliseconds): NewRelic.recordMetric(withName: \"My Important Metric\", category: \"Important Metrics\", value: 145.67) Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.05608,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "recordMetric (<em>iOS</em> SDK API)",
        "sections": "recordMetric (<em>iOS</em> SDK API)",
        "tags": "New Relic Mobile <em>iOS</em>",
        "body": " that accept additional arguments and give you more control over the metrics you record, see NewRelic.h. For more information about using this API, see the <em>iOS</em> SDK API usage guide. Parameters Parameter Description $name string Required. The name for the custom metric. $category string Required"
      },
      "id": "603e7830e7b9d22c4d2a07bd"
    },
    {
      "sections": [
        "recordError (iOS SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Return values",
        "Examples",
        "Objective-C",
        "Swift"
      ],
      "title": "recordError (iOS SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "iOS SDK API"
      ],
      "external_id": "c25ecc5732fba911258d0594660bbec1b49428dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/ios-sdk-api/recorderror-ios-sdk-api/",
      "published_at": "2021-05-05T05:37:45Z",
      "updated_at": "2021-03-16T09:56:52Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax recordError:(NSError* _Nonnull)error attributes:(NSDictionary* _Nullable)attributes; NewRelic.recordError(error: $Error, map $eventAttributes); Copy Records Swift errors and NSErrors as MobileHandledException events. Optionally takes map with additional attributes showing context. Requirements Agent version 6.0.0 or higher. Description You can use the recordError API call for crash analysis. Review the captured events to help you understand how often your app is throwing errors and under what conditions. In addition to any custom attributes that you added, the events will also have associated session attributes. This API takes an instance of an NSError and an optional NSDictionary attribute dictionary, then creates a recordHandledException event. You can view event data both in Insights and in the New Relic Mobile UI, including the Handled exceptions page and the Crash events trail. For context on how to use this API, see the documentation about sending custom attributes and events to Insights for: Objective-C Swift Parameters Parameter Description $error NSError, Error Required. The error object that was thrown. $attributes​ NSDictionary, [ AnyHashable, Any]? Optional. Dictionary of attributes that give context. Return values Returns true if the error was recorded successfully, or false if not. Examples Objective-C Method: + (void) recordError:(NSError* _Nonnull)error attributes:(NSDictionary* _Nullable)attributes; + (void) recordError:(NSError* _Nonnull)error; Copy Examples: Simple Objective-C example: [NSJSONSerialization JSONObjectWithData:data options:opt error:error]; if (error) { [NewRelic recordError:error]; } Copy Objective-C example with dictionary: [NSJSONSerialization JSONObjectWithData:data options:opt error:error]; if (error) { [NewRelic recordError:error withAttributes:@{@\"int\": @1, @\"Test Group\" : @\"A | B\"}]; } Copy Swift Method: func recordError(error: Error) func recordError(error: Error, attributes: [ AnyHashable : Any]?) Copy Examples: Simple Swift example: do { try method() } catch { NewRelic.recordError(error) } Copy Swift example with dictionary: do { try method() } catch { NewRelic.recordError(error, attributes: [ \"int\" : 1, \"Test Group\" : \"A | B\" ]) } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.0557,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "recordError (<em>iOS</em> SDK API)",
        "sections": "recordError (<em>iOS</em> SDK API)",
        "tags": "New Relic Mobile <em>iOS</em>"
      },
      "id": "603e8637e7b9d213f62a07ce"
    }
  ],
  "/docs/licenses/index": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.648865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.49564,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.48802,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/license-information/distributed-licenses/add-end-user-license-agreement": [
    {
      "sections": [
        "Services licenses",
        "Contents",
        "Java internal services",
        "Java crash data API",
        "CoffeeScript",
        "JavaScript",
        "Crash reporting",
        "Label services",
        "Infrastructure Monitoring services",
        ".NET support uploader service",
        "Ruby gems",
        "Storage services",
        "Go packages"
      ],
      "title": "Services licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "49a2ad450d31dacfc2aae690ca947d2326d18761",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/other-licenses/services-licenses/",
      "published_at": "2021-05-05T16:28:24Z",
      "updated_at": "2021-04-06T00:26:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Contents Java internal services Java crash data API Framework License Apache TomCat Apache 2.0 Bean Validation Apache 2.0 Cassandra Driver Core Apache 2.0 ClassMate Apache 2.0 Hamcrest BSD Mockito MIT Netty Apache 2.0 Objenesis MIT SnakeYAML Apache 2.0 Spring Boot Apache 2.0 Java internal services Library License json_simple Apache 2.0 newrelic-api New Relic newrelic-api New Relic antlr BSD aopalliance Public Domain asm-analysis BSD asm-commons BSD asm-tree BSD asm-util BSD asm BSD c3p0 EPLv1.0 cglib-nodep Apache 2.0 cglib Apache 2.0 cglib Apache 2.0 cal10n-api MIT logback-classic EPLv1.0 logback-core EPLv1.0 guava-jetty-service Apache 2.0 zkclient Apache 2.0 reporter-config-base Apache 2.0 reporter-config3 Apache 2.0 reporter-config Apache 2.0 aws-java-sdk-acm Apache 2.0 aws-java-sdk-api-gateway Apache 2.0 aws-java-sdk-applicationautoscaling Apache 2.0 aws-java-sdk-autoscaling Apache 2.0 aws-java-sdk-cloudformation Apache 2.0 aws-java-sdk-cloudfront Apache 2.0 aws-java-sdk-cloudhsm Apache 2.0 aws-java-sdk-cloudsearch Apache 2.0 aws-java-sdk-cloudtrail Apache 2.0 aws-java-sdk-cloudwatch Apache 2.0 aws-java-sdk-cloudwatchmetrics Apache 2.0 aws-java-sdk-codecommit Apache 2.0 aws-java-sdk-codedeploy Apache 2.0 aws-java-sdk-codepipeline Apache 2.0 aws-java-sdk-cognitoidentity Apache 2.0 aws-java-sdk-cognitoidp Apache 2.0 aws-java-sdk-cognitosync Apache 2.0 aws-java-sdk-config Apache 2.0 aws-java-sdk-core Apache 2.0 aws-java-sdk-datapipeline Apache 2.0 aws-java-sdk-devicefarm Apache 2.0 aws-java-sdk-directconnect Apache 2.0 aws-java-sdk-directory Apache 2.0 aws-java-sdk-discovery Apache 2.0 aws-java-sdk-dms Apache 2.0 aws-java-sdk-dynamodb Apache 2.0 aws-java-sdk-ec2 Apache 2.0 aws-java-sdk-ecr Apache 2.0 aws-java-sdk-ecs Apache 2.0 aws-java-sdk-efs Apache 2.0 aws-java-sdk-elasticache Apache 2.0 aws-java-sdk-elasticbeanstalk Apache 2.0 aws-java-sdk-elasticloadbalancing Apache 2.0 aws-java-sdk-elasticloadbalancingv2 Apache 2.0 aws-java-sdk-elasticsearch Apache 2.0 aws-java-sdk-elastictranscoder Apache 2.0 aws-java-sdk-emr Apache 2.0 aws-java-sdk-events Apache 2.0 aws-java-sdk-gamelift Apache 2.0 aws-java-sdk-glacier Apache 2.0 aws-java-sdk-iam Apache 2.0 aws-java-sdk-importexport Apache 2.0 aws-java-sdk-inspector Apache 2.0 aws-java-sdk-iot Apache 2.0 aws-java-sdk-kinesis Apache 2.0 aws-java-sdk-kms Apache 2.0 aws-java-sdk-lambda Apache 2.0 aws-java-sdk-logs Apache 2.0 aws-java-sdk-machinelearning Apache 2.0 aws-java-sdk-marketplacecommerceanalytics Apache 2.0 aws-java-sdk-marketplacemeteringservice Apache 2.0 aws-java-sdk-models Apache 2.0 aws-java-sdk-opsworks Apache 2.0 aws-java-sdk-rds Apache 2.0 aws-java-sdk-redshift Apache 2.0 aws-java-sdk-route53 Apache 2.0 aws-java-sdk-s3 Apache 2.0 aws-java-sdk-servicecatalog Apache 2.0 aws-java-sdk-ses Apache 2.0 aws-java-sdk-simpledb Apache 2.0 aws-java-sdk-simpleworkflow Apache 2.0 aws-java-sdk-snowball Apache 2.0 aws-java-sdk-sns Apache 2.0 aws-java-sdk-sqs Apache 2.0 aws-java-sdk-ssm Apache 2.0 aws-java-sdk-storagegateway Apache 2.0 aws-java-sdk-sts Apache 2.0 aws-java-sdk-support Apache 2.0 aws-java-sdk-swf-libraries Apache 2.0 aws-java-sdk-waf Apache 2.0 aws-java-sdk-workspaces Apache 2.0 aws-java-sdk Apache 2.0 jmespath-java Apache 2.0 AppleJavaExtensions BSD jcommander Apache 2.0 high-scale-lib MIT hppc Apache 2.0 clover Paid stream Apache 2.0 metrics-core Apache 2.0 cassandra-driver-core Apache 2.0 cassandra-driver-core Apache 2.0 uuid MIT grabbag MIT speed4j Apache 2.0 yamlbeans BSD jackson-annotations Apache 2.0 jackson-core Apache 2.0 jackson-databind Apache 2.0 jackson-dataformat-cbor Apache 2.0 jackson-dataformat-csv Apache 2.0 jackson-dataformat-xml Apache 2.0 jackson-dataformat-yaml Apache 2.0 jackson-datatype-guava Apache 2.0 jackson-datatype-jdk7 Apache 2.0 jackson-datatype-jdk8 Apache 2.0 jackson-datatype-joda Apache 2.0 jackson-datatype-jsr310 Apache 2.0 jackson-jaxrs-base Apache 2.0 jackson-jaxrs-json-provider Apache 2.0 jackson-module-afterburner Apache 2.0 jackson-module-jaxb-annotations Apache 2.0 jackson-module-kotlin Apache 2.0 woodstox-core Apache 2.0 classmate Apache 2.0 zjsonpatch Apache 2.0 caffeine Apache 2.0 waffle-jna EPLv1.0 docker-java Apache 2.0 docker-java Apache 2.0 btf Apache 2.0 jackson-coreutils Apache 2.0 json-schema-core Apache 2.0 json-schema-validator Apache 2.0 msg-simple Apache 2.0 uri-template Apache 2.0 jamm Apache 2.0 jffi Apache 2.0 jnr-constants Apache 2.0 jnr-ffi Apache 2.0 jnr-ffi Apache 2.0 jnr-posix EPLv1.0 jnr-x86asm MIT embedded-redis Apache 2.0 memoryfilesystem MIT guava-retrying Apache 2.0 guava-retrying Apache 2.0 snowball-stemmer BSD system-rules CPL uuid Apache 2.0 wiremock Apache 2.0 auto-common Apache 2.0 annotations LGPLv2.1 annotations LGPLv2.1 bcel-findbugs LGPLv2.1 findbugs LGPLv2.1 jFormatString BSD jFormatString BSD jsr305 BSD jsr305 BSD jsr305 BSD gson Apache 2.0 spymemcached MIT guava-testlib Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guice-multibindings Apache 2.0 guice Apache 2.0 truth Apache 2.0 concurrent-trees Apache 2.0 concurrentlinkedhashmap-lru Apache 2.0 json-simple Apache 2.0 libphonenumber Apache 2.0 locality-uuid BSD h2 EPLv1.0 annotations Apache 2.0 json-path-assert Apache 2.0 json-path Apache 2.0 json-path Apache 2.0 jzlib BSD bonecp-provider Apache 2.0 bonecp Apache 2.0 junixsocket-common Apache 2.0 junixsocket-native-common Apache 2.0 disruptor Apache 2.0 geoip-api LGPLv2.1 c3p0 LGPLv2.1 mchange-commons-java LGPLv2.1 archaius-core Apache 2.0 hystrix-core Apache 2.0 hystrix-servo-metrics-publisher Apache 2.0 rxjava-core Apache 2.0 servo-core Apache 2.0 kafka-clients Apache 2.0 kafka_2.10 Apache 2.0 kafka_2.11 Apache 2.0 common-cassandra Apache 2.0 timeslice_utils New Relic mockito-kotlin MIT compress-lzf Apache 2.0 checkstyle Apache 2.0 dagger-compiler Apache 2.0 dagger Apache 2.0 okhttp Apache 2.0 okio Apache 2.0 javapoet Apache 2.0 javawriter Apache 2.0 jaxb-impl CDDLv1 thrift-server Apache 2.0 finagle-core_2.10 Apache 2.0 finagle-core_2.11 Apache 2.0 finagle-http_2.10 Apache 2.0 finagle-http_2.11 Apache 2.0 jsr166e Creative Commons util-app_2.10 Apache 2.0 util-app_2.11 Apache 2.0 util-cache_2.10 Apache 2.0 util-cache_2.11 Apache 2.0 util-codec_2.10 Apache 2.0 util-codec_2.11 Apache 2.0 util-collection_2.10 Apache 2.0 util-collection_2.11 Apache 2.0 util-core_2.10 Apache 2.0 util-core_2.11 Apache 2.0 util-function_2.10 Apache 2.0 util-function_2.11 Apache 2.0 util-hashing_2.10 Apache 2.0 util-hashing_2.11 Apache 2.0 util-jvm_2.10 Apache 2.0 util-jvm_2.11 Apache 2.0 util-lint_2.10 Apache 2.0 util-lint_2.11 Apache 2.0 util-logging_2.10 Apache 2.0 util-logging_2.11 Apache 2.0 util-registry_2.10 Apache 2.0 util-registry_2.11 Apache 2.0 util-stats_2.10 Apache 2.0 util-stats_2.11 Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 HikariCP Apache 2.0 commons-beanutils Apache 2.0 commons-cli Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-io Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 commons-pool Apache 2.0 unix-socket-factory Apache 2.0 unix-socket-factory Apache 2.0 jflex BSD dom4j BSD airline Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 metrics-healthchecks Apache 2.0 metrics-httpclient Apache 2.0 metrics-jdbi Apache 2.0 metrics-jersey2 Apache 2.0 metrics-jetty9 Apache 2.0 metrics-json Apache 2.0 metrics-jvm Apache 2.0 metrics-logback Apache 2.0 metrics-servlets Apache 2.0 dropwizard-java8-jdbi Apache 2.0 dropwizard-client Apache 2.0 dropwizard-configuration Apache 2.0 dropwizard-core Apache 2.0 dropwizard-db Apache 2.0 dropwizard-jackson Apache 2.0 dropwizard-jdbi Apache 2.0 dropwizard-jersey Apache 2.0 dropwizard-jetty Apache 2.0 dropwizard-lifecycle Apache 2.0 dropwizard-logging Apache 2.0 dropwizard-metrics Apache 2.0 dropwizard-servlets Apache 2.0 dropwizard-testing Apache 2.0 dropwizard-util Apache 2.0 dropwizard-validation Apache 2.0 netty-all Apache 2.0 netty-buffer Apache 2.0 netty-codec-http Apache 2.0 netty-codec-socks Apache 2.0 netty-codec Apache 2.0 netty-common Apache 2.0 netty-handler-proxy Apache 2.0 netty-handler Apache 2.0 netty-resolver Apache 2.0 netty-transport-native-epoll Apache 2.0 netty-transport Apache 2.0 netty Apache 2.0 ratpack-core Apache 2.0 ratpack-groovy-test Apache 2.0 ratpack-groovy Apache 2.0 ratpack-guice Apache 2.0 ratpack-test Apache 2.0 rxjava Apache 2.0 fastutil Apache 2.0 janino BSD activation Apache 2.0 javax.annotation-api CDDLv1 jsr250-api CDDLv1 javax.inject Apache 2.0 mail CDDLv1 mailapi CDDLv1 javax.servlet-api Apache 2.0 servlet-api Apache 2.0 javax.transaction-api CDDLv1 validation-api Apache 2.0 javax.websocket-api CDDLv1 javax.ws.rs-api CDDLv1 jaxb-api CDDLv1 stax-api CDDLv1 jaxen Apache 2.0 jline BSD jline BSD joda-time Apache 2.0 junit-dep CPL junit CPL junit EPLv1.0 kafka_2.10 Apache 2.0 kafka_2.9.2 Apache 2.0 apache-log4j-extras Apache 2.0 log4j Apache 2.0 mysql-connector-java GPLv2 with Classpath Exception byte-buddy Apache 2.0 byte-buddy Apache 2.0 jna-platform LGPLv2.1 jna Apache 2.0 jcip-annotations Apache 2.0 lz4 Apache 2.0 accessors-smart Apache 2.0 asm Apache 2.0 json-smart Apache 2.0 json-smart Apache 2.0 primitive GPLv2 with Classpath Exception compiler Apache 2.0 lang Apache 2.0 beaver-cc BSD ehcache-core Apache 2.0 ehcache Apache 2.0 jopt-simple MIT jopt-simple MIT opencsv Apache 2.0 quality-check Apache 2.0 scannotation Apache 2.0 super-csv Apache 2.0 uadetector-core Apache 2.0 uadetector-resources Apache 2.0 argparse4j MIT spymemcached MIT kalium Apache 2.0 ST4 BSD antlr-runtime BSD antlr-runtime BSD antlr BSD stringtemplate BSD ant-launcher Apache 2.0 ant Apache 2.0 cassandra-all Apache 2.0 cassandra-all Apache 2.0 cassandra-thrift Apache 2.0 cassandra-thrift Apache 2.0 commons-collections4 Apache 2.0 commons-compress Apache 2.0 commons-csv Apache 2.0 commons-dbcp2 Apache 2.0 commons-io Apache 2.0 commons-lang3 Apache 2.0 commons-math3 Apache 2.0 commons-math Apache 2.0 commons-pool2 Apache 2.0 curator-client Apache 2.0 curator-framework Apache 2.0 curator-recipes Apache 2.0 curator-test Apache 2.0 derby Apache 2.0 geronimo-servlet_3.0_spec Apache 2.0 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 ivy Apache 2.0 kafka-clients Apache 2.0 kafka_2.11 Apache 2.0 libthrift Apache 2.0 tomcat-embed-core Apache 2.0 tomcat-embed-el Apache 2.0 tomcat-embed-logging-juli Apache 2.0 tomcat-embed-websocket Apache 2.0 tomcat-jdbc Apache 2.0 tomcat-juli Apache 2.0 zookeeper Apache 2.0 aspectjweaver EPLv1.0 assertj-core Apache 2.0 assertj-core Apache 2.0 evo-inflector Apache 2.0 bcmail-jdk15on MIT bcpkix-jdk15on MIT bcprov-jdk15on MIT ohc-core Apache 2.0 cassandra-unit-spring LGPLv3 cassandra-unit-spring LGPLv3 cassandra-unit LGPLv3 cassandra-unit LGPLv3 groovy-all Apache 2.0 groovy-all Apache 2.0 groovy Apache 2.0 groovy Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 easymock Apache 2.0 ecj EPLv1.0 javax.activation CDDLv1 javax.annotation CDDLv1 javax.mail.glassfish CDDLv1 javax.servlet CDDLv1 javax.transaction CDDLv1 org.objectweb.asm BSD jetty-setuid-java EPLv1.0 jetty-schemas Apache 2.0 javax-websocket-client-impl Apache 2.0 javax-websocket-server-impl Apache 2.0 websocket-api Apache 2.0 websocket-client Apache 2.0 websocket-common Apache 2.0 websocket-server Apache 2.0 websocket-servlet Apache 2.0 apache-jsp Apache 2.0 jetty-annotations CDDLv1 jetty-client Apache 2.0 jetty-continuation Apache 2.0 jetty-http Apache 2.0 jetty-io Apache 2.0 jetty-jmx Apache 2.0 jetty-jndi Apache 2.0 jetty-plus Apache 2.0 jetty-proxy Apache 2.0 jetty-security Apache 2.0 jetty-server Apache 2.0 jetty-servlet Apache 2.0 jetty-servlets Apache 2.0 jetty-util Apache 2.0 jetty-webapp Apache 2.0 jetty-xml Apache 2.0 sigar Apache 2.0 aopalliance-repackaged CDDLv1 javax.inject CDDLv1 hk2-api CDDLv1 hk2-locator CDDLv1 hk2-utils CDDLv1 osgi-resource-locator CDDLv1 jersey-guava CDDLv1 jersey-client CDDLv1 jersey-apache-connector CDDLv1 jersey-container-servlet-core CDDLv1 jersey-container-servlet CDDLv1 jersey-client CDDLv1 jersey-common CDDLv1 jersey-server CDDLv1 jersey-bean-validation CDDLv1 jersey-metainf-services CDDLv1 jersey-media-jaxb CDDLv1 jersey-client CDDLv1 jersey-test-framework-provider-inmemory CDDLv1 jersey-test-framework-core CDDLv1 javax.el CDDLv1 hamcrest-all BSD hamcrest-core BSD hamcrest-integration BSD hamcrest-library BSD HdrHistogram Public Domain hector-core MIT hibernate-commons-annotations LGPLv2.1 hibernate-jpa-2.0-api LGPLv2.1 hibernate-jpa-2.1-api LGPLv2.1 hibernate-c3p0 Apache 2.0 hibernate-core Apache 2.0 hibernate-ehcache Apache 2.0 hibernate-entitymanager Apache 2.0 hibernate-jmx Apache 2.0 hibernate-validator Apache 2.0 freebuilder Apache 2.0 org.jacoco.agent EPLv1.0 org.jacoco.ant EPLv1.0 org.jacoco.core EPLv1.0 org.jacoco.report EPLv1.0 javassist Apache 2.0 jboss-logging-annotations LGPLv2.1 jboss-logging Apache 2.0 jboss-transaction-api_1.1_spec LGPLv2.1 jboss-transaction-api_1.2_spec LGPLv2.1 jandex Apache 2.0 jdbi Apache 2.0 job-dsl-core Apache 2.0 version-number MIT kotlin-annotation-processing Apache 2.0 kotlin-reflect Apache 2.0 kotlin-runtime Apache 2.0 kotlin-stdlib Apache 2.0 kotlin-test-junit Apache 2.0 kotlin-test Apache 2.0 annotations Apache 2.0 jolokia-core Apache 2.0 jruby-complete LGPLv2.1 LGPLv2.1 json Public Domain json Apache 2.0 xstream BSD annotations Apache 2.0 mapdb Apache 2.0 mapdb Apache 2.0 jbcrypt ISC mockserver-client-java Apache 2.0 mockserver-core Apache 2.0 mockserver-logging Apache 2.0 mockserver-netty Apache 2.0 mockito-all MIT mockito-core MIT mockito-core MIT apache-el Apache 2.0 apache-jsp Apache 2.0 alpn-boot Apache 2.0 etcd4j Apache 2.0 msgpack Apache 2.0 objenesis Apache 2.0 objenesis Apache 2.0 jmh-core GPLv2 with Classpath Exception jmh-generator-annprocess GPLv2 with Classpath Exception jol-core GPLv2 with Classpath Exception asm-analysis BSD asm-analysis BSD asm-commons BSD asm-debug-all BSD asm-tree BSD asm-util BSD asm-util BSD asm BSD asm Public Domain postgresql BSD powermock-api-mockito Apache 2.0 powermock-api-support Apache 2.0 powermock-core Apache 2.0 powermock-module-junit4-common Apache 2.0 powermock-module-junit4 Apache 2.0 powermock-reflect Apache 2.0 lombok MIT reactive-streams Public Domain reflections WTFPL scala-java8-compat_2.11 Scala scala-parser-combinators_2.11 Scala scala-xml_2.11 Scala scala-library Scala scala-reflect Scala scalatest_2.10 Apache 2.0 scalatest_2.11 Apache 2.0 native-lib-loader BSD jsonassert Apache 2.0 jcl-over-slf4j MIT jul-to-slf4j MIT log4j-log4j12 MIT log4j-over-slf4j MIT slf4j-api MIT slf4j-ext MIT slf4j-log4j12 MIT slf4j-simple MIT spock-core Apache 2.0 spock-core Apache 2.0 spring-boot-actuator Apache 2.0 spring-boot-autoconfigure Apache 2.0 spring-boot-configuration-processor Apache 2.0 spring-boot-starter-actuator Apache 2.0 spring-boot-starter-aop Apache 2.0 spring-boot-starter-data-jpa Apache 2.0 spring-boot-starter-data-rest Apache 2.0 spring-boot-starter-jdbc Apache 2.0 spring-boot-starter-jetty Apache 2.0 spring-boot-starter-logging Apache 2.0 spring-boot-starter-test Apache 2.0 spring-boot-starter-tomcat Apache 2.0 spring-boot-starter-web Apache 2.0 spring-boot-starter Apache 2.0 spring-boot-test-autoconfigure Apache 2.0 spring-boot-test Apache 2.0 spring-boot Apache 2.0 spring-data-commons Apache 2.0 spring-data-jpa Apache 2.0 spring-data-rest-core Apache 2.0 spring-data-rest-webmvc Apache 2.0 spring-hateoas Apache 2.0 spring-plugin-core Apache 2.0 spring-aop Apache 2.0 spring-aspects Apache 2.0 spring-beans Apache 2.0 spring-context-support Apache 2.0 spring-context Apache 2.0 spring-core Apache 2.0 spring-core Apache 2.0 spring-expression Apache 2.0 spring-jdbc Apache 2.0 spring-orm Apache 2.0 spring-test Apache 2.0 spring-test Apache 2.0 spring-tx Apache 2.0 spring-web Apache 2.0 spring-webmvc Apache 2.0 xz Public Domain wasabi Apache 2.0 snappy-java Apache 2.0 xmlunit-core Apache 2.0 xmlunit-legacy Apache 2.0 snakeyaml Apache 2.0 JUnitParams Apache 2.0 postgresql BSD postgresql BSD jedis MIT scala-library Scala ion-java Apache 2.0 timeslice_service-thrift New Relic timeslice_service New Relic xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3_min Public Domain zkclient Apache 2.0 zookeeper Apache 2.0 CoffeeScript Library License CoffeeScript MIT coffin MIT JavaScript JavaScript License ie_html5/ie_html5.js MIT Angular.js MIT Angular UI directives for Bootstrap MIT Chart.js MIT Chosen JQuery plugin MIT Fullcalendar MIT Moment MIT Crash reporting Software License Apple OS X OS X Yosemite Xcode & Apple SDK Xcode license Label services Service License BoneCP Apache 2.0 Gradle Apache 2.0 Hibernate Apache 2.0 Spring Apache 2.0 Infrastructure Monitoring services Service License antlr BSD aopalliance Public Domain asm MIT cglib Apache 2.0 ch.qos.logback EPLv1.0 com.101tec Apache 2.0 com.amazonaws Apache 2.0 com.cenqua.clover Paid com.fasterxml.jackson.core Apache 2.0 com.fasterxml Apache 2.0 com.google.code.findbugs BSD com.google.guava Apache 2.0 com.googlecode.json-simple Apache 2.0 com.intellij Apache 2.0 New Relic com.squareup.dagger Apache 2.0 com.squareup Apache 2.0 com.yammer.metrics Apache 2.0 commons-codec Apache 2.0 commons-configuration Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 dom4j BSD io.netty Apache 2.0 javax.annotation CDDLv1 javax.inject Apache 2.0 javax.servlet.jsp CDDLv1 javax.servlet Apache 2.0 javax.validation Apache 2.0 javax.websocket CDDLv1 jline BSD joda-time Apache 2.0 junit CPL log4j Apache 2.0 mysql GPLv2 with Classpath Exception net.sf.jopt-simple MIT org.apache.commons Apache 2.0 org.apache.httpcomponents Apache 2.0 org.apache.ivy Apache 2.0 org.apache.thrift Apache 2.0 org.apache.tomcat.embed Apache 2.0 org.apache.zookeeper Apache 2.0 org.codehaus.groovy Apache 2.0 org.codehaus.jackson Apache 2.0 org.easymock Apache 2.0 org.eclipse.jetty.orbit CDDLv1 org.eclipse.jetty.toolchain Apache 2.0 org.eclipse.jetty.websocket Apache 2.0 org.eclipse.jetty CDDLv1 org.glassfish.jersey.core CDDLv1 org.glassfish.web CDDLv1 org.glassfish CDDLv1 org.hamcrest BSD org.hibernate Apache 2.0 org.javassist Apache 2.0 org.jboss.logging LGPLv2.1 org.jenkins-ci.plugins Apache 2.0 org.jenkins-ci Apache 2.0 org.jetbrains Apache 2.0 org.jolokia Apache 2.0 org.jvnet.hudson BSD org.mockito MIT org.objenesis Apache 2.0 org.ow2.asm MIT org.reflections WTFPL org.scala-lang Scala org.slf4j MIT org.springframework.boot Apache 2.0 org.springframework Apache 2.0 org.xerial.snappy Apache 2.0 org.yaml Apache 2.0 xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3 Public Domain .NET support uploader service Library License Amazon AWS SDK for Java Apache 2.0 Apache Commons Codec Apache 2.0 Gson Apache 2.0 Jetty Apache 2.0 Ruby gems Ruby gems Gem License aasm MIT actionmailer MIT actionpack MIT activeadmin MIT actionview MIT activejob MIT active_model_serializers MIT activemodel MIT activerecord MIT activerecord-deprecated_finders MIT activerecord-mysql2-adapter MIT activeresource MIT activesupport MIT addressable Apache 2.0 angularjs-rails MIT arbre MIT arel MIT arel MIT atomic Apache 2.0 atomic Apache-2.0 attr_required MIT awesome_print MIT backports MIT better_errors MIT binding_of_caller MIT bourbon MIT brwsr MIT browser-timezone-rails MIT builder MIT bundler MIT byebug MIT callsite MIT capistrano MIT capistrano-bundler MIT capistrano-ext MIT capistrano-rbenv MIT capistrano-stats MIT capybara MIT celluloid MIT CFPropertyList MIT chunky_png MIT ci_reporter MIT ci_reporter_rspec MIT clockwork MIT codeclimate-test-reporter MIT coderay MIT coderay MIT coffee-rails MIT coffee-script MIT coffee-script-source MIT columnize Ruby compass MIT compass-core MIT compass-import-once MIT compass-rails MIT concurrent-ruby MIT crack MIT crypt Unlicensed daemons MIT dalli MIT database_cleaner MIT debug_inspector MIT debugger-linecache MIT diff-lcs MIT docile MIT dotenv MIT dotenv-deployment MIT erubis MIT etcd MIT ethon MIT eventmachine Ruby excon MIT execjs MIT factory_girl MIT factory_girl_rails MIT faraday MIT faraday-middleware MIT faye-websocket MIT ffi MIT ffi BSD fission MIT fog MIT fog-atmos MIT fog-aws MIT fog-brightbox MIT fog-core MIT fog-ecloud MIT fog-google MIT fog-json MIT fog-local MIT fog-powerdns MIT fog-profitbricks MIT fog-radosgw MIT fog-riakcs MIT fog-sakuracloud MIT fog-serverlove MIT fog-softlayer MIT fog-storm_on_demand MIT fog-terremark MIT fog-vmfusion MIT fog-voxel MIT fog-xml MIT font-awesome-rails MIT foreman MIT formatador MIT formtastic MIT formtastic i18n MIT fssm MIT globalid MIT guard MIT guard-rspec MIT haml MIT haml-rails MIT has scope MIT hashie MIT highline Ruby hike MIT hipchat-api MIT histogram MIT hitimes ISC hiredis BSD http_parser.rb MIT httpclient Ruby httpclient Ruby httparty MIT i18n MIT inflecto MIT inherited resources MIT intercom-rails MIT ipaddress MIT jasmine MIT jasmine-core MIT jasmine-rails MIT jbuilder MIT jira MIT jira-ruby OSL-3.0 journey MIT jquery-rails MIT jquery-turbolinks MIT jquery-ui-rails MIT json Ruby jwt MIT kaminari MIT kgio LGPLv3 kgio LGPLv3 kgio LGPL-v2.1+ libv8 MIT listen MIT logger Ruby loofah MIT lumberjack MIT macaddr MIT mail MIT mailcatcher MIT memoist MIT metaclass MIT meta_request MIT method_source MIT mime-types MIT mini_portile MIT minitest MIT minitest-rails MIT mixlib-log Apache 2.0 mocha MIT mono_logger MIT multi_json MIT multi_xml MIT multipart-post MIT mysql2 MIT net-http-persistent MIT net-scp MIT net-sftp MIT net-ssh MIT net-ssh-gateway MIT netrc MIT nokogiri MIT oauth2 MIT oj MIT omniauth MIT omniauth-oauth2 MIT pagerduty MIT papers MIT pg BSD pg Ruby phantomjs BSD phantomjs-binaries Unlicensed poltergeist MIT polyamorous MIT polyglot MIT polyglot MIT protected_attributes MIT pry MIT pry-nav MIT pry-rails MIT pry-stack_explorer MIT puma BSD quiet assets MIT rack MIT rack-cache MIT rack-contrib MIT rack-oauth2 MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-ssl MIT rack-ssl-enforcer MIT rack-test MIT rails MIT rails-deprecated_sanitizer MIT rails-dom-testing MIT rails-html-sanitizer MIT rails-observers MIT rails_12factor MIT rails_serve_static_assets MIT rails_stdout_logging MIT railties MIT raindrops LGPLv3 raindrops LGPLv3 raindrops LGPLv2.1+ rake MIT rake MIT rake MIT rake MIT ransack MIT rb-fsevent MIT rb-inotify MIT rdoc Ruby redcarpet MIT redis MIT redis-namespace MIT redis-queue MIT ref MIT remote_syslog_logger MIT request_store MIT responders MIT resque MIT resque-cleaner MIT resque-pool MIT resque-scheduler MIT resque-status MIT rest-client MIT restforce MIT rspec MIT rspec-core MIT rspec-expectations MIT rspec-mocks MIT rspec-rails MIT rspec-support MIT rspec_junit_formatter MIT rubyntlm MIT ruby-saml MIT rufus-scheduler MIT safe_yaml MIT salesforce_bulk_query BSD sass MIT sass-rails MIT sass-rails MIT sdoc MIT secure_headers Apache 2.0 sequel MIT serveza MIT settingslogic MIT shoulda MIT shoulda-context MIT shoulda-matchers MIT simplecov MIT simplecov-html MIT simplecov-rcov MIT sinatra MIT sinatra-activerecord MIT sinatra-contrib MIT skinny MIT slop MIT spring MIT sprockets MIT sprockets-rails MIT sqlite3 BSD sshkit GPL-No Distro sys-uname Ruby syslog_protocol MIT systemu BSDL term-ansicolor GPL-No Distro terminal-table MIT therubyracer MIT thin Ruby thor MIT thread_safe Apache-2.0 thrift Apache 2.0 thrift-rack MIT tilt MIT timecop MIT timers MIT tins MIT treetop MIT turbolinks MIT twitter-bootstrap-rails MIT typhoeus MIT tzinfo MIT uglifier MIT unicorn Ruby unicorn-rails MIT uuid MIT uuidtools Apache-2.0 vegas MIT webmock MIT web-console MIT xml-simple Ruby xpath MIT yard MIT Storage services Library License Amazon AWS SDK for Java Apache 2.0 Amazon AWS Command Line Interface Apache 2.0 Go packages Library License Go-Mysql-Driver Mozilla Public License 2.0 gocql BSD 3-Clause groupcache Apache 2.0 Migrate MIT go-sqlite3 MIT Revel MIT Pathtree MIT Ansicolor MIT fsnotify BSD 3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.99942,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Services <em>licenses</em>",
        "sections": "Services <em>licenses</em>",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Contents Java internal"
      },
      "id": "603ea24364441f91fb4e8864"
    },
    {
      "sections": [
        "FIT instrumentation end user license agreement"
      ],
      "title": "FIT instrumentation end user license agreement",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "e8e10baf120678407d08c9f78ab708d271cf0223",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/fit-instrumentation-end-user-license-agreement/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NEW RELIC, INC. FIT INSTRUMENTATION END USER LICENSE AGREEMENT In connection with the work provided by New Relic’s Field Instrumentation Team, you may be provided with certain custom-created software to enable, optimize, or enhance your use of New Relic’s Services. By downloading, installing, authorizing installation, or using the FIT Instrumentation with your Underlying Software (defined below), you (“Customer”) agree to the terms and conditions herein (“Agreement”) with New Relic, Inc., a Delaware corporation with offices located at 188 Spear Street, Suite 1200 San Francisco, CA 94105 (“New Relic”), (collectively the “Parties”). Capitalized terms not defined herein shall have the meanings set forth in the New Relic Terms of Service (the “Terms of Service”) available here: http://newrelic.com/terms IF YOU DO NOT AGREE TO THIS AGREEMENT, PLEASE DO NOT USE THE FIT INSTRUMENTATION. 1. DEFINITIONS “FIT Instrumentation” means the New Relic custom-made software, including but not limited to connectors, extensions, and plugins, provided by New Relic to Customer to enable the Services to operate with certain third party or Customer software or systems (“Underlying Software”). For the purposes of the Terms of Service, the FIT Instrumentation shall be treated like an “Agent”, subject to the separate terms herein. 2. USE OF THE FIT INSTRUMENTATION 2.1 Software Evaluation License. Subject to the terms herein, New Relic grants to Customer a limited, non-exclusive, non-transferrable, non-sublicensable right to install, use, and configure the FIT Instrumentation solely as needed to enable the Services for internal evaluation purposes. New Relic reserves all rights and licenses not expressly granted herein. 2.2 Ownership. As between the Parties, New Relic owns all right, title, and interest to the FIT Instrumentation and Feedback, including but not limited to any intellectual property and proprietary rights therein. Customer retains all right, title, and interest in any Customer Data processed by the FIT Instrumentation in connection with the Services. 2.3 Feedback. Customer agrees to provide feedback, suggestions, ideas, requests or recommendations (“Feedback”) regarding the FIT Instrumentation, and hereby irrevocably assigns all intellectual property and proprietary rights it holds in the Feedback to New Relic. 2.4 Notice. Customer acknowledges and agrees that the FIT Instrumentation is made to work with the Underlying Software as configured at the time of creation and there is no guarantee that FIT Instrumentation will continue to work in the event Customer changes, replaces, upgrades versions of, updates, or otherwise changes the Underlying Software (an “Upgrade Event”). Customer shall hold New Relic harmless from any claims or damages arising from Customer’s Upgrade Event. 2.5 Restrictions. Customer will not: (i) use the FIT Instrumentation except as permitted hereunder; (ii) distribute, sell, sublicense, or otherwise transfer the FIT Instrumentation; (iii) decompile, disassemble or reverse engineer any software underlying the FIT Instrumentation; (iv) use the FIT Instrumentation to damage, disable, overburden or impair any New Relic server or network(s) connected to any New Relic server or interfere with any other party’s use and enjoyment of the Services; (v) use the FIT Instrumentation to defraud, defame, abuse, harass, stalk, threaten or infringe the rights of privacy or other intellectual property rights of others or otherwise violate any applicable law; (vi) circumvent or modify any security technologies included as part of the FIT Instrumentation; or (vii) attempt or permit any third party to do any of the foregoing. New Relic may suspend usage of the Services by any user, without notice, pending any investigation of misuse.  These restrictions may be supplemented or superceded (to the extent they conflict) by the New Relic Acceptable Use Policy as may be published and updated from time to time at https://docs.newrelic.com/docs/licenses/license-information/acceptable-use-policy/acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. “Confidential Information” means: (a) the FIT Instrumentation, and any features, results or output produced by, and other information relating to the FIT Instrumentation (including, without limitation, all Feedback); and (b) any business or technical information of New Relic including but not limited to any technical information, research, development, know-how that a reasonable person would understand to be confidential. 3.2 Restrictions. Customer will not use or disclose any Confidential Information, except as necessary for the performance of this Agreement. Customer will use all reasonable efforts to protect Confidential Information from unauthorized use or disclosure, but in no event less than the efforts that it ordinarily uses with respect to its own proprietary information. Customer may disclose Confidential Information to those of its employees who have a bona fide need to know such Confidential Information for the performance of this Agreement; provided that each such employee first executes a written agreement that contains use and nondisclosure restrictions at least as protective as those set forth herein. Confidential Information shall not include any information that: (a) is or becomes generally known to the public through no fault or breach of this Agreement by Customer; (b) is rightfully known by Customer at the time of disclosure without an obligation of confidentiality; (c) is independently developed by Customer without access or use of any Confidential Information; or (d) is rightfully obtained from a third party without restriction on use or disclosure. 4. DISCLAIMER 4.1 DISCLAIMER. FIT INSTRUMENTATION IS PROVIDED AS-IS AND AS-AVAILABLE AND NEW RELIC DISCLAIMS AND MAKES NO WARRANTIES, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE OR NON-INFRINGEMENT AND WHETHER OR NOT ARISING THROUGH A COURSE OF DEALING. FIT INSTRUMENTATION IS NOT GUARANTEED TO BE ERROR-FREE, COMPATIBLE WITH THE UNDERLYING SOFTWARE. , OR THAT CUSTOMER WILL ACHIEVE ANY RESULTS FROM USE OF THE FIT INSTRUMENTATION THEREFROM. SOME JURISDICTIONS DO NOT ALLOW THE EXCLUSION OF IMPLIED WARRANTIES OR LIMITATIONS ON APPLICABLE STATUTORY RIGHTS OF A CONSUMER, SO THE ABOVE EXCLUSION AND LIMITATIONS MAY NOT APPLY TO THE CUSTOMER. 4.2 LIMITATION OF LIABILITY. TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE TO CUSTOMER OR ANY THIRD PARTY FOR DAMAGES OF ANY KIND, INCLUDING, WITHOUT LIMITATION, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE INSTALLATION, USE OR INABILITY TO USE THE FIT INSTRUMENTATION OR FOR ANY ERROR OR DEFECT IN THE FIT INSTRUMENTATION OR THE SERVICES, WHETHER SUCH LIABILITY ARISES FROM ANY CLAIM BASED UPON CONTRACT, WARRANTY, TORT, STRICT LIABILITY, OR OTHERWISE, WHETHER OR NOT NEW RELIC HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSS OR DAMAGE. NEW RELIC'S AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS AGREEMENT WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE PARTIES HAVE AGREED THAT THESE LIMITATIONS WILL SURVIVE AND APPLY EVEN IF ANY LIMITED REMEDY SPECIFIED IN THIS AGREEMENT IS FOUND TO HAVE FAILED OF ITS ESSENTIAL PURPOSE. 4.3 EVALUATION VERSION. Customer agrees and acknowledges that: (a) the FIT Instrumentation is not an official product and has not been commercially released for sale by New Relic; (b) the FIT Instrumentation may not operate properly, being in final form, or fully functional; (c) the FIT Instrumentation may contain errors, security vulnerabilities, design flaws, or other problems; (d) it may not be possible to make the FIT Instrumentation fully functional; (e) the information obtained using the FIT Instrumentation may not be accurate; (f) use of the FIT Instrumentation may result in unexpected results, loss of data, delays or other unpredictable damages or loss; (g) New Relic is under no obligation to release a commercial version of the FIT Instrumentation; and (h) New Relic has the right unilaterally to abandon development of the FIT Instrumentation, at any time and without any obligation or liability to Customer. 5. GENERAL PROVISIONS 5.1 Terms of Service; Documentation. This Agreement shall be considered a part of the New Relic documentation, located at: https://docs.newrelic.com (the \"Documentation\").This Agreement and the Terms of Service constitute the entire and exclusive agreement between New Relic and Customer with respect to the FIT Instrumentation. In the absence of a separate agreement between New Relic and Customer with respect to the FIT Instrumentation, the terms and conditions of this Agreement shall govern the relationship between New Relic and Customer with respect to such FIT Instrumentation.  To the extent of a conflict between the Agreement and the Terms of Service, this Agreement shall govern with respect to the FIT Instrumentation only.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.32553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "FIT instrumentation end user <em>license</em> agreement",
        "sections": "FIT instrumentation end user <em>license</em> agreement",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": " Acceptable Use Policy as may be published and updated from time to time at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;acceptable-use-policy&#x2F;acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. “Confidential <em>Information</em>” means: (a) the FIT Instrumentation, and any features, results"
      },
      "id": "603e9f3ee7b9d206e32a0800"
    },
    {
      "sections": [
        "New Relic Agent Software Notice"
      ],
      "title": "New Relic Agent Software Notice",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "2bf9501c2767105130d3808f1bf3a91a032d903e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/new-relic-agent-software-notice/",
      "published_at": "2021-05-05T16:22:53Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This software is © 2008-2021 New Relic, Inc. and its licensors. This software is solely for use with New Relic’s proprietary SaaS service (“New Relic Service”), so to use the software you must have a valid account for the New Relic Service under a separate agreement with New Relic (“Subscription Agreement”). You may only use the software to support your use of the New Relic Service as permitted in the Subscription Agreement. Without a Subscription Agreement, you may not use the software. All other use is prohibited. New Relic and its suppliers retain all right, title and interest (including intellectual property rights) in the software. The Subscription Agreement will control in event of a conflict with this notice. Unless otherwise agreed by New Relic in your Subscription Agreement: You may not use, copy, distribute or sublicense the software, use the software on behalf of third parties, reverse engineer or decompile the software, modify or create derivative works of the software, use the software for competitive analysis or benchmarking, or remove or obscure any proprietary notices in the software. The software is provided “AS IS” and New Relic disclaims all warranties, whether express, implied, statutory or otherwise, including warranties of merchantability, fitness for a particular purpose, title or noninfringement. To the full extent permitted by law, New Relic will have no liability arising from or related to the software or under this notice for any direct, indirect, special, incidental, or consequential damages of any kind, even if advised of their possibility in advance, and regardless of legal theory (whether contract, tort, negligence, strict liability or otherwise). The software may contain third-party open source software (“OSS”) as described here and at https://github.com/newrelic. To the extent required by the OSS license, that license will apply to the OSS when used on a stand-alone basis. For avoidance of doubt, you may copy and distribute New Relic agents pursuant to your Subscription Agreement for New Relic Browser and New Relic Mobile and as set forth: https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/get-started and https://docs.newrelic.com/docs/browser/new-relic-browser/installation/install-new-relic-browser-agent Software versions New Relic makes available under an OSS license (such as Apache 2.0) are governed by the terms of the applicable OSS license. For a current list of New Relic software versions released as OSS please visit https://opensource.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.32553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": " and at https:&#x2F;&#x2F;github.com&#x2F;newrelic. To the extent required by the OSS <em>license</em>, that <em>license</em> will apply to the OSS when used on a stand-alone basis. For avoidance of doubt, you may copy and distribute New Relic agents pursuant to your Subscription Agreement for New Relic Browser and New Relic Mobile"
      },
      "id": "603eb73828ccbc1f99eba74a"
    }
  ],
  "/docs/licenses/license-information/distributed-licenses/fit-instrumentation-end-user-license-agreement": [
    {
      "sections": [
        "Services licenses",
        "Contents",
        "Java internal services",
        "Java crash data API",
        "CoffeeScript",
        "JavaScript",
        "Crash reporting",
        "Label services",
        "Infrastructure Monitoring services",
        ".NET support uploader service",
        "Ruby gems",
        "Storage services",
        "Go packages"
      ],
      "title": "Services licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "49a2ad450d31dacfc2aae690ca947d2326d18761",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/other-licenses/services-licenses/",
      "published_at": "2021-05-05T16:28:24Z",
      "updated_at": "2021-04-06T00:26:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Contents Java internal services Java crash data API Framework License Apache TomCat Apache 2.0 Bean Validation Apache 2.0 Cassandra Driver Core Apache 2.0 ClassMate Apache 2.0 Hamcrest BSD Mockito MIT Netty Apache 2.0 Objenesis MIT SnakeYAML Apache 2.0 Spring Boot Apache 2.0 Java internal services Library License json_simple Apache 2.0 newrelic-api New Relic newrelic-api New Relic antlr BSD aopalliance Public Domain asm-analysis BSD asm-commons BSD asm-tree BSD asm-util BSD asm BSD c3p0 EPLv1.0 cglib-nodep Apache 2.0 cglib Apache 2.0 cglib Apache 2.0 cal10n-api MIT logback-classic EPLv1.0 logback-core EPLv1.0 guava-jetty-service Apache 2.0 zkclient Apache 2.0 reporter-config-base Apache 2.0 reporter-config3 Apache 2.0 reporter-config Apache 2.0 aws-java-sdk-acm Apache 2.0 aws-java-sdk-api-gateway Apache 2.0 aws-java-sdk-applicationautoscaling Apache 2.0 aws-java-sdk-autoscaling Apache 2.0 aws-java-sdk-cloudformation Apache 2.0 aws-java-sdk-cloudfront Apache 2.0 aws-java-sdk-cloudhsm Apache 2.0 aws-java-sdk-cloudsearch Apache 2.0 aws-java-sdk-cloudtrail Apache 2.0 aws-java-sdk-cloudwatch Apache 2.0 aws-java-sdk-cloudwatchmetrics Apache 2.0 aws-java-sdk-codecommit Apache 2.0 aws-java-sdk-codedeploy Apache 2.0 aws-java-sdk-codepipeline Apache 2.0 aws-java-sdk-cognitoidentity Apache 2.0 aws-java-sdk-cognitoidp Apache 2.0 aws-java-sdk-cognitosync Apache 2.0 aws-java-sdk-config Apache 2.0 aws-java-sdk-core Apache 2.0 aws-java-sdk-datapipeline Apache 2.0 aws-java-sdk-devicefarm Apache 2.0 aws-java-sdk-directconnect Apache 2.0 aws-java-sdk-directory Apache 2.0 aws-java-sdk-discovery Apache 2.0 aws-java-sdk-dms Apache 2.0 aws-java-sdk-dynamodb Apache 2.0 aws-java-sdk-ec2 Apache 2.0 aws-java-sdk-ecr Apache 2.0 aws-java-sdk-ecs Apache 2.0 aws-java-sdk-efs Apache 2.0 aws-java-sdk-elasticache Apache 2.0 aws-java-sdk-elasticbeanstalk Apache 2.0 aws-java-sdk-elasticloadbalancing Apache 2.0 aws-java-sdk-elasticloadbalancingv2 Apache 2.0 aws-java-sdk-elasticsearch Apache 2.0 aws-java-sdk-elastictranscoder Apache 2.0 aws-java-sdk-emr Apache 2.0 aws-java-sdk-events Apache 2.0 aws-java-sdk-gamelift Apache 2.0 aws-java-sdk-glacier Apache 2.0 aws-java-sdk-iam Apache 2.0 aws-java-sdk-importexport Apache 2.0 aws-java-sdk-inspector Apache 2.0 aws-java-sdk-iot Apache 2.0 aws-java-sdk-kinesis Apache 2.0 aws-java-sdk-kms Apache 2.0 aws-java-sdk-lambda Apache 2.0 aws-java-sdk-logs Apache 2.0 aws-java-sdk-machinelearning Apache 2.0 aws-java-sdk-marketplacecommerceanalytics Apache 2.0 aws-java-sdk-marketplacemeteringservice Apache 2.0 aws-java-sdk-models Apache 2.0 aws-java-sdk-opsworks Apache 2.0 aws-java-sdk-rds Apache 2.0 aws-java-sdk-redshift Apache 2.0 aws-java-sdk-route53 Apache 2.0 aws-java-sdk-s3 Apache 2.0 aws-java-sdk-servicecatalog Apache 2.0 aws-java-sdk-ses Apache 2.0 aws-java-sdk-simpledb Apache 2.0 aws-java-sdk-simpleworkflow Apache 2.0 aws-java-sdk-snowball Apache 2.0 aws-java-sdk-sns Apache 2.0 aws-java-sdk-sqs Apache 2.0 aws-java-sdk-ssm Apache 2.0 aws-java-sdk-storagegateway Apache 2.0 aws-java-sdk-sts Apache 2.0 aws-java-sdk-support Apache 2.0 aws-java-sdk-swf-libraries Apache 2.0 aws-java-sdk-waf Apache 2.0 aws-java-sdk-workspaces Apache 2.0 aws-java-sdk Apache 2.0 jmespath-java Apache 2.0 AppleJavaExtensions BSD jcommander Apache 2.0 high-scale-lib MIT hppc Apache 2.0 clover Paid stream Apache 2.0 metrics-core Apache 2.0 cassandra-driver-core Apache 2.0 cassandra-driver-core Apache 2.0 uuid MIT grabbag MIT speed4j Apache 2.0 yamlbeans BSD jackson-annotations Apache 2.0 jackson-core Apache 2.0 jackson-databind Apache 2.0 jackson-dataformat-cbor Apache 2.0 jackson-dataformat-csv Apache 2.0 jackson-dataformat-xml Apache 2.0 jackson-dataformat-yaml Apache 2.0 jackson-datatype-guava Apache 2.0 jackson-datatype-jdk7 Apache 2.0 jackson-datatype-jdk8 Apache 2.0 jackson-datatype-joda Apache 2.0 jackson-datatype-jsr310 Apache 2.0 jackson-jaxrs-base Apache 2.0 jackson-jaxrs-json-provider Apache 2.0 jackson-module-afterburner Apache 2.0 jackson-module-jaxb-annotations Apache 2.0 jackson-module-kotlin Apache 2.0 woodstox-core Apache 2.0 classmate Apache 2.0 zjsonpatch Apache 2.0 caffeine Apache 2.0 waffle-jna EPLv1.0 docker-java Apache 2.0 docker-java Apache 2.0 btf Apache 2.0 jackson-coreutils Apache 2.0 json-schema-core Apache 2.0 json-schema-validator Apache 2.0 msg-simple Apache 2.0 uri-template Apache 2.0 jamm Apache 2.0 jffi Apache 2.0 jnr-constants Apache 2.0 jnr-ffi Apache 2.0 jnr-ffi Apache 2.0 jnr-posix EPLv1.0 jnr-x86asm MIT embedded-redis Apache 2.0 memoryfilesystem MIT guava-retrying Apache 2.0 guava-retrying Apache 2.0 snowball-stemmer BSD system-rules CPL uuid Apache 2.0 wiremock Apache 2.0 auto-common Apache 2.0 annotations LGPLv2.1 annotations LGPLv2.1 bcel-findbugs LGPLv2.1 findbugs LGPLv2.1 jFormatString BSD jFormatString BSD jsr305 BSD jsr305 BSD jsr305 BSD gson Apache 2.0 spymemcached MIT guava-testlib Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guice-multibindings Apache 2.0 guice Apache 2.0 truth Apache 2.0 concurrent-trees Apache 2.0 concurrentlinkedhashmap-lru Apache 2.0 json-simple Apache 2.0 libphonenumber Apache 2.0 locality-uuid BSD h2 EPLv1.0 annotations Apache 2.0 json-path-assert Apache 2.0 json-path Apache 2.0 json-path Apache 2.0 jzlib BSD bonecp-provider Apache 2.0 bonecp Apache 2.0 junixsocket-common Apache 2.0 junixsocket-native-common Apache 2.0 disruptor Apache 2.0 geoip-api LGPLv2.1 c3p0 LGPLv2.1 mchange-commons-java LGPLv2.1 archaius-core Apache 2.0 hystrix-core Apache 2.0 hystrix-servo-metrics-publisher Apache 2.0 rxjava-core Apache 2.0 servo-core Apache 2.0 kafka-clients Apache 2.0 kafka_2.10 Apache 2.0 kafka_2.11 Apache 2.0 common-cassandra Apache 2.0 timeslice_utils New Relic mockito-kotlin MIT compress-lzf Apache 2.0 checkstyle Apache 2.0 dagger-compiler Apache 2.0 dagger Apache 2.0 okhttp Apache 2.0 okio Apache 2.0 javapoet Apache 2.0 javawriter Apache 2.0 jaxb-impl CDDLv1 thrift-server Apache 2.0 finagle-core_2.10 Apache 2.0 finagle-core_2.11 Apache 2.0 finagle-http_2.10 Apache 2.0 finagle-http_2.11 Apache 2.0 jsr166e Creative Commons util-app_2.10 Apache 2.0 util-app_2.11 Apache 2.0 util-cache_2.10 Apache 2.0 util-cache_2.11 Apache 2.0 util-codec_2.10 Apache 2.0 util-codec_2.11 Apache 2.0 util-collection_2.10 Apache 2.0 util-collection_2.11 Apache 2.0 util-core_2.10 Apache 2.0 util-core_2.11 Apache 2.0 util-function_2.10 Apache 2.0 util-function_2.11 Apache 2.0 util-hashing_2.10 Apache 2.0 util-hashing_2.11 Apache 2.0 util-jvm_2.10 Apache 2.0 util-jvm_2.11 Apache 2.0 util-lint_2.10 Apache 2.0 util-lint_2.11 Apache 2.0 util-logging_2.10 Apache 2.0 util-logging_2.11 Apache 2.0 util-registry_2.10 Apache 2.0 util-registry_2.11 Apache 2.0 util-stats_2.10 Apache 2.0 util-stats_2.11 Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 HikariCP Apache 2.0 commons-beanutils Apache 2.0 commons-cli Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-io Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 commons-pool Apache 2.0 unix-socket-factory Apache 2.0 unix-socket-factory Apache 2.0 jflex BSD dom4j BSD airline Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 metrics-healthchecks Apache 2.0 metrics-httpclient Apache 2.0 metrics-jdbi Apache 2.0 metrics-jersey2 Apache 2.0 metrics-jetty9 Apache 2.0 metrics-json Apache 2.0 metrics-jvm Apache 2.0 metrics-logback Apache 2.0 metrics-servlets Apache 2.0 dropwizard-java8-jdbi Apache 2.0 dropwizard-client Apache 2.0 dropwizard-configuration Apache 2.0 dropwizard-core Apache 2.0 dropwizard-db Apache 2.0 dropwizard-jackson Apache 2.0 dropwizard-jdbi Apache 2.0 dropwizard-jersey Apache 2.0 dropwizard-jetty Apache 2.0 dropwizard-lifecycle Apache 2.0 dropwizard-logging Apache 2.0 dropwizard-metrics Apache 2.0 dropwizard-servlets Apache 2.0 dropwizard-testing Apache 2.0 dropwizard-util Apache 2.0 dropwizard-validation Apache 2.0 netty-all Apache 2.0 netty-buffer Apache 2.0 netty-codec-http Apache 2.0 netty-codec-socks Apache 2.0 netty-codec Apache 2.0 netty-common Apache 2.0 netty-handler-proxy Apache 2.0 netty-handler Apache 2.0 netty-resolver Apache 2.0 netty-transport-native-epoll Apache 2.0 netty-transport Apache 2.0 netty Apache 2.0 ratpack-core Apache 2.0 ratpack-groovy-test Apache 2.0 ratpack-groovy Apache 2.0 ratpack-guice Apache 2.0 ratpack-test Apache 2.0 rxjava Apache 2.0 fastutil Apache 2.0 janino BSD activation Apache 2.0 javax.annotation-api CDDLv1 jsr250-api CDDLv1 javax.inject Apache 2.0 mail CDDLv1 mailapi CDDLv1 javax.servlet-api Apache 2.0 servlet-api Apache 2.0 javax.transaction-api CDDLv1 validation-api Apache 2.0 javax.websocket-api CDDLv1 javax.ws.rs-api CDDLv1 jaxb-api CDDLv1 stax-api CDDLv1 jaxen Apache 2.0 jline BSD jline BSD joda-time Apache 2.0 junit-dep CPL junit CPL junit EPLv1.0 kafka_2.10 Apache 2.0 kafka_2.9.2 Apache 2.0 apache-log4j-extras Apache 2.0 log4j Apache 2.0 mysql-connector-java GPLv2 with Classpath Exception byte-buddy Apache 2.0 byte-buddy Apache 2.0 jna-platform LGPLv2.1 jna Apache 2.0 jcip-annotations Apache 2.0 lz4 Apache 2.0 accessors-smart Apache 2.0 asm Apache 2.0 json-smart Apache 2.0 json-smart Apache 2.0 primitive GPLv2 with Classpath Exception compiler Apache 2.0 lang Apache 2.0 beaver-cc BSD ehcache-core Apache 2.0 ehcache Apache 2.0 jopt-simple MIT jopt-simple MIT opencsv Apache 2.0 quality-check Apache 2.0 scannotation Apache 2.0 super-csv Apache 2.0 uadetector-core Apache 2.0 uadetector-resources Apache 2.0 argparse4j MIT spymemcached MIT kalium Apache 2.0 ST4 BSD antlr-runtime BSD antlr-runtime BSD antlr BSD stringtemplate BSD ant-launcher Apache 2.0 ant Apache 2.0 cassandra-all Apache 2.0 cassandra-all Apache 2.0 cassandra-thrift Apache 2.0 cassandra-thrift Apache 2.0 commons-collections4 Apache 2.0 commons-compress Apache 2.0 commons-csv Apache 2.0 commons-dbcp2 Apache 2.0 commons-io Apache 2.0 commons-lang3 Apache 2.0 commons-math3 Apache 2.0 commons-math Apache 2.0 commons-pool2 Apache 2.0 curator-client Apache 2.0 curator-framework Apache 2.0 curator-recipes Apache 2.0 curator-test Apache 2.0 derby Apache 2.0 geronimo-servlet_3.0_spec Apache 2.0 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 ivy Apache 2.0 kafka-clients Apache 2.0 kafka_2.11 Apache 2.0 libthrift Apache 2.0 tomcat-embed-core Apache 2.0 tomcat-embed-el Apache 2.0 tomcat-embed-logging-juli Apache 2.0 tomcat-embed-websocket Apache 2.0 tomcat-jdbc Apache 2.0 tomcat-juli Apache 2.0 zookeeper Apache 2.0 aspectjweaver EPLv1.0 assertj-core Apache 2.0 assertj-core Apache 2.0 evo-inflector Apache 2.0 bcmail-jdk15on MIT bcpkix-jdk15on MIT bcprov-jdk15on MIT ohc-core Apache 2.0 cassandra-unit-spring LGPLv3 cassandra-unit-spring LGPLv3 cassandra-unit LGPLv3 cassandra-unit LGPLv3 groovy-all Apache 2.0 groovy-all Apache 2.0 groovy Apache 2.0 groovy Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 easymock Apache 2.0 ecj EPLv1.0 javax.activation CDDLv1 javax.annotation CDDLv1 javax.mail.glassfish CDDLv1 javax.servlet CDDLv1 javax.transaction CDDLv1 org.objectweb.asm BSD jetty-setuid-java EPLv1.0 jetty-schemas Apache 2.0 javax-websocket-client-impl Apache 2.0 javax-websocket-server-impl Apache 2.0 websocket-api Apache 2.0 websocket-client Apache 2.0 websocket-common Apache 2.0 websocket-server Apache 2.0 websocket-servlet Apache 2.0 apache-jsp Apache 2.0 jetty-annotations CDDLv1 jetty-client Apache 2.0 jetty-continuation Apache 2.0 jetty-http Apache 2.0 jetty-io Apache 2.0 jetty-jmx Apache 2.0 jetty-jndi Apache 2.0 jetty-plus Apache 2.0 jetty-proxy Apache 2.0 jetty-security Apache 2.0 jetty-server Apache 2.0 jetty-servlet Apache 2.0 jetty-servlets Apache 2.0 jetty-util Apache 2.0 jetty-webapp Apache 2.0 jetty-xml Apache 2.0 sigar Apache 2.0 aopalliance-repackaged CDDLv1 javax.inject CDDLv1 hk2-api CDDLv1 hk2-locator CDDLv1 hk2-utils CDDLv1 osgi-resource-locator CDDLv1 jersey-guava CDDLv1 jersey-client CDDLv1 jersey-apache-connector CDDLv1 jersey-container-servlet-core CDDLv1 jersey-container-servlet CDDLv1 jersey-client CDDLv1 jersey-common CDDLv1 jersey-server CDDLv1 jersey-bean-validation CDDLv1 jersey-metainf-services CDDLv1 jersey-media-jaxb CDDLv1 jersey-client CDDLv1 jersey-test-framework-provider-inmemory CDDLv1 jersey-test-framework-core CDDLv1 javax.el CDDLv1 hamcrest-all BSD hamcrest-core BSD hamcrest-integration BSD hamcrest-library BSD HdrHistogram Public Domain hector-core MIT hibernate-commons-annotations LGPLv2.1 hibernate-jpa-2.0-api LGPLv2.1 hibernate-jpa-2.1-api LGPLv2.1 hibernate-c3p0 Apache 2.0 hibernate-core Apache 2.0 hibernate-ehcache Apache 2.0 hibernate-entitymanager Apache 2.0 hibernate-jmx Apache 2.0 hibernate-validator Apache 2.0 freebuilder Apache 2.0 org.jacoco.agent EPLv1.0 org.jacoco.ant EPLv1.0 org.jacoco.core EPLv1.0 org.jacoco.report EPLv1.0 javassist Apache 2.0 jboss-logging-annotations LGPLv2.1 jboss-logging Apache 2.0 jboss-transaction-api_1.1_spec LGPLv2.1 jboss-transaction-api_1.2_spec LGPLv2.1 jandex Apache 2.0 jdbi Apache 2.0 job-dsl-core Apache 2.0 version-number MIT kotlin-annotation-processing Apache 2.0 kotlin-reflect Apache 2.0 kotlin-runtime Apache 2.0 kotlin-stdlib Apache 2.0 kotlin-test-junit Apache 2.0 kotlin-test Apache 2.0 annotations Apache 2.0 jolokia-core Apache 2.0 jruby-complete LGPLv2.1 LGPLv2.1 json Public Domain json Apache 2.0 xstream BSD annotations Apache 2.0 mapdb Apache 2.0 mapdb Apache 2.0 jbcrypt ISC mockserver-client-java Apache 2.0 mockserver-core Apache 2.0 mockserver-logging Apache 2.0 mockserver-netty Apache 2.0 mockito-all MIT mockito-core MIT mockito-core MIT apache-el Apache 2.0 apache-jsp Apache 2.0 alpn-boot Apache 2.0 etcd4j Apache 2.0 msgpack Apache 2.0 objenesis Apache 2.0 objenesis Apache 2.0 jmh-core GPLv2 with Classpath Exception jmh-generator-annprocess GPLv2 with Classpath Exception jol-core GPLv2 with Classpath Exception asm-analysis BSD asm-analysis BSD asm-commons BSD asm-debug-all BSD asm-tree BSD asm-util BSD asm-util BSD asm BSD asm Public Domain postgresql BSD powermock-api-mockito Apache 2.0 powermock-api-support Apache 2.0 powermock-core Apache 2.0 powermock-module-junit4-common Apache 2.0 powermock-module-junit4 Apache 2.0 powermock-reflect Apache 2.0 lombok MIT reactive-streams Public Domain reflections WTFPL scala-java8-compat_2.11 Scala scala-parser-combinators_2.11 Scala scala-xml_2.11 Scala scala-library Scala scala-reflect Scala scalatest_2.10 Apache 2.0 scalatest_2.11 Apache 2.0 native-lib-loader BSD jsonassert Apache 2.0 jcl-over-slf4j MIT jul-to-slf4j MIT log4j-log4j12 MIT log4j-over-slf4j MIT slf4j-api MIT slf4j-ext MIT slf4j-log4j12 MIT slf4j-simple MIT spock-core Apache 2.0 spock-core Apache 2.0 spring-boot-actuator Apache 2.0 spring-boot-autoconfigure Apache 2.0 spring-boot-configuration-processor Apache 2.0 spring-boot-starter-actuator Apache 2.0 spring-boot-starter-aop Apache 2.0 spring-boot-starter-data-jpa Apache 2.0 spring-boot-starter-data-rest Apache 2.0 spring-boot-starter-jdbc Apache 2.0 spring-boot-starter-jetty Apache 2.0 spring-boot-starter-logging Apache 2.0 spring-boot-starter-test Apache 2.0 spring-boot-starter-tomcat Apache 2.0 spring-boot-starter-web Apache 2.0 spring-boot-starter Apache 2.0 spring-boot-test-autoconfigure Apache 2.0 spring-boot-test Apache 2.0 spring-boot Apache 2.0 spring-data-commons Apache 2.0 spring-data-jpa Apache 2.0 spring-data-rest-core Apache 2.0 spring-data-rest-webmvc Apache 2.0 spring-hateoas Apache 2.0 spring-plugin-core Apache 2.0 spring-aop Apache 2.0 spring-aspects Apache 2.0 spring-beans Apache 2.0 spring-context-support Apache 2.0 spring-context Apache 2.0 spring-core Apache 2.0 spring-core Apache 2.0 spring-expression Apache 2.0 spring-jdbc Apache 2.0 spring-orm Apache 2.0 spring-test Apache 2.0 spring-test Apache 2.0 spring-tx Apache 2.0 spring-web Apache 2.0 spring-webmvc Apache 2.0 xz Public Domain wasabi Apache 2.0 snappy-java Apache 2.0 xmlunit-core Apache 2.0 xmlunit-legacy Apache 2.0 snakeyaml Apache 2.0 JUnitParams Apache 2.0 postgresql BSD postgresql BSD jedis MIT scala-library Scala ion-java Apache 2.0 timeslice_service-thrift New Relic timeslice_service New Relic xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3_min Public Domain zkclient Apache 2.0 zookeeper Apache 2.0 CoffeeScript Library License CoffeeScript MIT coffin MIT JavaScript JavaScript License ie_html5/ie_html5.js MIT Angular.js MIT Angular UI directives for Bootstrap MIT Chart.js MIT Chosen JQuery plugin MIT Fullcalendar MIT Moment MIT Crash reporting Software License Apple OS X OS X Yosemite Xcode & Apple SDK Xcode license Label services Service License BoneCP Apache 2.0 Gradle Apache 2.0 Hibernate Apache 2.0 Spring Apache 2.0 Infrastructure Monitoring services Service License antlr BSD aopalliance Public Domain asm MIT cglib Apache 2.0 ch.qos.logback EPLv1.0 com.101tec Apache 2.0 com.amazonaws Apache 2.0 com.cenqua.clover Paid com.fasterxml.jackson.core Apache 2.0 com.fasterxml Apache 2.0 com.google.code.findbugs BSD com.google.guava Apache 2.0 com.googlecode.json-simple Apache 2.0 com.intellij Apache 2.0 New Relic com.squareup.dagger Apache 2.0 com.squareup Apache 2.0 com.yammer.metrics Apache 2.0 commons-codec Apache 2.0 commons-configuration Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 dom4j BSD io.netty Apache 2.0 javax.annotation CDDLv1 javax.inject Apache 2.0 javax.servlet.jsp CDDLv1 javax.servlet Apache 2.0 javax.validation Apache 2.0 javax.websocket CDDLv1 jline BSD joda-time Apache 2.0 junit CPL log4j Apache 2.0 mysql GPLv2 with Classpath Exception net.sf.jopt-simple MIT org.apache.commons Apache 2.0 org.apache.httpcomponents Apache 2.0 org.apache.ivy Apache 2.0 org.apache.thrift Apache 2.0 org.apache.tomcat.embed Apache 2.0 org.apache.zookeeper Apache 2.0 org.codehaus.groovy Apache 2.0 org.codehaus.jackson Apache 2.0 org.easymock Apache 2.0 org.eclipse.jetty.orbit CDDLv1 org.eclipse.jetty.toolchain Apache 2.0 org.eclipse.jetty.websocket Apache 2.0 org.eclipse.jetty CDDLv1 org.glassfish.jersey.core CDDLv1 org.glassfish.web CDDLv1 org.glassfish CDDLv1 org.hamcrest BSD org.hibernate Apache 2.0 org.javassist Apache 2.0 org.jboss.logging LGPLv2.1 org.jenkins-ci.plugins Apache 2.0 org.jenkins-ci Apache 2.0 org.jetbrains Apache 2.0 org.jolokia Apache 2.0 org.jvnet.hudson BSD org.mockito MIT org.objenesis Apache 2.0 org.ow2.asm MIT org.reflections WTFPL org.scala-lang Scala org.slf4j MIT org.springframework.boot Apache 2.0 org.springframework Apache 2.0 org.xerial.snappy Apache 2.0 org.yaml Apache 2.0 xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3 Public Domain .NET support uploader service Library License Amazon AWS SDK for Java Apache 2.0 Apache Commons Codec Apache 2.0 Gson Apache 2.0 Jetty Apache 2.0 Ruby gems Ruby gems Gem License aasm MIT actionmailer MIT actionpack MIT activeadmin MIT actionview MIT activejob MIT active_model_serializers MIT activemodel MIT activerecord MIT activerecord-deprecated_finders MIT activerecord-mysql2-adapter MIT activeresource MIT activesupport MIT addressable Apache 2.0 angularjs-rails MIT arbre MIT arel MIT arel MIT atomic Apache 2.0 atomic Apache-2.0 attr_required MIT awesome_print MIT backports MIT better_errors MIT binding_of_caller MIT bourbon MIT brwsr MIT browser-timezone-rails MIT builder MIT bundler MIT byebug MIT callsite MIT capistrano MIT capistrano-bundler MIT capistrano-ext MIT capistrano-rbenv MIT capistrano-stats MIT capybara MIT celluloid MIT CFPropertyList MIT chunky_png MIT ci_reporter MIT ci_reporter_rspec MIT clockwork MIT codeclimate-test-reporter MIT coderay MIT coderay MIT coffee-rails MIT coffee-script MIT coffee-script-source MIT columnize Ruby compass MIT compass-core MIT compass-import-once MIT compass-rails MIT concurrent-ruby MIT crack MIT crypt Unlicensed daemons MIT dalli MIT database_cleaner MIT debug_inspector MIT debugger-linecache MIT diff-lcs MIT docile MIT dotenv MIT dotenv-deployment MIT erubis MIT etcd MIT ethon MIT eventmachine Ruby excon MIT execjs MIT factory_girl MIT factory_girl_rails MIT faraday MIT faraday-middleware MIT faye-websocket MIT ffi MIT ffi BSD fission MIT fog MIT fog-atmos MIT fog-aws MIT fog-brightbox MIT fog-core MIT fog-ecloud MIT fog-google MIT fog-json MIT fog-local MIT fog-powerdns MIT fog-profitbricks MIT fog-radosgw MIT fog-riakcs MIT fog-sakuracloud MIT fog-serverlove MIT fog-softlayer MIT fog-storm_on_demand MIT fog-terremark MIT fog-vmfusion MIT fog-voxel MIT fog-xml MIT font-awesome-rails MIT foreman MIT formatador MIT formtastic MIT formtastic i18n MIT fssm MIT globalid MIT guard MIT guard-rspec MIT haml MIT haml-rails MIT has scope MIT hashie MIT highline Ruby hike MIT hipchat-api MIT histogram MIT hitimes ISC hiredis BSD http_parser.rb MIT httpclient Ruby httpclient Ruby httparty MIT i18n MIT inflecto MIT inherited resources MIT intercom-rails MIT ipaddress MIT jasmine MIT jasmine-core MIT jasmine-rails MIT jbuilder MIT jira MIT jira-ruby OSL-3.0 journey MIT jquery-rails MIT jquery-turbolinks MIT jquery-ui-rails MIT json Ruby jwt MIT kaminari MIT kgio LGPLv3 kgio LGPLv3 kgio LGPL-v2.1+ libv8 MIT listen MIT logger Ruby loofah MIT lumberjack MIT macaddr MIT mail MIT mailcatcher MIT memoist MIT metaclass MIT meta_request MIT method_source MIT mime-types MIT mini_portile MIT minitest MIT minitest-rails MIT mixlib-log Apache 2.0 mocha MIT mono_logger MIT multi_json MIT multi_xml MIT multipart-post MIT mysql2 MIT net-http-persistent MIT net-scp MIT net-sftp MIT net-ssh MIT net-ssh-gateway MIT netrc MIT nokogiri MIT oauth2 MIT oj MIT omniauth MIT omniauth-oauth2 MIT pagerduty MIT papers MIT pg BSD pg Ruby phantomjs BSD phantomjs-binaries Unlicensed poltergeist MIT polyamorous MIT polyglot MIT polyglot MIT protected_attributes MIT pry MIT pry-nav MIT pry-rails MIT pry-stack_explorer MIT puma BSD quiet assets MIT rack MIT rack-cache MIT rack-contrib MIT rack-oauth2 MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-ssl MIT rack-ssl-enforcer MIT rack-test MIT rails MIT rails-deprecated_sanitizer MIT rails-dom-testing MIT rails-html-sanitizer MIT rails-observers MIT rails_12factor MIT rails_serve_static_assets MIT rails_stdout_logging MIT railties MIT raindrops LGPLv3 raindrops LGPLv3 raindrops LGPLv2.1+ rake MIT rake MIT rake MIT rake MIT ransack MIT rb-fsevent MIT rb-inotify MIT rdoc Ruby redcarpet MIT redis MIT redis-namespace MIT redis-queue MIT ref MIT remote_syslog_logger MIT request_store MIT responders MIT resque MIT resque-cleaner MIT resque-pool MIT resque-scheduler MIT resque-status MIT rest-client MIT restforce MIT rspec MIT rspec-core MIT rspec-expectations MIT rspec-mocks MIT rspec-rails MIT rspec-support MIT rspec_junit_formatter MIT rubyntlm MIT ruby-saml MIT rufus-scheduler MIT safe_yaml MIT salesforce_bulk_query BSD sass MIT sass-rails MIT sass-rails MIT sdoc MIT secure_headers Apache 2.0 sequel MIT serveza MIT settingslogic MIT shoulda MIT shoulda-context MIT shoulda-matchers MIT simplecov MIT simplecov-html MIT simplecov-rcov MIT sinatra MIT sinatra-activerecord MIT sinatra-contrib MIT skinny MIT slop MIT spring MIT sprockets MIT sprockets-rails MIT sqlite3 BSD sshkit GPL-No Distro sys-uname Ruby syslog_protocol MIT systemu BSDL term-ansicolor GPL-No Distro terminal-table MIT therubyracer MIT thin Ruby thor MIT thread_safe Apache-2.0 thrift Apache 2.0 thrift-rack MIT tilt MIT timecop MIT timers MIT tins MIT treetop MIT turbolinks MIT twitter-bootstrap-rails MIT typhoeus MIT tzinfo MIT uglifier MIT unicorn Ruby unicorn-rails MIT uuid MIT uuidtools Apache-2.0 vegas MIT webmock MIT web-console MIT xml-simple Ruby xpath MIT yard MIT Storage services Library License Amazon AWS SDK for Java Apache 2.0 Amazon AWS Command Line Interface Apache 2.0 Go packages Library License Go-Mysql-Driver Mozilla Public License 2.0 gocql BSD 3-Clause groupcache Apache 2.0 Migrate MIT go-sqlite3 MIT Revel MIT Pathtree MIT Ansicolor MIT fsnotify BSD 3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.99942,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Services <em>licenses</em>",
        "sections": "Services <em>licenses</em>",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Contents Java internal"
      },
      "id": "603ea24364441f91fb4e8864"
    },
    {
      "sections": [
        "Add-on end user license agreement",
        "New Relic, Inc. Add-on End User License Agreement"
      ],
      "title": "Add-on end user license agreement",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "a01c225ca30f95dab7db856cd946c76de557c31f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/add-end-user-license-agreement/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-03-16T06:19:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic, Inc. Add-on End User License Agreement In connection with the work provided by New Relic's Expert Services, Field Instrumentation Team, or Sales team, you may be provided with certain custom-created software to visualize, enable, optimize, or enhance your use of New Relic's Services. By downloading, installing, authorizing installation, or using the Add-on (defined below) with your Underlying Software (defined below), you (“Customer”) agree to the terms and conditions herein (“Agreement”) with New Relic, Inc., a Delaware corporation with offices located at 188 Spear Street, Suite 1200 San Francisco, CA 94105 (“New Relic\"), (collectively the “Parties”). Capitalized terms not defined herein shall have the meanings set forth in the New Relic Terms of Service (the “Terms of Service”) available here: newrelic.com/termsandconditions/terms. IF YOU DO NOT AGREE TO THIS AGREEMENT, YOUR SOLE REMEDY IS TO NOT USE THE ADD-ON. 1. DEFINITIONS “Add-on” means the New Relic applications and/or software, including but not limited to connectors, extensions, UI extension, and plugins, provided by New Relic to Customer to enable the Services to operate with certain third party or Customer software or systems (“Underlying Software”). For the purposes of the Terms of Service, the Add-on shall be treated like an Agent, subject to the separate terms herein. 2. USE OF THE PROGRAMMABILITY ADD-ON 2.1 Software Evaluation License. Subject to the terms herein, New Relic grants to Customer a limited, non-exclusive, non-transferrable, non-sublicensable right to install, use, and configure the Add-on solely as needed to enable the Services for internal evaluation purposes. New Relic reserves all rights and licenses not expressly granted herein. 2.2 Ownership. As between the Parties, New Relic owns all right, title, and interest to the Add-on and Feedback, including but not limited to any intellectual property and proprietary rights therein. Customer retains all right, title, and interest in any Customer Data processed by the Add-on in connection with the Services. 2.3 Feedback. Customer agrees to provide feedback, suggestions, ideas, requests or recommendations (“Feedback”) regarding the Add-on, and hereby irrevocably assigns all intellectual property and proprietary rights it holds in the Feedback to New Relic. 2.4 Notice. Customer acknowledges and agrees that the Add-on is made to work with the Underlying Software as configured at the time of creation and there is no guarantee that Add-on will continue to work in the event Customer changes, replaces, upgrades versions of, updates, or otherwise changes the Underlying Software (an “Upgrade Event”). Customer shall hold New Relic harmless from any claims or damages arising from Customer’s Upgrade Event. 2.5 Restrictions. Customer will not: (i) use the Add-on except as permitted hereunder; (ii) distribute, sell, sublicense, or otherwise transfer the Add-on; (iii) decompile, disassemble or reverse engineer any software underlying the Add-on; (iv) use the Add-on to damage, disable, overburden or impair any New Relic server or network(s) connected to any New Relic server or interfere with any other party’s use and enjoyment of the Services; (v) use the Add-on to defraud, defame, abuse, harass, stalk, threaten or infringe the rights of privacy or other intellectual property rights of others or otherwise violate any applicable law; (vi) circumvent or modify any security technologies included as part of the Add-on; or (vii) attempt or permit any third party to do any of the foregoing. New Relic may suspend Customer usage of the Services, without notice, pending any investigation of misuse. These restrictions may be supplemented or superceded (to the extent they conflict) by the New Relic Acceptable Use Policy as may be published and updated from time to time on the New Relic web site at docs.newrelic.com/docs/licenses/license-information/acceptable-use-policy/acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. “Confidential Information” means: (a) the Programmability Add-on, and any features, results or output produced by, and other information relating to the Add-on (including, without limitation, all Feedback); and (b) any business or technical information of New Relic including but not limited to any technical information, research, development, know-how that a reasonable person would understand to be confidential. 3.2 Restrictions. Customer will not use or disclose any Confidential Information, except as necessary for the performance of this Agreement. Customer will use all reasonable efforts to protect Confidential Information from unauthorized use or disclosure, but in no event less than the efforts that it ordinarily uses with respect to its own proprietary information. Customer may disclose Confidential Information to those of its employees who have a bona fide need to know such Confidential Information for the performance of this Agreement; provided that each such employee first executes a written agreement that contains use and nondisclosure restrictions at least as protective as those set forth herein. Confidential Information shall not include any information that: (a) is or becomes generally known to the public through no fault or breach of this Agreement by Customer; (b) is rightfully known by Customer at the time of disclosure without an obligation of confidentiality; (c) is independently developed by Customer without access or use of any Confidential Information; or (d) is rightfully obtained from a third party without restriction on use or disclosure. 4. DISCLAIMER 4.1 DISCLAIMER. THE ADD-ON IS PROVIDED AS-IS AND AS-AVAILABLE AND NEW RELIC DISCLAIMS AND MAKES NO WARRANTIES, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE OR NON-INFRINGEMENT AND WHETHER OR NOT ARISING THROUGH A COURSE OF DEALING. THE ADD-ON IS NOT GUARANTEED TO BE ERROR-FREE, COMPATIBLE WITH THE UNDERLYING SOFTWARE, OR THAT CUSTOMER WILL ACHIEVE ANY RESULTS FROM USE OF THE ADD-ON THEREFROM. 4.2 LIMITATION OF LIABILITY. TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC, ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE TO CUSTOMER OR ANY THIRD PARTY FOR DAMAGES OF ANY KIND, INCLUDING, WITHOUT LIMITATION, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE INSTALLATION, USE OR INABILITY TO USE THE ADD-ON OR FOR ANY ERROR OR DEFECT IN THE ADD-ON OR THE SERVICES, REGARDLESS OF LEGAL THEORY, WHETHER OR NOT NEW RELIC HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSS OR DAMAGE. NEW RELIC’S AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS AGREEMENT WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE PARTIES HAVE AGREED THAT THESE LIMITATIONS WILL SURVIVE AND APPLY EVEN IF ANY LIMITED REMEDY SPECIFIED IN THIS AGREEMENT IS FOUND TO HAVE FAILED OF ITS ESSENTIAL PURPOSE. THE LIMITATIONS OF DAMAGES SET FORTH ABOVE ARE FUNDAMENTAL ELEMENTS OF THE BASIS OF THE BARGAIN BETWEEN NEW RELIC AND CUSTOMER. 4.3 EVALUATION VERSION. Customer agrees and acknowledges that: (a) the Add-on is not an official product and has not been commercially released for sale by New Relic; (b) the Add-on may not operate properly, being in final form, or fully functional; (c) the Add-on may contain errors, security vulnerabilities, design flaws, or other problems; (d) it may not be possible to make the Add-on fully functional; (e) the information obtained using the Add-on may not be accurate; (f) use of the Add-on may result in unexpected results, loss of data, delays or other unpredictable damages or loss; (g) New Relic is under no obligation to release a commercial version of the Add-on; and (h) New Relic has the right unilaterally to abandon development of the Add-on, at any time and without any obligation or liability to Customer. 5. GENERAL PROVISIONS 5.1 Terms of Service; Documentation. This Agreement shall be considered a part of the New Relic documentation, located at: https://docs.newrelic.com (the “Documentation). This Agreement and the Terms of Service constitute the entire and exclusive agreement between New Relic and Customer with respect to the Add-on. In the absence of a separate agreement, upon agreement between New Relic and Customer with respect to the Add-On, the terms and conditions of this Agreement shall govern the relationship between New Relic and Customer with respect to such Add-On. To the extent of a conflict between the Agreement and the Terms of Service, this Agreement shall govern with respect to the Add-on only.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.36885,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add-on end user <em>license</em> agreement",
        "sections": "Add-on end user <em>license</em> agreement",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": "&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;acceptable-use-policy&#x2F;acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. “Confidential <em>Information</em>” means: (a) the Programmability Add-on, and any features, results or output produced by, and other <em>information</em> relating to the Add-on (including, without limitation"
      },
      "id": "603ec23328ccbccf1beba79a"
    },
    {
      "sections": [
        "New Relic Agent Software Notice"
      ],
      "title": "New Relic Agent Software Notice",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "2bf9501c2767105130d3808f1bf3a91a032d903e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/new-relic-agent-software-notice/",
      "published_at": "2021-05-05T16:22:53Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This software is © 2008-2021 New Relic, Inc. and its licensors. This software is solely for use with New Relic’s proprietary SaaS service (“New Relic Service”), so to use the software you must have a valid account for the New Relic Service under a separate agreement with New Relic (“Subscription Agreement”). You may only use the software to support your use of the New Relic Service as permitted in the Subscription Agreement. Without a Subscription Agreement, you may not use the software. All other use is prohibited. New Relic and its suppliers retain all right, title and interest (including intellectual property rights) in the software. The Subscription Agreement will control in event of a conflict with this notice. Unless otherwise agreed by New Relic in your Subscription Agreement: You may not use, copy, distribute or sublicense the software, use the software on behalf of third parties, reverse engineer or decompile the software, modify or create derivative works of the software, use the software for competitive analysis or benchmarking, or remove or obscure any proprietary notices in the software. The software is provided “AS IS” and New Relic disclaims all warranties, whether express, implied, statutory or otherwise, including warranties of merchantability, fitness for a particular purpose, title or noninfringement. To the full extent permitted by law, New Relic will have no liability arising from or related to the software or under this notice for any direct, indirect, special, incidental, or consequential damages of any kind, even if advised of their possibility in advance, and regardless of legal theory (whether contract, tort, negligence, strict liability or otherwise). The software may contain third-party open source software (“OSS”) as described here and at https://github.com/newrelic. To the extent required by the OSS license, that license will apply to the OSS when used on a stand-alone basis. For avoidance of doubt, you may copy and distribute New Relic agents pursuant to your Subscription Agreement for New Relic Browser and New Relic Mobile and as set forth: https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/get-started and https://docs.newrelic.com/docs/browser/new-relic-browser/installation/install-new-relic-browser-agent Software versions New Relic makes available under an OSS license (such as Apache 2.0) are governed by the terms of the applicable OSS license. For a current list of New Relic software versions released as OSS please visit https://opensource.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.32553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": " and at https:&#x2F;&#x2F;github.com&#x2F;newrelic. To the extent required by the OSS <em>license</em>, that <em>license</em> will apply to the OSS when used on a stand-alone basis. For avoidance of doubt, you may copy and distribute New Relic agents pursuant to your Subscription Agreement for New Relic Browser and New Relic Mobile"
      },
      "id": "603eb73828ccbc1f99eba74a"
    }
  ],
  "/docs/licenses/license-information/distributed-licenses/new-relic-agent-software-notice": [
    {
      "sections": [
        "Services licenses",
        "Contents",
        "Java internal services",
        "Java crash data API",
        "CoffeeScript",
        "JavaScript",
        "Crash reporting",
        "Label services",
        "Infrastructure Monitoring services",
        ".NET support uploader service",
        "Ruby gems",
        "Storage services",
        "Go packages"
      ],
      "title": "Services licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "49a2ad450d31dacfc2aae690ca947d2326d18761",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/other-licenses/services-licenses/",
      "published_at": "2021-05-05T16:28:24Z",
      "updated_at": "2021-04-06T00:26:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Contents Java internal services Java crash data API Framework License Apache TomCat Apache 2.0 Bean Validation Apache 2.0 Cassandra Driver Core Apache 2.0 ClassMate Apache 2.0 Hamcrest BSD Mockito MIT Netty Apache 2.0 Objenesis MIT SnakeYAML Apache 2.0 Spring Boot Apache 2.0 Java internal services Library License json_simple Apache 2.0 newrelic-api New Relic newrelic-api New Relic antlr BSD aopalliance Public Domain asm-analysis BSD asm-commons BSD asm-tree BSD asm-util BSD asm BSD c3p0 EPLv1.0 cglib-nodep Apache 2.0 cglib Apache 2.0 cglib Apache 2.0 cal10n-api MIT logback-classic EPLv1.0 logback-core EPLv1.0 guava-jetty-service Apache 2.0 zkclient Apache 2.0 reporter-config-base Apache 2.0 reporter-config3 Apache 2.0 reporter-config Apache 2.0 aws-java-sdk-acm Apache 2.0 aws-java-sdk-api-gateway Apache 2.0 aws-java-sdk-applicationautoscaling Apache 2.0 aws-java-sdk-autoscaling Apache 2.0 aws-java-sdk-cloudformation Apache 2.0 aws-java-sdk-cloudfront Apache 2.0 aws-java-sdk-cloudhsm Apache 2.0 aws-java-sdk-cloudsearch Apache 2.0 aws-java-sdk-cloudtrail Apache 2.0 aws-java-sdk-cloudwatch Apache 2.0 aws-java-sdk-cloudwatchmetrics Apache 2.0 aws-java-sdk-codecommit Apache 2.0 aws-java-sdk-codedeploy Apache 2.0 aws-java-sdk-codepipeline Apache 2.0 aws-java-sdk-cognitoidentity Apache 2.0 aws-java-sdk-cognitoidp Apache 2.0 aws-java-sdk-cognitosync Apache 2.0 aws-java-sdk-config Apache 2.0 aws-java-sdk-core Apache 2.0 aws-java-sdk-datapipeline Apache 2.0 aws-java-sdk-devicefarm Apache 2.0 aws-java-sdk-directconnect Apache 2.0 aws-java-sdk-directory Apache 2.0 aws-java-sdk-discovery Apache 2.0 aws-java-sdk-dms Apache 2.0 aws-java-sdk-dynamodb Apache 2.0 aws-java-sdk-ec2 Apache 2.0 aws-java-sdk-ecr Apache 2.0 aws-java-sdk-ecs Apache 2.0 aws-java-sdk-efs Apache 2.0 aws-java-sdk-elasticache Apache 2.0 aws-java-sdk-elasticbeanstalk Apache 2.0 aws-java-sdk-elasticloadbalancing Apache 2.0 aws-java-sdk-elasticloadbalancingv2 Apache 2.0 aws-java-sdk-elasticsearch Apache 2.0 aws-java-sdk-elastictranscoder Apache 2.0 aws-java-sdk-emr Apache 2.0 aws-java-sdk-events Apache 2.0 aws-java-sdk-gamelift Apache 2.0 aws-java-sdk-glacier Apache 2.0 aws-java-sdk-iam Apache 2.0 aws-java-sdk-importexport Apache 2.0 aws-java-sdk-inspector Apache 2.0 aws-java-sdk-iot Apache 2.0 aws-java-sdk-kinesis Apache 2.0 aws-java-sdk-kms Apache 2.0 aws-java-sdk-lambda Apache 2.0 aws-java-sdk-logs Apache 2.0 aws-java-sdk-machinelearning Apache 2.0 aws-java-sdk-marketplacecommerceanalytics Apache 2.0 aws-java-sdk-marketplacemeteringservice Apache 2.0 aws-java-sdk-models Apache 2.0 aws-java-sdk-opsworks Apache 2.0 aws-java-sdk-rds Apache 2.0 aws-java-sdk-redshift Apache 2.0 aws-java-sdk-route53 Apache 2.0 aws-java-sdk-s3 Apache 2.0 aws-java-sdk-servicecatalog Apache 2.0 aws-java-sdk-ses Apache 2.0 aws-java-sdk-simpledb Apache 2.0 aws-java-sdk-simpleworkflow Apache 2.0 aws-java-sdk-snowball Apache 2.0 aws-java-sdk-sns Apache 2.0 aws-java-sdk-sqs Apache 2.0 aws-java-sdk-ssm Apache 2.0 aws-java-sdk-storagegateway Apache 2.0 aws-java-sdk-sts Apache 2.0 aws-java-sdk-support Apache 2.0 aws-java-sdk-swf-libraries Apache 2.0 aws-java-sdk-waf Apache 2.0 aws-java-sdk-workspaces Apache 2.0 aws-java-sdk Apache 2.0 jmespath-java Apache 2.0 AppleJavaExtensions BSD jcommander Apache 2.0 high-scale-lib MIT hppc Apache 2.0 clover Paid stream Apache 2.0 metrics-core Apache 2.0 cassandra-driver-core Apache 2.0 cassandra-driver-core Apache 2.0 uuid MIT grabbag MIT speed4j Apache 2.0 yamlbeans BSD jackson-annotations Apache 2.0 jackson-core Apache 2.0 jackson-databind Apache 2.0 jackson-dataformat-cbor Apache 2.0 jackson-dataformat-csv Apache 2.0 jackson-dataformat-xml Apache 2.0 jackson-dataformat-yaml Apache 2.0 jackson-datatype-guava Apache 2.0 jackson-datatype-jdk7 Apache 2.0 jackson-datatype-jdk8 Apache 2.0 jackson-datatype-joda Apache 2.0 jackson-datatype-jsr310 Apache 2.0 jackson-jaxrs-base Apache 2.0 jackson-jaxrs-json-provider Apache 2.0 jackson-module-afterburner Apache 2.0 jackson-module-jaxb-annotations Apache 2.0 jackson-module-kotlin Apache 2.0 woodstox-core Apache 2.0 classmate Apache 2.0 zjsonpatch Apache 2.0 caffeine Apache 2.0 waffle-jna EPLv1.0 docker-java Apache 2.0 docker-java Apache 2.0 btf Apache 2.0 jackson-coreutils Apache 2.0 json-schema-core Apache 2.0 json-schema-validator Apache 2.0 msg-simple Apache 2.0 uri-template Apache 2.0 jamm Apache 2.0 jffi Apache 2.0 jnr-constants Apache 2.0 jnr-ffi Apache 2.0 jnr-ffi Apache 2.0 jnr-posix EPLv1.0 jnr-x86asm MIT embedded-redis Apache 2.0 memoryfilesystem MIT guava-retrying Apache 2.0 guava-retrying Apache 2.0 snowball-stemmer BSD system-rules CPL uuid Apache 2.0 wiremock Apache 2.0 auto-common Apache 2.0 annotations LGPLv2.1 annotations LGPLv2.1 bcel-findbugs LGPLv2.1 findbugs LGPLv2.1 jFormatString BSD jFormatString BSD jsr305 BSD jsr305 BSD jsr305 BSD gson Apache 2.0 spymemcached MIT guava-testlib Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guice-multibindings Apache 2.0 guice Apache 2.0 truth Apache 2.0 concurrent-trees Apache 2.0 concurrentlinkedhashmap-lru Apache 2.0 json-simple Apache 2.0 libphonenumber Apache 2.0 locality-uuid BSD h2 EPLv1.0 annotations Apache 2.0 json-path-assert Apache 2.0 json-path Apache 2.0 json-path Apache 2.0 jzlib BSD bonecp-provider Apache 2.0 bonecp Apache 2.0 junixsocket-common Apache 2.0 junixsocket-native-common Apache 2.0 disruptor Apache 2.0 geoip-api LGPLv2.1 c3p0 LGPLv2.1 mchange-commons-java LGPLv2.1 archaius-core Apache 2.0 hystrix-core Apache 2.0 hystrix-servo-metrics-publisher Apache 2.0 rxjava-core Apache 2.0 servo-core Apache 2.0 kafka-clients Apache 2.0 kafka_2.10 Apache 2.0 kafka_2.11 Apache 2.0 common-cassandra Apache 2.0 timeslice_utils New Relic mockito-kotlin MIT compress-lzf Apache 2.0 checkstyle Apache 2.0 dagger-compiler Apache 2.0 dagger Apache 2.0 okhttp Apache 2.0 okio Apache 2.0 javapoet Apache 2.0 javawriter Apache 2.0 jaxb-impl CDDLv1 thrift-server Apache 2.0 finagle-core_2.10 Apache 2.0 finagle-core_2.11 Apache 2.0 finagle-http_2.10 Apache 2.0 finagle-http_2.11 Apache 2.0 jsr166e Creative Commons util-app_2.10 Apache 2.0 util-app_2.11 Apache 2.0 util-cache_2.10 Apache 2.0 util-cache_2.11 Apache 2.0 util-codec_2.10 Apache 2.0 util-codec_2.11 Apache 2.0 util-collection_2.10 Apache 2.0 util-collection_2.11 Apache 2.0 util-core_2.10 Apache 2.0 util-core_2.11 Apache 2.0 util-function_2.10 Apache 2.0 util-function_2.11 Apache 2.0 util-hashing_2.10 Apache 2.0 util-hashing_2.11 Apache 2.0 util-jvm_2.10 Apache 2.0 util-jvm_2.11 Apache 2.0 util-lint_2.10 Apache 2.0 util-lint_2.11 Apache 2.0 util-logging_2.10 Apache 2.0 util-logging_2.11 Apache 2.0 util-registry_2.10 Apache 2.0 util-registry_2.11 Apache 2.0 util-stats_2.10 Apache 2.0 util-stats_2.11 Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 HikariCP Apache 2.0 commons-beanutils Apache 2.0 commons-cli Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-io Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 commons-pool Apache 2.0 unix-socket-factory Apache 2.0 unix-socket-factory Apache 2.0 jflex BSD dom4j BSD airline Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 metrics-healthchecks Apache 2.0 metrics-httpclient Apache 2.0 metrics-jdbi Apache 2.0 metrics-jersey2 Apache 2.0 metrics-jetty9 Apache 2.0 metrics-json Apache 2.0 metrics-jvm Apache 2.0 metrics-logback Apache 2.0 metrics-servlets Apache 2.0 dropwizard-java8-jdbi Apache 2.0 dropwizard-client Apache 2.0 dropwizard-configuration Apache 2.0 dropwizard-core Apache 2.0 dropwizard-db Apache 2.0 dropwizard-jackson Apache 2.0 dropwizard-jdbi Apache 2.0 dropwizard-jersey Apache 2.0 dropwizard-jetty Apache 2.0 dropwizard-lifecycle Apache 2.0 dropwizard-logging Apache 2.0 dropwizard-metrics Apache 2.0 dropwizard-servlets Apache 2.0 dropwizard-testing Apache 2.0 dropwizard-util Apache 2.0 dropwizard-validation Apache 2.0 netty-all Apache 2.0 netty-buffer Apache 2.0 netty-codec-http Apache 2.0 netty-codec-socks Apache 2.0 netty-codec Apache 2.0 netty-common Apache 2.0 netty-handler-proxy Apache 2.0 netty-handler Apache 2.0 netty-resolver Apache 2.0 netty-transport-native-epoll Apache 2.0 netty-transport Apache 2.0 netty Apache 2.0 ratpack-core Apache 2.0 ratpack-groovy-test Apache 2.0 ratpack-groovy Apache 2.0 ratpack-guice Apache 2.0 ratpack-test Apache 2.0 rxjava Apache 2.0 fastutil Apache 2.0 janino BSD activation Apache 2.0 javax.annotation-api CDDLv1 jsr250-api CDDLv1 javax.inject Apache 2.0 mail CDDLv1 mailapi CDDLv1 javax.servlet-api Apache 2.0 servlet-api Apache 2.0 javax.transaction-api CDDLv1 validation-api Apache 2.0 javax.websocket-api CDDLv1 javax.ws.rs-api CDDLv1 jaxb-api CDDLv1 stax-api CDDLv1 jaxen Apache 2.0 jline BSD jline BSD joda-time Apache 2.0 junit-dep CPL junit CPL junit EPLv1.0 kafka_2.10 Apache 2.0 kafka_2.9.2 Apache 2.0 apache-log4j-extras Apache 2.0 log4j Apache 2.0 mysql-connector-java GPLv2 with Classpath Exception byte-buddy Apache 2.0 byte-buddy Apache 2.0 jna-platform LGPLv2.1 jna Apache 2.0 jcip-annotations Apache 2.0 lz4 Apache 2.0 accessors-smart Apache 2.0 asm Apache 2.0 json-smart Apache 2.0 json-smart Apache 2.0 primitive GPLv2 with Classpath Exception compiler Apache 2.0 lang Apache 2.0 beaver-cc BSD ehcache-core Apache 2.0 ehcache Apache 2.0 jopt-simple MIT jopt-simple MIT opencsv Apache 2.0 quality-check Apache 2.0 scannotation Apache 2.0 super-csv Apache 2.0 uadetector-core Apache 2.0 uadetector-resources Apache 2.0 argparse4j MIT spymemcached MIT kalium Apache 2.0 ST4 BSD antlr-runtime BSD antlr-runtime BSD antlr BSD stringtemplate BSD ant-launcher Apache 2.0 ant Apache 2.0 cassandra-all Apache 2.0 cassandra-all Apache 2.0 cassandra-thrift Apache 2.0 cassandra-thrift Apache 2.0 commons-collections4 Apache 2.0 commons-compress Apache 2.0 commons-csv Apache 2.0 commons-dbcp2 Apache 2.0 commons-io Apache 2.0 commons-lang3 Apache 2.0 commons-math3 Apache 2.0 commons-math Apache 2.0 commons-pool2 Apache 2.0 curator-client Apache 2.0 curator-framework Apache 2.0 curator-recipes Apache 2.0 curator-test Apache 2.0 derby Apache 2.0 geronimo-servlet_3.0_spec Apache 2.0 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 ivy Apache 2.0 kafka-clients Apache 2.0 kafka_2.11 Apache 2.0 libthrift Apache 2.0 tomcat-embed-core Apache 2.0 tomcat-embed-el Apache 2.0 tomcat-embed-logging-juli Apache 2.0 tomcat-embed-websocket Apache 2.0 tomcat-jdbc Apache 2.0 tomcat-juli Apache 2.0 zookeeper Apache 2.0 aspectjweaver EPLv1.0 assertj-core Apache 2.0 assertj-core Apache 2.0 evo-inflector Apache 2.0 bcmail-jdk15on MIT bcpkix-jdk15on MIT bcprov-jdk15on MIT ohc-core Apache 2.0 cassandra-unit-spring LGPLv3 cassandra-unit-spring LGPLv3 cassandra-unit LGPLv3 cassandra-unit LGPLv3 groovy-all Apache 2.0 groovy-all Apache 2.0 groovy Apache 2.0 groovy Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 easymock Apache 2.0 ecj EPLv1.0 javax.activation CDDLv1 javax.annotation CDDLv1 javax.mail.glassfish CDDLv1 javax.servlet CDDLv1 javax.transaction CDDLv1 org.objectweb.asm BSD jetty-setuid-java EPLv1.0 jetty-schemas Apache 2.0 javax-websocket-client-impl Apache 2.0 javax-websocket-server-impl Apache 2.0 websocket-api Apache 2.0 websocket-client Apache 2.0 websocket-common Apache 2.0 websocket-server Apache 2.0 websocket-servlet Apache 2.0 apache-jsp Apache 2.0 jetty-annotations CDDLv1 jetty-client Apache 2.0 jetty-continuation Apache 2.0 jetty-http Apache 2.0 jetty-io Apache 2.0 jetty-jmx Apache 2.0 jetty-jndi Apache 2.0 jetty-plus Apache 2.0 jetty-proxy Apache 2.0 jetty-security Apache 2.0 jetty-server Apache 2.0 jetty-servlet Apache 2.0 jetty-servlets Apache 2.0 jetty-util Apache 2.0 jetty-webapp Apache 2.0 jetty-xml Apache 2.0 sigar Apache 2.0 aopalliance-repackaged CDDLv1 javax.inject CDDLv1 hk2-api CDDLv1 hk2-locator CDDLv1 hk2-utils CDDLv1 osgi-resource-locator CDDLv1 jersey-guava CDDLv1 jersey-client CDDLv1 jersey-apache-connector CDDLv1 jersey-container-servlet-core CDDLv1 jersey-container-servlet CDDLv1 jersey-client CDDLv1 jersey-common CDDLv1 jersey-server CDDLv1 jersey-bean-validation CDDLv1 jersey-metainf-services CDDLv1 jersey-media-jaxb CDDLv1 jersey-client CDDLv1 jersey-test-framework-provider-inmemory CDDLv1 jersey-test-framework-core CDDLv1 javax.el CDDLv1 hamcrest-all BSD hamcrest-core BSD hamcrest-integration BSD hamcrest-library BSD HdrHistogram Public Domain hector-core MIT hibernate-commons-annotations LGPLv2.1 hibernate-jpa-2.0-api LGPLv2.1 hibernate-jpa-2.1-api LGPLv2.1 hibernate-c3p0 Apache 2.0 hibernate-core Apache 2.0 hibernate-ehcache Apache 2.0 hibernate-entitymanager Apache 2.0 hibernate-jmx Apache 2.0 hibernate-validator Apache 2.0 freebuilder Apache 2.0 org.jacoco.agent EPLv1.0 org.jacoco.ant EPLv1.0 org.jacoco.core EPLv1.0 org.jacoco.report EPLv1.0 javassist Apache 2.0 jboss-logging-annotations LGPLv2.1 jboss-logging Apache 2.0 jboss-transaction-api_1.1_spec LGPLv2.1 jboss-transaction-api_1.2_spec LGPLv2.1 jandex Apache 2.0 jdbi Apache 2.0 job-dsl-core Apache 2.0 version-number MIT kotlin-annotation-processing Apache 2.0 kotlin-reflect Apache 2.0 kotlin-runtime Apache 2.0 kotlin-stdlib Apache 2.0 kotlin-test-junit Apache 2.0 kotlin-test Apache 2.0 annotations Apache 2.0 jolokia-core Apache 2.0 jruby-complete LGPLv2.1 LGPLv2.1 json Public Domain json Apache 2.0 xstream BSD annotations Apache 2.0 mapdb Apache 2.0 mapdb Apache 2.0 jbcrypt ISC mockserver-client-java Apache 2.0 mockserver-core Apache 2.0 mockserver-logging Apache 2.0 mockserver-netty Apache 2.0 mockito-all MIT mockito-core MIT mockito-core MIT apache-el Apache 2.0 apache-jsp Apache 2.0 alpn-boot Apache 2.0 etcd4j Apache 2.0 msgpack Apache 2.0 objenesis Apache 2.0 objenesis Apache 2.0 jmh-core GPLv2 with Classpath Exception jmh-generator-annprocess GPLv2 with Classpath Exception jol-core GPLv2 with Classpath Exception asm-analysis BSD asm-analysis BSD asm-commons BSD asm-debug-all BSD asm-tree BSD asm-util BSD asm-util BSD asm BSD asm Public Domain postgresql BSD powermock-api-mockito Apache 2.0 powermock-api-support Apache 2.0 powermock-core Apache 2.0 powermock-module-junit4-common Apache 2.0 powermock-module-junit4 Apache 2.0 powermock-reflect Apache 2.0 lombok MIT reactive-streams Public Domain reflections WTFPL scala-java8-compat_2.11 Scala scala-parser-combinators_2.11 Scala scala-xml_2.11 Scala scala-library Scala scala-reflect Scala scalatest_2.10 Apache 2.0 scalatest_2.11 Apache 2.0 native-lib-loader BSD jsonassert Apache 2.0 jcl-over-slf4j MIT jul-to-slf4j MIT log4j-log4j12 MIT log4j-over-slf4j MIT slf4j-api MIT slf4j-ext MIT slf4j-log4j12 MIT slf4j-simple MIT spock-core Apache 2.0 spock-core Apache 2.0 spring-boot-actuator Apache 2.0 spring-boot-autoconfigure Apache 2.0 spring-boot-configuration-processor Apache 2.0 spring-boot-starter-actuator Apache 2.0 spring-boot-starter-aop Apache 2.0 spring-boot-starter-data-jpa Apache 2.0 spring-boot-starter-data-rest Apache 2.0 spring-boot-starter-jdbc Apache 2.0 spring-boot-starter-jetty Apache 2.0 spring-boot-starter-logging Apache 2.0 spring-boot-starter-test Apache 2.0 spring-boot-starter-tomcat Apache 2.0 spring-boot-starter-web Apache 2.0 spring-boot-starter Apache 2.0 spring-boot-test-autoconfigure Apache 2.0 spring-boot-test Apache 2.0 spring-boot Apache 2.0 spring-data-commons Apache 2.0 spring-data-jpa Apache 2.0 spring-data-rest-core Apache 2.0 spring-data-rest-webmvc Apache 2.0 spring-hateoas Apache 2.0 spring-plugin-core Apache 2.0 spring-aop Apache 2.0 spring-aspects Apache 2.0 spring-beans Apache 2.0 spring-context-support Apache 2.0 spring-context Apache 2.0 spring-core Apache 2.0 spring-core Apache 2.0 spring-expression Apache 2.0 spring-jdbc Apache 2.0 spring-orm Apache 2.0 spring-test Apache 2.0 spring-test Apache 2.0 spring-tx Apache 2.0 spring-web Apache 2.0 spring-webmvc Apache 2.0 xz Public Domain wasabi Apache 2.0 snappy-java Apache 2.0 xmlunit-core Apache 2.0 xmlunit-legacy Apache 2.0 snakeyaml Apache 2.0 JUnitParams Apache 2.0 postgresql BSD postgresql BSD jedis MIT scala-library Scala ion-java Apache 2.0 timeslice_service-thrift New Relic timeslice_service New Relic xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3_min Public Domain zkclient Apache 2.0 zookeeper Apache 2.0 CoffeeScript Library License CoffeeScript MIT coffin MIT JavaScript JavaScript License ie_html5/ie_html5.js MIT Angular.js MIT Angular UI directives for Bootstrap MIT Chart.js MIT Chosen JQuery plugin MIT Fullcalendar MIT Moment MIT Crash reporting Software License Apple OS X OS X Yosemite Xcode & Apple SDK Xcode license Label services Service License BoneCP Apache 2.0 Gradle Apache 2.0 Hibernate Apache 2.0 Spring Apache 2.0 Infrastructure Monitoring services Service License antlr BSD aopalliance Public Domain asm MIT cglib Apache 2.0 ch.qos.logback EPLv1.0 com.101tec Apache 2.0 com.amazonaws Apache 2.0 com.cenqua.clover Paid com.fasterxml.jackson.core Apache 2.0 com.fasterxml Apache 2.0 com.google.code.findbugs BSD com.google.guava Apache 2.0 com.googlecode.json-simple Apache 2.0 com.intellij Apache 2.0 New Relic com.squareup.dagger Apache 2.0 com.squareup Apache 2.0 com.yammer.metrics Apache 2.0 commons-codec Apache 2.0 commons-configuration Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 dom4j BSD io.netty Apache 2.0 javax.annotation CDDLv1 javax.inject Apache 2.0 javax.servlet.jsp CDDLv1 javax.servlet Apache 2.0 javax.validation Apache 2.0 javax.websocket CDDLv1 jline BSD joda-time Apache 2.0 junit CPL log4j Apache 2.0 mysql GPLv2 with Classpath Exception net.sf.jopt-simple MIT org.apache.commons Apache 2.0 org.apache.httpcomponents Apache 2.0 org.apache.ivy Apache 2.0 org.apache.thrift Apache 2.0 org.apache.tomcat.embed Apache 2.0 org.apache.zookeeper Apache 2.0 org.codehaus.groovy Apache 2.0 org.codehaus.jackson Apache 2.0 org.easymock Apache 2.0 org.eclipse.jetty.orbit CDDLv1 org.eclipse.jetty.toolchain Apache 2.0 org.eclipse.jetty.websocket Apache 2.0 org.eclipse.jetty CDDLv1 org.glassfish.jersey.core CDDLv1 org.glassfish.web CDDLv1 org.glassfish CDDLv1 org.hamcrest BSD org.hibernate Apache 2.0 org.javassist Apache 2.0 org.jboss.logging LGPLv2.1 org.jenkins-ci.plugins Apache 2.0 org.jenkins-ci Apache 2.0 org.jetbrains Apache 2.0 org.jolokia Apache 2.0 org.jvnet.hudson BSD org.mockito MIT org.objenesis Apache 2.0 org.ow2.asm MIT org.reflections WTFPL org.scala-lang Scala org.slf4j MIT org.springframework.boot Apache 2.0 org.springframework Apache 2.0 org.xerial.snappy Apache 2.0 org.yaml Apache 2.0 xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3 Public Domain .NET support uploader service Library License Amazon AWS SDK for Java Apache 2.0 Apache Commons Codec Apache 2.0 Gson Apache 2.0 Jetty Apache 2.0 Ruby gems Ruby gems Gem License aasm MIT actionmailer MIT actionpack MIT activeadmin MIT actionview MIT activejob MIT active_model_serializers MIT activemodel MIT activerecord MIT activerecord-deprecated_finders MIT activerecord-mysql2-adapter MIT activeresource MIT activesupport MIT addressable Apache 2.0 angularjs-rails MIT arbre MIT arel MIT arel MIT atomic Apache 2.0 atomic Apache-2.0 attr_required MIT awesome_print MIT backports MIT better_errors MIT binding_of_caller MIT bourbon MIT brwsr MIT browser-timezone-rails MIT builder MIT bundler MIT byebug MIT callsite MIT capistrano MIT capistrano-bundler MIT capistrano-ext MIT capistrano-rbenv MIT capistrano-stats MIT capybara MIT celluloid MIT CFPropertyList MIT chunky_png MIT ci_reporter MIT ci_reporter_rspec MIT clockwork MIT codeclimate-test-reporter MIT coderay MIT coderay MIT coffee-rails MIT coffee-script MIT coffee-script-source MIT columnize Ruby compass MIT compass-core MIT compass-import-once MIT compass-rails MIT concurrent-ruby MIT crack MIT crypt Unlicensed daemons MIT dalli MIT database_cleaner MIT debug_inspector MIT debugger-linecache MIT diff-lcs MIT docile MIT dotenv MIT dotenv-deployment MIT erubis MIT etcd MIT ethon MIT eventmachine Ruby excon MIT execjs MIT factory_girl MIT factory_girl_rails MIT faraday MIT faraday-middleware MIT faye-websocket MIT ffi MIT ffi BSD fission MIT fog MIT fog-atmos MIT fog-aws MIT fog-brightbox MIT fog-core MIT fog-ecloud MIT fog-google MIT fog-json MIT fog-local MIT fog-powerdns MIT fog-profitbricks MIT fog-radosgw MIT fog-riakcs MIT fog-sakuracloud MIT fog-serverlove MIT fog-softlayer MIT fog-storm_on_demand MIT fog-terremark MIT fog-vmfusion MIT fog-voxel MIT fog-xml MIT font-awesome-rails MIT foreman MIT formatador MIT formtastic MIT formtastic i18n MIT fssm MIT globalid MIT guard MIT guard-rspec MIT haml MIT haml-rails MIT has scope MIT hashie MIT highline Ruby hike MIT hipchat-api MIT histogram MIT hitimes ISC hiredis BSD http_parser.rb MIT httpclient Ruby httpclient Ruby httparty MIT i18n MIT inflecto MIT inherited resources MIT intercom-rails MIT ipaddress MIT jasmine MIT jasmine-core MIT jasmine-rails MIT jbuilder MIT jira MIT jira-ruby OSL-3.0 journey MIT jquery-rails MIT jquery-turbolinks MIT jquery-ui-rails MIT json Ruby jwt MIT kaminari MIT kgio LGPLv3 kgio LGPLv3 kgio LGPL-v2.1+ libv8 MIT listen MIT logger Ruby loofah MIT lumberjack MIT macaddr MIT mail MIT mailcatcher MIT memoist MIT metaclass MIT meta_request MIT method_source MIT mime-types MIT mini_portile MIT minitest MIT minitest-rails MIT mixlib-log Apache 2.0 mocha MIT mono_logger MIT multi_json MIT multi_xml MIT multipart-post MIT mysql2 MIT net-http-persistent MIT net-scp MIT net-sftp MIT net-ssh MIT net-ssh-gateway MIT netrc MIT nokogiri MIT oauth2 MIT oj MIT omniauth MIT omniauth-oauth2 MIT pagerduty MIT papers MIT pg BSD pg Ruby phantomjs BSD phantomjs-binaries Unlicensed poltergeist MIT polyamorous MIT polyglot MIT polyglot MIT protected_attributes MIT pry MIT pry-nav MIT pry-rails MIT pry-stack_explorer MIT puma BSD quiet assets MIT rack MIT rack-cache MIT rack-contrib MIT rack-oauth2 MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-ssl MIT rack-ssl-enforcer MIT rack-test MIT rails MIT rails-deprecated_sanitizer MIT rails-dom-testing MIT rails-html-sanitizer MIT rails-observers MIT rails_12factor MIT rails_serve_static_assets MIT rails_stdout_logging MIT railties MIT raindrops LGPLv3 raindrops LGPLv3 raindrops LGPLv2.1+ rake MIT rake MIT rake MIT rake MIT ransack MIT rb-fsevent MIT rb-inotify MIT rdoc Ruby redcarpet MIT redis MIT redis-namespace MIT redis-queue MIT ref MIT remote_syslog_logger MIT request_store MIT responders MIT resque MIT resque-cleaner MIT resque-pool MIT resque-scheduler MIT resque-status MIT rest-client MIT restforce MIT rspec MIT rspec-core MIT rspec-expectations MIT rspec-mocks MIT rspec-rails MIT rspec-support MIT rspec_junit_formatter MIT rubyntlm MIT ruby-saml MIT rufus-scheduler MIT safe_yaml MIT salesforce_bulk_query BSD sass MIT sass-rails MIT sass-rails MIT sdoc MIT secure_headers Apache 2.0 sequel MIT serveza MIT settingslogic MIT shoulda MIT shoulda-context MIT shoulda-matchers MIT simplecov MIT simplecov-html MIT simplecov-rcov MIT sinatra MIT sinatra-activerecord MIT sinatra-contrib MIT skinny MIT slop MIT spring MIT sprockets MIT sprockets-rails MIT sqlite3 BSD sshkit GPL-No Distro sys-uname Ruby syslog_protocol MIT systemu BSDL term-ansicolor GPL-No Distro terminal-table MIT therubyracer MIT thin Ruby thor MIT thread_safe Apache-2.0 thrift Apache 2.0 thrift-rack MIT tilt MIT timecop MIT timers MIT tins MIT treetop MIT turbolinks MIT twitter-bootstrap-rails MIT typhoeus MIT tzinfo MIT uglifier MIT unicorn Ruby unicorn-rails MIT uuid MIT uuidtools Apache-2.0 vegas MIT webmock MIT web-console MIT xml-simple Ruby xpath MIT yard MIT Storage services Library License Amazon AWS SDK for Java Apache 2.0 Amazon AWS Command Line Interface Apache 2.0 Go packages Library License Go-Mysql-Driver Mozilla Public License 2.0 gocql BSD 3-Clause groupcache Apache 2.0 Migrate MIT go-sqlite3 MIT Revel MIT Pathtree MIT Ansicolor MIT fsnotify BSD 3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.99942,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Services <em>licenses</em>",
        "sections": "Services <em>licenses</em>",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Contents Java internal"
      },
      "id": "603ea24364441f91fb4e8864"
    },
    {
      "sections": [
        "Add-on end user license agreement",
        "New Relic, Inc. Add-on End User License Agreement"
      ],
      "title": "Add-on end user license agreement",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "a01c225ca30f95dab7db856cd946c76de557c31f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/add-end-user-license-agreement/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-03-16T06:19:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic, Inc. Add-on End User License Agreement In connection with the work provided by New Relic's Expert Services, Field Instrumentation Team, or Sales team, you may be provided with certain custom-created software to visualize, enable, optimize, or enhance your use of New Relic's Services. By downloading, installing, authorizing installation, or using the Add-on (defined below) with your Underlying Software (defined below), you (“Customer”) agree to the terms and conditions herein (“Agreement”) with New Relic, Inc., a Delaware corporation with offices located at 188 Spear Street, Suite 1200 San Francisco, CA 94105 (“New Relic\"), (collectively the “Parties”). Capitalized terms not defined herein shall have the meanings set forth in the New Relic Terms of Service (the “Terms of Service”) available here: newrelic.com/termsandconditions/terms. IF YOU DO NOT AGREE TO THIS AGREEMENT, YOUR SOLE REMEDY IS TO NOT USE THE ADD-ON. 1. DEFINITIONS “Add-on” means the New Relic applications and/or software, including but not limited to connectors, extensions, UI extension, and plugins, provided by New Relic to Customer to enable the Services to operate with certain third party or Customer software or systems (“Underlying Software”). For the purposes of the Terms of Service, the Add-on shall be treated like an Agent, subject to the separate terms herein. 2. USE OF THE PROGRAMMABILITY ADD-ON 2.1 Software Evaluation License. Subject to the terms herein, New Relic grants to Customer a limited, non-exclusive, non-transferrable, non-sublicensable right to install, use, and configure the Add-on solely as needed to enable the Services for internal evaluation purposes. New Relic reserves all rights and licenses not expressly granted herein. 2.2 Ownership. As between the Parties, New Relic owns all right, title, and interest to the Add-on and Feedback, including but not limited to any intellectual property and proprietary rights therein. Customer retains all right, title, and interest in any Customer Data processed by the Add-on in connection with the Services. 2.3 Feedback. Customer agrees to provide feedback, suggestions, ideas, requests or recommendations (“Feedback”) regarding the Add-on, and hereby irrevocably assigns all intellectual property and proprietary rights it holds in the Feedback to New Relic. 2.4 Notice. Customer acknowledges and agrees that the Add-on is made to work with the Underlying Software as configured at the time of creation and there is no guarantee that Add-on will continue to work in the event Customer changes, replaces, upgrades versions of, updates, or otherwise changes the Underlying Software (an “Upgrade Event”). Customer shall hold New Relic harmless from any claims or damages arising from Customer’s Upgrade Event. 2.5 Restrictions. Customer will not: (i) use the Add-on except as permitted hereunder; (ii) distribute, sell, sublicense, or otherwise transfer the Add-on; (iii) decompile, disassemble or reverse engineer any software underlying the Add-on; (iv) use the Add-on to damage, disable, overburden or impair any New Relic server or network(s) connected to any New Relic server or interfere with any other party’s use and enjoyment of the Services; (v) use the Add-on to defraud, defame, abuse, harass, stalk, threaten or infringe the rights of privacy or other intellectual property rights of others or otherwise violate any applicable law; (vi) circumvent or modify any security technologies included as part of the Add-on; or (vii) attempt or permit any third party to do any of the foregoing. New Relic may suspend Customer usage of the Services, without notice, pending any investigation of misuse. These restrictions may be supplemented or superceded (to the extent they conflict) by the New Relic Acceptable Use Policy as may be published and updated from time to time on the New Relic web site at docs.newrelic.com/docs/licenses/license-information/acceptable-use-policy/acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. “Confidential Information” means: (a) the Programmability Add-on, and any features, results or output produced by, and other information relating to the Add-on (including, without limitation, all Feedback); and (b) any business or technical information of New Relic including but not limited to any technical information, research, development, know-how that a reasonable person would understand to be confidential. 3.2 Restrictions. Customer will not use or disclose any Confidential Information, except as necessary for the performance of this Agreement. Customer will use all reasonable efforts to protect Confidential Information from unauthorized use or disclosure, but in no event less than the efforts that it ordinarily uses with respect to its own proprietary information. Customer may disclose Confidential Information to those of its employees who have a bona fide need to know such Confidential Information for the performance of this Agreement; provided that each such employee first executes a written agreement that contains use and nondisclosure restrictions at least as protective as those set forth herein. Confidential Information shall not include any information that: (a) is or becomes generally known to the public through no fault or breach of this Agreement by Customer; (b) is rightfully known by Customer at the time of disclosure without an obligation of confidentiality; (c) is independently developed by Customer without access or use of any Confidential Information; or (d) is rightfully obtained from a third party without restriction on use or disclosure. 4. DISCLAIMER 4.1 DISCLAIMER. THE ADD-ON IS PROVIDED AS-IS AND AS-AVAILABLE AND NEW RELIC DISCLAIMS AND MAKES NO WARRANTIES, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE OR NON-INFRINGEMENT AND WHETHER OR NOT ARISING THROUGH A COURSE OF DEALING. THE ADD-ON IS NOT GUARANTEED TO BE ERROR-FREE, COMPATIBLE WITH THE UNDERLYING SOFTWARE, OR THAT CUSTOMER WILL ACHIEVE ANY RESULTS FROM USE OF THE ADD-ON THEREFROM. 4.2 LIMITATION OF LIABILITY. TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC, ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE TO CUSTOMER OR ANY THIRD PARTY FOR DAMAGES OF ANY KIND, INCLUDING, WITHOUT LIMITATION, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE INSTALLATION, USE OR INABILITY TO USE THE ADD-ON OR FOR ANY ERROR OR DEFECT IN THE ADD-ON OR THE SERVICES, REGARDLESS OF LEGAL THEORY, WHETHER OR NOT NEW RELIC HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSS OR DAMAGE. NEW RELIC’S AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS AGREEMENT WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE PARTIES HAVE AGREED THAT THESE LIMITATIONS WILL SURVIVE AND APPLY EVEN IF ANY LIMITED REMEDY SPECIFIED IN THIS AGREEMENT IS FOUND TO HAVE FAILED OF ITS ESSENTIAL PURPOSE. THE LIMITATIONS OF DAMAGES SET FORTH ABOVE ARE FUNDAMENTAL ELEMENTS OF THE BASIS OF THE BARGAIN BETWEEN NEW RELIC AND CUSTOMER. 4.3 EVALUATION VERSION. Customer agrees and acknowledges that: (a) the Add-on is not an official product and has not been commercially released for sale by New Relic; (b) the Add-on may not operate properly, being in final form, or fully functional; (c) the Add-on may contain errors, security vulnerabilities, design flaws, or other problems; (d) it may not be possible to make the Add-on fully functional; (e) the information obtained using the Add-on may not be accurate; (f) use of the Add-on may result in unexpected results, loss of data, delays or other unpredictable damages or loss; (g) New Relic is under no obligation to release a commercial version of the Add-on; and (h) New Relic has the right unilaterally to abandon development of the Add-on, at any time and without any obligation or liability to Customer. 5. GENERAL PROVISIONS 5.1 Terms of Service; Documentation. This Agreement shall be considered a part of the New Relic documentation, located at: https://docs.newrelic.com (the “Documentation). This Agreement and the Terms of Service constitute the entire and exclusive agreement between New Relic and Customer with respect to the Add-on. In the absence of a separate agreement, upon agreement between New Relic and Customer with respect to the Add-On, the terms and conditions of this Agreement shall govern the relationship between New Relic and Customer with respect to such Add-On. To the extent of a conflict between the Agreement and the Terms of Service, this Agreement shall govern with respect to the Add-on only.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.36885,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add-on end user <em>license</em> agreement",
        "sections": "Add-on end user <em>license</em> agreement",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": "&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;acceptable-use-policy&#x2F;acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. “Confidential <em>Information</em>” means: (a) the Programmability Add-on, and any features, results or output produced by, and other <em>information</em> relating to the Add-on (including, without limitation"
      },
      "id": "603ec23328ccbccf1beba79a"
    },
    {
      "sections": [
        "FIT instrumentation end user license agreement"
      ],
      "title": "FIT instrumentation end user license agreement",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "e8e10baf120678407d08c9f78ab708d271cf0223",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/fit-instrumentation-end-user-license-agreement/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NEW RELIC, INC. FIT INSTRUMENTATION END USER LICENSE AGREEMENT In connection with the work provided by New Relic’s Field Instrumentation Team, you may be provided with certain custom-created software to enable, optimize, or enhance your use of New Relic’s Services. By downloading, installing, authorizing installation, or using the FIT Instrumentation with your Underlying Software (defined below), you (“Customer”) agree to the terms and conditions herein (“Agreement”) with New Relic, Inc., a Delaware corporation with offices located at 188 Spear Street, Suite 1200 San Francisco, CA 94105 (“New Relic”), (collectively the “Parties”). Capitalized terms not defined herein shall have the meanings set forth in the New Relic Terms of Service (the “Terms of Service”) available here: http://newrelic.com/terms IF YOU DO NOT AGREE TO THIS AGREEMENT, PLEASE DO NOT USE THE FIT INSTRUMENTATION. 1. DEFINITIONS “FIT Instrumentation” means the New Relic custom-made software, including but not limited to connectors, extensions, and plugins, provided by New Relic to Customer to enable the Services to operate with certain third party or Customer software or systems (“Underlying Software”). For the purposes of the Terms of Service, the FIT Instrumentation shall be treated like an “Agent”, subject to the separate terms herein. 2. USE OF THE FIT INSTRUMENTATION 2.1 Software Evaluation License. Subject to the terms herein, New Relic grants to Customer a limited, non-exclusive, non-transferrable, non-sublicensable right to install, use, and configure the FIT Instrumentation solely as needed to enable the Services for internal evaluation purposes. New Relic reserves all rights and licenses not expressly granted herein. 2.2 Ownership. As between the Parties, New Relic owns all right, title, and interest to the FIT Instrumentation and Feedback, including but not limited to any intellectual property and proprietary rights therein. Customer retains all right, title, and interest in any Customer Data processed by the FIT Instrumentation in connection with the Services. 2.3 Feedback. Customer agrees to provide feedback, suggestions, ideas, requests or recommendations (“Feedback”) regarding the FIT Instrumentation, and hereby irrevocably assigns all intellectual property and proprietary rights it holds in the Feedback to New Relic. 2.4 Notice. Customer acknowledges and agrees that the FIT Instrumentation is made to work with the Underlying Software as configured at the time of creation and there is no guarantee that FIT Instrumentation will continue to work in the event Customer changes, replaces, upgrades versions of, updates, or otherwise changes the Underlying Software (an “Upgrade Event”). Customer shall hold New Relic harmless from any claims or damages arising from Customer’s Upgrade Event. 2.5 Restrictions. Customer will not: (i) use the FIT Instrumentation except as permitted hereunder; (ii) distribute, sell, sublicense, or otherwise transfer the FIT Instrumentation; (iii) decompile, disassemble or reverse engineer any software underlying the FIT Instrumentation; (iv) use the FIT Instrumentation to damage, disable, overburden or impair any New Relic server or network(s) connected to any New Relic server or interfere with any other party’s use and enjoyment of the Services; (v) use the FIT Instrumentation to defraud, defame, abuse, harass, stalk, threaten or infringe the rights of privacy or other intellectual property rights of others or otherwise violate any applicable law; (vi) circumvent or modify any security technologies included as part of the FIT Instrumentation; or (vii) attempt or permit any third party to do any of the foregoing. New Relic may suspend usage of the Services by any user, without notice, pending any investigation of misuse.  These restrictions may be supplemented or superceded (to the extent they conflict) by the New Relic Acceptable Use Policy as may be published and updated from time to time at https://docs.newrelic.com/docs/licenses/license-information/acceptable-use-policy/acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. “Confidential Information” means: (a) the FIT Instrumentation, and any features, results or output produced by, and other information relating to the FIT Instrumentation (including, without limitation, all Feedback); and (b) any business or technical information of New Relic including but not limited to any technical information, research, development, know-how that a reasonable person would understand to be confidential. 3.2 Restrictions. Customer will not use or disclose any Confidential Information, except as necessary for the performance of this Agreement. Customer will use all reasonable efforts to protect Confidential Information from unauthorized use or disclosure, but in no event less than the efforts that it ordinarily uses with respect to its own proprietary information. Customer may disclose Confidential Information to those of its employees who have a bona fide need to know such Confidential Information for the performance of this Agreement; provided that each such employee first executes a written agreement that contains use and nondisclosure restrictions at least as protective as those set forth herein. Confidential Information shall not include any information that: (a) is or becomes generally known to the public through no fault or breach of this Agreement by Customer; (b) is rightfully known by Customer at the time of disclosure without an obligation of confidentiality; (c) is independently developed by Customer without access or use of any Confidential Information; or (d) is rightfully obtained from a third party without restriction on use or disclosure. 4. DISCLAIMER 4.1 DISCLAIMER. FIT INSTRUMENTATION IS PROVIDED AS-IS AND AS-AVAILABLE AND NEW RELIC DISCLAIMS AND MAKES NO WARRANTIES, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE OR NON-INFRINGEMENT AND WHETHER OR NOT ARISING THROUGH A COURSE OF DEALING. FIT INSTRUMENTATION IS NOT GUARANTEED TO BE ERROR-FREE, COMPATIBLE WITH THE UNDERLYING SOFTWARE. , OR THAT CUSTOMER WILL ACHIEVE ANY RESULTS FROM USE OF THE FIT INSTRUMENTATION THEREFROM. SOME JURISDICTIONS DO NOT ALLOW THE EXCLUSION OF IMPLIED WARRANTIES OR LIMITATIONS ON APPLICABLE STATUTORY RIGHTS OF A CONSUMER, SO THE ABOVE EXCLUSION AND LIMITATIONS MAY NOT APPLY TO THE CUSTOMER. 4.2 LIMITATION OF LIABILITY. TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE TO CUSTOMER OR ANY THIRD PARTY FOR DAMAGES OF ANY KIND, INCLUDING, WITHOUT LIMITATION, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE INSTALLATION, USE OR INABILITY TO USE THE FIT INSTRUMENTATION OR FOR ANY ERROR OR DEFECT IN THE FIT INSTRUMENTATION OR THE SERVICES, WHETHER SUCH LIABILITY ARISES FROM ANY CLAIM BASED UPON CONTRACT, WARRANTY, TORT, STRICT LIABILITY, OR OTHERWISE, WHETHER OR NOT NEW RELIC HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSS OR DAMAGE. NEW RELIC'S AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS AGREEMENT WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE PARTIES HAVE AGREED THAT THESE LIMITATIONS WILL SURVIVE AND APPLY EVEN IF ANY LIMITED REMEDY SPECIFIED IN THIS AGREEMENT IS FOUND TO HAVE FAILED OF ITS ESSENTIAL PURPOSE. 4.3 EVALUATION VERSION. Customer agrees and acknowledges that: (a) the FIT Instrumentation is not an official product and has not been commercially released for sale by New Relic; (b) the FIT Instrumentation may not operate properly, being in final form, or fully functional; (c) the FIT Instrumentation may contain errors, security vulnerabilities, design flaws, or other problems; (d) it may not be possible to make the FIT Instrumentation fully functional; (e) the information obtained using the FIT Instrumentation may not be accurate; (f) use of the FIT Instrumentation may result in unexpected results, loss of data, delays or other unpredictable damages or loss; (g) New Relic is under no obligation to release a commercial version of the FIT Instrumentation; and (h) New Relic has the right unilaterally to abandon development of the FIT Instrumentation, at any time and without any obligation or liability to Customer. 5. GENERAL PROVISIONS 5.1 Terms of Service; Documentation. This Agreement shall be considered a part of the New Relic documentation, located at: https://docs.newrelic.com (the \"Documentation\").This Agreement and the Terms of Service constitute the entire and exclusive agreement between New Relic and Customer with respect to the FIT Instrumentation. In the absence of a separate agreement between New Relic and Customer with respect to the FIT Instrumentation, the terms and conditions of this Agreement shall govern the relationship between New Relic and Customer with respect to such FIT Instrumentation.  To the extent of a conflict between the Agreement and the Terms of Service, this Agreement shall govern with respect to the FIT Instrumentation only.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.32553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "FIT instrumentation end user <em>license</em> agreement",
        "sections": "FIT instrumentation end user <em>license</em> agreement",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": " Acceptable Use Policy as may be published and updated from time to time at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;acceptable-use-policy&#x2F;acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. “Confidential <em>Information</em>” means: (a) the FIT Instrumentation, and any features, results"
      },
      "id": "603e9f3ee7b9d206e32a0800"
    }
  ],
  "/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions": [
    {
      "sections": [
        "New Relic One pricing: Definitions",
        "Account",
        "Commitment Term",
        "Customer Data",
        "Customer Properties",
        "Documentation",
        "GB Ingested",
        "Login Credentials",
        "Monthly Provisioned User",
        "Order",
        "Paid Terms of Service",
        "Product(s)",
        "Software",
        "Terms",
        "Third-Party Services",
        "Unpaid Terms of Service",
        "Usage Plan"
      ],
      "title": "New Relic One pricing: Definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "609575acd671fecf7899378157eabc57bc8d68e2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-04-22T16:06:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for organizations on our New Relic One pricing plan. For terms used in our original pricing plan, see Original pricing plan definitions. Account Account refers to the online account or subaccounts that New Relic provides for customers to manage their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, information, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer Properties Customer Properties means Customer’s websites, infrastructure, networks, mobile applications, or other systems, as well as Customer accounts on Third-Party Services. Documentation Documentation means the New Relic technical guides and documentation made available from the dedicated ‘Documentation’ page of the New Relic website. GB Ingested A GB Ingested is a measurement of the volume of metrics, events, logs, traces, or other telemetry data sent to or generated by the Products for the benefit of the Customer, including from the Software, the Customer Properties, or Third-Party Services. In this context, a GB is defined as 1 billion bytes. Login Credentials Login Credentials means the username, email address, password, or other personal information that is provided by a Customer user in order to manage an Account. Monthly Provisioned User A Monthly Provisioned User is any user who can log into Customer’s Account(s) and access the New Relic One Product functionality as specified in an Order and the Documentation. Order Order means the purchasing order for access to the Service or related services that: (1) is either executed by the Parties or entered into by you via self-service, and references this Agreement, or (2) is entered into by you and a Channel Partner. Paid Terms of Service Paid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/paid. Product(s) Product(s) mean the purchase of the New Relic subscription products described in the applicable Order and any updates, corrections, bug fixes, modifications, improvements, related services, new features, and functionality (made generally available to New Relic’s customer base) thereto. Software Software means the distributed software, APIs, scripts, or other code proprietary to New Relic provided with the Products. Terms Terms means the underlying Customer-New Relic agreement and the Order. Third-Party Services Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/unpaid. Usage Plan Usage Plan refers to the Service or Product pricing, invoicing related information, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.71135,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": " their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, <em>information</em>, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third"
      },
      "id": "6044e6e528ccbc26f22c6084"
    },
    {
      "sections": [
        "Original product-based pricing definitions",
        "App",
        "App transaction",
        "AWS Lambda event",
        "Check",
        "Compute unit",
        "Datapoints per minute",
        "Event",
        "Host",
        "Incident event",
        "Page view",
        "Per GB daily",
        "Span",
        "User"
      ],
      "title": "Original product-based pricing definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "42087e53167736831855bf9a4c2967c465677b45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/legacy-product-definitions/",
      "published_at": "2021-05-05T16:22:53Z",
      "updated_at": "2021-04-22T16:04:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our original product-based pricing. For New Relic One pricing plan terms, see New Relic One pricing definitions. App An app means the application software designed to run on smartphones, tablet computers, and other mobile devices. Each app includes a predefined number of users. App transaction An app transaction is an APM application's attempt to process a web or non-web request. In APM these manifest as throughput TIMESERIES or individually as events in the Transaction event type. AWS Lambda event An AWS Lambda event means the row of data collected from the customer's AWS Lambda function by the New Relic agent or sent from an external service into the New Relic platform. It consists of the AwsLambdaInvocation, AwsLambdaInvocationError, or custom event types. Check A check means the single instance of a Synthetics monitor running in New Relic's monitoring network and reporting back response time, and whether the check was a success or failure. Compute unit A compute unit means the measure of resources associated with a unit of computation on a physical or virtual host. Datapoints per minute Datapoints per minute (DPM) refers to the per-minute rate at which individual metric values are sent to the New Relic Metric Ingest API. For billing purposes, datapoints per minute are calculated as a monthly average value by summing the datapoints ingested during a 30 day period and dividing by the number of minutes in that period (43,200). Event An event means the row of data collected from the customer's application by the New Relic agent or sent from an external service into the Insights event database. Host A host means the physical computer or virtual machine instance running a single copy of an operating system. Host usage is tracked monthly by summing the hours that every host in the account is connected to New Relic and dividing by 750. A host is counted if it is connected any time during an hour. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic AI platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Page view A page view means the full page load (triggering an onLoad event) or a recorded URL change (state change). Per GB daily Per GB daily represents a daily average of Log data sent to New Relic over a 30 day period. Span A span represents an operation summary collected from the customer's application via the New Relic APM agent or New Relic Serverless for AWS Lambda agent, or sent from other tracing tools to the New Relic Trace API. User A user means the individual that connects to your app from a single device. Each unique device is considered as a unique user.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.70958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ebacc64441f77774e8872"
    },
    {
      "sections": [
        "Services licenses",
        "Contents",
        "Java internal services",
        "Java crash data API",
        "CoffeeScript",
        "JavaScript",
        "Crash reporting",
        "Label services",
        "Infrastructure Monitoring services",
        ".NET support uploader service",
        "Ruby gems",
        "Storage services",
        "Go packages"
      ],
      "title": "Services licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "49a2ad450d31dacfc2aae690ca947d2326d18761",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/other-licenses/services-licenses/",
      "published_at": "2021-05-05T16:28:24Z",
      "updated_at": "2021-04-06T00:26:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Contents Java internal services Java crash data API Framework License Apache TomCat Apache 2.0 Bean Validation Apache 2.0 Cassandra Driver Core Apache 2.0 ClassMate Apache 2.0 Hamcrest BSD Mockito MIT Netty Apache 2.0 Objenesis MIT SnakeYAML Apache 2.0 Spring Boot Apache 2.0 Java internal services Library License json_simple Apache 2.0 newrelic-api New Relic newrelic-api New Relic antlr BSD aopalliance Public Domain asm-analysis BSD asm-commons BSD asm-tree BSD asm-util BSD asm BSD c3p0 EPLv1.0 cglib-nodep Apache 2.0 cglib Apache 2.0 cglib Apache 2.0 cal10n-api MIT logback-classic EPLv1.0 logback-core EPLv1.0 guava-jetty-service Apache 2.0 zkclient Apache 2.0 reporter-config-base Apache 2.0 reporter-config3 Apache 2.0 reporter-config Apache 2.0 aws-java-sdk-acm Apache 2.0 aws-java-sdk-api-gateway Apache 2.0 aws-java-sdk-applicationautoscaling Apache 2.0 aws-java-sdk-autoscaling Apache 2.0 aws-java-sdk-cloudformation Apache 2.0 aws-java-sdk-cloudfront Apache 2.0 aws-java-sdk-cloudhsm Apache 2.0 aws-java-sdk-cloudsearch Apache 2.0 aws-java-sdk-cloudtrail Apache 2.0 aws-java-sdk-cloudwatch Apache 2.0 aws-java-sdk-cloudwatchmetrics Apache 2.0 aws-java-sdk-codecommit Apache 2.0 aws-java-sdk-codedeploy Apache 2.0 aws-java-sdk-codepipeline Apache 2.0 aws-java-sdk-cognitoidentity Apache 2.0 aws-java-sdk-cognitoidp Apache 2.0 aws-java-sdk-cognitosync Apache 2.0 aws-java-sdk-config Apache 2.0 aws-java-sdk-core Apache 2.0 aws-java-sdk-datapipeline Apache 2.0 aws-java-sdk-devicefarm Apache 2.0 aws-java-sdk-directconnect Apache 2.0 aws-java-sdk-directory Apache 2.0 aws-java-sdk-discovery Apache 2.0 aws-java-sdk-dms Apache 2.0 aws-java-sdk-dynamodb Apache 2.0 aws-java-sdk-ec2 Apache 2.0 aws-java-sdk-ecr Apache 2.0 aws-java-sdk-ecs Apache 2.0 aws-java-sdk-efs Apache 2.0 aws-java-sdk-elasticache Apache 2.0 aws-java-sdk-elasticbeanstalk Apache 2.0 aws-java-sdk-elasticloadbalancing Apache 2.0 aws-java-sdk-elasticloadbalancingv2 Apache 2.0 aws-java-sdk-elasticsearch Apache 2.0 aws-java-sdk-elastictranscoder Apache 2.0 aws-java-sdk-emr Apache 2.0 aws-java-sdk-events Apache 2.0 aws-java-sdk-gamelift Apache 2.0 aws-java-sdk-glacier Apache 2.0 aws-java-sdk-iam Apache 2.0 aws-java-sdk-importexport Apache 2.0 aws-java-sdk-inspector Apache 2.0 aws-java-sdk-iot Apache 2.0 aws-java-sdk-kinesis Apache 2.0 aws-java-sdk-kms Apache 2.0 aws-java-sdk-lambda Apache 2.0 aws-java-sdk-logs Apache 2.0 aws-java-sdk-machinelearning Apache 2.0 aws-java-sdk-marketplacecommerceanalytics Apache 2.0 aws-java-sdk-marketplacemeteringservice Apache 2.0 aws-java-sdk-models Apache 2.0 aws-java-sdk-opsworks Apache 2.0 aws-java-sdk-rds Apache 2.0 aws-java-sdk-redshift Apache 2.0 aws-java-sdk-route53 Apache 2.0 aws-java-sdk-s3 Apache 2.0 aws-java-sdk-servicecatalog Apache 2.0 aws-java-sdk-ses Apache 2.0 aws-java-sdk-simpledb Apache 2.0 aws-java-sdk-simpleworkflow Apache 2.0 aws-java-sdk-snowball Apache 2.0 aws-java-sdk-sns Apache 2.0 aws-java-sdk-sqs Apache 2.0 aws-java-sdk-ssm Apache 2.0 aws-java-sdk-storagegateway Apache 2.0 aws-java-sdk-sts Apache 2.0 aws-java-sdk-support Apache 2.0 aws-java-sdk-swf-libraries Apache 2.0 aws-java-sdk-waf Apache 2.0 aws-java-sdk-workspaces Apache 2.0 aws-java-sdk Apache 2.0 jmespath-java Apache 2.0 AppleJavaExtensions BSD jcommander Apache 2.0 high-scale-lib MIT hppc Apache 2.0 clover Paid stream Apache 2.0 metrics-core Apache 2.0 cassandra-driver-core Apache 2.0 cassandra-driver-core Apache 2.0 uuid MIT grabbag MIT speed4j Apache 2.0 yamlbeans BSD jackson-annotations Apache 2.0 jackson-core Apache 2.0 jackson-databind Apache 2.0 jackson-dataformat-cbor Apache 2.0 jackson-dataformat-csv Apache 2.0 jackson-dataformat-xml Apache 2.0 jackson-dataformat-yaml Apache 2.0 jackson-datatype-guava Apache 2.0 jackson-datatype-jdk7 Apache 2.0 jackson-datatype-jdk8 Apache 2.0 jackson-datatype-joda Apache 2.0 jackson-datatype-jsr310 Apache 2.0 jackson-jaxrs-base Apache 2.0 jackson-jaxrs-json-provider Apache 2.0 jackson-module-afterburner Apache 2.0 jackson-module-jaxb-annotations Apache 2.0 jackson-module-kotlin Apache 2.0 woodstox-core Apache 2.0 classmate Apache 2.0 zjsonpatch Apache 2.0 caffeine Apache 2.0 waffle-jna EPLv1.0 docker-java Apache 2.0 docker-java Apache 2.0 btf Apache 2.0 jackson-coreutils Apache 2.0 json-schema-core Apache 2.0 json-schema-validator Apache 2.0 msg-simple Apache 2.0 uri-template Apache 2.0 jamm Apache 2.0 jffi Apache 2.0 jnr-constants Apache 2.0 jnr-ffi Apache 2.0 jnr-ffi Apache 2.0 jnr-posix EPLv1.0 jnr-x86asm MIT embedded-redis Apache 2.0 memoryfilesystem MIT guava-retrying Apache 2.0 guava-retrying Apache 2.0 snowball-stemmer BSD system-rules CPL uuid Apache 2.0 wiremock Apache 2.0 auto-common Apache 2.0 annotations LGPLv2.1 annotations LGPLv2.1 bcel-findbugs LGPLv2.1 findbugs LGPLv2.1 jFormatString BSD jFormatString BSD jsr305 BSD jsr305 BSD jsr305 BSD gson Apache 2.0 spymemcached MIT guava-testlib Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guice-multibindings Apache 2.0 guice Apache 2.0 truth Apache 2.0 concurrent-trees Apache 2.0 concurrentlinkedhashmap-lru Apache 2.0 json-simple Apache 2.0 libphonenumber Apache 2.0 locality-uuid BSD h2 EPLv1.0 annotations Apache 2.0 json-path-assert Apache 2.0 json-path Apache 2.0 json-path Apache 2.0 jzlib BSD bonecp-provider Apache 2.0 bonecp Apache 2.0 junixsocket-common Apache 2.0 junixsocket-native-common Apache 2.0 disruptor Apache 2.0 geoip-api LGPLv2.1 c3p0 LGPLv2.1 mchange-commons-java LGPLv2.1 archaius-core Apache 2.0 hystrix-core Apache 2.0 hystrix-servo-metrics-publisher Apache 2.0 rxjava-core Apache 2.0 servo-core Apache 2.0 kafka-clients Apache 2.0 kafka_2.10 Apache 2.0 kafka_2.11 Apache 2.0 common-cassandra Apache 2.0 timeslice_utils New Relic mockito-kotlin MIT compress-lzf Apache 2.0 checkstyle Apache 2.0 dagger-compiler Apache 2.0 dagger Apache 2.0 okhttp Apache 2.0 okio Apache 2.0 javapoet Apache 2.0 javawriter Apache 2.0 jaxb-impl CDDLv1 thrift-server Apache 2.0 finagle-core_2.10 Apache 2.0 finagle-core_2.11 Apache 2.0 finagle-http_2.10 Apache 2.0 finagle-http_2.11 Apache 2.0 jsr166e Creative Commons util-app_2.10 Apache 2.0 util-app_2.11 Apache 2.0 util-cache_2.10 Apache 2.0 util-cache_2.11 Apache 2.0 util-codec_2.10 Apache 2.0 util-codec_2.11 Apache 2.0 util-collection_2.10 Apache 2.0 util-collection_2.11 Apache 2.0 util-core_2.10 Apache 2.0 util-core_2.11 Apache 2.0 util-function_2.10 Apache 2.0 util-function_2.11 Apache 2.0 util-hashing_2.10 Apache 2.0 util-hashing_2.11 Apache 2.0 util-jvm_2.10 Apache 2.0 util-jvm_2.11 Apache 2.0 util-lint_2.10 Apache 2.0 util-lint_2.11 Apache 2.0 util-logging_2.10 Apache 2.0 util-logging_2.11 Apache 2.0 util-registry_2.10 Apache 2.0 util-registry_2.11 Apache 2.0 util-stats_2.10 Apache 2.0 util-stats_2.11 Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 HikariCP Apache 2.0 commons-beanutils Apache 2.0 commons-cli Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-io Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 commons-pool Apache 2.0 unix-socket-factory Apache 2.0 unix-socket-factory Apache 2.0 jflex BSD dom4j BSD airline Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 metrics-healthchecks Apache 2.0 metrics-httpclient Apache 2.0 metrics-jdbi Apache 2.0 metrics-jersey2 Apache 2.0 metrics-jetty9 Apache 2.0 metrics-json Apache 2.0 metrics-jvm Apache 2.0 metrics-logback Apache 2.0 metrics-servlets Apache 2.0 dropwizard-java8-jdbi Apache 2.0 dropwizard-client Apache 2.0 dropwizard-configuration Apache 2.0 dropwizard-core Apache 2.0 dropwizard-db Apache 2.0 dropwizard-jackson Apache 2.0 dropwizard-jdbi Apache 2.0 dropwizard-jersey Apache 2.0 dropwizard-jetty Apache 2.0 dropwizard-lifecycle Apache 2.0 dropwizard-logging Apache 2.0 dropwizard-metrics Apache 2.0 dropwizard-servlets Apache 2.0 dropwizard-testing Apache 2.0 dropwizard-util Apache 2.0 dropwizard-validation Apache 2.0 netty-all Apache 2.0 netty-buffer Apache 2.0 netty-codec-http Apache 2.0 netty-codec-socks Apache 2.0 netty-codec Apache 2.0 netty-common Apache 2.0 netty-handler-proxy Apache 2.0 netty-handler Apache 2.0 netty-resolver Apache 2.0 netty-transport-native-epoll Apache 2.0 netty-transport Apache 2.0 netty Apache 2.0 ratpack-core Apache 2.0 ratpack-groovy-test Apache 2.0 ratpack-groovy Apache 2.0 ratpack-guice Apache 2.0 ratpack-test Apache 2.0 rxjava Apache 2.0 fastutil Apache 2.0 janino BSD activation Apache 2.0 javax.annotation-api CDDLv1 jsr250-api CDDLv1 javax.inject Apache 2.0 mail CDDLv1 mailapi CDDLv1 javax.servlet-api Apache 2.0 servlet-api Apache 2.0 javax.transaction-api CDDLv1 validation-api Apache 2.0 javax.websocket-api CDDLv1 javax.ws.rs-api CDDLv1 jaxb-api CDDLv1 stax-api CDDLv1 jaxen Apache 2.0 jline BSD jline BSD joda-time Apache 2.0 junit-dep CPL junit CPL junit EPLv1.0 kafka_2.10 Apache 2.0 kafka_2.9.2 Apache 2.0 apache-log4j-extras Apache 2.0 log4j Apache 2.0 mysql-connector-java GPLv2 with Classpath Exception byte-buddy Apache 2.0 byte-buddy Apache 2.0 jna-platform LGPLv2.1 jna Apache 2.0 jcip-annotations Apache 2.0 lz4 Apache 2.0 accessors-smart Apache 2.0 asm Apache 2.0 json-smart Apache 2.0 json-smart Apache 2.0 primitive GPLv2 with Classpath Exception compiler Apache 2.0 lang Apache 2.0 beaver-cc BSD ehcache-core Apache 2.0 ehcache Apache 2.0 jopt-simple MIT jopt-simple MIT opencsv Apache 2.0 quality-check Apache 2.0 scannotation Apache 2.0 super-csv Apache 2.0 uadetector-core Apache 2.0 uadetector-resources Apache 2.0 argparse4j MIT spymemcached MIT kalium Apache 2.0 ST4 BSD antlr-runtime BSD antlr-runtime BSD antlr BSD stringtemplate BSD ant-launcher Apache 2.0 ant Apache 2.0 cassandra-all Apache 2.0 cassandra-all Apache 2.0 cassandra-thrift Apache 2.0 cassandra-thrift Apache 2.0 commons-collections4 Apache 2.0 commons-compress Apache 2.0 commons-csv Apache 2.0 commons-dbcp2 Apache 2.0 commons-io Apache 2.0 commons-lang3 Apache 2.0 commons-math3 Apache 2.0 commons-math Apache 2.0 commons-pool2 Apache 2.0 curator-client Apache 2.0 curator-framework Apache 2.0 curator-recipes Apache 2.0 curator-test Apache 2.0 derby Apache 2.0 geronimo-servlet_3.0_spec Apache 2.0 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 ivy Apache 2.0 kafka-clients Apache 2.0 kafka_2.11 Apache 2.0 libthrift Apache 2.0 tomcat-embed-core Apache 2.0 tomcat-embed-el Apache 2.0 tomcat-embed-logging-juli Apache 2.0 tomcat-embed-websocket Apache 2.0 tomcat-jdbc Apache 2.0 tomcat-juli Apache 2.0 zookeeper Apache 2.0 aspectjweaver EPLv1.0 assertj-core Apache 2.0 assertj-core Apache 2.0 evo-inflector Apache 2.0 bcmail-jdk15on MIT bcpkix-jdk15on MIT bcprov-jdk15on MIT ohc-core Apache 2.0 cassandra-unit-spring LGPLv3 cassandra-unit-spring LGPLv3 cassandra-unit LGPLv3 cassandra-unit LGPLv3 groovy-all Apache 2.0 groovy-all Apache 2.0 groovy Apache 2.0 groovy Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 easymock Apache 2.0 ecj EPLv1.0 javax.activation CDDLv1 javax.annotation CDDLv1 javax.mail.glassfish CDDLv1 javax.servlet CDDLv1 javax.transaction CDDLv1 org.objectweb.asm BSD jetty-setuid-java EPLv1.0 jetty-schemas Apache 2.0 javax-websocket-client-impl Apache 2.0 javax-websocket-server-impl Apache 2.0 websocket-api Apache 2.0 websocket-client Apache 2.0 websocket-common Apache 2.0 websocket-server Apache 2.0 websocket-servlet Apache 2.0 apache-jsp Apache 2.0 jetty-annotations CDDLv1 jetty-client Apache 2.0 jetty-continuation Apache 2.0 jetty-http Apache 2.0 jetty-io Apache 2.0 jetty-jmx Apache 2.0 jetty-jndi Apache 2.0 jetty-plus Apache 2.0 jetty-proxy Apache 2.0 jetty-security Apache 2.0 jetty-server Apache 2.0 jetty-servlet Apache 2.0 jetty-servlets Apache 2.0 jetty-util Apache 2.0 jetty-webapp Apache 2.0 jetty-xml Apache 2.0 sigar Apache 2.0 aopalliance-repackaged CDDLv1 javax.inject CDDLv1 hk2-api CDDLv1 hk2-locator CDDLv1 hk2-utils CDDLv1 osgi-resource-locator CDDLv1 jersey-guava CDDLv1 jersey-client CDDLv1 jersey-apache-connector CDDLv1 jersey-container-servlet-core CDDLv1 jersey-container-servlet CDDLv1 jersey-client CDDLv1 jersey-common CDDLv1 jersey-server CDDLv1 jersey-bean-validation CDDLv1 jersey-metainf-services CDDLv1 jersey-media-jaxb CDDLv1 jersey-client CDDLv1 jersey-test-framework-provider-inmemory CDDLv1 jersey-test-framework-core CDDLv1 javax.el CDDLv1 hamcrest-all BSD hamcrest-core BSD hamcrest-integration BSD hamcrest-library BSD HdrHistogram Public Domain hector-core MIT hibernate-commons-annotations LGPLv2.1 hibernate-jpa-2.0-api LGPLv2.1 hibernate-jpa-2.1-api LGPLv2.1 hibernate-c3p0 Apache 2.0 hibernate-core Apache 2.0 hibernate-ehcache Apache 2.0 hibernate-entitymanager Apache 2.0 hibernate-jmx Apache 2.0 hibernate-validator Apache 2.0 freebuilder Apache 2.0 org.jacoco.agent EPLv1.0 org.jacoco.ant EPLv1.0 org.jacoco.core EPLv1.0 org.jacoco.report EPLv1.0 javassist Apache 2.0 jboss-logging-annotations LGPLv2.1 jboss-logging Apache 2.0 jboss-transaction-api_1.1_spec LGPLv2.1 jboss-transaction-api_1.2_spec LGPLv2.1 jandex Apache 2.0 jdbi Apache 2.0 job-dsl-core Apache 2.0 version-number MIT kotlin-annotation-processing Apache 2.0 kotlin-reflect Apache 2.0 kotlin-runtime Apache 2.0 kotlin-stdlib Apache 2.0 kotlin-test-junit Apache 2.0 kotlin-test Apache 2.0 annotations Apache 2.0 jolokia-core Apache 2.0 jruby-complete LGPLv2.1 LGPLv2.1 json Public Domain json Apache 2.0 xstream BSD annotations Apache 2.0 mapdb Apache 2.0 mapdb Apache 2.0 jbcrypt ISC mockserver-client-java Apache 2.0 mockserver-core Apache 2.0 mockserver-logging Apache 2.0 mockserver-netty Apache 2.0 mockito-all MIT mockito-core MIT mockito-core MIT apache-el Apache 2.0 apache-jsp Apache 2.0 alpn-boot Apache 2.0 etcd4j Apache 2.0 msgpack Apache 2.0 objenesis Apache 2.0 objenesis Apache 2.0 jmh-core GPLv2 with Classpath Exception jmh-generator-annprocess GPLv2 with Classpath Exception jol-core GPLv2 with Classpath Exception asm-analysis BSD asm-analysis BSD asm-commons BSD asm-debug-all BSD asm-tree BSD asm-util BSD asm-util BSD asm BSD asm Public Domain postgresql BSD powermock-api-mockito Apache 2.0 powermock-api-support Apache 2.0 powermock-core Apache 2.0 powermock-module-junit4-common Apache 2.0 powermock-module-junit4 Apache 2.0 powermock-reflect Apache 2.0 lombok MIT reactive-streams Public Domain reflections WTFPL scala-java8-compat_2.11 Scala scala-parser-combinators_2.11 Scala scala-xml_2.11 Scala scala-library Scala scala-reflect Scala scalatest_2.10 Apache 2.0 scalatest_2.11 Apache 2.0 native-lib-loader BSD jsonassert Apache 2.0 jcl-over-slf4j MIT jul-to-slf4j MIT log4j-log4j12 MIT log4j-over-slf4j MIT slf4j-api MIT slf4j-ext MIT slf4j-log4j12 MIT slf4j-simple MIT spock-core Apache 2.0 spock-core Apache 2.0 spring-boot-actuator Apache 2.0 spring-boot-autoconfigure Apache 2.0 spring-boot-configuration-processor Apache 2.0 spring-boot-starter-actuator Apache 2.0 spring-boot-starter-aop Apache 2.0 spring-boot-starter-data-jpa Apache 2.0 spring-boot-starter-data-rest Apache 2.0 spring-boot-starter-jdbc Apache 2.0 spring-boot-starter-jetty Apache 2.0 spring-boot-starter-logging Apache 2.0 spring-boot-starter-test Apache 2.0 spring-boot-starter-tomcat Apache 2.0 spring-boot-starter-web Apache 2.0 spring-boot-starter Apache 2.0 spring-boot-test-autoconfigure Apache 2.0 spring-boot-test Apache 2.0 spring-boot Apache 2.0 spring-data-commons Apache 2.0 spring-data-jpa Apache 2.0 spring-data-rest-core Apache 2.0 spring-data-rest-webmvc Apache 2.0 spring-hateoas Apache 2.0 spring-plugin-core Apache 2.0 spring-aop Apache 2.0 spring-aspects Apache 2.0 spring-beans Apache 2.0 spring-context-support Apache 2.0 spring-context Apache 2.0 spring-core Apache 2.0 spring-core Apache 2.0 spring-expression Apache 2.0 spring-jdbc Apache 2.0 spring-orm Apache 2.0 spring-test Apache 2.0 spring-test Apache 2.0 spring-tx Apache 2.0 spring-web Apache 2.0 spring-webmvc Apache 2.0 xz Public Domain wasabi Apache 2.0 snappy-java Apache 2.0 xmlunit-core Apache 2.0 xmlunit-legacy Apache 2.0 snakeyaml Apache 2.0 JUnitParams Apache 2.0 postgresql BSD postgresql BSD jedis MIT scala-library Scala ion-java Apache 2.0 timeslice_service-thrift New Relic timeslice_service New Relic xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3_min Public Domain zkclient Apache 2.0 zookeeper Apache 2.0 CoffeeScript Library License CoffeeScript MIT coffin MIT JavaScript JavaScript License ie_html5/ie_html5.js MIT Angular.js MIT Angular UI directives for Bootstrap MIT Chart.js MIT Chosen JQuery plugin MIT Fullcalendar MIT Moment MIT Crash reporting Software License Apple OS X OS X Yosemite Xcode & Apple SDK Xcode license Label services Service License BoneCP Apache 2.0 Gradle Apache 2.0 Hibernate Apache 2.0 Spring Apache 2.0 Infrastructure Monitoring services Service License antlr BSD aopalliance Public Domain asm MIT cglib Apache 2.0 ch.qos.logback EPLv1.0 com.101tec Apache 2.0 com.amazonaws Apache 2.0 com.cenqua.clover Paid com.fasterxml.jackson.core Apache 2.0 com.fasterxml Apache 2.0 com.google.code.findbugs BSD com.google.guava Apache 2.0 com.googlecode.json-simple Apache 2.0 com.intellij Apache 2.0 New Relic com.squareup.dagger Apache 2.0 com.squareup Apache 2.0 com.yammer.metrics Apache 2.0 commons-codec Apache 2.0 commons-configuration Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 dom4j BSD io.netty Apache 2.0 javax.annotation CDDLv1 javax.inject Apache 2.0 javax.servlet.jsp CDDLv1 javax.servlet Apache 2.0 javax.validation Apache 2.0 javax.websocket CDDLv1 jline BSD joda-time Apache 2.0 junit CPL log4j Apache 2.0 mysql GPLv2 with Classpath Exception net.sf.jopt-simple MIT org.apache.commons Apache 2.0 org.apache.httpcomponents Apache 2.0 org.apache.ivy Apache 2.0 org.apache.thrift Apache 2.0 org.apache.tomcat.embed Apache 2.0 org.apache.zookeeper Apache 2.0 org.codehaus.groovy Apache 2.0 org.codehaus.jackson Apache 2.0 org.easymock Apache 2.0 org.eclipse.jetty.orbit CDDLv1 org.eclipse.jetty.toolchain Apache 2.0 org.eclipse.jetty.websocket Apache 2.0 org.eclipse.jetty CDDLv1 org.glassfish.jersey.core CDDLv1 org.glassfish.web CDDLv1 org.glassfish CDDLv1 org.hamcrest BSD org.hibernate Apache 2.0 org.javassist Apache 2.0 org.jboss.logging LGPLv2.1 org.jenkins-ci.plugins Apache 2.0 org.jenkins-ci Apache 2.0 org.jetbrains Apache 2.0 org.jolokia Apache 2.0 org.jvnet.hudson BSD org.mockito MIT org.objenesis Apache 2.0 org.ow2.asm MIT org.reflections WTFPL org.scala-lang Scala org.slf4j MIT org.springframework.boot Apache 2.0 org.springframework Apache 2.0 org.xerial.snappy Apache 2.0 org.yaml Apache 2.0 xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3 Public Domain .NET support uploader service Library License Amazon AWS SDK for Java Apache 2.0 Apache Commons Codec Apache 2.0 Gson Apache 2.0 Jetty Apache 2.0 Ruby gems Ruby gems Gem License aasm MIT actionmailer MIT actionpack MIT activeadmin MIT actionview MIT activejob MIT active_model_serializers MIT activemodel MIT activerecord MIT activerecord-deprecated_finders MIT activerecord-mysql2-adapter MIT activeresource MIT activesupport MIT addressable Apache 2.0 angularjs-rails MIT arbre MIT arel MIT arel MIT atomic Apache 2.0 atomic Apache-2.0 attr_required MIT awesome_print MIT backports MIT better_errors MIT binding_of_caller MIT bourbon MIT brwsr MIT browser-timezone-rails MIT builder MIT bundler MIT byebug MIT callsite MIT capistrano MIT capistrano-bundler MIT capistrano-ext MIT capistrano-rbenv MIT capistrano-stats MIT capybara MIT celluloid MIT CFPropertyList MIT chunky_png MIT ci_reporter MIT ci_reporter_rspec MIT clockwork MIT codeclimate-test-reporter MIT coderay MIT coderay MIT coffee-rails MIT coffee-script MIT coffee-script-source MIT columnize Ruby compass MIT compass-core MIT compass-import-once MIT compass-rails MIT concurrent-ruby MIT crack MIT crypt Unlicensed daemons MIT dalli MIT database_cleaner MIT debug_inspector MIT debugger-linecache MIT diff-lcs MIT docile MIT dotenv MIT dotenv-deployment MIT erubis MIT etcd MIT ethon MIT eventmachine Ruby excon MIT execjs MIT factory_girl MIT factory_girl_rails MIT faraday MIT faraday-middleware MIT faye-websocket MIT ffi MIT ffi BSD fission MIT fog MIT fog-atmos MIT fog-aws MIT fog-brightbox MIT fog-core MIT fog-ecloud MIT fog-google MIT fog-json MIT fog-local MIT fog-powerdns MIT fog-profitbricks MIT fog-radosgw MIT fog-riakcs MIT fog-sakuracloud MIT fog-serverlove MIT fog-softlayer MIT fog-storm_on_demand MIT fog-terremark MIT fog-vmfusion MIT fog-voxel MIT fog-xml MIT font-awesome-rails MIT foreman MIT formatador MIT formtastic MIT formtastic i18n MIT fssm MIT globalid MIT guard MIT guard-rspec MIT haml MIT haml-rails MIT has scope MIT hashie MIT highline Ruby hike MIT hipchat-api MIT histogram MIT hitimes ISC hiredis BSD http_parser.rb MIT httpclient Ruby httpclient Ruby httparty MIT i18n MIT inflecto MIT inherited resources MIT intercom-rails MIT ipaddress MIT jasmine MIT jasmine-core MIT jasmine-rails MIT jbuilder MIT jira MIT jira-ruby OSL-3.0 journey MIT jquery-rails MIT jquery-turbolinks MIT jquery-ui-rails MIT json Ruby jwt MIT kaminari MIT kgio LGPLv3 kgio LGPLv3 kgio LGPL-v2.1+ libv8 MIT listen MIT logger Ruby loofah MIT lumberjack MIT macaddr MIT mail MIT mailcatcher MIT memoist MIT metaclass MIT meta_request MIT method_source MIT mime-types MIT mini_portile MIT minitest MIT minitest-rails MIT mixlib-log Apache 2.0 mocha MIT mono_logger MIT multi_json MIT multi_xml MIT multipart-post MIT mysql2 MIT net-http-persistent MIT net-scp MIT net-sftp MIT net-ssh MIT net-ssh-gateway MIT netrc MIT nokogiri MIT oauth2 MIT oj MIT omniauth MIT omniauth-oauth2 MIT pagerduty MIT papers MIT pg BSD pg Ruby phantomjs BSD phantomjs-binaries Unlicensed poltergeist MIT polyamorous MIT polyglot MIT polyglot MIT protected_attributes MIT pry MIT pry-nav MIT pry-rails MIT pry-stack_explorer MIT puma BSD quiet assets MIT rack MIT rack-cache MIT rack-contrib MIT rack-oauth2 MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-ssl MIT rack-ssl-enforcer MIT rack-test MIT rails MIT rails-deprecated_sanitizer MIT rails-dom-testing MIT rails-html-sanitizer MIT rails-observers MIT rails_12factor MIT rails_serve_static_assets MIT rails_stdout_logging MIT railties MIT raindrops LGPLv3 raindrops LGPLv3 raindrops LGPLv2.1+ rake MIT rake MIT rake MIT rake MIT ransack MIT rb-fsevent MIT rb-inotify MIT rdoc Ruby redcarpet MIT redis MIT redis-namespace MIT redis-queue MIT ref MIT remote_syslog_logger MIT request_store MIT responders MIT resque MIT resque-cleaner MIT resque-pool MIT resque-scheduler MIT resque-status MIT rest-client MIT restforce MIT rspec MIT rspec-core MIT rspec-expectations MIT rspec-mocks MIT rspec-rails MIT rspec-support MIT rspec_junit_formatter MIT rubyntlm MIT ruby-saml MIT rufus-scheduler MIT safe_yaml MIT salesforce_bulk_query BSD sass MIT sass-rails MIT sass-rails MIT sdoc MIT secure_headers Apache 2.0 sequel MIT serveza MIT settingslogic MIT shoulda MIT shoulda-context MIT shoulda-matchers MIT simplecov MIT simplecov-html MIT simplecov-rcov MIT sinatra MIT sinatra-activerecord MIT sinatra-contrib MIT skinny MIT slop MIT spring MIT sprockets MIT sprockets-rails MIT sqlite3 BSD sshkit GPL-No Distro sys-uname Ruby syslog_protocol MIT systemu BSDL term-ansicolor GPL-No Distro terminal-table MIT therubyracer MIT thin Ruby thor MIT thread_safe Apache-2.0 thrift Apache 2.0 thrift-rack MIT tilt MIT timecop MIT timers MIT tins MIT treetop MIT turbolinks MIT twitter-bootstrap-rails MIT typhoeus MIT tzinfo MIT uglifier MIT unicorn Ruby unicorn-rails MIT uuid MIT uuidtools Apache-2.0 vegas MIT webmock MIT web-console MIT xml-simple Ruby xpath MIT yard MIT Storage services Library License Amazon AWS SDK for Java Apache 2.0 Amazon AWS Command Line Interface Apache 2.0 Go packages Library License Go-Mysql-Driver Mozilla Public License 2.0 gocql BSD 3-Clause groupcache Apache 2.0 Migrate MIT go-sqlite3 MIT Revel MIT Pathtree MIT Ansicolor MIT fsnotify BSD 3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.98354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Services <em>licenses</em>",
        "sections": "Services <em>licenses</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Contents Java internal"
      },
      "id": "603ea24364441f91fb4e8864"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/acceptable-use-policy": [
    {
      "sections": [
        "The People's Republic of China"
      ],
      "title": "The People's Republic of China",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "c3c078b8139d695b928d2001cd6c6c9318c43599",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/peoples-republic-china/",
      "published_at": "2021-05-05T16:26:05Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Information Regarding the People’s Republic of China and the Use of New Relic New Relic is not authorized to do business in the People’s Republic of China (“PRC”). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory requirements in the PRC. New Relic does not provide support for, including but not limited to, the deployment, access, or use of the Service(s) or Software in the PRC, or otherwise in respect of assets in the PRC (“PRC Use”). Without overriding any express prohibitions that you may have agreed to as part of your agreement with New Relic, you (and you as an agent of the respective New Relic Customer (\"Customer\")) acknowledge that any PRC use is subject to the PRC national firewall system and may be subject to outages and other interference outside of the control of New Relic. Accordingly, you acknowledge and agree (on behalf of yourself and including any Customer on whose behalf you use the Service(s) or Software) that any PRC Use is at your sole risk and is fully excepted from all representations and warranties, including, but not limited to, any terms that assure the confidentiality, integrity, availability or privacy of your data. New Relic makes no other representations and hereby expressly disclaims any and all warranties in respect of PRC Use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.63385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "Important <em>Information</em> Regarding the People’s Republic of China and the Use of New Relic New Relic is not authorized to do business in the People’s Republic of China (“PRC”). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory"
      },
      "id": "603eb3a328ccbcb488eba76b"
    },
    {
      "sections": [
        "New Relic data usage limits and policies",
        "Overview of limits",
        "View limits and manage data",
        "Account-level limits",
        "Data ingest APIs",
        "Other agent and integration limits",
        "Manage data"
      ],
      "title": "New Relic data usage limits and policies",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "fc32c25b40a030ffa0fad6bfc95be7fca1360ee1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies/",
      "published_at": "2021-05-05T16:19:47Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data usage spikes in one New Relic account from impacting other customers' accounts, we have various data volume and rate limits in place. We reserve the right to enforce these limits to protect our system and to avoid issues for you and other customers. If your New Relic account, whether by configuration or by error, exceeds one of these limits, it or its sub-accounts might experience one or both of the following: Sampling of data Temporary pause or cessation of data collection To learn more about how hitting a limit can affect your data, see View limits. If you have further questions about these limits, your contract, or a limit you've reached, contact your New Relic account representative. We can work with you to adjust any rate limits to meet your needs. View limits and manage data Want to understand your account’s limit violations using the UI? See View limits. Want to manage your data for organization or billing purposes? See Manage data. Account-level limits The following table includes general max limits that apply across all New Relic accounts. Specific New Relic tools, like agents and integrations, have their own limits and configurations, and might be lower than these theoretical maximum limits. Limited condition Limit Rate of NRDB record * ingest 55 million per account per minute Max NRDB records * ingested per API call 1MB (10^6 bytes) Max attribute value size 1KB (10^3 bytes) Max payload size 1MB (10^6 bytes) Max total attributes per data type (including default attributes) 254 (less for some tools; for example, 64 for agents) Number of unique custom data types 250 per account per day (applies to custom events because that's source of new data types) APM limits Agent instances: 50K per account Agent instances per app: 10K APM apps/services: 10K per second Browser: number of page views 1M per minute per app Rate of metric timeslice data (used by APM, browser, mobile) Ingest: 2 million per minute Rate of names: 4 million per minute per account Number per monitored app: 300K Mobile monitoring: number of crashes reported 10K per hour Infrastructure agents, integrations Number of infrastructure agents and/or integrations: 5K per account Gross number of new monitored containers: 5K per hour per account Query limits NRDB records * inspected: 100 billion per account per hour Rate of queries: 20 per account per second See other query limits * NRDB records refers to database records for our core data types, which includes events, metrics (dimensional), logs, and distributed tracing (span) data, all stored in the New Relic database (NRDB). This does not include metric timeslice data. Data ingest APIs Our ingest APIs have additional limits that may override the more general account-level limits. Note that these limits also apply to our tools that use these APIs (like our Telemetry SDKs or our open source telemetry integrations). Metric API (dimensional metrics) Event API Log API Trace API Other agent and integration limits To find limits for our other agents and integrations, which will override more general account-level limits, see the docs for those tools: you can search our solutions here. Some default reporting limits are located in these tools' configuration docs. Manage data Want to manage your New Relic data ingest and storage to improve data organization or reduce billing? See Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.6249,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic data <em>usage</em> limits and policies",
        "sections": "New Relic data <em>usage</em> limits and policies",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data <em>usage</em> spikes in one New Relic account from impacting other"
      },
      "id": "603eb1c528ccbc0311eba7c7"
    },
    {
      "sections": [
        "Government addendum",
        "New Relic, Inc.Government Addendum"
      ],
      "title": "Government addendum",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "cfed51b7f4f7583476f56b2b574204d38493e882",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/government-addendum/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The below Government Addendum applies only to customers that are United States federal, state, or local government customers with an existing New Relic agreement in place that explicitly references this Government Addendum applying to the Service purchased in an Order. Capitalized terms not defined below shall take on the meaning set forth in such New Relic agreement. New Relic, Inc.Government Addendum For purposes of this Agreement and to the extent applicable, the Service is \"commercial computer software\" and a \"commercially available off-the-shelf (COTS) item\" as defined at FAR 2.101 developed at the private expense of New Relic. If acquired by or on behalf of a civilian agency, the U.S. Government acquires this commercial computer software and/or commercial computer software documentation and other technical data subject to the terms of the Agreement as specified in 48 C.F.R. 12.212 (Computer Software) and 12.211 (Technical Data) of the Federal Acquisition Regulation (\"FAR\") and its successors. If acquired by or on behalf of any agency within the Department of Defense (\"DOD\"), the U.S. Government acquires this commercial computer software and/or commercial computer software documentation subject to the terms of the Agreement as specified in 48 C.F.R. 227.7202-3 of the DOD FAR Supplement (\"DFARS\") and its successors. This addendum is in lieu of and supersedes any other FAR, DFARS, or other clause or provision that addresses government rights in computer software or technical data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.6249,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>"
      },
      "id": "603ea47ee7b9d2dd0d2a07ef"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings": [
    {
      "sections": [
        "The People's Republic of China"
      ],
      "title": "The People's Republic of China",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "c3c078b8139d695b928d2001cd6c6c9318c43599",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/peoples-republic-china/",
      "published_at": "2021-05-05T16:26:05Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Information Regarding the People’s Republic of China and the Use of New Relic New Relic is not authorized to do business in the People’s Republic of China (“PRC”). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory requirements in the PRC. New Relic does not provide support for, including but not limited to, the deployment, access, or use of the Service(s) or Software in the PRC, or otherwise in respect of assets in the PRC (“PRC Use”). Without overriding any express prohibitions that you may have agreed to as part of your agreement with New Relic, you (and you as an agent of the respective New Relic Customer (\"Customer\")) acknowledge that any PRC use is subject to the PRC national firewall system and may be subject to outages and other interference outside of the control of New Relic. Accordingly, you acknowledge and agree (on behalf of yourself and including any Customer on whose behalf you use the Service(s) or Software) that any PRC Use is at your sole risk and is fully excepted from all representations and warranties, including, but not limited to, any terms that assure the confidentiality, integrity, availability or privacy of your data. New Relic makes no other representations and hereby expressly disclaims any and all warranties in respect of PRC Use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.63385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "Important <em>Information</em> Regarding the People’s Republic of China and the Use of New Relic New Relic is not authorized to do business in the People’s Republic of China (“PRC”). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory"
      },
      "id": "603eb3a328ccbcb488eba76b"
    },
    {
      "sections": [
        "New Relic data usage limits and policies",
        "Overview of limits",
        "View limits and manage data",
        "Account-level limits",
        "Data ingest APIs",
        "Other agent and integration limits",
        "Manage data"
      ],
      "title": "New Relic data usage limits and policies",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "fc32c25b40a030ffa0fad6bfc95be7fca1360ee1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies/",
      "published_at": "2021-05-05T16:19:47Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data usage spikes in one New Relic account from impacting other customers' accounts, we have various data volume and rate limits in place. We reserve the right to enforce these limits to protect our system and to avoid issues for you and other customers. If your New Relic account, whether by configuration or by error, exceeds one of these limits, it or its sub-accounts might experience one or both of the following: Sampling of data Temporary pause or cessation of data collection To learn more about how hitting a limit can affect your data, see View limits. If you have further questions about these limits, your contract, or a limit you've reached, contact your New Relic account representative. We can work with you to adjust any rate limits to meet your needs. View limits and manage data Want to understand your account’s limit violations using the UI? See View limits. Want to manage your data for organization or billing purposes? See Manage data. Account-level limits The following table includes general max limits that apply across all New Relic accounts. Specific New Relic tools, like agents and integrations, have their own limits and configurations, and might be lower than these theoretical maximum limits. Limited condition Limit Rate of NRDB record * ingest 55 million per account per minute Max NRDB records * ingested per API call 1MB (10^6 bytes) Max attribute value size 1KB (10^3 bytes) Max payload size 1MB (10^6 bytes) Max total attributes per data type (including default attributes) 254 (less for some tools; for example, 64 for agents) Number of unique custom data types 250 per account per day (applies to custom events because that's source of new data types) APM limits Agent instances: 50K per account Agent instances per app: 10K APM apps/services: 10K per second Browser: number of page views 1M per minute per app Rate of metric timeslice data (used by APM, browser, mobile) Ingest: 2 million per minute Rate of names: 4 million per minute per account Number per monitored app: 300K Mobile monitoring: number of crashes reported 10K per hour Infrastructure agents, integrations Number of infrastructure agents and/or integrations: 5K per account Gross number of new monitored containers: 5K per hour per account Query limits NRDB records * inspected: 100 billion per account per hour Rate of queries: 20 per account per second See other query limits * NRDB records refers to database records for our core data types, which includes events, metrics (dimensional), logs, and distributed tracing (span) data, all stored in the New Relic database (NRDB). This does not include metric timeslice data. Data ingest APIs Our ingest APIs have additional limits that may override the more general account-level limits. Note that these limits also apply to our tools that use these APIs (like our Telemetry SDKs or our open source telemetry integrations). Metric API (dimensional metrics) Event API Log API Trace API Other agent and integration limits To find limits for our other agents and integrations, which will override more general account-level limits, see the docs for those tools: you can search our solutions here. Some default reporting limits are located in these tools' configuration docs. Manage data Want to manage your New Relic data ingest and storage to improve data organization or reduce billing? See Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.6249,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic data <em>usage</em> limits and policies",
        "sections": "New Relic data <em>usage</em> limits and policies",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data <em>usage</em> spikes in one New Relic account from impacting other"
      },
      "id": "603eb1c528ccbc0311eba7c7"
    },
    {
      "sections": [
        "Government addendum",
        "New Relic, Inc.Government Addendum"
      ],
      "title": "Government addendum",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "cfed51b7f4f7583476f56b2b574204d38493e882",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/government-addendum/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The below Government Addendum applies only to customers that are United States federal, state, or local government customers with an existing New Relic agreement in place that explicitly references this Government Addendum applying to the Service purchased in an Order. Capitalized terms not defined below shall take on the meaning set forth in such New Relic agreement. New Relic, Inc.Government Addendum For purposes of this Agreement and to the extent applicable, the Service is \"commercial computer software\" and a \"commercially available off-the-shelf (COTS) item\" as defined at FAR 2.101 developed at the private expense of New Relic. If acquired by or on behalf of a civilian agency, the U.S. Government acquires this commercial computer software and/or commercial computer software documentation and other technical data subject to the terms of the Agreement as specified in 48 C.F.R. 12.212 (Computer Software) and 12.211 (Technical Data) of the Federal Acquisition Regulation (\"FAR\") and its successors. If acquired by or on behalf of any agency within the Department of Defense (\"DOD\"), the U.S. Government acquires this commercial computer software and/or commercial computer software documentation subject to the terms of the Agreement as specified in 48 C.F.R. 227.7202-3 of the DOD FAR Supplement (\"DFARS\") and its successors. This addendum is in lieu of and supersedes any other FAR, DFARS, or other clause or provision that addresses government rights in computer software or technical data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.6249,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>"
      },
      "id": "603ea47ee7b9d2dd0d2a07ef"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/government-addendum": [
    {
      "sections": [
        "The People's Republic of China"
      ],
      "title": "The People's Republic of China",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "c3c078b8139d695b928d2001cd6c6c9318c43599",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/peoples-republic-china/",
      "published_at": "2021-05-05T16:26:05Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Information Regarding the People’s Republic of China and the Use of New Relic New Relic is not authorized to do business in the People’s Republic of China (“PRC”). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory requirements in the PRC. New Relic does not provide support for, including but not limited to, the deployment, access, or use of the Service(s) or Software in the PRC, or otherwise in respect of assets in the PRC (“PRC Use”). Without overriding any express prohibitions that you may have agreed to as part of your agreement with New Relic, you (and you as an agent of the respective New Relic Customer (\"Customer\")) acknowledge that any PRC use is subject to the PRC national firewall system and may be subject to outages and other interference outside of the control of New Relic. Accordingly, you acknowledge and agree (on behalf of yourself and including any Customer on whose behalf you use the Service(s) or Software) that any PRC Use is at your sole risk and is fully excepted from all representations and warranties, including, but not limited to, any terms that assure the confidentiality, integrity, availability or privacy of your data. New Relic makes no other representations and hereby expressly disclaims any and all warranties in respect of PRC Use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.63383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "Important <em>Information</em> Regarding the People’s Republic of China and the Use of New Relic New Relic is not authorized to do business in the People’s Republic of China (“PRC”). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory"
      },
      "id": "603eb3a328ccbcb488eba76b"
    },
    {
      "sections": [
        "New Relic data usage limits and policies",
        "Overview of limits",
        "View limits and manage data",
        "Account-level limits",
        "Data ingest APIs",
        "Other agent and integration limits",
        "Manage data"
      ],
      "title": "New Relic data usage limits and policies",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "fc32c25b40a030ffa0fad6bfc95be7fca1360ee1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies/",
      "published_at": "2021-05-05T16:19:47Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data usage spikes in one New Relic account from impacting other customers' accounts, we have various data volume and rate limits in place. We reserve the right to enforce these limits to protect our system and to avoid issues for you and other customers. If your New Relic account, whether by configuration or by error, exceeds one of these limits, it or its sub-accounts might experience one or both of the following: Sampling of data Temporary pause or cessation of data collection To learn more about how hitting a limit can affect your data, see View limits. If you have further questions about these limits, your contract, or a limit you've reached, contact your New Relic account representative. We can work with you to adjust any rate limits to meet your needs. View limits and manage data Want to understand your account’s limit violations using the UI? See View limits. Want to manage your data for organization or billing purposes? See Manage data. Account-level limits The following table includes general max limits that apply across all New Relic accounts. Specific New Relic tools, like agents and integrations, have their own limits and configurations, and might be lower than these theoretical maximum limits. Limited condition Limit Rate of NRDB record * ingest 55 million per account per minute Max NRDB records * ingested per API call 1MB (10^6 bytes) Max attribute value size 1KB (10^3 bytes) Max payload size 1MB (10^6 bytes) Max total attributes per data type (including default attributes) 254 (less for some tools; for example, 64 for agents) Number of unique custom data types 250 per account per day (applies to custom events because that's source of new data types) APM limits Agent instances: 50K per account Agent instances per app: 10K APM apps/services: 10K per second Browser: number of page views 1M per minute per app Rate of metric timeslice data (used by APM, browser, mobile) Ingest: 2 million per minute Rate of names: 4 million per minute per account Number per monitored app: 300K Mobile monitoring: number of crashes reported 10K per hour Infrastructure agents, integrations Number of infrastructure agents and/or integrations: 5K per account Gross number of new monitored containers: 5K per hour per account Query limits NRDB records * inspected: 100 billion per account per hour Rate of queries: 20 per account per second See other query limits * NRDB records refers to database records for our core data types, which includes events, metrics (dimensional), logs, and distributed tracing (span) data, all stored in the New Relic database (NRDB). This does not include metric timeslice data. Data ingest APIs Our ingest APIs have additional limits that may override the more general account-level limits. Note that these limits also apply to our tools that use these APIs (like our Telemetry SDKs or our open source telemetry integrations). Metric API (dimensional metrics) Event API Log API Trace API Other agent and integration limits To find limits for our other agents and integrations, which will override more general account-level limits, see the docs for those tools: you can search our solutions here. Some default reporting limits are located in these tools' configuration docs. Manage data Want to manage your New Relic data ingest and storage to improve data organization or reduce billing? See Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.6249,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic data <em>usage</em> limits and policies",
        "sections": "New Relic data <em>usage</em> limits and policies",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data <em>usage</em> spikes in one New Relic account from impacting other"
      },
      "id": "603eb1c528ccbc0311eba7c7"
    },
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos",
        "For more help"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-05-05T09:56:00Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, scope of support, and video overview below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Support plan for New Relic One pricing and packaging model The below New Relic One Support Plan applies only to a customer’s paid subscription to New Relic One (Full Stack Observability). Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customer’s paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relic’s distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relic’s Global Technical Support provides assistance with the New Relic One Platform, and the features and capabilities inherent in the Telemetry Data Platform, Full Stack Observability, and Applied Intelligence Product lines. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and we’re here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relic’s Open Source Community Plus Projects. New Relic’s Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relic’s Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relic’s Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered “generally available.” If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we can’t help with things we didn’t build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and we’ll help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. We’ll do our best to determine whether an issue is with New Relic’s Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the “account owner,” such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relic’s Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relic’s Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For an overview of our help resources, watch this video (less than 6 min.): For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. For more help Recommendations for learning more: See the Docs site's landing page for Licenses documentation. Browse New Relic's Explorers Hub for community discussions about New Relic licenses.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.6249,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " environments Troubleshooting problems with ingesting data into New Relic <em>General</em> <em>usage</em> and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments"
      },
      "id": "603ea419e7b9d27b942a07b4"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies": [
    {
      "sections": [
        "The People's Republic of China"
      ],
      "title": "The People's Republic of China",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "c3c078b8139d695b928d2001cd6c6c9318c43599",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/peoples-republic-china/",
      "published_at": "2021-05-05T16:26:05Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Information Regarding the People’s Republic of China and the Use of New Relic New Relic is not authorized to do business in the People’s Republic of China (“PRC”). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory requirements in the PRC. New Relic does not provide support for, including but not limited to, the deployment, access, or use of the Service(s) or Software in the PRC, or otherwise in respect of assets in the PRC (“PRC Use”). Without overriding any express prohibitions that you may have agreed to as part of your agreement with New Relic, you (and you as an agent of the respective New Relic Customer (\"Customer\")) acknowledge that any PRC use is subject to the PRC national firewall system and may be subject to outages and other interference outside of the control of New Relic. Accordingly, you acknowledge and agree (on behalf of yourself and including any Customer on whose behalf you use the Service(s) or Software) that any PRC Use is at your sole risk and is fully excepted from all representations and warranties, including, but not limited to, any terms that assure the confidentiality, integrity, availability or privacy of your data. New Relic makes no other representations and hereby expressly disclaims any and all warranties in respect of PRC Use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.63383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "Important <em>Information</em> Regarding the People’s Republic of China and the Use of New Relic New Relic is not authorized to do business in the People’s Republic of China (“PRC”). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory"
      },
      "id": "603eb3a328ccbcb488eba76b"
    },
    {
      "sections": [
        "Government addendum",
        "New Relic, Inc.Government Addendum"
      ],
      "title": "Government addendum",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "cfed51b7f4f7583476f56b2b574204d38493e882",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/government-addendum/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The below Government Addendum applies only to customers that are United States federal, state, or local government customers with an existing New Relic agreement in place that explicitly references this Government Addendum applying to the Service purchased in an Order. Capitalized terms not defined below shall take on the meaning set forth in such New Relic agreement. New Relic, Inc.Government Addendum For purposes of this Agreement and to the extent applicable, the Service is \"commercial computer software\" and a \"commercially available off-the-shelf (COTS) item\" as defined at FAR 2.101 developed at the private expense of New Relic. If acquired by or on behalf of a civilian agency, the U.S. Government acquires this commercial computer software and/or commercial computer software documentation and other technical data subject to the terms of the Agreement as specified in 48 C.F.R. 12.212 (Computer Software) and 12.211 (Technical Data) of the Federal Acquisition Regulation (\"FAR\") and its successors. If acquired by or on behalf of any agency within the Department of Defense (\"DOD\"), the U.S. Government acquires this commercial computer software and/or commercial computer software documentation subject to the terms of the Agreement as specified in 48 C.F.R. 227.7202-3 of the DOD FAR Supplement (\"DFARS\") and its successors. This addendum is in lieu of and supersedes any other FAR, DFARS, or other clause or provision that addresses government rights in computer software or technical data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.6249,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>"
      },
      "id": "603ea47ee7b9d2dd0d2a07ef"
    },
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos",
        "For more help"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-05-05T09:56:00Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, scope of support, and video overview below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Support plan for New Relic One pricing and packaging model The below New Relic One Support Plan applies only to a customer’s paid subscription to New Relic One (Full Stack Observability). Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customer’s paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relic’s distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relic’s Global Technical Support provides assistance with the New Relic One Platform, and the features and capabilities inherent in the Telemetry Data Platform, Full Stack Observability, and Applied Intelligence Product lines. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and we’re here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relic’s Open Source Community Plus Projects. New Relic’s Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relic’s Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relic’s Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered “generally available.” If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we can’t help with things we didn’t build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and we’ll help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. We’ll do our best to determine whether an issue is with New Relic’s Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the “account owner,” such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relic’s Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relic’s Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For an overview of our help resources, watch this video (less than 6 min.): For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. For more help Recommendations for learning more: See the Docs site's landing page for Licenses documentation. Browse New Relic's Explorers Hub for community discussions about New Relic licenses.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.6249,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " environments Troubleshooting problems with ingesting data into New Relic <em>General</em> <em>usage</em> and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments"
      },
      "id": "603ea419e7b9d27b942a07b4"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/new-relics-provision-services": [
    {
      "sections": [
        "The People's Republic of China"
      ],
      "title": "The People's Republic of China",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "c3c078b8139d695b928d2001cd6c6c9318c43599",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/peoples-republic-china/",
      "published_at": "2021-05-05T16:26:05Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Information Regarding the People’s Republic of China and the Use of New Relic New Relic is not authorized to do business in the People’s Republic of China (“PRC”). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory requirements in the PRC. New Relic does not provide support for, including but not limited to, the deployment, access, or use of the Service(s) or Software in the PRC, or otherwise in respect of assets in the PRC (“PRC Use”). Without overriding any express prohibitions that you may have agreed to as part of your agreement with New Relic, you (and you as an agent of the respective New Relic Customer (\"Customer\")) acknowledge that any PRC use is subject to the PRC national firewall system and may be subject to outages and other interference outside of the control of New Relic. Accordingly, you acknowledge and agree (on behalf of yourself and including any Customer on whose behalf you use the Service(s) or Software) that any PRC Use is at your sole risk and is fully excepted from all representations and warranties, including, but not limited to, any terms that assure the confidentiality, integrity, availability or privacy of your data. New Relic makes no other representations and hereby expressly disclaims any and all warranties in respect of PRC Use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.63383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "Important <em>Information</em> Regarding the People’s Republic of China and the Use of New Relic New Relic is not authorized to do business in the People’s Republic of China (“PRC”). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory"
      },
      "id": "603eb3a328ccbcb488eba76b"
    },
    {
      "sections": [
        "New Relic data usage limits and policies",
        "Overview of limits",
        "View limits and manage data",
        "Account-level limits",
        "Data ingest APIs",
        "Other agent and integration limits",
        "Manage data"
      ],
      "title": "New Relic data usage limits and policies",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "fc32c25b40a030ffa0fad6bfc95be7fca1360ee1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies/",
      "published_at": "2021-05-05T16:19:47Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data usage spikes in one New Relic account from impacting other customers' accounts, we have various data volume and rate limits in place. We reserve the right to enforce these limits to protect our system and to avoid issues for you and other customers. If your New Relic account, whether by configuration or by error, exceeds one of these limits, it or its sub-accounts might experience one or both of the following: Sampling of data Temporary pause or cessation of data collection To learn more about how hitting a limit can affect your data, see View limits. If you have further questions about these limits, your contract, or a limit you've reached, contact your New Relic account representative. We can work with you to adjust any rate limits to meet your needs. View limits and manage data Want to understand your account’s limit violations using the UI? See View limits. Want to manage your data for organization or billing purposes? See Manage data. Account-level limits The following table includes general max limits that apply across all New Relic accounts. Specific New Relic tools, like agents and integrations, have their own limits and configurations, and might be lower than these theoretical maximum limits. Limited condition Limit Rate of NRDB record * ingest 55 million per account per minute Max NRDB records * ingested per API call 1MB (10^6 bytes) Max attribute value size 1KB (10^3 bytes) Max payload size 1MB (10^6 bytes) Max total attributes per data type (including default attributes) 254 (less for some tools; for example, 64 for agents) Number of unique custom data types 250 per account per day (applies to custom events because that's source of new data types) APM limits Agent instances: 50K per account Agent instances per app: 10K APM apps/services: 10K per second Browser: number of page views 1M per minute per app Rate of metric timeslice data (used by APM, browser, mobile) Ingest: 2 million per minute Rate of names: 4 million per minute per account Number per monitored app: 300K Mobile monitoring: number of crashes reported 10K per hour Infrastructure agents, integrations Number of infrastructure agents and/or integrations: 5K per account Gross number of new monitored containers: 5K per hour per account Query limits NRDB records * inspected: 100 billion per account per hour Rate of queries: 20 per account per second See other query limits * NRDB records refers to database records for our core data types, which includes events, metrics (dimensional), logs, and distributed tracing (span) data, all stored in the New Relic database (NRDB). This does not include metric timeslice data. Data ingest APIs Our ingest APIs have additional limits that may override the more general account-level limits. Note that these limits also apply to our tools that use these APIs (like our Telemetry SDKs or our open source telemetry integrations). Metric API (dimensional metrics) Event API Log API Trace API Other agent and integration limits To find limits for our other agents and integrations, which will override more general account-level limits, see the docs for those tools: you can search our solutions here. Some default reporting limits are located in these tools' configuration docs. Manage data Want to manage your New Relic data ingest and storage to improve data organization or reduce billing? See Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.62488,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic data <em>usage</em> limits and policies",
        "sections": "New Relic data <em>usage</em> limits and policies",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data <em>usage</em> spikes in one New Relic account from impacting other"
      },
      "id": "603eb1c528ccbc0311eba7c7"
    },
    {
      "sections": [
        "Government addendum",
        "New Relic, Inc.Government Addendum"
      ],
      "title": "Government addendum",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "cfed51b7f4f7583476f56b2b574204d38493e882",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/government-addendum/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The below Government Addendum applies only to customers that are United States federal, state, or local government customers with an existing New Relic agreement in place that explicitly references this Government Addendum applying to the Service purchased in an Order. Capitalized terms not defined below shall take on the meaning set forth in such New Relic agreement. New Relic, Inc.Government Addendum For purposes of this Agreement and to the extent applicable, the Service is \"commercial computer software\" and a \"commercially available off-the-shelf (COTS) item\" as defined at FAR 2.101 developed at the private expense of New Relic. If acquired by or on behalf of a civilian agency, the U.S. Government acquires this commercial computer software and/or commercial computer software documentation and other technical data subject to the terms of the Agreement as specified in 48 C.F.R. 12.212 (Computer Software) and 12.211 (Technical Data) of the Federal Acquisition Regulation (\"FAR\") and its successors. If acquired by or on behalf of any agency within the Department of Defense (\"DOD\"), the U.S. Government acquires this commercial computer software and/or commercial computer software documentation subject to the terms of the Agreement as specified in 48 C.F.R. 227.7202-3 of the DOD FAR Supplement (\"DFARS\") and its successors. This addendum is in lieu of and supersedes any other FAR, DFARS, or other clause or provision that addresses government rights in computer software or technical data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.62488,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>"
      },
      "id": "603ea47ee7b9d2dd0d2a07ef"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/peoples-republic-china": [
    {
      "sections": [
        "New Relic data usage limits and policies",
        "Overview of limits",
        "View limits and manage data",
        "Account-level limits",
        "Data ingest APIs",
        "Other agent and integration limits",
        "Manage data"
      ],
      "title": "New Relic data usage limits and policies",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "fc32c25b40a030ffa0fad6bfc95be7fca1360ee1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies/",
      "published_at": "2021-05-05T16:19:47Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data usage spikes in one New Relic account from impacting other customers' accounts, we have various data volume and rate limits in place. We reserve the right to enforce these limits to protect our system and to avoid issues for you and other customers. If your New Relic account, whether by configuration or by error, exceeds one of these limits, it or its sub-accounts might experience one or both of the following: Sampling of data Temporary pause or cessation of data collection To learn more about how hitting a limit can affect your data, see View limits. If you have further questions about these limits, your contract, or a limit you've reached, contact your New Relic account representative. We can work with you to adjust any rate limits to meet your needs. View limits and manage data Want to understand your account’s limit violations using the UI? See View limits. Want to manage your data for organization or billing purposes? See Manage data. Account-level limits The following table includes general max limits that apply across all New Relic accounts. Specific New Relic tools, like agents and integrations, have their own limits and configurations, and might be lower than these theoretical maximum limits. Limited condition Limit Rate of NRDB record * ingest 55 million per account per minute Max NRDB records * ingested per API call 1MB (10^6 bytes) Max attribute value size 1KB (10^3 bytes) Max payload size 1MB (10^6 bytes) Max total attributes per data type (including default attributes) 254 (less for some tools; for example, 64 for agents) Number of unique custom data types 250 per account per day (applies to custom events because that's source of new data types) APM limits Agent instances: 50K per account Agent instances per app: 10K APM apps/services: 10K per second Browser: number of page views 1M per minute per app Rate of metric timeslice data (used by APM, browser, mobile) Ingest: 2 million per minute Rate of names: 4 million per minute per account Number per monitored app: 300K Mobile monitoring: number of crashes reported 10K per hour Infrastructure agents, integrations Number of infrastructure agents and/or integrations: 5K per account Gross number of new monitored containers: 5K per hour per account Query limits NRDB records * inspected: 100 billion per account per hour Rate of queries: 20 per account per second See other query limits * NRDB records refers to database records for our core data types, which includes events, metrics (dimensional), logs, and distributed tracing (span) data, all stored in the New Relic database (NRDB). This does not include metric timeslice data. Data ingest APIs Our ingest APIs have additional limits that may override the more general account-level limits. Note that these limits also apply to our tools that use these APIs (like our Telemetry SDKs or our open source telemetry integrations). Metric API (dimensional metrics) Event API Log API Trace API Other agent and integration limits To find limits for our other agents and integrations, which will override more general account-level limits, see the docs for those tools: you can search our solutions here. Some default reporting limits are located in these tools' configuration docs. Manage data Want to manage your New Relic data ingest and storage to improve data organization or reduce billing? See Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.62488,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic data <em>usage</em> limits and policies",
        "sections": "New Relic data <em>usage</em> limits and policies",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data <em>usage</em> spikes in one New Relic account from impacting other"
      },
      "id": "603eb1c528ccbc0311eba7c7"
    },
    {
      "sections": [
        "Government addendum",
        "New Relic, Inc.Government Addendum"
      ],
      "title": "Government addendum",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "cfed51b7f4f7583476f56b2b574204d38493e882",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/government-addendum/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The below Government Addendum applies only to customers that are United States federal, state, or local government customers with an existing New Relic agreement in place that explicitly references this Government Addendum applying to the Service purchased in an Order. Capitalized terms not defined below shall take on the meaning set forth in such New Relic agreement. New Relic, Inc.Government Addendum For purposes of this Agreement and to the extent applicable, the Service is \"commercial computer software\" and a \"commercially available off-the-shelf (COTS) item\" as defined at FAR 2.101 developed at the private expense of New Relic. If acquired by or on behalf of a civilian agency, the U.S. Government acquires this commercial computer software and/or commercial computer software documentation and other technical data subject to the terms of the Agreement as specified in 48 C.F.R. 12.212 (Computer Software) and 12.211 (Technical Data) of the Federal Acquisition Regulation (\"FAR\") and its successors. If acquired by or on behalf of any agency within the Department of Defense (\"DOD\"), the U.S. Government acquires this commercial computer software and/or commercial computer software documentation subject to the terms of the Agreement as specified in 48 C.F.R. 227.7202-3 of the DOD FAR Supplement (\"DFARS\") and its successors. This addendum is in lieu of and supersedes any other FAR, DFARS, or other clause or provision that addresses government rights in computer software or technical data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.62488,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>"
      },
      "id": "603ea47ee7b9d2dd0d2a07ef"
    },
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos",
        "For more help"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-05-05T09:56:00Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, scope of support, and video overview below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Support plan for New Relic One pricing and packaging model The below New Relic One Support Plan applies only to a customer’s paid subscription to New Relic One (Full Stack Observability). Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customer’s paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customer’s business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relic’s distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relic’s Global Technical Support provides assistance with the New Relic One Platform, and the features and capabilities inherent in the Telemetry Data Platform, Full Stack Observability, and Applied Intelligence Product lines. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and we’re here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relic’s Open Source Community Plus Projects. New Relic’s Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relic’s Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relic’s Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relic’s Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered “generally available.” If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we can’t help with things we didn’t build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and we’ll help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. We’ll do our best to determine whether an issue is with New Relic’s Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the “account owner,” such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relic’s Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relic’s Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For an overview of our help resources, watch this video (less than 6 min.): For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. For more help Recommendations for learning more: See the Docs site's landing page for Licenses documentation. Browse New Relic's Explorers Hub for community discussions about New Relic licenses.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.62488,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " environments Troubleshooting problems with ingesting data into New Relic <em>General</em> <em>usage</em> and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments"
      },
      "id": "603ea419e7b9d27b942a07b4"
    }
  ],
  "/docs/licenses/license-information/other-licenses/services-licenses": [
    {
      "sections": [
        "Add-on end user license agreement",
        "New Relic, Inc. Add-on End User License Agreement"
      ],
      "title": "Add-on end user license agreement",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "a01c225ca30f95dab7db856cd946c76de557c31f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/add-end-user-license-agreement/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-03-16T06:19:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic, Inc. Add-on End User License Agreement In connection with the work provided by New Relic's Expert Services, Field Instrumentation Team, or Sales team, you may be provided with certain custom-created software to visualize, enable, optimize, or enhance your use of New Relic's Services. By downloading, installing, authorizing installation, or using the Add-on (defined below) with your Underlying Software (defined below), you (“Customer”) agree to the terms and conditions herein (“Agreement”) with New Relic, Inc., a Delaware corporation with offices located at 188 Spear Street, Suite 1200 San Francisco, CA 94105 (“New Relic\"), (collectively the “Parties”). Capitalized terms not defined herein shall have the meanings set forth in the New Relic Terms of Service (the “Terms of Service”) available here: newrelic.com/termsandconditions/terms. IF YOU DO NOT AGREE TO THIS AGREEMENT, YOUR SOLE REMEDY IS TO NOT USE THE ADD-ON. 1. DEFINITIONS “Add-on” means the New Relic applications and/or software, including but not limited to connectors, extensions, UI extension, and plugins, provided by New Relic to Customer to enable the Services to operate with certain third party or Customer software or systems (“Underlying Software”). For the purposes of the Terms of Service, the Add-on shall be treated like an Agent, subject to the separate terms herein. 2. USE OF THE PROGRAMMABILITY ADD-ON 2.1 Software Evaluation License. Subject to the terms herein, New Relic grants to Customer a limited, non-exclusive, non-transferrable, non-sublicensable right to install, use, and configure the Add-on solely as needed to enable the Services for internal evaluation purposes. New Relic reserves all rights and licenses not expressly granted herein. 2.2 Ownership. As between the Parties, New Relic owns all right, title, and interest to the Add-on and Feedback, including but not limited to any intellectual property and proprietary rights therein. Customer retains all right, title, and interest in any Customer Data processed by the Add-on in connection with the Services. 2.3 Feedback. Customer agrees to provide feedback, suggestions, ideas, requests or recommendations (“Feedback”) regarding the Add-on, and hereby irrevocably assigns all intellectual property and proprietary rights it holds in the Feedback to New Relic. 2.4 Notice. Customer acknowledges and agrees that the Add-on is made to work with the Underlying Software as configured at the time of creation and there is no guarantee that Add-on will continue to work in the event Customer changes, replaces, upgrades versions of, updates, or otherwise changes the Underlying Software (an “Upgrade Event”). Customer shall hold New Relic harmless from any claims or damages arising from Customer’s Upgrade Event. 2.5 Restrictions. Customer will not: (i) use the Add-on except as permitted hereunder; (ii) distribute, sell, sublicense, or otherwise transfer the Add-on; (iii) decompile, disassemble or reverse engineer any software underlying the Add-on; (iv) use the Add-on to damage, disable, overburden or impair any New Relic server or network(s) connected to any New Relic server or interfere with any other party’s use and enjoyment of the Services; (v) use the Add-on to defraud, defame, abuse, harass, stalk, threaten or infringe the rights of privacy or other intellectual property rights of others or otherwise violate any applicable law; (vi) circumvent or modify any security technologies included as part of the Add-on; or (vii) attempt or permit any third party to do any of the foregoing. New Relic may suspend Customer usage of the Services, without notice, pending any investigation of misuse. These restrictions may be supplemented or superceded (to the extent they conflict) by the New Relic Acceptable Use Policy as may be published and updated from time to time on the New Relic web site at docs.newrelic.com/docs/licenses/license-information/acceptable-use-policy/acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. “Confidential Information” means: (a) the Programmability Add-on, and any features, results or output produced by, and other information relating to the Add-on (including, without limitation, all Feedback); and (b) any business or technical information of New Relic including but not limited to any technical information, research, development, know-how that a reasonable person would understand to be confidential. 3.2 Restrictions. Customer will not use or disclose any Confidential Information, except as necessary for the performance of this Agreement. Customer will use all reasonable efforts to protect Confidential Information from unauthorized use or disclosure, but in no event less than the efforts that it ordinarily uses with respect to its own proprietary information. Customer may disclose Confidential Information to those of its employees who have a bona fide need to know such Confidential Information for the performance of this Agreement; provided that each such employee first executes a written agreement that contains use and nondisclosure restrictions at least as protective as those set forth herein. Confidential Information shall not include any information that: (a) is or becomes generally known to the public through no fault or breach of this Agreement by Customer; (b) is rightfully known by Customer at the time of disclosure without an obligation of confidentiality; (c) is independently developed by Customer without access or use of any Confidential Information; or (d) is rightfully obtained from a third party without restriction on use or disclosure. 4. DISCLAIMER 4.1 DISCLAIMER. THE ADD-ON IS PROVIDED AS-IS AND AS-AVAILABLE AND NEW RELIC DISCLAIMS AND MAKES NO WARRANTIES, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE OR NON-INFRINGEMENT AND WHETHER OR NOT ARISING THROUGH A COURSE OF DEALING. THE ADD-ON IS NOT GUARANTEED TO BE ERROR-FREE, COMPATIBLE WITH THE UNDERLYING SOFTWARE, OR THAT CUSTOMER WILL ACHIEVE ANY RESULTS FROM USE OF THE ADD-ON THEREFROM. 4.2 LIMITATION OF LIABILITY. TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC, ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE TO CUSTOMER OR ANY THIRD PARTY FOR DAMAGES OF ANY KIND, INCLUDING, WITHOUT LIMITATION, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE INSTALLATION, USE OR INABILITY TO USE THE ADD-ON OR FOR ANY ERROR OR DEFECT IN THE ADD-ON OR THE SERVICES, REGARDLESS OF LEGAL THEORY, WHETHER OR NOT NEW RELIC HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSS OR DAMAGE. NEW RELIC’S AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS AGREEMENT WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE PARTIES HAVE AGREED THAT THESE LIMITATIONS WILL SURVIVE AND APPLY EVEN IF ANY LIMITED REMEDY SPECIFIED IN THIS AGREEMENT IS FOUND TO HAVE FAILED OF ITS ESSENTIAL PURPOSE. THE LIMITATIONS OF DAMAGES SET FORTH ABOVE ARE FUNDAMENTAL ELEMENTS OF THE BASIS OF THE BARGAIN BETWEEN NEW RELIC AND CUSTOMER. 4.3 EVALUATION VERSION. Customer agrees and acknowledges that: (a) the Add-on is not an official product and has not been commercially released for sale by New Relic; (b) the Add-on may not operate properly, being in final form, or fully functional; (c) the Add-on may contain errors, security vulnerabilities, design flaws, or other problems; (d) it may not be possible to make the Add-on fully functional; (e) the information obtained using the Add-on may not be accurate; (f) use of the Add-on may result in unexpected results, loss of data, delays or other unpredictable damages or loss; (g) New Relic is under no obligation to release a commercial version of the Add-on; and (h) New Relic has the right unilaterally to abandon development of the Add-on, at any time and without any obligation or liability to Customer. 5. GENERAL PROVISIONS 5.1 Terms of Service; Documentation. This Agreement shall be considered a part of the New Relic documentation, located at: https://docs.newrelic.com (the “Documentation). This Agreement and the Terms of Service constitute the entire and exclusive agreement between New Relic and Customer with respect to the Add-on. In the absence of a separate agreement, upon agreement between New Relic and Customer with respect to the Add-On, the terms and conditions of this Agreement shall govern the relationship between New Relic and Customer with respect to such Add-On. To the extent of a conflict between the Agreement and the Terms of Service, this Agreement shall govern with respect to the Add-on only.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.36882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add-on end user <em>license</em> agreement",
        "sections": "Add-on end user <em>license</em> agreement",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": "&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;acceptable-use-policy&#x2F;acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. “Confidential <em>Information</em>” means: (a) the Programmability Add-on, and any features, results or output produced by, and other <em>information</em> relating to the Add-on (including, without limitation"
      },
      "id": "603ec23328ccbccf1beba79a"
    },
    {
      "sections": [
        "FIT instrumentation end user license agreement"
      ],
      "title": "FIT instrumentation end user license agreement",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "e8e10baf120678407d08c9f78ab708d271cf0223",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/fit-instrumentation-end-user-license-agreement/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NEW RELIC, INC. FIT INSTRUMENTATION END USER LICENSE AGREEMENT In connection with the work provided by New Relic’s Field Instrumentation Team, you may be provided with certain custom-created software to enable, optimize, or enhance your use of New Relic’s Services. By downloading, installing, authorizing installation, or using the FIT Instrumentation with your Underlying Software (defined below), you (“Customer”) agree to the terms and conditions herein (“Agreement”) with New Relic, Inc., a Delaware corporation with offices located at 188 Spear Street, Suite 1200 San Francisco, CA 94105 (“New Relic”), (collectively the “Parties”). Capitalized terms not defined herein shall have the meanings set forth in the New Relic Terms of Service (the “Terms of Service”) available here: http://newrelic.com/terms IF YOU DO NOT AGREE TO THIS AGREEMENT, PLEASE DO NOT USE THE FIT INSTRUMENTATION. 1. DEFINITIONS “FIT Instrumentation” means the New Relic custom-made software, including but not limited to connectors, extensions, and plugins, provided by New Relic to Customer to enable the Services to operate with certain third party or Customer software or systems (“Underlying Software”). For the purposes of the Terms of Service, the FIT Instrumentation shall be treated like an “Agent”, subject to the separate terms herein. 2. USE OF THE FIT INSTRUMENTATION 2.1 Software Evaluation License. Subject to the terms herein, New Relic grants to Customer a limited, non-exclusive, non-transferrable, non-sublicensable right to install, use, and configure the FIT Instrumentation solely as needed to enable the Services for internal evaluation purposes. New Relic reserves all rights and licenses not expressly granted herein. 2.2 Ownership. As between the Parties, New Relic owns all right, title, and interest to the FIT Instrumentation and Feedback, including but not limited to any intellectual property and proprietary rights therein. Customer retains all right, title, and interest in any Customer Data processed by the FIT Instrumentation in connection with the Services. 2.3 Feedback. Customer agrees to provide feedback, suggestions, ideas, requests or recommendations (“Feedback”) regarding the FIT Instrumentation, and hereby irrevocably assigns all intellectual property and proprietary rights it holds in the Feedback to New Relic. 2.4 Notice. Customer acknowledges and agrees that the FIT Instrumentation is made to work with the Underlying Software as configured at the time of creation and there is no guarantee that FIT Instrumentation will continue to work in the event Customer changes, replaces, upgrades versions of, updates, or otherwise changes the Underlying Software (an “Upgrade Event”). Customer shall hold New Relic harmless from any claims or damages arising from Customer’s Upgrade Event. 2.5 Restrictions. Customer will not: (i) use the FIT Instrumentation except as permitted hereunder; (ii) distribute, sell, sublicense, or otherwise transfer the FIT Instrumentation; (iii) decompile, disassemble or reverse engineer any software underlying the FIT Instrumentation; (iv) use the FIT Instrumentation to damage, disable, overburden or impair any New Relic server or network(s) connected to any New Relic server or interfere with any other party’s use and enjoyment of the Services; (v) use the FIT Instrumentation to defraud, defame, abuse, harass, stalk, threaten or infringe the rights of privacy or other intellectual property rights of others or otherwise violate any applicable law; (vi) circumvent or modify any security technologies included as part of the FIT Instrumentation; or (vii) attempt or permit any third party to do any of the foregoing. New Relic may suspend usage of the Services by any user, without notice, pending any investigation of misuse.  These restrictions may be supplemented or superceded (to the extent they conflict) by the New Relic Acceptable Use Policy as may be published and updated from time to time at https://docs.newrelic.com/docs/licenses/license-information/acceptable-use-policy/acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. “Confidential Information” means: (a) the FIT Instrumentation, and any features, results or output produced by, and other information relating to the FIT Instrumentation (including, without limitation, all Feedback); and (b) any business or technical information of New Relic including but not limited to any technical information, research, development, know-how that a reasonable person would understand to be confidential. 3.2 Restrictions. Customer will not use or disclose any Confidential Information, except as necessary for the performance of this Agreement. Customer will use all reasonable efforts to protect Confidential Information from unauthorized use or disclosure, but in no event less than the efforts that it ordinarily uses with respect to its own proprietary information. Customer may disclose Confidential Information to those of its employees who have a bona fide need to know such Confidential Information for the performance of this Agreement; provided that each such employee first executes a written agreement that contains use and nondisclosure restrictions at least as protective as those set forth herein. Confidential Information shall not include any information that: (a) is or becomes generally known to the public through no fault or breach of this Agreement by Customer; (b) is rightfully known by Customer at the time of disclosure without an obligation of confidentiality; (c) is independently developed by Customer without access or use of any Confidential Information; or (d) is rightfully obtained from a third party without restriction on use or disclosure. 4. DISCLAIMER 4.1 DISCLAIMER. FIT INSTRUMENTATION IS PROVIDED AS-IS AND AS-AVAILABLE AND NEW RELIC DISCLAIMS AND MAKES NO WARRANTIES, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE OR NON-INFRINGEMENT AND WHETHER OR NOT ARISING THROUGH A COURSE OF DEALING. FIT INSTRUMENTATION IS NOT GUARANTEED TO BE ERROR-FREE, COMPATIBLE WITH THE UNDERLYING SOFTWARE. , OR THAT CUSTOMER WILL ACHIEVE ANY RESULTS FROM USE OF THE FIT INSTRUMENTATION THEREFROM. SOME JURISDICTIONS DO NOT ALLOW THE EXCLUSION OF IMPLIED WARRANTIES OR LIMITATIONS ON APPLICABLE STATUTORY RIGHTS OF A CONSUMER, SO THE ABOVE EXCLUSION AND LIMITATIONS MAY NOT APPLY TO THE CUSTOMER. 4.2 LIMITATION OF LIABILITY. TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE TO CUSTOMER OR ANY THIRD PARTY FOR DAMAGES OF ANY KIND, INCLUDING, WITHOUT LIMITATION, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE INSTALLATION, USE OR INABILITY TO USE THE FIT INSTRUMENTATION OR FOR ANY ERROR OR DEFECT IN THE FIT INSTRUMENTATION OR THE SERVICES, WHETHER SUCH LIABILITY ARISES FROM ANY CLAIM BASED UPON CONTRACT, WARRANTY, TORT, STRICT LIABILITY, OR OTHERWISE, WHETHER OR NOT NEW RELIC HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSS OR DAMAGE. NEW RELIC'S AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS AGREEMENT WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE PARTIES HAVE AGREED THAT THESE LIMITATIONS WILL SURVIVE AND APPLY EVEN IF ANY LIMITED REMEDY SPECIFIED IN THIS AGREEMENT IS FOUND TO HAVE FAILED OF ITS ESSENTIAL PURPOSE. 4.3 EVALUATION VERSION. Customer agrees and acknowledges that: (a) the FIT Instrumentation is not an official product and has not been commercially released for sale by New Relic; (b) the FIT Instrumentation may not operate properly, being in final form, or fully functional; (c) the FIT Instrumentation may contain errors, security vulnerabilities, design flaws, or other problems; (d) it may not be possible to make the FIT Instrumentation fully functional; (e) the information obtained using the FIT Instrumentation may not be accurate; (f) use of the FIT Instrumentation may result in unexpected results, loss of data, delays or other unpredictable damages or loss; (g) New Relic is under no obligation to release a commercial version of the FIT Instrumentation; and (h) New Relic has the right unilaterally to abandon development of the FIT Instrumentation, at any time and without any obligation or liability to Customer. 5. GENERAL PROVISIONS 5.1 Terms of Service; Documentation. This Agreement shall be considered a part of the New Relic documentation, located at: https://docs.newrelic.com (the \"Documentation\").This Agreement and the Terms of Service constitute the entire and exclusive agreement between New Relic and Customer with respect to the FIT Instrumentation. In the absence of a separate agreement between New Relic and Customer with respect to the FIT Instrumentation, the terms and conditions of this Agreement shall govern the relationship between New Relic and Customer with respect to such FIT Instrumentation.  To the extent of a conflict between the Agreement and the Terms of Service, this Agreement shall govern with respect to the FIT Instrumentation only.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.3255,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "FIT instrumentation end user <em>license</em> agreement",
        "sections": "FIT instrumentation end user <em>license</em> agreement",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": " Acceptable Use Policy as may be published and updated from time to time at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;acceptable-use-policy&#x2F;acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. “Confidential <em>Information</em>” means: (a) the FIT Instrumentation, and any features, results"
      },
      "id": "603e9f3ee7b9d206e32a0800"
    },
    {
      "sections": [
        "New Relic Agent Software Notice"
      ],
      "title": "New Relic Agent Software Notice",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "2bf9501c2767105130d3808f1bf3a91a032d903e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/new-relic-agent-software-notice/",
      "published_at": "2021-05-05T16:22:53Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This software is © 2008-2021 New Relic, Inc. and its licensors. This software is solely for use with New Relic’s proprietary SaaS service (“New Relic Service”), so to use the software you must have a valid account for the New Relic Service under a separate agreement with New Relic (“Subscription Agreement”). You may only use the software to support your use of the New Relic Service as permitted in the Subscription Agreement. Without a Subscription Agreement, you may not use the software. All other use is prohibited. New Relic and its suppliers retain all right, title and interest (including intellectual property rights) in the software. The Subscription Agreement will control in event of a conflict with this notice. Unless otherwise agreed by New Relic in your Subscription Agreement: You may not use, copy, distribute or sublicense the software, use the software on behalf of third parties, reverse engineer or decompile the software, modify or create derivative works of the software, use the software for competitive analysis or benchmarking, or remove or obscure any proprietary notices in the software. The software is provided “AS IS” and New Relic disclaims all warranties, whether express, implied, statutory or otherwise, including warranties of merchantability, fitness for a particular purpose, title or noninfringement. To the full extent permitted by law, New Relic will have no liability arising from or related to the software or under this notice for any direct, indirect, special, incidental, or consequential damages of any kind, even if advised of their possibility in advance, and regardless of legal theory (whether contract, tort, negligence, strict liability or otherwise). The software may contain third-party open source software (“OSS”) as described here and at https://github.com/newrelic. To the extent required by the OSS license, that license will apply to the OSS when used on a stand-alone basis. For avoidance of doubt, you may copy and distribute New Relic agents pursuant to your Subscription Agreement for New Relic Browser and New Relic Mobile and as set forth: https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/get-started and https://docs.newrelic.com/docs/browser/new-relic-browser/installation/install-new-relic-browser-agent Software versions New Relic makes available under an OSS license (such as Apache 2.0) are governed by the terms of the applicable OSS license. For a current list of New Relic software versions released as OSS please visit https://opensource.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.3255,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": " and at https:&#x2F;&#x2F;github.com&#x2F;newrelic. To the extent required by the OSS <em>license</em>, that <em>license</em> will apply to the OSS when used on a stand-alone basis. For avoidance of doubt, you may copy and distribute New Relic agents pursuant to your Subscription Agreement for New Relic Browser and New Relic Mobile"
      },
      "id": "603eb73828ccbc1f99eba74a"
    }
  ],
  "/docs/licenses/license-information/product-definitions/legacy-product-definitions": [
    {
      "sections": [
        "New Relic One pricing: Definitions",
        "Account",
        "Commitment Term",
        "Customer Data",
        "Customer Properties",
        "Documentation",
        "GB Ingested",
        "Login Credentials",
        "Monthly Provisioned User",
        "Order",
        "Paid Terms of Service",
        "Product(s)",
        "Software",
        "Terms",
        "Third-Party Services",
        "Unpaid Terms of Service",
        "Usage Plan"
      ],
      "title": "New Relic One pricing: Definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "609575acd671fecf7899378157eabc57bc8d68e2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-04-22T16:06:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for organizations on our New Relic One pricing plan. For terms used in our original pricing plan, see Original pricing plan definitions. Account Account refers to the online account or subaccounts that New Relic provides for customers to manage their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, information, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer Properties Customer Properties means Customer’s websites, infrastructure, networks, mobile applications, or other systems, as well as Customer accounts on Third-Party Services. Documentation Documentation means the New Relic technical guides and documentation made available from the dedicated ‘Documentation’ page of the New Relic website. GB Ingested A GB Ingested is a measurement of the volume of metrics, events, logs, traces, or other telemetry data sent to or generated by the Products for the benefit of the Customer, including from the Software, the Customer Properties, or Third-Party Services. In this context, a GB is defined as 1 billion bytes. Login Credentials Login Credentials means the username, email address, password, or other personal information that is provided by a Customer user in order to manage an Account. Monthly Provisioned User A Monthly Provisioned User is any user who can log into Customer’s Account(s) and access the New Relic One Product functionality as specified in an Order and the Documentation. Order Order means the purchasing order for access to the Service or related services that: (1) is either executed by the Parties or entered into by you via self-service, and references this Agreement, or (2) is entered into by you and a Channel Partner. Paid Terms of Service Paid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/paid. Product(s) Product(s) mean the purchase of the New Relic subscription products described in the applicable Order and any updates, corrections, bug fixes, modifications, improvements, related services, new features, and functionality (made generally available to New Relic’s customer base) thereto. Software Software means the distributed software, APIs, scripts, or other code proprietary to New Relic provided with the Products. Terms Terms means the underlying Customer-New Relic agreement and the Order. Third-Party Services Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/unpaid. Usage Plan Usage Plan refers to the Service or Product pricing, invoicing related information, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.8098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic One pricing: <em>Definitions</em>",
        "sections": "New Relic One pricing: <em>Definitions</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https:&#x2F;&#x2F;newrelic.com&#x2F;termsandconditions&#x2F;unpaid. Usage Plan Usage Plan refers to the Service or <em>Product</em> pricing, invoicing related <em>information</em>, and <em>product</em>-specific terms (e.g. concurrent user account sessions) contained within the Documentation."
      },
      "id": "6044e6e528ccbc26f22c6084"
    },
    {
      "sections": [
        "Product-based pricing usage and New Relic Platform Pricing Usage Plan",
        "Important",
        "Usage Plan: New Relic Platform Pricing",
        "Eligible Services",
        "Eligible Services (Partners)",
        "Subscriptions with indeterminate pricing or usage quantities",
        "Product Usage Ratio"
      ],
      "title": "Product-based pricing usage and New Relic Platform Pricing Usage Plan",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "e2686dc773c4e844544ce633a9a41a16f15edf5a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/product-based-pricing-usage-new-relic-platform-pricing-usage-plan/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-03-16T04:22:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc explains our original product-based pricing plan. For more about pricing changes, see Overview of pricing changes. The following provisions are applicable to existing customers (i) that have existing Terms, and (ii) that to the extent its subscription to the New Relic products reference the usage plans set forth below or where a subscription has indeterminate product pricing or usage quantities. New customers are eligible for New Relic One pricing as described here. Capitalized terms not defined below shall take on the meaning set forth in such New Relic order form. Usage Plan: New Relic Platform Pricing The following Eligible Services with New Relic are products that are referenced in specific order forms for New Relic Platform Pricing. For more information, contact your New Relic account representative. Eligible Services Eligible Services Per Unit Unit of Measure Monthly Standard Fee Rate New Relic APM Pro CU Annual* 10,000 Compute Units $166.70 New Relic APM Pro Host Annual* 1 Hosts $149 New Relic Insights Pro Annual 50,000,000 Events $165 New Relic Infrastructure Pro Annual 10,000 Compute Units $12 New Relic Browser Pro Annual 500,000 Page Views $149 New Relic Logs Annual - 8 Days* * 1 Per GB Daily $55 New Relic Logs Annual - 15 Days* * 1 Per GB Daily $65 New Relic Logs Annual - 30 Days* * 1 Per GB Daily $75 New Relic Metrics Annual 1,000 Data Points per Minute $25 New Relic Mobile Enterprise Annual 50,000 Total Users $499 New Relic Serverless for AWS Lambda Annual 1,000,000 AWS Lambda Events $15 New Relic Synthetics Pro Annual 10,000 Checks $69 New Relic Synthetics private locations (for New Relic Synthetics Pro Annual product) Fixed fee N/A $1,000 New Relic Traces Annual 1,000,000 Spans $1 New Relic AI Incident Intelligence Annual 1,000 Incident Events $500 New Relic AI Proactive Detection Annual 1,000,000,000 App Transactions $250 * Customer may utilize either New Relic APM Pro Annual or New Relic APM Pro CUs Annual, but not both. Customer will be provisioned New Relic APM Pro CUs Annual by default, unless otherwise stated in the relevant Order Form. * * Customer may utilize only one of New Relic Logs Annual - 8 Days, New Relic Logs Annual - 15 Days, or New Relic Logs Annual - 30 days. For the avoidance of doubt, Customer may not utilize New Relic Logs Annual with varying numbers of days retention concurrently. Customer will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. For more information about units of measures, see Product definitions. Eligible Services (Partners) Eligible services for New Relic Partners Measurement New Relic APM Pro CU Annual* Sold in Units of 8,900 Compute Units New Relic APM Pro Host Annual* Sold in Units of 1 Host New Relic Browser Pro Annual Sold in Units of 500,000 Page Views New Relic Infrastructure Pro Annual Sold in Units of 125,000 Compute Units New Relic Insights Pro Annual Sold in Units of 45,000,000 Events New Relic Logs Annual - 8 Days* * Sold in Units of 3 GB Daily New Relic Logs Annual - 15 Days* * Sold in Units of 2.5 GB Daily New Relic Logs Annual - 30 Days* * Sold in Units of 2 GB Daily New Relic Metrics Annual Sold in Units of 6,000 Data Points per Minute New Relic Mobile Enterprise Annual Sold in Units of 15,000 Total Users New Relic Serverless for AWS Lambda Annual Sold in Units of 10,000,000 AWS Lambda Events New Relic Synthetics Pro with Private Locations Annual Sold in Units of 22,000 Checks New Relic Traces Annual Sold in Units of 149,000,000 Spans * Customer and/or Partner may utilize either New Relic APM Pro Annual or New Relic APM Pro CUs Annual, but not both. Customer and/or Partner will be provisioned New Relic APM Pro CUs Annual by default, unless otherwise stated in the relevant Order Form. * * Customer and/or Partner may utilize only one of New Relic Logs Annual - 8 Days, New Relic Logs Annual - 15 Days, or New Relic Logs Annual - 30 days. For the avoidance of doubt, Customer may not utilize New Relic Logs Annual with varying numbers of days retention concurrently. Customer and/or Partner will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. Subscriptions with indeterminate pricing or usage quantities Product Usage Ratio Where a Customer subscription to the Products contain no specific pricing or quantities, Product-specific usage for a specific calendar month shall be determined through the calculation of the following ratio (the “Product Usage Ratio”) where: (1) the numerator shall be the Product specific usage for such calendar month multiplied by such Product’s list price, and (2) the denominator shall be the the aggregate Customer usage of all Products during such calendar month multiplied by all such Product(s) list price. The Product Usage Ratio shall be the percentage of usage for a specific Product for a calendar month period, or if usage cannot be measured for a period, the last Product Usage Ratio that can be calculated shall be assumed constant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.53058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Product</em>-based pricing usage and New Relic Platform Pricing Usage Plan",
        "sections": "<em>Product</em>-based pricing usage and New Relic Platform Pricing Usage Plan",
        "tags": "<em>License</em> <em>information</em>",
        "body": " will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. For more <em>information</em> about units of measures, see <em>Product</em> <em>definitions</em>. Eligible Services (Partners) Eligible services for New Relic Partners Measurement New Relic APM Pro CU Annual* Sold in Units"
      },
      "id": "603ea32a28ccbc7e22eba768"
    },
    {
      "sections": [
        "Services licenses",
        "Contents",
        "Java internal services",
        "Java crash data API",
        "CoffeeScript",
        "JavaScript",
        "Crash reporting",
        "Label services",
        "Infrastructure Monitoring services",
        ".NET support uploader service",
        "Ruby gems",
        "Storage services",
        "Go packages"
      ],
      "title": "Services licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "49a2ad450d31dacfc2aae690ca947d2326d18761",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/other-licenses/services-licenses/",
      "published_at": "2021-05-05T16:28:24Z",
      "updated_at": "2021-04-06T00:26:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Contents Java internal services Java crash data API Framework License Apache TomCat Apache 2.0 Bean Validation Apache 2.0 Cassandra Driver Core Apache 2.0 ClassMate Apache 2.0 Hamcrest BSD Mockito MIT Netty Apache 2.0 Objenesis MIT SnakeYAML Apache 2.0 Spring Boot Apache 2.0 Java internal services Library License json_simple Apache 2.0 newrelic-api New Relic newrelic-api New Relic antlr BSD aopalliance Public Domain asm-analysis BSD asm-commons BSD asm-tree BSD asm-util BSD asm BSD c3p0 EPLv1.0 cglib-nodep Apache 2.0 cglib Apache 2.0 cglib Apache 2.0 cal10n-api MIT logback-classic EPLv1.0 logback-core EPLv1.0 guava-jetty-service Apache 2.0 zkclient Apache 2.0 reporter-config-base Apache 2.0 reporter-config3 Apache 2.0 reporter-config Apache 2.0 aws-java-sdk-acm Apache 2.0 aws-java-sdk-api-gateway Apache 2.0 aws-java-sdk-applicationautoscaling Apache 2.0 aws-java-sdk-autoscaling Apache 2.0 aws-java-sdk-cloudformation Apache 2.0 aws-java-sdk-cloudfront Apache 2.0 aws-java-sdk-cloudhsm Apache 2.0 aws-java-sdk-cloudsearch Apache 2.0 aws-java-sdk-cloudtrail Apache 2.0 aws-java-sdk-cloudwatch Apache 2.0 aws-java-sdk-cloudwatchmetrics Apache 2.0 aws-java-sdk-codecommit Apache 2.0 aws-java-sdk-codedeploy Apache 2.0 aws-java-sdk-codepipeline Apache 2.0 aws-java-sdk-cognitoidentity Apache 2.0 aws-java-sdk-cognitoidp Apache 2.0 aws-java-sdk-cognitosync Apache 2.0 aws-java-sdk-config Apache 2.0 aws-java-sdk-core Apache 2.0 aws-java-sdk-datapipeline Apache 2.0 aws-java-sdk-devicefarm Apache 2.0 aws-java-sdk-directconnect Apache 2.0 aws-java-sdk-directory Apache 2.0 aws-java-sdk-discovery Apache 2.0 aws-java-sdk-dms Apache 2.0 aws-java-sdk-dynamodb Apache 2.0 aws-java-sdk-ec2 Apache 2.0 aws-java-sdk-ecr Apache 2.0 aws-java-sdk-ecs Apache 2.0 aws-java-sdk-efs Apache 2.0 aws-java-sdk-elasticache Apache 2.0 aws-java-sdk-elasticbeanstalk Apache 2.0 aws-java-sdk-elasticloadbalancing Apache 2.0 aws-java-sdk-elasticloadbalancingv2 Apache 2.0 aws-java-sdk-elasticsearch Apache 2.0 aws-java-sdk-elastictranscoder Apache 2.0 aws-java-sdk-emr Apache 2.0 aws-java-sdk-events Apache 2.0 aws-java-sdk-gamelift Apache 2.0 aws-java-sdk-glacier Apache 2.0 aws-java-sdk-iam Apache 2.0 aws-java-sdk-importexport Apache 2.0 aws-java-sdk-inspector Apache 2.0 aws-java-sdk-iot Apache 2.0 aws-java-sdk-kinesis Apache 2.0 aws-java-sdk-kms Apache 2.0 aws-java-sdk-lambda Apache 2.0 aws-java-sdk-logs Apache 2.0 aws-java-sdk-machinelearning Apache 2.0 aws-java-sdk-marketplacecommerceanalytics Apache 2.0 aws-java-sdk-marketplacemeteringservice Apache 2.0 aws-java-sdk-models Apache 2.0 aws-java-sdk-opsworks Apache 2.0 aws-java-sdk-rds Apache 2.0 aws-java-sdk-redshift Apache 2.0 aws-java-sdk-route53 Apache 2.0 aws-java-sdk-s3 Apache 2.0 aws-java-sdk-servicecatalog Apache 2.0 aws-java-sdk-ses Apache 2.0 aws-java-sdk-simpledb Apache 2.0 aws-java-sdk-simpleworkflow Apache 2.0 aws-java-sdk-snowball Apache 2.0 aws-java-sdk-sns Apache 2.0 aws-java-sdk-sqs Apache 2.0 aws-java-sdk-ssm Apache 2.0 aws-java-sdk-storagegateway Apache 2.0 aws-java-sdk-sts Apache 2.0 aws-java-sdk-support Apache 2.0 aws-java-sdk-swf-libraries Apache 2.0 aws-java-sdk-waf Apache 2.0 aws-java-sdk-workspaces Apache 2.0 aws-java-sdk Apache 2.0 jmespath-java Apache 2.0 AppleJavaExtensions BSD jcommander Apache 2.0 high-scale-lib MIT hppc Apache 2.0 clover Paid stream Apache 2.0 metrics-core Apache 2.0 cassandra-driver-core Apache 2.0 cassandra-driver-core Apache 2.0 uuid MIT grabbag MIT speed4j Apache 2.0 yamlbeans BSD jackson-annotations Apache 2.0 jackson-core Apache 2.0 jackson-databind Apache 2.0 jackson-dataformat-cbor Apache 2.0 jackson-dataformat-csv Apache 2.0 jackson-dataformat-xml Apache 2.0 jackson-dataformat-yaml Apache 2.0 jackson-datatype-guava Apache 2.0 jackson-datatype-jdk7 Apache 2.0 jackson-datatype-jdk8 Apache 2.0 jackson-datatype-joda Apache 2.0 jackson-datatype-jsr310 Apache 2.0 jackson-jaxrs-base Apache 2.0 jackson-jaxrs-json-provider Apache 2.0 jackson-module-afterburner Apache 2.0 jackson-module-jaxb-annotations Apache 2.0 jackson-module-kotlin Apache 2.0 woodstox-core Apache 2.0 classmate Apache 2.0 zjsonpatch Apache 2.0 caffeine Apache 2.0 waffle-jna EPLv1.0 docker-java Apache 2.0 docker-java Apache 2.0 btf Apache 2.0 jackson-coreutils Apache 2.0 json-schema-core Apache 2.0 json-schema-validator Apache 2.0 msg-simple Apache 2.0 uri-template Apache 2.0 jamm Apache 2.0 jffi Apache 2.0 jnr-constants Apache 2.0 jnr-ffi Apache 2.0 jnr-ffi Apache 2.0 jnr-posix EPLv1.0 jnr-x86asm MIT embedded-redis Apache 2.0 memoryfilesystem MIT guava-retrying Apache 2.0 guava-retrying Apache 2.0 snowball-stemmer BSD system-rules CPL uuid Apache 2.0 wiremock Apache 2.0 auto-common Apache 2.0 annotations LGPLv2.1 annotations LGPLv2.1 bcel-findbugs LGPLv2.1 findbugs LGPLv2.1 jFormatString BSD jFormatString BSD jsr305 BSD jsr305 BSD jsr305 BSD gson Apache 2.0 spymemcached MIT guava-testlib Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guice-multibindings Apache 2.0 guice Apache 2.0 truth Apache 2.0 concurrent-trees Apache 2.0 concurrentlinkedhashmap-lru Apache 2.0 json-simple Apache 2.0 libphonenumber Apache 2.0 locality-uuid BSD h2 EPLv1.0 annotations Apache 2.0 json-path-assert Apache 2.0 json-path Apache 2.0 json-path Apache 2.0 jzlib BSD bonecp-provider Apache 2.0 bonecp Apache 2.0 junixsocket-common Apache 2.0 junixsocket-native-common Apache 2.0 disruptor Apache 2.0 geoip-api LGPLv2.1 c3p0 LGPLv2.1 mchange-commons-java LGPLv2.1 archaius-core Apache 2.0 hystrix-core Apache 2.0 hystrix-servo-metrics-publisher Apache 2.0 rxjava-core Apache 2.0 servo-core Apache 2.0 kafka-clients Apache 2.0 kafka_2.10 Apache 2.0 kafka_2.11 Apache 2.0 common-cassandra Apache 2.0 timeslice_utils New Relic mockito-kotlin MIT compress-lzf Apache 2.0 checkstyle Apache 2.0 dagger-compiler Apache 2.0 dagger Apache 2.0 okhttp Apache 2.0 okio Apache 2.0 javapoet Apache 2.0 javawriter Apache 2.0 jaxb-impl CDDLv1 thrift-server Apache 2.0 finagle-core_2.10 Apache 2.0 finagle-core_2.11 Apache 2.0 finagle-http_2.10 Apache 2.0 finagle-http_2.11 Apache 2.0 jsr166e Creative Commons util-app_2.10 Apache 2.0 util-app_2.11 Apache 2.0 util-cache_2.10 Apache 2.0 util-cache_2.11 Apache 2.0 util-codec_2.10 Apache 2.0 util-codec_2.11 Apache 2.0 util-collection_2.10 Apache 2.0 util-collection_2.11 Apache 2.0 util-core_2.10 Apache 2.0 util-core_2.11 Apache 2.0 util-function_2.10 Apache 2.0 util-function_2.11 Apache 2.0 util-hashing_2.10 Apache 2.0 util-hashing_2.11 Apache 2.0 util-jvm_2.10 Apache 2.0 util-jvm_2.11 Apache 2.0 util-lint_2.10 Apache 2.0 util-lint_2.11 Apache 2.0 util-logging_2.10 Apache 2.0 util-logging_2.11 Apache 2.0 util-registry_2.10 Apache 2.0 util-registry_2.11 Apache 2.0 util-stats_2.10 Apache 2.0 util-stats_2.11 Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 HikariCP Apache 2.0 commons-beanutils Apache 2.0 commons-cli Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-io Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 commons-pool Apache 2.0 unix-socket-factory Apache 2.0 unix-socket-factory Apache 2.0 jflex BSD dom4j BSD airline Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 metrics-healthchecks Apache 2.0 metrics-httpclient Apache 2.0 metrics-jdbi Apache 2.0 metrics-jersey2 Apache 2.0 metrics-jetty9 Apache 2.0 metrics-json Apache 2.0 metrics-jvm Apache 2.0 metrics-logback Apache 2.0 metrics-servlets Apache 2.0 dropwizard-java8-jdbi Apache 2.0 dropwizard-client Apache 2.0 dropwizard-configuration Apache 2.0 dropwizard-core Apache 2.0 dropwizard-db Apache 2.0 dropwizard-jackson Apache 2.0 dropwizard-jdbi Apache 2.0 dropwizard-jersey Apache 2.0 dropwizard-jetty Apache 2.0 dropwizard-lifecycle Apache 2.0 dropwizard-logging Apache 2.0 dropwizard-metrics Apache 2.0 dropwizard-servlets Apache 2.0 dropwizard-testing Apache 2.0 dropwizard-util Apache 2.0 dropwizard-validation Apache 2.0 netty-all Apache 2.0 netty-buffer Apache 2.0 netty-codec-http Apache 2.0 netty-codec-socks Apache 2.0 netty-codec Apache 2.0 netty-common Apache 2.0 netty-handler-proxy Apache 2.0 netty-handler Apache 2.0 netty-resolver Apache 2.0 netty-transport-native-epoll Apache 2.0 netty-transport Apache 2.0 netty Apache 2.0 ratpack-core Apache 2.0 ratpack-groovy-test Apache 2.0 ratpack-groovy Apache 2.0 ratpack-guice Apache 2.0 ratpack-test Apache 2.0 rxjava Apache 2.0 fastutil Apache 2.0 janino BSD activation Apache 2.0 javax.annotation-api CDDLv1 jsr250-api CDDLv1 javax.inject Apache 2.0 mail CDDLv1 mailapi CDDLv1 javax.servlet-api Apache 2.0 servlet-api Apache 2.0 javax.transaction-api CDDLv1 validation-api Apache 2.0 javax.websocket-api CDDLv1 javax.ws.rs-api CDDLv1 jaxb-api CDDLv1 stax-api CDDLv1 jaxen Apache 2.0 jline BSD jline BSD joda-time Apache 2.0 junit-dep CPL junit CPL junit EPLv1.0 kafka_2.10 Apache 2.0 kafka_2.9.2 Apache 2.0 apache-log4j-extras Apache 2.0 log4j Apache 2.0 mysql-connector-java GPLv2 with Classpath Exception byte-buddy Apache 2.0 byte-buddy Apache 2.0 jna-platform LGPLv2.1 jna Apache 2.0 jcip-annotations Apache 2.0 lz4 Apache 2.0 accessors-smart Apache 2.0 asm Apache 2.0 json-smart Apache 2.0 json-smart Apache 2.0 primitive GPLv2 with Classpath Exception compiler Apache 2.0 lang Apache 2.0 beaver-cc BSD ehcache-core Apache 2.0 ehcache Apache 2.0 jopt-simple MIT jopt-simple MIT opencsv Apache 2.0 quality-check Apache 2.0 scannotation Apache 2.0 super-csv Apache 2.0 uadetector-core Apache 2.0 uadetector-resources Apache 2.0 argparse4j MIT spymemcached MIT kalium Apache 2.0 ST4 BSD antlr-runtime BSD antlr-runtime BSD antlr BSD stringtemplate BSD ant-launcher Apache 2.0 ant Apache 2.0 cassandra-all Apache 2.0 cassandra-all Apache 2.0 cassandra-thrift Apache 2.0 cassandra-thrift Apache 2.0 commons-collections4 Apache 2.0 commons-compress Apache 2.0 commons-csv Apache 2.0 commons-dbcp2 Apache 2.0 commons-io Apache 2.0 commons-lang3 Apache 2.0 commons-math3 Apache 2.0 commons-math Apache 2.0 commons-pool2 Apache 2.0 curator-client Apache 2.0 curator-framework Apache 2.0 curator-recipes Apache 2.0 curator-test Apache 2.0 derby Apache 2.0 geronimo-servlet_3.0_spec Apache 2.0 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 ivy Apache 2.0 kafka-clients Apache 2.0 kafka_2.11 Apache 2.0 libthrift Apache 2.0 tomcat-embed-core Apache 2.0 tomcat-embed-el Apache 2.0 tomcat-embed-logging-juli Apache 2.0 tomcat-embed-websocket Apache 2.0 tomcat-jdbc Apache 2.0 tomcat-juli Apache 2.0 zookeeper Apache 2.0 aspectjweaver EPLv1.0 assertj-core Apache 2.0 assertj-core Apache 2.0 evo-inflector Apache 2.0 bcmail-jdk15on MIT bcpkix-jdk15on MIT bcprov-jdk15on MIT ohc-core Apache 2.0 cassandra-unit-spring LGPLv3 cassandra-unit-spring LGPLv3 cassandra-unit LGPLv3 cassandra-unit LGPLv3 groovy-all Apache 2.0 groovy-all Apache 2.0 groovy Apache 2.0 groovy Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 easymock Apache 2.0 ecj EPLv1.0 javax.activation CDDLv1 javax.annotation CDDLv1 javax.mail.glassfish CDDLv1 javax.servlet CDDLv1 javax.transaction CDDLv1 org.objectweb.asm BSD jetty-setuid-java EPLv1.0 jetty-schemas Apache 2.0 javax-websocket-client-impl Apache 2.0 javax-websocket-server-impl Apache 2.0 websocket-api Apache 2.0 websocket-client Apache 2.0 websocket-common Apache 2.0 websocket-server Apache 2.0 websocket-servlet Apache 2.0 apache-jsp Apache 2.0 jetty-annotations CDDLv1 jetty-client Apache 2.0 jetty-continuation Apache 2.0 jetty-http Apache 2.0 jetty-io Apache 2.0 jetty-jmx Apache 2.0 jetty-jndi Apache 2.0 jetty-plus Apache 2.0 jetty-proxy Apache 2.0 jetty-security Apache 2.0 jetty-server Apache 2.0 jetty-servlet Apache 2.0 jetty-servlets Apache 2.0 jetty-util Apache 2.0 jetty-webapp Apache 2.0 jetty-xml Apache 2.0 sigar Apache 2.0 aopalliance-repackaged CDDLv1 javax.inject CDDLv1 hk2-api CDDLv1 hk2-locator CDDLv1 hk2-utils CDDLv1 osgi-resource-locator CDDLv1 jersey-guava CDDLv1 jersey-client CDDLv1 jersey-apache-connector CDDLv1 jersey-container-servlet-core CDDLv1 jersey-container-servlet CDDLv1 jersey-client CDDLv1 jersey-common CDDLv1 jersey-server CDDLv1 jersey-bean-validation CDDLv1 jersey-metainf-services CDDLv1 jersey-media-jaxb CDDLv1 jersey-client CDDLv1 jersey-test-framework-provider-inmemory CDDLv1 jersey-test-framework-core CDDLv1 javax.el CDDLv1 hamcrest-all BSD hamcrest-core BSD hamcrest-integration BSD hamcrest-library BSD HdrHistogram Public Domain hector-core MIT hibernate-commons-annotations LGPLv2.1 hibernate-jpa-2.0-api LGPLv2.1 hibernate-jpa-2.1-api LGPLv2.1 hibernate-c3p0 Apache 2.0 hibernate-core Apache 2.0 hibernate-ehcache Apache 2.0 hibernate-entitymanager Apache 2.0 hibernate-jmx Apache 2.0 hibernate-validator Apache 2.0 freebuilder Apache 2.0 org.jacoco.agent EPLv1.0 org.jacoco.ant EPLv1.0 org.jacoco.core EPLv1.0 org.jacoco.report EPLv1.0 javassist Apache 2.0 jboss-logging-annotations LGPLv2.1 jboss-logging Apache 2.0 jboss-transaction-api_1.1_spec LGPLv2.1 jboss-transaction-api_1.2_spec LGPLv2.1 jandex Apache 2.0 jdbi Apache 2.0 job-dsl-core Apache 2.0 version-number MIT kotlin-annotation-processing Apache 2.0 kotlin-reflect Apache 2.0 kotlin-runtime Apache 2.0 kotlin-stdlib Apache 2.0 kotlin-test-junit Apache 2.0 kotlin-test Apache 2.0 annotations Apache 2.0 jolokia-core Apache 2.0 jruby-complete LGPLv2.1 LGPLv2.1 json Public Domain json Apache 2.0 xstream BSD annotations Apache 2.0 mapdb Apache 2.0 mapdb Apache 2.0 jbcrypt ISC mockserver-client-java Apache 2.0 mockserver-core Apache 2.0 mockserver-logging Apache 2.0 mockserver-netty Apache 2.0 mockito-all MIT mockito-core MIT mockito-core MIT apache-el Apache 2.0 apache-jsp Apache 2.0 alpn-boot Apache 2.0 etcd4j Apache 2.0 msgpack Apache 2.0 objenesis Apache 2.0 objenesis Apache 2.0 jmh-core GPLv2 with Classpath Exception jmh-generator-annprocess GPLv2 with Classpath Exception jol-core GPLv2 with Classpath Exception asm-analysis BSD asm-analysis BSD asm-commons BSD asm-debug-all BSD asm-tree BSD asm-util BSD asm-util BSD asm BSD asm Public Domain postgresql BSD powermock-api-mockito Apache 2.0 powermock-api-support Apache 2.0 powermock-core Apache 2.0 powermock-module-junit4-common Apache 2.0 powermock-module-junit4 Apache 2.0 powermock-reflect Apache 2.0 lombok MIT reactive-streams Public Domain reflections WTFPL scala-java8-compat_2.11 Scala scala-parser-combinators_2.11 Scala scala-xml_2.11 Scala scala-library Scala scala-reflect Scala scalatest_2.10 Apache 2.0 scalatest_2.11 Apache 2.0 native-lib-loader BSD jsonassert Apache 2.0 jcl-over-slf4j MIT jul-to-slf4j MIT log4j-log4j12 MIT log4j-over-slf4j MIT slf4j-api MIT slf4j-ext MIT slf4j-log4j12 MIT slf4j-simple MIT spock-core Apache 2.0 spock-core Apache 2.0 spring-boot-actuator Apache 2.0 spring-boot-autoconfigure Apache 2.0 spring-boot-configuration-processor Apache 2.0 spring-boot-starter-actuator Apache 2.0 spring-boot-starter-aop Apache 2.0 spring-boot-starter-data-jpa Apache 2.0 spring-boot-starter-data-rest Apache 2.0 spring-boot-starter-jdbc Apache 2.0 spring-boot-starter-jetty Apache 2.0 spring-boot-starter-logging Apache 2.0 spring-boot-starter-test Apache 2.0 spring-boot-starter-tomcat Apache 2.0 spring-boot-starter-web Apache 2.0 spring-boot-starter Apache 2.0 spring-boot-test-autoconfigure Apache 2.0 spring-boot-test Apache 2.0 spring-boot Apache 2.0 spring-data-commons Apache 2.0 spring-data-jpa Apache 2.0 spring-data-rest-core Apache 2.0 spring-data-rest-webmvc Apache 2.0 spring-hateoas Apache 2.0 spring-plugin-core Apache 2.0 spring-aop Apache 2.0 spring-aspects Apache 2.0 spring-beans Apache 2.0 spring-context-support Apache 2.0 spring-context Apache 2.0 spring-core Apache 2.0 spring-core Apache 2.0 spring-expression Apache 2.0 spring-jdbc Apache 2.0 spring-orm Apache 2.0 spring-test Apache 2.0 spring-test Apache 2.0 spring-tx Apache 2.0 spring-web Apache 2.0 spring-webmvc Apache 2.0 xz Public Domain wasabi Apache 2.0 snappy-java Apache 2.0 xmlunit-core Apache 2.0 xmlunit-legacy Apache 2.0 snakeyaml Apache 2.0 JUnitParams Apache 2.0 postgresql BSD postgresql BSD jedis MIT scala-library Scala ion-java Apache 2.0 timeslice_service-thrift New Relic timeslice_service New Relic xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3_min Public Domain zkclient Apache 2.0 zookeeper Apache 2.0 CoffeeScript Library License CoffeeScript MIT coffin MIT JavaScript JavaScript License ie_html5/ie_html5.js MIT Angular.js MIT Angular UI directives for Bootstrap MIT Chart.js MIT Chosen JQuery plugin MIT Fullcalendar MIT Moment MIT Crash reporting Software License Apple OS X OS X Yosemite Xcode & Apple SDK Xcode license Label services Service License BoneCP Apache 2.0 Gradle Apache 2.0 Hibernate Apache 2.0 Spring Apache 2.0 Infrastructure Monitoring services Service License antlr BSD aopalliance Public Domain asm MIT cglib Apache 2.0 ch.qos.logback EPLv1.0 com.101tec Apache 2.0 com.amazonaws Apache 2.0 com.cenqua.clover Paid com.fasterxml.jackson.core Apache 2.0 com.fasterxml Apache 2.0 com.google.code.findbugs BSD com.google.guava Apache 2.0 com.googlecode.json-simple Apache 2.0 com.intellij Apache 2.0 New Relic com.squareup.dagger Apache 2.0 com.squareup Apache 2.0 com.yammer.metrics Apache 2.0 commons-codec Apache 2.0 commons-configuration Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 dom4j BSD io.netty Apache 2.0 javax.annotation CDDLv1 javax.inject Apache 2.0 javax.servlet.jsp CDDLv1 javax.servlet Apache 2.0 javax.validation Apache 2.0 javax.websocket CDDLv1 jline BSD joda-time Apache 2.0 junit CPL log4j Apache 2.0 mysql GPLv2 with Classpath Exception net.sf.jopt-simple MIT org.apache.commons Apache 2.0 org.apache.httpcomponents Apache 2.0 org.apache.ivy Apache 2.0 org.apache.thrift Apache 2.0 org.apache.tomcat.embed Apache 2.0 org.apache.zookeeper Apache 2.0 org.codehaus.groovy Apache 2.0 org.codehaus.jackson Apache 2.0 org.easymock Apache 2.0 org.eclipse.jetty.orbit CDDLv1 org.eclipse.jetty.toolchain Apache 2.0 org.eclipse.jetty.websocket Apache 2.0 org.eclipse.jetty CDDLv1 org.glassfish.jersey.core CDDLv1 org.glassfish.web CDDLv1 org.glassfish CDDLv1 org.hamcrest BSD org.hibernate Apache 2.0 org.javassist Apache 2.0 org.jboss.logging LGPLv2.1 org.jenkins-ci.plugins Apache 2.0 org.jenkins-ci Apache 2.0 org.jetbrains Apache 2.0 org.jolokia Apache 2.0 org.jvnet.hudson BSD org.mockito MIT org.objenesis Apache 2.0 org.ow2.asm MIT org.reflections WTFPL org.scala-lang Scala org.slf4j MIT org.springframework.boot Apache 2.0 org.springframework Apache 2.0 org.xerial.snappy Apache 2.0 org.yaml Apache 2.0 xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3 Public Domain .NET support uploader service Library License Amazon AWS SDK for Java Apache 2.0 Apache Commons Codec Apache 2.0 Gson Apache 2.0 Jetty Apache 2.0 Ruby gems Ruby gems Gem License aasm MIT actionmailer MIT actionpack MIT activeadmin MIT actionview MIT activejob MIT active_model_serializers MIT activemodel MIT activerecord MIT activerecord-deprecated_finders MIT activerecord-mysql2-adapter MIT activeresource MIT activesupport MIT addressable Apache 2.0 angularjs-rails MIT arbre MIT arel MIT arel MIT atomic Apache 2.0 atomic Apache-2.0 attr_required MIT awesome_print MIT backports MIT better_errors MIT binding_of_caller MIT bourbon MIT brwsr MIT browser-timezone-rails MIT builder MIT bundler MIT byebug MIT callsite MIT capistrano MIT capistrano-bundler MIT capistrano-ext MIT capistrano-rbenv MIT capistrano-stats MIT capybara MIT celluloid MIT CFPropertyList MIT chunky_png MIT ci_reporter MIT ci_reporter_rspec MIT clockwork MIT codeclimate-test-reporter MIT coderay MIT coderay MIT coffee-rails MIT coffee-script MIT coffee-script-source MIT columnize Ruby compass MIT compass-core MIT compass-import-once MIT compass-rails MIT concurrent-ruby MIT crack MIT crypt Unlicensed daemons MIT dalli MIT database_cleaner MIT debug_inspector MIT debugger-linecache MIT diff-lcs MIT docile MIT dotenv MIT dotenv-deployment MIT erubis MIT etcd MIT ethon MIT eventmachine Ruby excon MIT execjs MIT factory_girl MIT factory_girl_rails MIT faraday MIT faraday-middleware MIT faye-websocket MIT ffi MIT ffi BSD fission MIT fog MIT fog-atmos MIT fog-aws MIT fog-brightbox MIT fog-core MIT fog-ecloud MIT fog-google MIT fog-json MIT fog-local MIT fog-powerdns MIT fog-profitbricks MIT fog-radosgw MIT fog-riakcs MIT fog-sakuracloud MIT fog-serverlove MIT fog-softlayer MIT fog-storm_on_demand MIT fog-terremark MIT fog-vmfusion MIT fog-voxel MIT fog-xml MIT font-awesome-rails MIT foreman MIT formatador MIT formtastic MIT formtastic i18n MIT fssm MIT globalid MIT guard MIT guard-rspec MIT haml MIT haml-rails MIT has scope MIT hashie MIT highline Ruby hike MIT hipchat-api MIT histogram MIT hitimes ISC hiredis BSD http_parser.rb MIT httpclient Ruby httpclient Ruby httparty MIT i18n MIT inflecto MIT inherited resources MIT intercom-rails MIT ipaddress MIT jasmine MIT jasmine-core MIT jasmine-rails MIT jbuilder MIT jira MIT jira-ruby OSL-3.0 journey MIT jquery-rails MIT jquery-turbolinks MIT jquery-ui-rails MIT json Ruby jwt MIT kaminari MIT kgio LGPLv3 kgio LGPLv3 kgio LGPL-v2.1+ libv8 MIT listen MIT logger Ruby loofah MIT lumberjack MIT macaddr MIT mail MIT mailcatcher MIT memoist MIT metaclass MIT meta_request MIT method_source MIT mime-types MIT mini_portile MIT minitest MIT minitest-rails MIT mixlib-log Apache 2.0 mocha MIT mono_logger MIT multi_json MIT multi_xml MIT multipart-post MIT mysql2 MIT net-http-persistent MIT net-scp MIT net-sftp MIT net-ssh MIT net-ssh-gateway MIT netrc MIT nokogiri MIT oauth2 MIT oj MIT omniauth MIT omniauth-oauth2 MIT pagerduty MIT papers MIT pg BSD pg Ruby phantomjs BSD phantomjs-binaries Unlicensed poltergeist MIT polyamorous MIT polyglot MIT polyglot MIT protected_attributes MIT pry MIT pry-nav MIT pry-rails MIT pry-stack_explorer MIT puma BSD quiet assets MIT rack MIT rack-cache MIT rack-contrib MIT rack-oauth2 MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-ssl MIT rack-ssl-enforcer MIT rack-test MIT rails MIT rails-deprecated_sanitizer MIT rails-dom-testing MIT rails-html-sanitizer MIT rails-observers MIT rails_12factor MIT rails_serve_static_assets MIT rails_stdout_logging MIT railties MIT raindrops LGPLv3 raindrops LGPLv3 raindrops LGPLv2.1+ rake MIT rake MIT rake MIT rake MIT ransack MIT rb-fsevent MIT rb-inotify MIT rdoc Ruby redcarpet MIT redis MIT redis-namespace MIT redis-queue MIT ref MIT remote_syslog_logger MIT request_store MIT responders MIT resque MIT resque-cleaner MIT resque-pool MIT resque-scheduler MIT resque-status MIT rest-client MIT restforce MIT rspec MIT rspec-core MIT rspec-expectations MIT rspec-mocks MIT rspec-rails MIT rspec-support MIT rspec_junit_formatter MIT rubyntlm MIT ruby-saml MIT rufus-scheduler MIT safe_yaml MIT salesforce_bulk_query BSD sass MIT sass-rails MIT sass-rails MIT sdoc MIT secure_headers Apache 2.0 sequel MIT serveza MIT settingslogic MIT shoulda MIT shoulda-context MIT shoulda-matchers MIT simplecov MIT simplecov-html MIT simplecov-rcov MIT sinatra MIT sinatra-activerecord MIT sinatra-contrib MIT skinny MIT slop MIT spring MIT sprockets MIT sprockets-rails MIT sqlite3 BSD sshkit GPL-No Distro sys-uname Ruby syslog_protocol MIT systemu BSDL term-ansicolor GPL-No Distro terminal-table MIT therubyracer MIT thin Ruby thor MIT thread_safe Apache-2.0 thrift Apache 2.0 thrift-rack MIT tilt MIT timecop MIT timers MIT tins MIT treetop MIT turbolinks MIT twitter-bootstrap-rails MIT typhoeus MIT tzinfo MIT uglifier MIT unicorn Ruby unicorn-rails MIT uuid MIT uuidtools Apache-2.0 vegas MIT webmock MIT web-console MIT xml-simple Ruby xpath MIT yard MIT Storage services Library License Amazon AWS SDK for Java Apache 2.0 Amazon AWS Command Line Interface Apache 2.0 Go packages Library License Go-Mysql-Driver Mozilla Public License 2.0 gocql BSD 3-Clause groupcache Apache 2.0 Migrate MIT go-sqlite3 MIT Revel MIT Pathtree MIT Ansicolor MIT fsnotify BSD 3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.98349,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Services <em>licenses</em>",
        "sections": "Services <em>licenses</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Contents Java internal"
      },
      "id": "603ea24364441f91fb4e8864"
    }
  ],
  "/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions": [
    {
      "sections": [
        "Original product-based pricing definitions",
        "App",
        "App transaction",
        "AWS Lambda event",
        "Check",
        "Compute unit",
        "Datapoints per minute",
        "Event",
        "Host",
        "Incident event",
        "Page view",
        "Per GB daily",
        "Span",
        "User"
      ],
      "title": "Original product-based pricing definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "42087e53167736831855bf9a4c2967c465677b45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/legacy-product-definitions/",
      "published_at": "2021-05-05T16:22:53Z",
      "updated_at": "2021-04-22T16:04:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our original product-based pricing. For New Relic One pricing plan terms, see New Relic One pricing definitions. App An app means the application software designed to run on smartphones, tablet computers, and other mobile devices. Each app includes a predefined number of users. App transaction An app transaction is an APM application's attempt to process a web or non-web request. In APM these manifest as throughput TIMESERIES or individually as events in the Transaction event type. AWS Lambda event An AWS Lambda event means the row of data collected from the customer's AWS Lambda function by the New Relic agent or sent from an external service into the New Relic platform. It consists of the AwsLambdaInvocation, AwsLambdaInvocationError, or custom event types. Check A check means the single instance of a Synthetics monitor running in New Relic's monitoring network and reporting back response time, and whether the check was a success or failure. Compute unit A compute unit means the measure of resources associated with a unit of computation on a physical or virtual host. Datapoints per minute Datapoints per minute (DPM) refers to the per-minute rate at which individual metric values are sent to the New Relic Metric Ingest API. For billing purposes, datapoints per minute are calculated as a monthly average value by summing the datapoints ingested during a 30 day period and dividing by the number of minutes in that period (43,200). Event An event means the row of data collected from the customer's application by the New Relic agent or sent from an external service into the Insights event database. Host A host means the physical computer or virtual machine instance running a single copy of an operating system. Host usage is tracked monthly by summing the hours that every host in the account is connected to New Relic and dividing by 750. A host is counted if it is connected any time during an hour. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic AI platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Page view A page view means the full page load (triggering an onLoad event) or a recorded URL change (state change). Per GB daily Per GB daily represents a daily average of Log data sent to New Relic over a 30 day period. Span A span represents an operation summary collected from the customer's application via the New Relic APM agent or New Relic Serverless for AWS Lambda agent, or sent from other tracing tools to the New Relic Trace API. User A user means the individual that connects to your app from a single device. Each unique device is considered as a unique user.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.8066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Original <em>product</em>-based pricing <em>definitions</em>",
        "sections": "Original <em>product</em>-based pricing <em>definitions</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": "This is a glossary of terms that appear in contracts for our original <em>product</em>-based pricing. For New Relic One pricing plan terms, see New Relic One pricing <em>definitions</em>. App An app means the application software designed to run on smartphones, tablet computers, and other mobile devices. Each app"
      },
      "id": "603ebacc64441f77774e8872"
    },
    {
      "sections": [
        "Product-based pricing usage and New Relic Platform Pricing Usage Plan",
        "Important",
        "Usage Plan: New Relic Platform Pricing",
        "Eligible Services",
        "Eligible Services (Partners)",
        "Subscriptions with indeterminate pricing or usage quantities",
        "Product Usage Ratio"
      ],
      "title": "Product-based pricing usage and New Relic Platform Pricing Usage Plan",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "e2686dc773c4e844544ce633a9a41a16f15edf5a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/product-based-pricing-usage-new-relic-platform-pricing-usage-plan/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-03-16T04:22:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc explains our original product-based pricing plan. For more about pricing changes, see Overview of pricing changes. The following provisions are applicable to existing customers (i) that have existing Terms, and (ii) that to the extent its subscription to the New Relic products reference the usage plans set forth below or where a subscription has indeterminate product pricing or usage quantities. New customers are eligible for New Relic One pricing as described here. Capitalized terms not defined below shall take on the meaning set forth in such New Relic order form. Usage Plan: New Relic Platform Pricing The following Eligible Services with New Relic are products that are referenced in specific order forms for New Relic Platform Pricing. For more information, contact your New Relic account representative. Eligible Services Eligible Services Per Unit Unit of Measure Monthly Standard Fee Rate New Relic APM Pro CU Annual* 10,000 Compute Units $166.70 New Relic APM Pro Host Annual* 1 Hosts $149 New Relic Insights Pro Annual 50,000,000 Events $165 New Relic Infrastructure Pro Annual 10,000 Compute Units $12 New Relic Browser Pro Annual 500,000 Page Views $149 New Relic Logs Annual - 8 Days* * 1 Per GB Daily $55 New Relic Logs Annual - 15 Days* * 1 Per GB Daily $65 New Relic Logs Annual - 30 Days* * 1 Per GB Daily $75 New Relic Metrics Annual 1,000 Data Points per Minute $25 New Relic Mobile Enterprise Annual 50,000 Total Users $499 New Relic Serverless for AWS Lambda Annual 1,000,000 AWS Lambda Events $15 New Relic Synthetics Pro Annual 10,000 Checks $69 New Relic Synthetics private locations (for New Relic Synthetics Pro Annual product) Fixed fee N/A $1,000 New Relic Traces Annual 1,000,000 Spans $1 New Relic AI Incident Intelligence Annual 1,000 Incident Events $500 New Relic AI Proactive Detection Annual 1,000,000,000 App Transactions $250 * Customer may utilize either New Relic APM Pro Annual or New Relic APM Pro CUs Annual, but not both. Customer will be provisioned New Relic APM Pro CUs Annual by default, unless otherwise stated in the relevant Order Form. * * Customer may utilize only one of New Relic Logs Annual - 8 Days, New Relic Logs Annual - 15 Days, or New Relic Logs Annual - 30 days. For the avoidance of doubt, Customer may not utilize New Relic Logs Annual with varying numbers of days retention concurrently. Customer will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. For more information about units of measures, see Product definitions. Eligible Services (Partners) Eligible services for New Relic Partners Measurement New Relic APM Pro CU Annual* Sold in Units of 8,900 Compute Units New Relic APM Pro Host Annual* Sold in Units of 1 Host New Relic Browser Pro Annual Sold in Units of 500,000 Page Views New Relic Infrastructure Pro Annual Sold in Units of 125,000 Compute Units New Relic Insights Pro Annual Sold in Units of 45,000,000 Events New Relic Logs Annual - 8 Days* * Sold in Units of 3 GB Daily New Relic Logs Annual - 15 Days* * Sold in Units of 2.5 GB Daily New Relic Logs Annual - 30 Days* * Sold in Units of 2 GB Daily New Relic Metrics Annual Sold in Units of 6,000 Data Points per Minute New Relic Mobile Enterprise Annual Sold in Units of 15,000 Total Users New Relic Serverless for AWS Lambda Annual Sold in Units of 10,000,000 AWS Lambda Events New Relic Synthetics Pro with Private Locations Annual Sold in Units of 22,000 Checks New Relic Traces Annual Sold in Units of 149,000,000 Spans * Customer and/or Partner may utilize either New Relic APM Pro Annual or New Relic APM Pro CUs Annual, but not both. Customer and/or Partner will be provisioned New Relic APM Pro CUs Annual by default, unless otherwise stated in the relevant Order Form. * * Customer and/or Partner may utilize only one of New Relic Logs Annual - 8 Days, New Relic Logs Annual - 15 Days, or New Relic Logs Annual - 30 days. For the avoidance of doubt, Customer may not utilize New Relic Logs Annual with varying numbers of days retention concurrently. Customer and/or Partner will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. Subscriptions with indeterminate pricing or usage quantities Product Usage Ratio Where a Customer subscription to the Products contain no specific pricing or quantities, Product-specific usage for a specific calendar month shall be determined through the calculation of the following ratio (the “Product Usage Ratio”) where: (1) the numerator shall be the Product specific usage for such calendar month multiplied by such Product’s list price, and (2) the denominator shall be the the aggregate Customer usage of all Products during such calendar month multiplied by all such Product(s) list price. The Product Usage Ratio shall be the percentage of usage for a specific Product for a calendar month period, or if usage cannot be measured for a period, the last Product Usage Ratio that can be calculated shall be assumed constant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.53058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Product</em>-based pricing usage and New Relic Platform Pricing Usage Plan",
        "sections": "<em>Product</em>-based pricing usage and New Relic Platform Pricing Usage Plan",
        "tags": "<em>License</em> <em>information</em>",
        "body": " will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. For more <em>information</em> about units of measures, see <em>Product</em> <em>definitions</em>. Eligible Services (Partners) Eligible services for New Relic Partners Measurement New Relic APM Pro CU Annual* Sold in Units"
      },
      "id": "603ea32a28ccbc7e22eba768"
    },
    {
      "sections": [
        "Services licenses",
        "Contents",
        "Java internal services",
        "Java crash data API",
        "CoffeeScript",
        "JavaScript",
        "Crash reporting",
        "Label services",
        "Infrastructure Monitoring services",
        ".NET support uploader service",
        "Ruby gems",
        "Storage services",
        "Go packages"
      ],
      "title": "Services licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "49a2ad450d31dacfc2aae690ca947d2326d18761",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/other-licenses/services-licenses/",
      "published_at": "2021-05-05T16:28:24Z",
      "updated_at": "2021-04-06T00:26:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Contents Java internal services Java crash data API Framework License Apache TomCat Apache 2.0 Bean Validation Apache 2.0 Cassandra Driver Core Apache 2.0 ClassMate Apache 2.0 Hamcrest BSD Mockito MIT Netty Apache 2.0 Objenesis MIT SnakeYAML Apache 2.0 Spring Boot Apache 2.0 Java internal services Library License json_simple Apache 2.0 newrelic-api New Relic newrelic-api New Relic antlr BSD aopalliance Public Domain asm-analysis BSD asm-commons BSD asm-tree BSD asm-util BSD asm BSD c3p0 EPLv1.0 cglib-nodep Apache 2.0 cglib Apache 2.0 cglib Apache 2.0 cal10n-api MIT logback-classic EPLv1.0 logback-core EPLv1.0 guava-jetty-service Apache 2.0 zkclient Apache 2.0 reporter-config-base Apache 2.0 reporter-config3 Apache 2.0 reporter-config Apache 2.0 aws-java-sdk-acm Apache 2.0 aws-java-sdk-api-gateway Apache 2.0 aws-java-sdk-applicationautoscaling Apache 2.0 aws-java-sdk-autoscaling Apache 2.0 aws-java-sdk-cloudformation Apache 2.0 aws-java-sdk-cloudfront Apache 2.0 aws-java-sdk-cloudhsm Apache 2.0 aws-java-sdk-cloudsearch Apache 2.0 aws-java-sdk-cloudtrail Apache 2.0 aws-java-sdk-cloudwatch Apache 2.0 aws-java-sdk-cloudwatchmetrics Apache 2.0 aws-java-sdk-codecommit Apache 2.0 aws-java-sdk-codedeploy Apache 2.0 aws-java-sdk-codepipeline Apache 2.0 aws-java-sdk-cognitoidentity Apache 2.0 aws-java-sdk-cognitoidp Apache 2.0 aws-java-sdk-cognitosync Apache 2.0 aws-java-sdk-config Apache 2.0 aws-java-sdk-core Apache 2.0 aws-java-sdk-datapipeline Apache 2.0 aws-java-sdk-devicefarm Apache 2.0 aws-java-sdk-directconnect Apache 2.0 aws-java-sdk-directory Apache 2.0 aws-java-sdk-discovery Apache 2.0 aws-java-sdk-dms Apache 2.0 aws-java-sdk-dynamodb Apache 2.0 aws-java-sdk-ec2 Apache 2.0 aws-java-sdk-ecr Apache 2.0 aws-java-sdk-ecs Apache 2.0 aws-java-sdk-efs Apache 2.0 aws-java-sdk-elasticache Apache 2.0 aws-java-sdk-elasticbeanstalk Apache 2.0 aws-java-sdk-elasticloadbalancing Apache 2.0 aws-java-sdk-elasticloadbalancingv2 Apache 2.0 aws-java-sdk-elasticsearch Apache 2.0 aws-java-sdk-elastictranscoder Apache 2.0 aws-java-sdk-emr Apache 2.0 aws-java-sdk-events Apache 2.0 aws-java-sdk-gamelift Apache 2.0 aws-java-sdk-glacier Apache 2.0 aws-java-sdk-iam Apache 2.0 aws-java-sdk-importexport Apache 2.0 aws-java-sdk-inspector Apache 2.0 aws-java-sdk-iot Apache 2.0 aws-java-sdk-kinesis Apache 2.0 aws-java-sdk-kms Apache 2.0 aws-java-sdk-lambda Apache 2.0 aws-java-sdk-logs Apache 2.0 aws-java-sdk-machinelearning Apache 2.0 aws-java-sdk-marketplacecommerceanalytics Apache 2.0 aws-java-sdk-marketplacemeteringservice Apache 2.0 aws-java-sdk-models Apache 2.0 aws-java-sdk-opsworks Apache 2.0 aws-java-sdk-rds Apache 2.0 aws-java-sdk-redshift Apache 2.0 aws-java-sdk-route53 Apache 2.0 aws-java-sdk-s3 Apache 2.0 aws-java-sdk-servicecatalog Apache 2.0 aws-java-sdk-ses Apache 2.0 aws-java-sdk-simpledb Apache 2.0 aws-java-sdk-simpleworkflow Apache 2.0 aws-java-sdk-snowball Apache 2.0 aws-java-sdk-sns Apache 2.0 aws-java-sdk-sqs Apache 2.0 aws-java-sdk-ssm Apache 2.0 aws-java-sdk-storagegateway Apache 2.0 aws-java-sdk-sts Apache 2.0 aws-java-sdk-support Apache 2.0 aws-java-sdk-swf-libraries Apache 2.0 aws-java-sdk-waf Apache 2.0 aws-java-sdk-workspaces Apache 2.0 aws-java-sdk Apache 2.0 jmespath-java Apache 2.0 AppleJavaExtensions BSD jcommander Apache 2.0 high-scale-lib MIT hppc Apache 2.0 clover Paid stream Apache 2.0 metrics-core Apache 2.0 cassandra-driver-core Apache 2.0 cassandra-driver-core Apache 2.0 uuid MIT grabbag MIT speed4j Apache 2.0 yamlbeans BSD jackson-annotations Apache 2.0 jackson-core Apache 2.0 jackson-databind Apache 2.0 jackson-dataformat-cbor Apache 2.0 jackson-dataformat-csv Apache 2.0 jackson-dataformat-xml Apache 2.0 jackson-dataformat-yaml Apache 2.0 jackson-datatype-guava Apache 2.0 jackson-datatype-jdk7 Apache 2.0 jackson-datatype-jdk8 Apache 2.0 jackson-datatype-joda Apache 2.0 jackson-datatype-jsr310 Apache 2.0 jackson-jaxrs-base Apache 2.0 jackson-jaxrs-json-provider Apache 2.0 jackson-module-afterburner Apache 2.0 jackson-module-jaxb-annotations Apache 2.0 jackson-module-kotlin Apache 2.0 woodstox-core Apache 2.0 classmate Apache 2.0 zjsonpatch Apache 2.0 caffeine Apache 2.0 waffle-jna EPLv1.0 docker-java Apache 2.0 docker-java Apache 2.0 btf Apache 2.0 jackson-coreutils Apache 2.0 json-schema-core Apache 2.0 json-schema-validator Apache 2.0 msg-simple Apache 2.0 uri-template Apache 2.0 jamm Apache 2.0 jffi Apache 2.0 jnr-constants Apache 2.0 jnr-ffi Apache 2.0 jnr-ffi Apache 2.0 jnr-posix EPLv1.0 jnr-x86asm MIT embedded-redis Apache 2.0 memoryfilesystem MIT guava-retrying Apache 2.0 guava-retrying Apache 2.0 snowball-stemmer BSD system-rules CPL uuid Apache 2.0 wiremock Apache 2.0 auto-common Apache 2.0 annotations LGPLv2.1 annotations LGPLv2.1 bcel-findbugs LGPLv2.1 findbugs LGPLv2.1 jFormatString BSD jFormatString BSD jsr305 BSD jsr305 BSD jsr305 BSD gson Apache 2.0 spymemcached MIT guava-testlib Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guice-multibindings Apache 2.0 guice Apache 2.0 truth Apache 2.0 concurrent-trees Apache 2.0 concurrentlinkedhashmap-lru Apache 2.0 json-simple Apache 2.0 libphonenumber Apache 2.0 locality-uuid BSD h2 EPLv1.0 annotations Apache 2.0 json-path-assert Apache 2.0 json-path Apache 2.0 json-path Apache 2.0 jzlib BSD bonecp-provider Apache 2.0 bonecp Apache 2.0 junixsocket-common Apache 2.0 junixsocket-native-common Apache 2.0 disruptor Apache 2.0 geoip-api LGPLv2.1 c3p0 LGPLv2.1 mchange-commons-java LGPLv2.1 archaius-core Apache 2.0 hystrix-core Apache 2.0 hystrix-servo-metrics-publisher Apache 2.0 rxjava-core Apache 2.0 servo-core Apache 2.0 kafka-clients Apache 2.0 kafka_2.10 Apache 2.0 kafka_2.11 Apache 2.0 common-cassandra Apache 2.0 timeslice_utils New Relic mockito-kotlin MIT compress-lzf Apache 2.0 checkstyle Apache 2.0 dagger-compiler Apache 2.0 dagger Apache 2.0 okhttp Apache 2.0 okio Apache 2.0 javapoet Apache 2.0 javawriter Apache 2.0 jaxb-impl CDDLv1 thrift-server Apache 2.0 finagle-core_2.10 Apache 2.0 finagle-core_2.11 Apache 2.0 finagle-http_2.10 Apache 2.0 finagle-http_2.11 Apache 2.0 jsr166e Creative Commons util-app_2.10 Apache 2.0 util-app_2.11 Apache 2.0 util-cache_2.10 Apache 2.0 util-cache_2.11 Apache 2.0 util-codec_2.10 Apache 2.0 util-codec_2.11 Apache 2.0 util-collection_2.10 Apache 2.0 util-collection_2.11 Apache 2.0 util-core_2.10 Apache 2.0 util-core_2.11 Apache 2.0 util-function_2.10 Apache 2.0 util-function_2.11 Apache 2.0 util-hashing_2.10 Apache 2.0 util-hashing_2.11 Apache 2.0 util-jvm_2.10 Apache 2.0 util-jvm_2.11 Apache 2.0 util-lint_2.10 Apache 2.0 util-lint_2.11 Apache 2.0 util-logging_2.10 Apache 2.0 util-logging_2.11 Apache 2.0 util-registry_2.10 Apache 2.0 util-registry_2.11 Apache 2.0 util-stats_2.10 Apache 2.0 util-stats_2.11 Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 HikariCP Apache 2.0 commons-beanutils Apache 2.0 commons-cli Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-io Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 commons-pool Apache 2.0 unix-socket-factory Apache 2.0 unix-socket-factory Apache 2.0 jflex BSD dom4j BSD airline Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 metrics-healthchecks Apache 2.0 metrics-httpclient Apache 2.0 metrics-jdbi Apache 2.0 metrics-jersey2 Apache 2.0 metrics-jetty9 Apache 2.0 metrics-json Apache 2.0 metrics-jvm Apache 2.0 metrics-logback Apache 2.0 metrics-servlets Apache 2.0 dropwizard-java8-jdbi Apache 2.0 dropwizard-client Apache 2.0 dropwizard-configuration Apache 2.0 dropwizard-core Apache 2.0 dropwizard-db Apache 2.0 dropwizard-jackson Apache 2.0 dropwizard-jdbi Apache 2.0 dropwizard-jersey Apache 2.0 dropwizard-jetty Apache 2.0 dropwizard-lifecycle Apache 2.0 dropwizard-logging Apache 2.0 dropwizard-metrics Apache 2.0 dropwizard-servlets Apache 2.0 dropwizard-testing Apache 2.0 dropwizard-util Apache 2.0 dropwizard-validation Apache 2.0 netty-all Apache 2.0 netty-buffer Apache 2.0 netty-codec-http Apache 2.0 netty-codec-socks Apache 2.0 netty-codec Apache 2.0 netty-common Apache 2.0 netty-handler-proxy Apache 2.0 netty-handler Apache 2.0 netty-resolver Apache 2.0 netty-transport-native-epoll Apache 2.0 netty-transport Apache 2.0 netty Apache 2.0 ratpack-core Apache 2.0 ratpack-groovy-test Apache 2.0 ratpack-groovy Apache 2.0 ratpack-guice Apache 2.0 ratpack-test Apache 2.0 rxjava Apache 2.0 fastutil Apache 2.0 janino BSD activation Apache 2.0 javax.annotation-api CDDLv1 jsr250-api CDDLv1 javax.inject Apache 2.0 mail CDDLv1 mailapi CDDLv1 javax.servlet-api Apache 2.0 servlet-api Apache 2.0 javax.transaction-api CDDLv1 validation-api Apache 2.0 javax.websocket-api CDDLv1 javax.ws.rs-api CDDLv1 jaxb-api CDDLv1 stax-api CDDLv1 jaxen Apache 2.0 jline BSD jline BSD joda-time Apache 2.0 junit-dep CPL junit CPL junit EPLv1.0 kafka_2.10 Apache 2.0 kafka_2.9.2 Apache 2.0 apache-log4j-extras Apache 2.0 log4j Apache 2.0 mysql-connector-java GPLv2 with Classpath Exception byte-buddy Apache 2.0 byte-buddy Apache 2.0 jna-platform LGPLv2.1 jna Apache 2.0 jcip-annotations Apache 2.0 lz4 Apache 2.0 accessors-smart Apache 2.0 asm Apache 2.0 json-smart Apache 2.0 json-smart Apache 2.0 primitive GPLv2 with Classpath Exception compiler Apache 2.0 lang Apache 2.0 beaver-cc BSD ehcache-core Apache 2.0 ehcache Apache 2.0 jopt-simple MIT jopt-simple MIT opencsv Apache 2.0 quality-check Apache 2.0 scannotation Apache 2.0 super-csv Apache 2.0 uadetector-core Apache 2.0 uadetector-resources Apache 2.0 argparse4j MIT spymemcached MIT kalium Apache 2.0 ST4 BSD antlr-runtime BSD antlr-runtime BSD antlr BSD stringtemplate BSD ant-launcher Apache 2.0 ant Apache 2.0 cassandra-all Apache 2.0 cassandra-all Apache 2.0 cassandra-thrift Apache 2.0 cassandra-thrift Apache 2.0 commons-collections4 Apache 2.0 commons-compress Apache 2.0 commons-csv Apache 2.0 commons-dbcp2 Apache 2.0 commons-io Apache 2.0 commons-lang3 Apache 2.0 commons-math3 Apache 2.0 commons-math Apache 2.0 commons-pool2 Apache 2.0 curator-client Apache 2.0 curator-framework Apache 2.0 curator-recipes Apache 2.0 curator-test Apache 2.0 derby Apache 2.0 geronimo-servlet_3.0_spec Apache 2.0 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 ivy Apache 2.0 kafka-clients Apache 2.0 kafka_2.11 Apache 2.0 libthrift Apache 2.0 tomcat-embed-core Apache 2.0 tomcat-embed-el Apache 2.0 tomcat-embed-logging-juli Apache 2.0 tomcat-embed-websocket Apache 2.0 tomcat-jdbc Apache 2.0 tomcat-juli Apache 2.0 zookeeper Apache 2.0 aspectjweaver EPLv1.0 assertj-core Apache 2.0 assertj-core Apache 2.0 evo-inflector Apache 2.0 bcmail-jdk15on MIT bcpkix-jdk15on MIT bcprov-jdk15on MIT ohc-core Apache 2.0 cassandra-unit-spring LGPLv3 cassandra-unit-spring LGPLv3 cassandra-unit LGPLv3 cassandra-unit LGPLv3 groovy-all Apache 2.0 groovy-all Apache 2.0 groovy Apache 2.0 groovy Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 easymock Apache 2.0 ecj EPLv1.0 javax.activation CDDLv1 javax.annotation CDDLv1 javax.mail.glassfish CDDLv1 javax.servlet CDDLv1 javax.transaction CDDLv1 org.objectweb.asm BSD jetty-setuid-java EPLv1.0 jetty-schemas Apache 2.0 javax-websocket-client-impl Apache 2.0 javax-websocket-server-impl Apache 2.0 websocket-api Apache 2.0 websocket-client Apache 2.0 websocket-common Apache 2.0 websocket-server Apache 2.0 websocket-servlet Apache 2.0 apache-jsp Apache 2.0 jetty-annotations CDDLv1 jetty-client Apache 2.0 jetty-continuation Apache 2.0 jetty-http Apache 2.0 jetty-io Apache 2.0 jetty-jmx Apache 2.0 jetty-jndi Apache 2.0 jetty-plus Apache 2.0 jetty-proxy Apache 2.0 jetty-security Apache 2.0 jetty-server Apache 2.0 jetty-servlet Apache 2.0 jetty-servlets Apache 2.0 jetty-util Apache 2.0 jetty-webapp Apache 2.0 jetty-xml Apache 2.0 sigar Apache 2.0 aopalliance-repackaged CDDLv1 javax.inject CDDLv1 hk2-api CDDLv1 hk2-locator CDDLv1 hk2-utils CDDLv1 osgi-resource-locator CDDLv1 jersey-guava CDDLv1 jersey-client CDDLv1 jersey-apache-connector CDDLv1 jersey-container-servlet-core CDDLv1 jersey-container-servlet CDDLv1 jersey-client CDDLv1 jersey-common CDDLv1 jersey-server CDDLv1 jersey-bean-validation CDDLv1 jersey-metainf-services CDDLv1 jersey-media-jaxb CDDLv1 jersey-client CDDLv1 jersey-test-framework-provider-inmemory CDDLv1 jersey-test-framework-core CDDLv1 javax.el CDDLv1 hamcrest-all BSD hamcrest-core BSD hamcrest-integration BSD hamcrest-library BSD HdrHistogram Public Domain hector-core MIT hibernate-commons-annotations LGPLv2.1 hibernate-jpa-2.0-api LGPLv2.1 hibernate-jpa-2.1-api LGPLv2.1 hibernate-c3p0 Apache 2.0 hibernate-core Apache 2.0 hibernate-ehcache Apache 2.0 hibernate-entitymanager Apache 2.0 hibernate-jmx Apache 2.0 hibernate-validator Apache 2.0 freebuilder Apache 2.0 org.jacoco.agent EPLv1.0 org.jacoco.ant EPLv1.0 org.jacoco.core EPLv1.0 org.jacoco.report EPLv1.0 javassist Apache 2.0 jboss-logging-annotations LGPLv2.1 jboss-logging Apache 2.0 jboss-transaction-api_1.1_spec LGPLv2.1 jboss-transaction-api_1.2_spec LGPLv2.1 jandex Apache 2.0 jdbi Apache 2.0 job-dsl-core Apache 2.0 version-number MIT kotlin-annotation-processing Apache 2.0 kotlin-reflect Apache 2.0 kotlin-runtime Apache 2.0 kotlin-stdlib Apache 2.0 kotlin-test-junit Apache 2.0 kotlin-test Apache 2.0 annotations Apache 2.0 jolokia-core Apache 2.0 jruby-complete LGPLv2.1 LGPLv2.1 json Public Domain json Apache 2.0 xstream BSD annotations Apache 2.0 mapdb Apache 2.0 mapdb Apache 2.0 jbcrypt ISC mockserver-client-java Apache 2.0 mockserver-core Apache 2.0 mockserver-logging Apache 2.0 mockserver-netty Apache 2.0 mockito-all MIT mockito-core MIT mockito-core MIT apache-el Apache 2.0 apache-jsp Apache 2.0 alpn-boot Apache 2.0 etcd4j Apache 2.0 msgpack Apache 2.0 objenesis Apache 2.0 objenesis Apache 2.0 jmh-core GPLv2 with Classpath Exception jmh-generator-annprocess GPLv2 with Classpath Exception jol-core GPLv2 with Classpath Exception asm-analysis BSD asm-analysis BSD asm-commons BSD asm-debug-all BSD asm-tree BSD asm-util BSD asm-util BSD asm BSD asm Public Domain postgresql BSD powermock-api-mockito Apache 2.0 powermock-api-support Apache 2.0 powermock-core Apache 2.0 powermock-module-junit4-common Apache 2.0 powermock-module-junit4 Apache 2.0 powermock-reflect Apache 2.0 lombok MIT reactive-streams Public Domain reflections WTFPL scala-java8-compat_2.11 Scala scala-parser-combinators_2.11 Scala scala-xml_2.11 Scala scala-library Scala scala-reflect Scala scalatest_2.10 Apache 2.0 scalatest_2.11 Apache 2.0 native-lib-loader BSD jsonassert Apache 2.0 jcl-over-slf4j MIT jul-to-slf4j MIT log4j-log4j12 MIT log4j-over-slf4j MIT slf4j-api MIT slf4j-ext MIT slf4j-log4j12 MIT slf4j-simple MIT spock-core Apache 2.0 spock-core Apache 2.0 spring-boot-actuator Apache 2.0 spring-boot-autoconfigure Apache 2.0 spring-boot-configuration-processor Apache 2.0 spring-boot-starter-actuator Apache 2.0 spring-boot-starter-aop Apache 2.0 spring-boot-starter-data-jpa Apache 2.0 spring-boot-starter-data-rest Apache 2.0 spring-boot-starter-jdbc Apache 2.0 spring-boot-starter-jetty Apache 2.0 spring-boot-starter-logging Apache 2.0 spring-boot-starter-test Apache 2.0 spring-boot-starter-tomcat Apache 2.0 spring-boot-starter-web Apache 2.0 spring-boot-starter Apache 2.0 spring-boot-test-autoconfigure Apache 2.0 spring-boot-test Apache 2.0 spring-boot Apache 2.0 spring-data-commons Apache 2.0 spring-data-jpa Apache 2.0 spring-data-rest-core Apache 2.0 spring-data-rest-webmvc Apache 2.0 spring-hateoas Apache 2.0 spring-plugin-core Apache 2.0 spring-aop Apache 2.0 spring-aspects Apache 2.0 spring-beans Apache 2.0 spring-context-support Apache 2.0 spring-context Apache 2.0 spring-core Apache 2.0 spring-core Apache 2.0 spring-expression Apache 2.0 spring-jdbc Apache 2.0 spring-orm Apache 2.0 spring-test Apache 2.0 spring-test Apache 2.0 spring-tx Apache 2.0 spring-web Apache 2.0 spring-webmvc Apache 2.0 xz Public Domain wasabi Apache 2.0 snappy-java Apache 2.0 xmlunit-core Apache 2.0 xmlunit-legacy Apache 2.0 snakeyaml Apache 2.0 JUnitParams Apache 2.0 postgresql BSD postgresql BSD jedis MIT scala-library Scala ion-java Apache 2.0 timeslice_service-thrift New Relic timeslice_service New Relic xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3_min Public Domain zkclient Apache 2.0 zookeeper Apache 2.0 CoffeeScript Library License CoffeeScript MIT coffin MIT JavaScript JavaScript License ie_html5/ie_html5.js MIT Angular.js MIT Angular UI directives for Bootstrap MIT Chart.js MIT Chosen JQuery plugin MIT Fullcalendar MIT Moment MIT Crash reporting Software License Apple OS X OS X Yosemite Xcode & Apple SDK Xcode license Label services Service License BoneCP Apache 2.0 Gradle Apache 2.0 Hibernate Apache 2.0 Spring Apache 2.0 Infrastructure Monitoring services Service License antlr BSD aopalliance Public Domain asm MIT cglib Apache 2.0 ch.qos.logback EPLv1.0 com.101tec Apache 2.0 com.amazonaws Apache 2.0 com.cenqua.clover Paid com.fasterxml.jackson.core Apache 2.0 com.fasterxml Apache 2.0 com.google.code.findbugs BSD com.google.guava Apache 2.0 com.googlecode.json-simple Apache 2.0 com.intellij Apache 2.0 New Relic com.squareup.dagger Apache 2.0 com.squareup Apache 2.0 com.yammer.metrics Apache 2.0 commons-codec Apache 2.0 commons-configuration Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 dom4j BSD io.netty Apache 2.0 javax.annotation CDDLv1 javax.inject Apache 2.0 javax.servlet.jsp CDDLv1 javax.servlet Apache 2.0 javax.validation Apache 2.0 javax.websocket CDDLv1 jline BSD joda-time Apache 2.0 junit CPL log4j Apache 2.0 mysql GPLv2 with Classpath Exception net.sf.jopt-simple MIT org.apache.commons Apache 2.0 org.apache.httpcomponents Apache 2.0 org.apache.ivy Apache 2.0 org.apache.thrift Apache 2.0 org.apache.tomcat.embed Apache 2.0 org.apache.zookeeper Apache 2.0 org.codehaus.groovy Apache 2.0 org.codehaus.jackson Apache 2.0 org.easymock Apache 2.0 org.eclipse.jetty.orbit CDDLv1 org.eclipse.jetty.toolchain Apache 2.0 org.eclipse.jetty.websocket Apache 2.0 org.eclipse.jetty CDDLv1 org.glassfish.jersey.core CDDLv1 org.glassfish.web CDDLv1 org.glassfish CDDLv1 org.hamcrest BSD org.hibernate Apache 2.0 org.javassist Apache 2.0 org.jboss.logging LGPLv2.1 org.jenkins-ci.plugins Apache 2.0 org.jenkins-ci Apache 2.0 org.jetbrains Apache 2.0 org.jolokia Apache 2.0 org.jvnet.hudson BSD org.mockito MIT org.objenesis Apache 2.0 org.ow2.asm MIT org.reflections WTFPL org.scala-lang Scala org.slf4j MIT org.springframework.boot Apache 2.0 org.springframework Apache 2.0 org.xerial.snappy Apache 2.0 org.yaml Apache 2.0 xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3 Public Domain .NET support uploader service Library License Amazon AWS SDK for Java Apache 2.0 Apache Commons Codec Apache 2.0 Gson Apache 2.0 Jetty Apache 2.0 Ruby gems Ruby gems Gem License aasm MIT actionmailer MIT actionpack MIT activeadmin MIT actionview MIT activejob MIT active_model_serializers MIT activemodel MIT activerecord MIT activerecord-deprecated_finders MIT activerecord-mysql2-adapter MIT activeresource MIT activesupport MIT addressable Apache 2.0 angularjs-rails MIT arbre MIT arel MIT arel MIT atomic Apache 2.0 atomic Apache-2.0 attr_required MIT awesome_print MIT backports MIT better_errors MIT binding_of_caller MIT bourbon MIT brwsr MIT browser-timezone-rails MIT builder MIT bundler MIT byebug MIT callsite MIT capistrano MIT capistrano-bundler MIT capistrano-ext MIT capistrano-rbenv MIT capistrano-stats MIT capybara MIT celluloid MIT CFPropertyList MIT chunky_png MIT ci_reporter MIT ci_reporter_rspec MIT clockwork MIT codeclimate-test-reporter MIT coderay MIT coderay MIT coffee-rails MIT coffee-script MIT coffee-script-source MIT columnize Ruby compass MIT compass-core MIT compass-import-once MIT compass-rails MIT concurrent-ruby MIT crack MIT crypt Unlicensed daemons MIT dalli MIT database_cleaner MIT debug_inspector MIT debugger-linecache MIT diff-lcs MIT docile MIT dotenv MIT dotenv-deployment MIT erubis MIT etcd MIT ethon MIT eventmachine Ruby excon MIT execjs MIT factory_girl MIT factory_girl_rails MIT faraday MIT faraday-middleware MIT faye-websocket MIT ffi MIT ffi BSD fission MIT fog MIT fog-atmos MIT fog-aws MIT fog-brightbox MIT fog-core MIT fog-ecloud MIT fog-google MIT fog-json MIT fog-local MIT fog-powerdns MIT fog-profitbricks MIT fog-radosgw MIT fog-riakcs MIT fog-sakuracloud MIT fog-serverlove MIT fog-softlayer MIT fog-storm_on_demand MIT fog-terremark MIT fog-vmfusion MIT fog-voxel MIT fog-xml MIT font-awesome-rails MIT foreman MIT formatador MIT formtastic MIT formtastic i18n MIT fssm MIT globalid MIT guard MIT guard-rspec MIT haml MIT haml-rails MIT has scope MIT hashie MIT highline Ruby hike MIT hipchat-api MIT histogram MIT hitimes ISC hiredis BSD http_parser.rb MIT httpclient Ruby httpclient Ruby httparty MIT i18n MIT inflecto MIT inherited resources MIT intercom-rails MIT ipaddress MIT jasmine MIT jasmine-core MIT jasmine-rails MIT jbuilder MIT jira MIT jira-ruby OSL-3.0 journey MIT jquery-rails MIT jquery-turbolinks MIT jquery-ui-rails MIT json Ruby jwt MIT kaminari MIT kgio LGPLv3 kgio LGPLv3 kgio LGPL-v2.1+ libv8 MIT listen MIT logger Ruby loofah MIT lumberjack MIT macaddr MIT mail MIT mailcatcher MIT memoist MIT metaclass MIT meta_request MIT method_source MIT mime-types MIT mini_portile MIT minitest MIT minitest-rails MIT mixlib-log Apache 2.0 mocha MIT mono_logger MIT multi_json MIT multi_xml MIT multipart-post MIT mysql2 MIT net-http-persistent MIT net-scp MIT net-sftp MIT net-ssh MIT net-ssh-gateway MIT netrc MIT nokogiri MIT oauth2 MIT oj MIT omniauth MIT omniauth-oauth2 MIT pagerduty MIT papers MIT pg BSD pg Ruby phantomjs BSD phantomjs-binaries Unlicensed poltergeist MIT polyamorous MIT polyglot MIT polyglot MIT protected_attributes MIT pry MIT pry-nav MIT pry-rails MIT pry-stack_explorer MIT puma BSD quiet assets MIT rack MIT rack-cache MIT rack-contrib MIT rack-oauth2 MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-ssl MIT rack-ssl-enforcer MIT rack-test MIT rails MIT rails-deprecated_sanitizer MIT rails-dom-testing MIT rails-html-sanitizer MIT rails-observers MIT rails_12factor MIT rails_serve_static_assets MIT rails_stdout_logging MIT railties MIT raindrops LGPLv3 raindrops LGPLv3 raindrops LGPLv2.1+ rake MIT rake MIT rake MIT rake MIT ransack MIT rb-fsevent MIT rb-inotify MIT rdoc Ruby redcarpet MIT redis MIT redis-namespace MIT redis-queue MIT ref MIT remote_syslog_logger MIT request_store MIT responders MIT resque MIT resque-cleaner MIT resque-pool MIT resque-scheduler MIT resque-status MIT rest-client MIT restforce MIT rspec MIT rspec-core MIT rspec-expectations MIT rspec-mocks MIT rspec-rails MIT rspec-support MIT rspec_junit_formatter MIT rubyntlm MIT ruby-saml MIT rufus-scheduler MIT safe_yaml MIT salesforce_bulk_query BSD sass MIT sass-rails MIT sass-rails MIT sdoc MIT secure_headers Apache 2.0 sequel MIT serveza MIT settingslogic MIT shoulda MIT shoulda-context MIT shoulda-matchers MIT simplecov MIT simplecov-html MIT simplecov-rcov MIT sinatra MIT sinatra-activerecord MIT sinatra-contrib MIT skinny MIT slop MIT spring MIT sprockets MIT sprockets-rails MIT sqlite3 BSD sshkit GPL-No Distro sys-uname Ruby syslog_protocol MIT systemu BSDL term-ansicolor GPL-No Distro terminal-table MIT therubyracer MIT thin Ruby thor MIT thread_safe Apache-2.0 thrift Apache 2.0 thrift-rack MIT tilt MIT timecop MIT timers MIT tins MIT treetop MIT turbolinks MIT twitter-bootstrap-rails MIT typhoeus MIT tzinfo MIT uglifier MIT unicorn Ruby unicorn-rails MIT uuid MIT uuidtools Apache-2.0 vegas MIT webmock MIT web-console MIT xml-simple Ruby xpath MIT yard MIT Storage services Library License Amazon AWS SDK for Java Apache 2.0 Amazon AWS Command Line Interface Apache 2.0 Go packages Library License Go-Mysql-Driver Mozilla Public License 2.0 gocql BSD 3-Clause groupcache Apache 2.0 Migrate MIT go-sqlite3 MIT Revel MIT Pathtree MIT Ansicolor MIT fsnotify BSD 3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.98349,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Services <em>licenses</em>",
        "sections": "Services <em>licenses</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Contents Java internal"
      },
      "id": "603ea24364441f91fb4e8864"
    }
  ],
  "/docs/licenses/license-information/referenced-policies/new-relic-pre-release-policy": [
    {
      "sections": [
        "Security policy",
        "New Relic Security Policy",
        "1. Data Security",
        "2. Data Access",
        "3. Server Security",
        "4. Network Security",
        "5. Security Audits",
        "6. Security and Incident Response",
        "7. Disaster Recovery",
        "8. Copies and Removal",
        "9. Disclosure by Law"
      ],
      "title": "Security policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "291509f6b521ca34ac9d49039518e7da8b883518",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-policy/",
      "published_at": "2021-05-04T18:36:05Z",
      "updated_at": "2021-03-16T06:20:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The below Security Policy applies only to customers with an existing New Relic agreement in place that explicitly references this Security Policy applying to the Service purchased in an Order. Capitalized terms not defined below shall take on the meaning set forth in such New Relic agreement. New Relic Security Policy 1. Data Security 1.1. New Relic shall establish and maintain data security procedures and other safeguards designed to protect against the loss, theft or other unauthorized access or alteration of Customer Data in the possession or under the control of New Relic or to which New Relic has access, which are no less rigorous than accepted security standards in the industry. 1.2. New Relic shall maintain an information security policy that outlines a definition of information security and its overall objectives; a framework for setting control objectives and controls, including the structure of risk assessment and risk management; a brief explanation of the compliance requirements, and procedures for managing information security incidents. 2. Data Access 2.1. Access to Customer Data stored on New Relic’s systems shall not be granted to members of New Relic unless they have been uniquely identified and have sufficient credentials. 2.2. Access permissions shall be established in a manner that allows for the minimum access level(s) required for each employee. 2.3. Access to Customer Data shall be logged with sufficient information to determine the nature and scope of any inappropriate access. 3. Server Security 3.1. New Relic shall establish and follow reasonable server configuration guidelines and processes to prevent unauthorized access to Customer Data. 3.2. New Relic shall establish and follow reasonable configuration change management procedures for its servers containing Customer Data. 4. Network Security 4.1. New Relic network architecture shall be designed to limit site access and restrict the availability of information services that are considered to be vulnerable to attack. 4.2. New Relic shall utilize SSL certificates for all Internet activity. By default, Customer Data transmitted to and from the New Relic network shall be sent over encrypted medium or an encrypted format. 4.3. New Relic network shall use IDS technologies for network intrusion detection. 4.4. Access to New Relic systems containing Customer Data shall be restricted to authorized personnel. 5. Security Audits 5.1. New Relic shall conduct at least annually a SOC 2 or industry equivalent audit. New Relic shall provide to Customer audit results upon request, and shall explain and provide remediation plans to correct any problems to the extent reasonably possible. 6. Security and Incident Response 6.1. New Relic shall maintain an Information Security Incident Response plan, and make that plan available to Customer if requested. 6.2. In the event of an actual theft, loss, or unauthorized access of Customer Data by New Relic’s personnel and/or any unauthorized individual or entity, New Relic shall: (a) investigate such breach, (b) attempt to cure such breach, and (c) provide notification to Customer that describes such breach. 7. Disaster Recovery 7.1. New Relic shall have in effect a disaster recovery plan designed to respond to both a component failure of New Relic equipment within its data center and a catastrophic loss of service. This plan shall include documented policies and procedures to restore service in the event of either type of failure. 7.2. New Relic shall establish and follow backup and restore procedures for servers containing Customer Data. 8. Copies and Removal 8.1. In addition to any obligations of New Relic in the Agreement, upon expiration or termination of this Agreement for any reason: (a) New Relic shall, and shall cause its personnel, to cease and desist all access and use of any Customer Data, (b) New Relic shall delete all copies of Customer Data within ninety (90) days. 9. Disclosure by Law 9.1. In the event the New Relic is required by law, regulation, or legal process to disclose any Customer Data, New Relic shall (a) give Customer, to the extent possible, reasonable advance notice prior to disclosure so Customer may contest the disclosure or seek a protective order, and (b) reasonably limit the disclosure to the minimum amount that is legally required to be disclosed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.32755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security <em>policy</em>",
        "sections": "Security <em>policy</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " Relic has access, which are no less rigorous than accepted security standards in the industry. 1.2. New Relic shall maintain an <em>information</em> security policy that outlines a definition of <em>information</em> security and its overall objectives; a framework for setting control objectives and controls"
      },
      "id": "603ea3dbe7b9d22b802a0802"
    },
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-05-05T16:29:05Z",
      "updated_at": "2021-03-16T04:22:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to New Relic Full Stack Observability Pro or Enterprise Products, the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to New Relic Full Stack Observability Standard, any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make New Relic Full Stack Observability Standard and Telemetry Data Platform available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.27802,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One pricing: Definitions",
        "Account",
        "Commitment Term",
        "Customer Data",
        "Customer Properties",
        "Documentation",
        "GB Ingested",
        "Login Credentials",
        "Monthly Provisioned User",
        "Order",
        "Paid Terms of Service",
        "Product(s)",
        "Software",
        "Terms",
        "Third-Party Services",
        "Unpaid Terms of Service",
        "Usage Plan"
      ],
      "title": "New Relic One pricing: Definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "609575acd671fecf7899378157eabc57bc8d68e2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-04-22T16:06:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for organizations on our New Relic One pricing plan. For terms used in our original pricing plan, see Original pricing plan definitions. Account Account refers to the online account or subaccounts that New Relic provides for customers to manage their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, information, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer Properties Customer Properties means Customer’s websites, infrastructure, networks, mobile applications, or other systems, as well as Customer accounts on Third-Party Services. Documentation Documentation means the New Relic technical guides and documentation made available from the dedicated ‘Documentation’ page of the New Relic website. GB Ingested A GB Ingested is a measurement of the volume of metrics, events, logs, traces, or other telemetry data sent to or generated by the Products for the benefit of the Customer, including from the Software, the Customer Properties, or Third-Party Services. In this context, a GB is defined as 1 billion bytes. Login Credentials Login Credentials means the username, email address, password, or other personal information that is provided by a Customer user in order to manage an Account. Monthly Provisioned User A Monthly Provisioned User is any user who can log into Customer’s Account(s) and access the New Relic One Product functionality as specified in an Order and the Documentation. Order Order means the purchasing order for access to the Service or related services that: (1) is either executed by the Parties or entered into by you via self-service, and references this Agreement, or (2) is entered into by you and a Channel Partner. Paid Terms of Service Paid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/paid. Product(s) Product(s) mean the purchase of the New Relic subscription products described in the applicable Order and any updates, corrections, bug fixes, modifications, improvements, related services, new features, and functionality (made generally available to New Relic’s customer base) thereto. Software Software means the distributed software, APIs, scripts, or other code proprietary to New Relic provided with the Products. Terms Terms means the underlying Customer-New Relic agreement and the Order. Third-Party Services Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/unpaid. Usage Plan Usage Plan refers to the Service or Product pricing, invoicing related information, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.91359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": " their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, <em>information</em>, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third"
      },
      "id": "6044e6e528ccbc26f22c6084"
    }
  ],
  "/docs/licenses/license-information/referenced-policies/security-policy": [
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-05-05T16:29:05Z",
      "updated_at": "2021-03-16T04:22:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to New Relic Full Stack Observability Pro or Enterprise Products, the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to New Relic Full Stack Observability Standard, any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make New Relic Full Stack Observability Standard and Telemetry Data Platform available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customer’s access or use of the Service in accordance with this Agreement. This describes Customer’s sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.27802,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic Pre-release policy",
        "New Relic Pre-Release Policy",
        "1. Introduction",
        "2. License and Restrictions",
        "3. Confidential Information",
        "4. Disclaimers and Acknowledgement",
        "5. Limitation of Liability",
        "6. Indemnity",
        "7. Export Restrictions",
        "8. Termination"
      ],
      "title": "New Relic Pre-release policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5ca324e942906913fc346245cfd80d405e90ad1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/new-relic-pre-release-policy/",
      "published_at": "2021-05-05T16:29:56Z",
      "updated_at": "2021-03-13T01:17:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Without overriding any express provisions that you may have agreed to in a separate written beta or pre-release agreement executed by you and New Relic, the following terms apply to your use of any New Relic Pre-Release Service(s). New Relic Pre-Release Policy Through your use of any New Relic, Inc. (“New Relic”) Pre-Release Services (as further defined), you signify that you have read, understood, and accept the terms of this Pre-Release Policy (the “Policy”) governing your use and participation in New Relic’s program for making beta, alpha and pre-release versions of New Relic software (i.e. agents, SDKs, APIs, integrations, private locations, code, etc.), services, features, user-interfaces, and platforms made available for evaluation purposes (the “Pre-Release Service(s)”). This Policy is effective on behalf of yourself or the entity(ies) associated with your New Relic account (collectively referred to herein as “you” or “your”) as of your date of first use of the Pre-Release Service(s) (the “Effective Date”), which means that your choice to use the Pre-Release Service(s) means that you have the legal authority to use the Pre-Release Service(s) personally or on behalf of the company or organization associated with your New Relic account in accordance with this Policy. Please read this Policy carefully as your use of Pre-Release Service(s) may have unintended consequences and materially impact your data or use of the New Relic services and products. If you do not agree to this Policy, your sole remedy is to not make use of the Pre-Release Services. 1. Introduction This Policy and any New Relic technical guides and documentation made available with the Pre-Release Service(s) or from the dedicated ‘Documentation’ page of the New Relic website (the “Documentation”) enables you to test experimental features and products before they are made generally available. New Relic reserves the right to withhold or discontinue any Pre-Release Service(s), which may be designated as an alpha, beta, pilot, limited release, developer preview, technology preview, non-production, evaluation, or by a similar description, in its sole discretion and provides no guarantee that any Pre-Release Service(s) will eventually be made commercially or generally available. Pre-Release Service(s) are versions provided before they are generally available and may have bugs, stability issues, or other problems. Use of the Pre-Release Service(s) may result in unexpected results, loss of data, outages, or other damage to your systems or networks. New Relic advises against using the Pre-Release Service(s) in production. No support is offered with or for Pre-Release Service(s). You hereby release New Relic from any liability arising from or related to your use of the Pre-Release Service(s). In connection with your use of the Pre-Release Services, you may provide feedback, comments, and/or suggestions based on or relating to the Pre-Release Services (“Feedback”). The Pre-Release Services and any related information, including without limitation features, functionality, designs, user interface, capabilities, specifications, architectural diagrams, usage data, APIs, deployment schedules, email lists, bug databases, know how, source code, potential features, Feedback, and information related to any business or technical information of New Relic, including without limitation product plans, costs, prices, finances, marketing plans, business opportunities, research, development, and negotiations are considered confidential information of New Relic (“Confidential Information”). 2. License and Restrictions 2.1 Evaluation License. Subject to your compliance with the Policy, New Relic hereby grants you a limited, non-exclusive, non-transferable, revocable license, during the term of this Policy, to use the Pre-Release Service(s) in accordance with the Documentation solely for the purpose of internal evaluation and supplying Feedback to New Relic. 2.2 License Restrictions. You may not (and may not authorize or enable a third party to): (i) reverse engineer, decompile, disassemble, or otherwise attempt to discover the source code or other trade secrets in the Pre-Release Service(s); (ii) access the Pre-Release Service(s) in order to build a similar or competitive application, service, feature or other competitive purpose; (iii) remove or destroy any copyright notices or other proprietary marks contained on or in the Pre-Release Service(s); (iv) use the Pre-Release Service(s) for any benchmarking purposes or in connection with a service bureau, timeshare, service provider, or like activity where you operate the Pre-Release Service(s) on behalf of a third party; (v) mirror, frame, copy, modify, host, rent, lease, sell, commercialize, sublicense, assign or otherwise transfer the Pre-Release Service(s), or the access or use of the Pre-Release Service(s); (vi) use the Pre-Release Service(s) in a manner that may violate or infringe the intellectual property, data protection, or other proprietary right of a third party; (vii) use or access the Pre-Release Service(s) in an unauthorized manner and/or in a manner that violates any applicable law, rule, contract, or guideline (including but not limited to our Documentation or Community Guidelines); (viii) use the Pre-Release Service(s) to transmit worms, viruses, malicious code, security vulnerabilities, or otherwise negatively impact network operations, third parties, or New Relic; (ix) use any data mining or similar data gathering and extraction methods in connection with the Pre-Release Service(s); or (x) use the Pre-Release Service(s) to process sensitive personal information, e.g., “personal information” of children as defined by the Children’s Online Privacy Protection Act, “protected health information” as defined by the Health Insurance Portability and Accountability Act of 1996, government issued identification numbers, financial account information, payment card data, “special categories of data” as described in the EU General Data Protection Regulation (GDPR), or other information subject to regulatory, statutory, or contractual restrictions. New Relic reserves the right, but not the obligation, to monitor or review your use of the Pre-Release Service(s) at any time and may investigate any suspected violations of this Policy. 2.3 Intellectual Property Rights. You acknowledge and agree that, as between you and New Relic, New Relic owns all right, title, and interest in and to the Pre-Release Service(s), Confidential Information, and Feedback, including but not limited to all intellectual property and proprietary rights therein. New Relic and its licensors reserve all rights and licenses not expressly granted herein. 2.4 Feedback. You acknowledge and agree that all Feedback will be the sole and exclusive property of New Relic. You hereby irrevocably transfer and assign to New Relic all right, title, and interest in all Feedback, including but not limited to all intellectual property and proprietary rights therein. 3. Confidential Information You will not use or disclose any Confidential Information, except as necessary for the performance of this Policy, and you will use reasonable efforts to protect Confidential Information from unauthorized use or disclosure. You may disclose Confidential Information only to those employees with a bona fide need to know, provided that each employee has signed a written agreement with nondisclosure restrictions at least as protective of the Confidential Information as those set forth herein. For the purposes of this section, information will not be deemed Confidential Information if it: (a) is or becomes generally known to the public through no fault or breach of this Policy; (b) is rightfully known by you at the time of disclosure without an obligation of confidentiality; (c) is independently developed by you without access to or use of the Confidential Information; or (d) is rightfully obtained by you from a third party without restriction on use or disclosure. Upon New Relic’s request, you agree to destroy all Confidential Information in your possession within 30 days of termination of this Policy. 4. Disclaimers and Acknowledgement 4.1 Acknowledgement of Pre-Release Service(s). You acknowledge and agree that: (a) the Pre-Release Service(s) is not an official product and has not been commercially released for sale by New Relic; (b) the Pre-Release Service(s) may not operate properly, be in final form, or fully function; (c) the Pre-Release Service(s) may contain errors, design flaws, security vulnerabilities, or other problems; (d) it may not be possible to make the Pre-Release Service(s) fully functional or secure; (e) the information obtained using the Pre-Release Service(s) may not be accurate; (f) use of the Pre-Release Service(s) may result in unexpected results, vulnerabilities, loss of data, project delays, or other unpredictable damage or loss, including without limitation to your use of New Relic services and products not governed by this Policy (collectively “Unintended Effects”); (g) New Relic is under no obligation to release a commercial or generally available version of the Pre-Release Service(s); and (h) New Relic has the right unilaterally to abandon development of the Pre-Release Service(s) at any time and without any obligation or liability to you. 4.2 Your Data. You acknowledge and agree that you should not rely on the Pre-Release Service(s) for any reason. You further acknowledge and agree that you are solely responsible for maintaining and protecting all data and information that is stored, retrieved, or otherwise processed by the Pre-Release Service(s) in accordance with your contractual obligations and requirements under applicable law. Without limiting the foregoing, you are responsible for all costs and expenses required to backup and restore any data and information that is lost or corrupted as a result of your use of the Pre-Release Service(s) or any Unintended Effects. You understand and agree that your Data may be transferred to the United States for storage, processing, and use by New Relic to provide the Pre-Release Service(s). For any data that you process using the Pre-Release Service(s), you represent and warrant that you have all necessary rights and consent to do so. New Relic has no obligation to store any data you process using the Pre-Release Service(s) and shall have no liability for the deletion or accuracy of such data. 4.3 Warranty Disclaimers. YOU ACKNOWLEDGE THAT PRE-RELEASE SERVICE(S) ARE PROVIDED “AS IS.” TO THE EXTENT PERMITTED BY APPLICABLE LAW, NEW RELIC DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES REGARDING MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, SECURITY, AND ANY WARRANTIES ARISING OUT OF THE COURSE OF DEALING OR USAGE OF TRADE. NEW RELIC MAKES NO WARRANTY THAT PRE-RELEASE SERVICE(S) WILL MEET YOUR REQUIREMENTS OR WILL BE ACCURATE, RELIABLE, ERROR-FREE, UNINTERRUPTED, TIMELY, OR SECURE. YOUR USE OF PRE-RELEASE SERVICE(S) IS AT YOUR OWN RISK. 4.4 Modifications. New Relic may change the Policy from time to time as our business changes and technology evolves, and future versions of our generally available services may not be compatible with Pre-Release Service(s) built using previous versions. The most current version of this Policy will be posted in the Documentation. Any changes to this Policy will be effective immediately for all users in instances to comply with applicable law, for new users of a Pre-Release Service(s) and, for all other users, any changes to this Policy will be effective as of fifteen (15) days after posting notice of such changes. If we determine in our sole discretion that an update is material, we will provide notice of such material change to you through your New Relic account, the Pre-Release Service(s), the Documentation, our blogs or community forums, and/or by email to the email address of your account administrator. We may require you to provide consent to the updated Policy in a specified manner before further use of the Pre-Release Service(s) is permitted. If you do not agree to any change(s), your sole remedy is to stop using the Pre-Release Service(s) and any such termination by you shall be without penalty except as specified in this Policy. Otherwise, your use of any Pre-Release Service(s) after any such update shall constitute acceptance of the then-current Policy. 5. Limitation of Liability TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC, ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE FOR ANY INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, EXEMPLARY OR CONSEQUENTIAL (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) DAMAGES, REGARDLESS OF LEGAL THEORY, WHETHER OR NOT NEW RELIC HAS BEEN WARNED OF THE POSSIBILITY OF SUCH DAMAGES, AND EVEN IF A REMEDY FAILS OF ITS ESSENTIAL PURPOSE. NEW RELIC’S AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS POLICY, THE PRE-RELEASE SERVICES, OR ANY UNINTENDED EFFECTS WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE LIMITATIONS OF DAMAGES SET FORTH ABOVE ARE FUNDAMENTAL ELEMENTS OF THE BASIS OF THE BARGAIN BETWEEN NEW RELIC AND YOU. 6. Indemnity You agree to indemnify and hold New Relic, its parents, subsidiaries, affiliates, officers, agents, employees, and licensors harmless from any claims, fees, fines, demands, losses, liabilities, damages, and costs, including reasonable attorney’s fees, arising from or related to your use of the Pre-Release Service(s), including but not limited to allegations arising from your breach of any terms herein and/or allegations that data processed by the Pre-Release Service(s) violates or infringes the privacy, data protection, or intellectual property rights of a third party. 7. Export Restrictions You acknowledge that the software in the Pre-Release Service(s) licensed hereunder may be subject to the export control laws and regulations of the U.S. and other countries. You agree that you will not export or re-export the Pre-Release Service(s), any part thereof, or any process or service that is the direct product of the Pre-Release Service(s) to any country, person or entity subject to U.S. export restrictions. 8. Termination Your access to the Pre-Release Service(s) will terminate upon the earliest of: (i) New Relic making the Pre-Release Service(s) or a successor version of the Pre-Release Service(s) generally available or available for commercial release; (ii) New Relic ceasing to make the Pre-Release Service(s) available to you; or (iii) New Relic terminating this Policy. New Relic may terminate this Policy for any reason upon notice to you. Sections 2.2, 2.3, 2.4, 3, 4, 5, 6, and 7 will survive your use of the Pre-Release Service(s).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.4787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Pre-release <em>policy</em>",
        "sections": "2. <em>License</em> and Restrictions",
        "tags": "<em>License</em> <em>information</em>",
        "body": " Services and any related <em>information</em>, including without limitation features, functionality, designs, user interface, capabilities, specifications, architectural diagrams, usage data, APIs, deployment schedules, email lists, bug databases, know how, source code, potential features, Feedback"
      },
      "id": "6044e71b28ccbc984d2c60c8"
    },
    {
      "sections": [
        "New Relic One pricing: Definitions",
        "Account",
        "Commitment Term",
        "Customer Data",
        "Customer Properties",
        "Documentation",
        "GB Ingested",
        "Login Credentials",
        "Monthly Provisioned User",
        "Order",
        "Paid Terms of Service",
        "Product(s)",
        "Software",
        "Terms",
        "Third-Party Services",
        "Unpaid Terms of Service",
        "Usage Plan"
      ],
      "title": "New Relic One pricing: Definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "609575acd671fecf7899378157eabc57bc8d68e2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-04-22T16:06:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for organizations on our New Relic One pricing plan. For terms used in our original pricing plan, see Original pricing plan definitions. Account Account refers to the online account or subaccounts that New Relic provides for customers to manage their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, information, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer Properties Customer Properties means Customer’s websites, infrastructure, networks, mobile applications, or other systems, as well as Customer accounts on Third-Party Services. Documentation Documentation means the New Relic technical guides and documentation made available from the dedicated ‘Documentation’ page of the New Relic website. GB Ingested A GB Ingested is a measurement of the volume of metrics, events, logs, traces, or other telemetry data sent to or generated by the Products for the benefit of the Customer, including from the Software, the Customer Properties, or Third-Party Services. In this context, a GB is defined as 1 billion bytes. Login Credentials Login Credentials means the username, email address, password, or other personal information that is provided by a Customer user in order to manage an Account. Monthly Provisioned User A Monthly Provisioned User is any user who can log into Customer’s Account(s) and access the New Relic One Product functionality as specified in an Order and the Documentation. Order Order means the purchasing order for access to the Service or related services that: (1) is either executed by the Parties or entered into by you via self-service, and references this Agreement, or (2) is entered into by you and a Channel Partner. Paid Terms of Service Paid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/paid. Product(s) Product(s) mean the purchase of the New Relic subscription products described in the applicable Order and any updates, corrections, bug fixes, modifications, improvements, related services, new features, and functionality (made generally available to New Relic’s customer base) thereto. Software Software means the distributed software, APIs, scripts, or other code proprietary to New Relic provided with the Products. Terms Terms means the underlying Customer-New Relic agreement and the Order. Third-Party Services Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/unpaid. Usage Plan Usage Plan refers to the Service or Product pricing, invoicing related information, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.91357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": " their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, <em>information</em>, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third"
      },
      "id": "6044e6e528ccbc26f22c6084"
    }
  ],
  "/docs/licenses/license-information/referenced-policies/service-level-availability-commitment": [
    {
      "sections": [
        "Security policy",
        "New Relic Security Policy",
        "1. Data Security",
        "2. Data Access",
        "3. Server Security",
        "4. Network Security",
        "5. Security Audits",
        "6. Security and Incident Response",
        "7. Disaster Recovery",
        "8. Copies and Removal",
        "9. Disclosure by Law"
      ],
      "title": "Security policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "291509f6b521ca34ac9d49039518e7da8b883518",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-policy/",
      "published_at": "2021-05-04T18:36:05Z",
      "updated_at": "2021-03-16T06:20:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The below Security Policy applies only to customers with an existing New Relic agreement in place that explicitly references this Security Policy applying to the Service purchased in an Order. Capitalized terms not defined below shall take on the meaning set forth in such New Relic agreement. New Relic Security Policy 1. Data Security 1.1. New Relic shall establish and maintain data security procedures and other safeguards designed to protect against the loss, theft or other unauthorized access or alteration of Customer Data in the possession or under the control of New Relic or to which New Relic has access, which are no less rigorous than accepted security standards in the industry. 1.2. New Relic shall maintain an information security policy that outlines a definition of information security and its overall objectives; a framework for setting control objectives and controls, including the structure of risk assessment and risk management; a brief explanation of the compliance requirements, and procedures for managing information security incidents. 2. Data Access 2.1. Access to Customer Data stored on New Relic’s systems shall not be granted to members of New Relic unless they have been uniquely identified and have sufficient credentials. 2.2. Access permissions shall be established in a manner that allows for the minimum access level(s) required for each employee. 2.3. Access to Customer Data shall be logged with sufficient information to determine the nature and scope of any inappropriate access. 3. Server Security 3.1. New Relic shall establish and follow reasonable server configuration guidelines and processes to prevent unauthorized access to Customer Data. 3.2. New Relic shall establish and follow reasonable configuration change management procedures for its servers containing Customer Data. 4. Network Security 4.1. New Relic network architecture shall be designed to limit site access and restrict the availability of information services that are considered to be vulnerable to attack. 4.2. New Relic shall utilize SSL certificates for all Internet activity. By default, Customer Data transmitted to and from the New Relic network shall be sent over encrypted medium or an encrypted format. 4.3. New Relic network shall use IDS technologies for network intrusion detection. 4.4. Access to New Relic systems containing Customer Data shall be restricted to authorized personnel. 5. Security Audits 5.1. New Relic shall conduct at least annually a SOC 2 or industry equivalent audit. New Relic shall provide to Customer audit results upon request, and shall explain and provide remediation plans to correct any problems to the extent reasonably possible. 6. Security and Incident Response 6.1. New Relic shall maintain an Information Security Incident Response plan, and make that plan available to Customer if requested. 6.2. In the event of an actual theft, loss, or unauthorized access of Customer Data by New Relic’s personnel and/or any unauthorized individual or entity, New Relic shall: (a) investigate such breach, (b) attempt to cure such breach, and (c) provide notification to Customer that describes such breach. 7. Disaster Recovery 7.1. New Relic shall have in effect a disaster recovery plan designed to respond to both a component failure of New Relic equipment within its data center and a catastrophic loss of service. This plan shall include documented policies and procedures to restore service in the event of either type of failure. 7.2. New Relic shall establish and follow backup and restore procedures for servers containing Customer Data. 8. Copies and Removal 8.1. In addition to any obligations of New Relic in the Agreement, upon expiration or termination of this Agreement for any reason: (a) New Relic shall, and shall cause its personnel, to cease and desist all access and use of any Customer Data, (b) New Relic shall delete all copies of Customer Data within ninety (90) days. 9. Disclosure by Law 9.1. In the event the New Relic is required by law, regulation, or legal process to disclose any Customer Data, New Relic shall (a) give Customer, to the extent possible, reasonable advance notice prior to disclosure so Customer may contest the disclosure or seek a protective order, and (b) reasonably limit the disclosure to the minimum amount that is legally required to be disclosed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.32753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security <em>policy</em>",
        "sections": "Security <em>policy</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " Relic has access, which are no less rigorous than accepted security standards in the industry. 1.2. New Relic shall maintain an <em>information</em> security policy that outlines a definition of <em>information</em> security and its overall objectives; a framework for setting control objectives and controls"
      },
      "id": "603ea3dbe7b9d22b802a0802"
    },
    {
      "sections": [
        "New Relic Pre-release policy",
        "New Relic Pre-Release Policy",
        "1. Introduction",
        "2. License and Restrictions",
        "3. Confidential Information",
        "4. Disclaimers and Acknowledgement",
        "5. Limitation of Liability",
        "6. Indemnity",
        "7. Export Restrictions",
        "8. Termination"
      ],
      "title": "New Relic Pre-release policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5ca324e942906913fc346245cfd80d405e90ad1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/new-relic-pre-release-policy/",
      "published_at": "2021-05-05T16:29:56Z",
      "updated_at": "2021-03-13T01:17:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Without overriding any express provisions that you may have agreed to in a separate written beta or pre-release agreement executed by you and New Relic, the following terms apply to your use of any New Relic Pre-Release Service(s). New Relic Pre-Release Policy Through your use of any New Relic, Inc. (“New Relic”) Pre-Release Services (as further defined), you signify that you have read, understood, and accept the terms of this Pre-Release Policy (the “Policy”) governing your use and participation in New Relic’s program for making beta, alpha and pre-release versions of New Relic software (i.e. agents, SDKs, APIs, integrations, private locations, code, etc.), services, features, user-interfaces, and platforms made available for evaluation purposes (the “Pre-Release Service(s)”). This Policy is effective on behalf of yourself or the entity(ies) associated with your New Relic account (collectively referred to herein as “you” or “your”) as of your date of first use of the Pre-Release Service(s) (the “Effective Date”), which means that your choice to use the Pre-Release Service(s) means that you have the legal authority to use the Pre-Release Service(s) personally or on behalf of the company or organization associated with your New Relic account in accordance with this Policy. Please read this Policy carefully as your use of Pre-Release Service(s) may have unintended consequences and materially impact your data or use of the New Relic services and products. If you do not agree to this Policy, your sole remedy is to not make use of the Pre-Release Services. 1. Introduction This Policy and any New Relic technical guides and documentation made available with the Pre-Release Service(s) or from the dedicated ‘Documentation’ page of the New Relic website (the “Documentation”) enables you to test experimental features and products before they are made generally available. New Relic reserves the right to withhold or discontinue any Pre-Release Service(s), which may be designated as an alpha, beta, pilot, limited release, developer preview, technology preview, non-production, evaluation, or by a similar description, in its sole discretion and provides no guarantee that any Pre-Release Service(s) will eventually be made commercially or generally available. Pre-Release Service(s) are versions provided before they are generally available and may have bugs, stability issues, or other problems. Use of the Pre-Release Service(s) may result in unexpected results, loss of data, outages, or other damage to your systems or networks. New Relic advises against using the Pre-Release Service(s) in production. No support is offered with or for Pre-Release Service(s). You hereby release New Relic from any liability arising from or related to your use of the Pre-Release Service(s). In connection with your use of the Pre-Release Services, you may provide feedback, comments, and/or suggestions based on or relating to the Pre-Release Services (“Feedback”). The Pre-Release Services and any related information, including without limitation features, functionality, designs, user interface, capabilities, specifications, architectural diagrams, usage data, APIs, deployment schedules, email lists, bug databases, know how, source code, potential features, Feedback, and information related to any business or technical information of New Relic, including without limitation product plans, costs, prices, finances, marketing plans, business opportunities, research, development, and negotiations are considered confidential information of New Relic (“Confidential Information”). 2. License and Restrictions 2.1 Evaluation License. Subject to your compliance with the Policy, New Relic hereby grants you a limited, non-exclusive, non-transferable, revocable license, during the term of this Policy, to use the Pre-Release Service(s) in accordance with the Documentation solely for the purpose of internal evaluation and supplying Feedback to New Relic. 2.2 License Restrictions. You may not (and may not authorize or enable a third party to): (i) reverse engineer, decompile, disassemble, or otherwise attempt to discover the source code or other trade secrets in the Pre-Release Service(s); (ii) access the Pre-Release Service(s) in order to build a similar or competitive application, service, feature or other competitive purpose; (iii) remove or destroy any copyright notices or other proprietary marks contained on or in the Pre-Release Service(s); (iv) use the Pre-Release Service(s) for any benchmarking purposes or in connection with a service bureau, timeshare, service provider, or like activity where you operate the Pre-Release Service(s) on behalf of a third party; (v) mirror, frame, copy, modify, host, rent, lease, sell, commercialize, sublicense, assign or otherwise transfer the Pre-Release Service(s), or the access or use of the Pre-Release Service(s); (vi) use the Pre-Release Service(s) in a manner that may violate or infringe the intellectual property, data protection, or other proprietary right of a third party; (vii) use or access the Pre-Release Service(s) in an unauthorized manner and/or in a manner that violates any applicable law, rule, contract, or guideline (including but not limited to our Documentation or Community Guidelines); (viii) use the Pre-Release Service(s) to transmit worms, viruses, malicious code, security vulnerabilities, or otherwise negatively impact network operations, third parties, or New Relic; (ix) use any data mining or similar data gathering and extraction methods in connection with the Pre-Release Service(s); or (x) use the Pre-Release Service(s) to process sensitive personal information, e.g., “personal information” of children as defined by the Children’s Online Privacy Protection Act, “protected health information” as defined by the Health Insurance Portability and Accountability Act of 1996, government issued identification numbers, financial account information, payment card data, “special categories of data” as described in the EU General Data Protection Regulation (GDPR), or other information subject to regulatory, statutory, or contractual restrictions. New Relic reserves the right, but not the obligation, to monitor or review your use of the Pre-Release Service(s) at any time and may investigate any suspected violations of this Policy. 2.3 Intellectual Property Rights. You acknowledge and agree that, as between you and New Relic, New Relic owns all right, title, and interest in and to the Pre-Release Service(s), Confidential Information, and Feedback, including but not limited to all intellectual property and proprietary rights therein. New Relic and its licensors reserve all rights and licenses not expressly granted herein. 2.4 Feedback. You acknowledge and agree that all Feedback will be the sole and exclusive property of New Relic. You hereby irrevocably transfer and assign to New Relic all right, title, and interest in all Feedback, including but not limited to all intellectual property and proprietary rights therein. 3. Confidential Information You will not use or disclose any Confidential Information, except as necessary for the performance of this Policy, and you will use reasonable efforts to protect Confidential Information from unauthorized use or disclosure. You may disclose Confidential Information only to those employees with a bona fide need to know, provided that each employee has signed a written agreement with nondisclosure restrictions at least as protective of the Confidential Information as those set forth herein. For the purposes of this section, information will not be deemed Confidential Information if it: (a) is or becomes generally known to the public through no fault or breach of this Policy; (b) is rightfully known by you at the time of disclosure without an obligation of confidentiality; (c) is independently developed by you without access to or use of the Confidential Information; or (d) is rightfully obtained by you from a third party without restriction on use or disclosure. Upon New Relic’s request, you agree to destroy all Confidential Information in your possession within 30 days of termination of this Policy. 4. Disclaimers and Acknowledgement 4.1 Acknowledgement of Pre-Release Service(s). You acknowledge and agree that: (a) the Pre-Release Service(s) is not an official product and has not been commercially released for sale by New Relic; (b) the Pre-Release Service(s) may not operate properly, be in final form, or fully function; (c) the Pre-Release Service(s) may contain errors, design flaws, security vulnerabilities, or other problems; (d) it may not be possible to make the Pre-Release Service(s) fully functional or secure; (e) the information obtained using the Pre-Release Service(s) may not be accurate; (f) use of the Pre-Release Service(s) may result in unexpected results, vulnerabilities, loss of data, project delays, or other unpredictable damage or loss, including without limitation to your use of New Relic services and products not governed by this Policy (collectively “Unintended Effects”); (g) New Relic is under no obligation to release a commercial or generally available version of the Pre-Release Service(s); and (h) New Relic has the right unilaterally to abandon development of the Pre-Release Service(s) at any time and without any obligation or liability to you. 4.2 Your Data. You acknowledge and agree that you should not rely on the Pre-Release Service(s) for any reason. You further acknowledge and agree that you are solely responsible for maintaining and protecting all data and information that is stored, retrieved, or otherwise processed by the Pre-Release Service(s) in accordance with your contractual obligations and requirements under applicable law. Without limiting the foregoing, you are responsible for all costs and expenses required to backup and restore any data and information that is lost or corrupted as a result of your use of the Pre-Release Service(s) or any Unintended Effects. You understand and agree that your Data may be transferred to the United States for storage, processing, and use by New Relic to provide the Pre-Release Service(s). For any data that you process using the Pre-Release Service(s), you represent and warrant that you have all necessary rights and consent to do so. New Relic has no obligation to store any data you process using the Pre-Release Service(s) and shall have no liability for the deletion or accuracy of such data. 4.3 Warranty Disclaimers. YOU ACKNOWLEDGE THAT PRE-RELEASE SERVICE(S) ARE PROVIDED “AS IS.” TO THE EXTENT PERMITTED BY APPLICABLE LAW, NEW RELIC DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES REGARDING MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, SECURITY, AND ANY WARRANTIES ARISING OUT OF THE COURSE OF DEALING OR USAGE OF TRADE. NEW RELIC MAKES NO WARRANTY THAT PRE-RELEASE SERVICE(S) WILL MEET YOUR REQUIREMENTS OR WILL BE ACCURATE, RELIABLE, ERROR-FREE, UNINTERRUPTED, TIMELY, OR SECURE. YOUR USE OF PRE-RELEASE SERVICE(S) IS AT YOUR OWN RISK. 4.4 Modifications. New Relic may change the Policy from time to time as our business changes and technology evolves, and future versions of our generally available services may not be compatible with Pre-Release Service(s) built using previous versions. The most current version of this Policy will be posted in the Documentation. Any changes to this Policy will be effective immediately for all users in instances to comply with applicable law, for new users of a Pre-Release Service(s) and, for all other users, any changes to this Policy will be effective as of fifteen (15) days after posting notice of such changes. If we determine in our sole discretion that an update is material, we will provide notice of such material change to you through your New Relic account, the Pre-Release Service(s), the Documentation, our blogs or community forums, and/or by email to the email address of your account administrator. We may require you to provide consent to the updated Policy in a specified manner before further use of the Pre-Release Service(s) is permitted. If you do not agree to any change(s), your sole remedy is to stop using the Pre-Release Service(s) and any such termination by you shall be without penalty except as specified in this Policy. Otherwise, your use of any Pre-Release Service(s) after any such update shall constitute acceptance of the then-current Policy. 5. Limitation of Liability TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC, ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE FOR ANY INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, EXEMPLARY OR CONSEQUENTIAL (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) DAMAGES, REGARDLESS OF LEGAL THEORY, WHETHER OR NOT NEW RELIC HAS BEEN WARNED OF THE POSSIBILITY OF SUCH DAMAGES, AND EVEN IF A REMEDY FAILS OF ITS ESSENTIAL PURPOSE. NEW RELIC’S AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS POLICY, THE PRE-RELEASE SERVICES, OR ANY UNINTENDED EFFECTS WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE LIMITATIONS OF DAMAGES SET FORTH ABOVE ARE FUNDAMENTAL ELEMENTS OF THE BASIS OF THE BARGAIN BETWEEN NEW RELIC AND YOU. 6. Indemnity You agree to indemnify and hold New Relic, its parents, subsidiaries, affiliates, officers, agents, employees, and licensors harmless from any claims, fees, fines, demands, losses, liabilities, damages, and costs, including reasonable attorney’s fees, arising from or related to your use of the Pre-Release Service(s), including but not limited to allegations arising from your breach of any terms herein and/or allegations that data processed by the Pre-Release Service(s) violates or infringes the privacy, data protection, or intellectual property rights of a third party. 7. Export Restrictions You acknowledge that the software in the Pre-Release Service(s) licensed hereunder may be subject to the export control laws and regulations of the U.S. and other countries. You agree that you will not export or re-export the Pre-Release Service(s), any part thereof, or any process or service that is the direct product of the Pre-Release Service(s) to any country, person or entity subject to U.S. export restrictions. 8. Termination Your access to the Pre-Release Service(s) will terminate upon the earliest of: (i) New Relic making the Pre-Release Service(s) or a successor version of the Pre-Release Service(s) generally available or available for commercial release; (ii) New Relic ceasing to make the Pre-Release Service(s) available to you; or (iii) New Relic terminating this Policy. New Relic may terminate this Policy for any reason upon notice to you. Sections 2.2, 2.3, 2.4, 3, 4, 5, 6, and 7 will survive your use of the Pre-Release Service(s).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.47868,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Pre-release <em>policy</em>",
        "sections": "2. <em>License</em> and Restrictions",
        "tags": "<em>License</em> <em>information</em>",
        "body": " Services and any related <em>information</em>, including without limitation features, functionality, designs, user interface, capabilities, specifications, architectural diagrams, usage data, APIs, deployment schedules, email lists, bug databases, know how, source code, potential features, Feedback"
      },
      "id": "6044e71b28ccbc984d2c60c8"
    },
    {
      "sections": [
        "New Relic One pricing: Definitions",
        "Account",
        "Commitment Term",
        "Customer Data",
        "Customer Properties",
        "Documentation",
        "GB Ingested",
        "Login Credentials",
        "Monthly Provisioned User",
        "Order",
        "Paid Terms of Service",
        "Product(s)",
        "Software",
        "Terms",
        "Third-Party Services",
        "Unpaid Terms of Service",
        "Usage Plan"
      ],
      "title": "New Relic One pricing: Definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "609575acd671fecf7899378157eabc57bc8d68e2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-04-22T16:06:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for organizations on our New Relic One pricing plan. For terms used in our original pricing plan, see Original pricing plan definitions. Account Account refers to the online account or subaccounts that New Relic provides for customers to manage their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, information, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer Properties Customer Properties means Customer’s websites, infrastructure, networks, mobile applications, or other systems, as well as Customer accounts on Third-Party Services. Documentation Documentation means the New Relic technical guides and documentation made available from the dedicated ‘Documentation’ page of the New Relic website. GB Ingested A GB Ingested is a measurement of the volume of metrics, events, logs, traces, or other telemetry data sent to or generated by the Products for the benefit of the Customer, including from the Software, the Customer Properties, or Third-Party Services. In this context, a GB is defined as 1 billion bytes. Login Credentials Login Credentials means the username, email address, password, or other personal information that is provided by a Customer user in order to manage an Account. Monthly Provisioned User A Monthly Provisioned User is any user who can log into Customer’s Account(s) and access the New Relic One Product functionality as specified in an Order and the Documentation. Order Order means the purchasing order for access to the Service or related services that: (1) is either executed by the Parties or entered into by you via self-service, and references this Agreement, or (2) is entered into by you and a Channel Partner. Paid Terms of Service Paid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/paid. Product(s) Product(s) mean the purchase of the New Relic subscription products described in the applicable Order and any updates, corrections, bug fixes, modifications, improvements, related services, new features, and functionality (made generally available to New Relic’s customer base) thereto. Software Software means the distributed software, APIs, scripts, or other code proprietary to New Relic provided with the Products. Terms Terms means the underlying Customer-New Relic agreement and the Order. Third-Party Services Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/unpaid. Usage Plan Usage Plan refers to the Service or Product pricing, invoicing related information, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.91354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": " their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, <em>information</em>, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third"
      },
      "id": "6044e6e528ccbc26f22c6084"
    }
  ],
  "/docs/licenses/license-information/special-services-licenses/data-collector-licenses": [
    {
      "sections": [
        "New Relic Priority Support"
      ],
      "title": "New Relic Priority Support",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "f700b8b349627e66540b23ed020c7d9a46e19580",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-priority-support/",
      "published_at": "2021-05-05T16:29:56Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download the New Relic Priority Support document as a PDF (172 KB). The services described in this document only apply to initial orders entered after August 1, 2019. If you have questions about New Relic Priority Support, contact your New Relic account representative.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.7207,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "Download the New Relic Priority Support document as a PDF (172 KB). The <em>services</em> described in this document only apply to initial orders entered after August 1, 2019. If you have questions about New Relic Priority Support, contact your New Relic account representative."
      },
      "id": "603ea90ae7b9d2e9d42a07d1"
    },
    {
      "sections": [
        "New Relic Premium Support"
      ],
      "title": "New Relic Premium Support",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "db095214148ca053cdabd9815dc74b04299dbe7b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-premium-support/",
      "published_at": "2021-05-05T16:20:33Z",
      "updated_at": "2021-03-16T04:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download the New Relic Premium Support document as a PDF (248 KB). The services described in this document only apply to initial orders entered after April 1, 2018. If you have questions about New Relic Premium Support, contact your New Relic account representative.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.70874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "Download the New Relic Premium Support document as a PDF (248 KB). The <em>services</em> described in this document only apply to initial orders entered after April 1, 2018. If you have questions about New Relic Premium Support, contact your New Relic account representative."
      },
      "id": "603ea8c964441fe48b4e88af"
    },
    {
      "sections": [
        "New Relic Diagnostics licenses",
        "Proprietary license",
        "New Relic Diagnostics license terms",
        "Open-source licenses"
      ],
      "title": "New Relic Diagnostics licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "6d86f8f63d372be98270fadc8634f9da8da2a893",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-diagnostics-licenses/",
      "published_at": "2021-05-05T16:21:23Z",
      "updated_at": "2021-03-13T03:25:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Proprietary license New Relic Diagnostics license terms These New Relic Diagnostics License Terms (“Terms”) set forth the terms and conditions under which you (“Customer”) may use New Relic Diagnostics (the “Software”), as made available by New Relic, Inc. (“New Relic”). By clicking “accept” or downloading or using the Software, you agree to be bound by these Terms. If you are agreeing to these Terms on behalf of your company, then “Customer” means your company and you are binding your company to these Terms. 1. License Grant. Subject to all of the terms and conditions of these Terms, New Relic grants Customer a limited, non-exclusive, non-transferable, non-sublicensable license to use the Software in accordance with its documentation in support of Customer’s use of New Relic products to which Customer has a separate subscription (“New Relic Products”). Unless otherwise specified, there is no fee for use of the Software. 2. License Restrictions. Customer will not (a) sell, rent, sublicense, transfer, time-share or otherwise provide access to any copies of the Software, or portions thereof, to a third party; (b) modify, decompile, disassemble or reverse engineer the Software; (c) use the Software to develop services or products for sale or include any components of the Software in any product; (d) remove any product identification, proprietary, copyright or other notices in the Software; or (e) publicly disseminate performance information or analysis (including benchmarks) relating to the Software. 3. Ownership. Except for the limited license rights expressly provided herein, New Relic and its suppliers have and will retain all right, title and interest in and to the Software, and all copies, updates, modifications and derivative works thereof. Customer acknowledges that it is obtaining only a limited license right to the Software and no ownership rights are being conveyed to Customer under these Terms or otherwise. 4. Usage Data. Customer agrees that New Relic and its affiliates have the right to collect Usage Data from Customer through the Software and use Usage Data to support, operate and improve New Relic products and services and for other lawful business purposes. “Usage Data” means diagnostics data related to the use of the Software with New Relic Products, including, without limitation, configuration information, details on diagnostics tasks, New Relic account and application ID numbers and New Relic license keys. For clarity, Usage Data is not considered “Customer Data”, “your Data” or any other similar term as used in any applicable subscription or license agreement for New Relic Products. At Customer’s election, Customer may disable the collection of Usage Data as described in the Software documentation. 5. Disclaimers. New Relic is not obligated to provide any support or maintenance for the Software. ALL USE OF SOFTWARE IS AT CUSTOMER’S OWN RISK. SOFTWARE IS PROVIDED “AS IS,” WITH ALL FAULTS AND WITHOUT WARRANTY OF ANY KIND, EXPRESS, IMPLIED OR STATUTORY, INCLUDING, BUT NOT LIMITED TO, WARRANTIES OF TITLE OR NON-INFRINGEMENT. CUSTOMER MAY HAVE OTHER STATUTORY RIGHTS, HOWEVER, THE DURATION OF STATUTORILY REQUIRED WARRANTIES, IF ANY, WILL BE LIMITED TO THE FULLEST EXTENT PERMITTED BY LAW. 6. Limitation of Liability. TO THE FULLEST EXTENT PERMITTED BY LAW, IN NO EVENT WILL NEW RELIC BE LIABLE FOR ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES OF ANY KIND, REGARDLESS OF THE FORM OF ACTION, WHETHER IN CONTRACT, TORT (INCLUDING NEGLIGENCE), STRICT LIABILITY OR OTHERWISE, EVEN IF INFORMED OF THE POSSIBILITY OF SUCH DAMAGES IN ADVANCE. TO THE EXTENT ANY OF THE ABOVE LIMITATIONS ARE NOT ENFORCEABLE AT APPLICABLE LAW, NEW RELIC’S ENTIRE LIABILITY TO CUSTOMER UNDER THESE TERMS WILL NOT EXCEED $50. THESE LIMITATIONS ON LIABILITY ARE A FUNDAMENTAL BASIS OF THE BARGAIN AND NEW RELIC WOULD NOT BE ABLE TO PROVIDE THE SOFTWARE WITHOUT SUCH LIMITATIONS. THESE LIMITATIONS ON LIABILITY WILL APPLY NOTWITHSTANDING ANY FAILURE OF ESSENTIAL PURPOSE OF ANY LIMITED REMEDY. 7. Changes and Termination. At its discretion, without notice or liability to Customer, New Relic may (a) update, modify or discontinue the Software; (b) modify these Terms, effective upon posting; or (c) terminate or suspend these Terms or Customer’s access to the Software. If Customer does not agree with any modification, its sole remedy is to terminate its use of the Software. Upon any termination or suspension, Customer must stop using the Software. 8. Third Party Code. The Software may contain or be provided with third party code (including code which may be made available to Customer in source code form). A list of third party code and ownership, use, warranty and modification rights with respect to such code may be identified in the documentation or provided by New Relic upon Customer’s written request. New Relic is not responsible for applications and services not licensed by New Relic. 9. Export Compliance. Customer acknowledges that the Software is subject to export restrictions by the U.S. government and import restrictions by certain foreign governments. Customer shall not remove or export from the U.S. or allow the export or re-export of any part of the Software or any direct product thereof: (a) into (or to a national or resident of) any embargoed or terrorist-supporting country; (b) to anyone on the U.S. Commerce Department’s Table of Denial Orders or U.S. Treasury Department’s list of Specially Designated Nationals; (c) to any country to which such export or re-export is restricted or prohibited, or as to which the U.S. government or any agency thereof requires an export license or other governmental approval at the time of export or re-export without first obtaining such license or approval; or (d) otherwise in violation of any export or import restrictions, laws or regulations of any U.S. or foreign agency or authority. Customer agrees to the foregoing and warrants that Customer is not located in, under the control of, or a national or resident of any such prohibited country or on any such prohibited party list. 10. Government End-Users. The Software is commercial computer software. If Customer is an entity of the U.S. government, the use, duplication, reproduction, release, modification, disclosure or transfer of the Software, or any related documentation of any kind, is restricted by a license agreement or by these Terms in accordance with Federal Acquisition Regulation 12.212 for civilian purposes and Defense Federal Acquisition Regulation Supplement 227.7202 for military purposes. The Software was developed fully at private expense. All other use is prohibited. 11. General. These Terms will be governed by and construed under the laws of the State of California and the U.S. without regard to conflicts of law provisions thereof, and without regard to the United Nations Convention on the International Sale of Goods. The jurisdiction and venue for actions arising out of or relating to these Terms shall be in the state and federal courts in San Francisco, California. The parties are independent contractors. Customer may not assign these Terms without New Relic’s prior written consent and any attempt to do so will be void; New Relic may assign these Terms freely to any party without Customer’s consent. If any provision of these Terms is held by a court of competent jurisdiction to be unenforceable or invalid for any reason, that provision shall be limited to the minimum extent necessary so that these Terms shall otherwise remain in effect. These Terms are the entire agreement between the parties relating to the Software, and supersede all prior or contemporaneous agreements (oral or written) relating to the Software. Any separate agreement Customer has for New Relic Products does not apply to the Software. Open-source licenses We love open-source software, and use the following in New Relic Diagnostics. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License clbanning/mxj MIT go-yaml/yaml Apache 2.0 StackExchange/wmi MIT go-ole/go-ole MIT shirou/gopsutil BSD-3-Clause shirou/w32 BSD-3-Clause cheggaaa/pb BSD-3-Clause google/uuid BSD-3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.0031,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Diagnostics <em>licenses</em>",
        "sections": "New Relic Diagnostics <em>licenses</em>",
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": ") use the Software to develop <em>services</em> or products for sale or include any components of the Software in any product; (d) remove any product identification, proprietary, copyright or other notices in the Software; or (e) publicly disseminate performance <em>information</em> or analysis (including benchmarks"
      },
      "id": "604505ad28ccbc457e2c60b4"
    }
  ],
  "/docs/licenses/license-information/special-services-licenses/new-relic-diagnostics-licenses": [
    {
      "sections": [
        "Data collector licenses"
      ],
      "title": "Data collector licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "8eeb19ae388c1f4fd6856084084467a037861675",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/data-collector-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-03-16T06:20:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in New Relic data collectors. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Package Licenses annotations Apache 2.0 antlr BSD apache-log4j-extras Apache 2.0 apache-mime4j Apache 2.0 bonecp Apache 2.0 bonecp-provider Apache 2.0 bytelist MIT c3p0 Eclipse 1.0 commons-beanutils Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-digester Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-lang3 Apache 2.0 commons-logging Apache 2.0 commons-math Apache 2.0 commons-pool Apache 2.0 constantine MIT dom4j BSD ehcache Apache 2.0 gson Apache 2.0 guava Apache 2.0 hamcrest-core BSD-3-Clause hibernate-commons-annotations GNU LGPL 2.1 hibernate-core GNU LGPL 2.1 hibernate-ehcache GNU LGPL 2.1 hibernate-jpa-2.0-api GNU LGPL 2.1 hibernate-c3p0 GNU LGPL 2.1 hibernate-ehcache GNU LGPL 2.1 hibernate-jpa-2.0-api GNU LGPL 2.1 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 hystrix Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 jaffl GNU LGPL 3.0 java-driver Apache 2.0 javassist MPL 1.1, GNU GPL 2.1, Apache 2.0 javax.servlet Apache 2.0, Eclipse 1.0 javax.servlet-api CDDL + GPLv2 with classpath exception jboss-logging GNU LGPL 2.1 jboss-transaction-api_1.1_spec GNU LGPL 2.1 jcodings Common Public License 1.0, GNU GPL 2, GNU LGPL 2.1 jedis MIT jetty Apache 2.0, Eclipse 1.0 jffi GNU LGPL 3.0 jline BSD 2-Clause joni MIT jnr-netdb GNU LGPL 3.0 jnr-posix Common Public License 1.0, GNU GPL 2, GNU LGPL 2.1 joda-time Apache 2.0 jopt-simple MIT json-simple Apache 2.0 jsr305 Apache 2.0 junit Common Public License 1.0 kafka Apache 2.0 libthrift Apache 2.0 log4j Apache 2.0 logback-classic Eclipse 1.0 logback-core Eclipse 1.0 metrics-annotation Apache 2.0 mockito-all MIT msgpack Apache 2.0 mysql-connector-java GNU GPL 2 reflections WTFPL scala-library Apache 2.0 scannotation Apache 2.0 slf4j-api MIT slf4j-over-log4j MIT snakeyaml Apache 2.0 snappy Apache 2.0 syslog4j LGPL xml-apis Apache 2.0 yamlbeans MIT zkclient Apache 2.0 zookeeper Apache 2.0",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.7605,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Data collector <em>licenses</em>",
        "sections": "Data collector <em>licenses</em>",
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in New Relic data collectors. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Package <em>Licenses</em> annotations"
      },
      "id": "603eb41d64441fd7f74e8893"
    },
    {
      "sections": [
        "New Relic Priority Support"
      ],
      "title": "New Relic Priority Support",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "f700b8b349627e66540b23ed020c7d9a46e19580",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-priority-support/",
      "published_at": "2021-05-05T16:29:56Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download the New Relic Priority Support document as a PDF (172 KB). The services described in this document only apply to initial orders entered after August 1, 2019. If you have questions about New Relic Priority Support, contact your New Relic account representative.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.7207,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "Download the New Relic Priority Support document as a PDF (172 KB). The <em>services</em> described in this document only apply to initial orders entered after August 1, 2019. If you have questions about New Relic Priority Support, contact your New Relic account representative."
      },
      "id": "603ea90ae7b9d2e9d42a07d1"
    },
    {
      "sections": [
        "New Relic Premium Support"
      ],
      "title": "New Relic Premium Support",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "db095214148ca053cdabd9815dc74b04299dbe7b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-premium-support/",
      "published_at": "2021-05-05T16:20:33Z",
      "updated_at": "2021-03-16T04:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download the New Relic Premium Support document as a PDF (248 KB). The services described in this document only apply to initial orders entered after April 1, 2018. If you have questions about New Relic Premium Support, contact your New Relic account representative.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.70872,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "Download the New Relic Premium Support document as a PDF (248 KB). The <em>services</em> described in this document only apply to initial orders entered after April 1, 2018. If you have questions about New Relic Premium Support, contact your New Relic account representative."
      },
      "id": "603ea8c964441fe48b4e88af"
    }
  ],
  "/docs/licenses/license-information/special-services-licenses/new-relic-premium-support": [
    {
      "sections": [
        "Data collector licenses"
      ],
      "title": "Data collector licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "8eeb19ae388c1f4fd6856084084467a037861675",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/data-collector-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-03-16T06:20:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in New Relic data collectors. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Package Licenses annotations Apache 2.0 antlr BSD apache-log4j-extras Apache 2.0 apache-mime4j Apache 2.0 bonecp Apache 2.0 bonecp-provider Apache 2.0 bytelist MIT c3p0 Eclipse 1.0 commons-beanutils Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-digester Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-lang3 Apache 2.0 commons-logging Apache 2.0 commons-math Apache 2.0 commons-pool Apache 2.0 constantine MIT dom4j BSD ehcache Apache 2.0 gson Apache 2.0 guava Apache 2.0 hamcrest-core BSD-3-Clause hibernate-commons-annotations GNU LGPL 2.1 hibernate-core GNU LGPL 2.1 hibernate-ehcache GNU LGPL 2.1 hibernate-jpa-2.0-api GNU LGPL 2.1 hibernate-c3p0 GNU LGPL 2.1 hibernate-ehcache GNU LGPL 2.1 hibernate-jpa-2.0-api GNU LGPL 2.1 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 hystrix Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 jaffl GNU LGPL 3.0 java-driver Apache 2.0 javassist MPL 1.1, GNU GPL 2.1, Apache 2.0 javax.servlet Apache 2.0, Eclipse 1.0 javax.servlet-api CDDL + GPLv2 with classpath exception jboss-logging GNU LGPL 2.1 jboss-transaction-api_1.1_spec GNU LGPL 2.1 jcodings Common Public License 1.0, GNU GPL 2, GNU LGPL 2.1 jedis MIT jetty Apache 2.0, Eclipse 1.0 jffi GNU LGPL 3.0 jline BSD 2-Clause joni MIT jnr-netdb GNU LGPL 3.0 jnr-posix Common Public License 1.0, GNU GPL 2, GNU LGPL 2.1 joda-time Apache 2.0 jopt-simple MIT json-simple Apache 2.0 jsr305 Apache 2.0 junit Common Public License 1.0 kafka Apache 2.0 libthrift Apache 2.0 log4j Apache 2.0 logback-classic Eclipse 1.0 logback-core Eclipse 1.0 metrics-annotation Apache 2.0 mockito-all MIT msgpack Apache 2.0 mysql-connector-java GNU GPL 2 reflections WTFPL scala-library Apache 2.0 scannotation Apache 2.0 slf4j-api MIT slf4j-over-log4j MIT snakeyaml Apache 2.0 snappy Apache 2.0 syslog4j LGPL xml-apis Apache 2.0 yamlbeans MIT zkclient Apache 2.0 zookeeper Apache 2.0",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.7605,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Data collector <em>licenses</em>",
        "sections": "Data collector <em>licenses</em>",
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in New Relic data collectors. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Package <em>Licenses</em> annotations"
      },
      "id": "603eb41d64441fd7f74e8893"
    },
    {
      "sections": [
        "New Relic Priority Support"
      ],
      "title": "New Relic Priority Support",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "f700b8b349627e66540b23ed020c7d9a46e19580",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-priority-support/",
      "published_at": "2021-05-05T16:29:56Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download the New Relic Priority Support document as a PDF (172 KB). The services described in this document only apply to initial orders entered after August 1, 2019. If you have questions about New Relic Priority Support, contact your New Relic account representative.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.7207,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "Download the New Relic Priority Support document as a PDF (172 KB). The <em>services</em> described in this document only apply to initial orders entered after August 1, 2019. If you have questions about New Relic Priority Support, contact your New Relic account representative."
      },
      "id": "603ea90ae7b9d2e9d42a07d1"
    },
    {
      "sections": [
        "New Relic Diagnostics licenses",
        "Proprietary license",
        "New Relic Diagnostics license terms",
        "Open-source licenses"
      ],
      "title": "New Relic Diagnostics licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "6d86f8f63d372be98270fadc8634f9da8da2a893",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-diagnostics-licenses/",
      "published_at": "2021-05-05T16:21:23Z",
      "updated_at": "2021-03-13T03:25:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Proprietary license New Relic Diagnostics license terms These New Relic Diagnostics License Terms (“Terms”) set forth the terms and conditions under which you (“Customer”) may use New Relic Diagnostics (the “Software”), as made available by New Relic, Inc. (“New Relic”). By clicking “accept” or downloading or using the Software, you agree to be bound by these Terms. If you are agreeing to these Terms on behalf of your company, then “Customer” means your company and you are binding your company to these Terms. 1. License Grant. Subject to all of the terms and conditions of these Terms, New Relic grants Customer a limited, non-exclusive, non-transferable, non-sublicensable license to use the Software in accordance with its documentation in support of Customer’s use of New Relic products to which Customer has a separate subscription (“New Relic Products”). Unless otherwise specified, there is no fee for use of the Software. 2. License Restrictions. Customer will not (a) sell, rent, sublicense, transfer, time-share or otherwise provide access to any copies of the Software, or portions thereof, to a third party; (b) modify, decompile, disassemble or reverse engineer the Software; (c) use the Software to develop services or products for sale or include any components of the Software in any product; (d) remove any product identification, proprietary, copyright or other notices in the Software; or (e) publicly disseminate performance information or analysis (including benchmarks) relating to the Software. 3. Ownership. Except for the limited license rights expressly provided herein, New Relic and its suppliers have and will retain all right, title and interest in and to the Software, and all copies, updates, modifications and derivative works thereof. Customer acknowledges that it is obtaining only a limited license right to the Software and no ownership rights are being conveyed to Customer under these Terms or otherwise. 4. Usage Data. Customer agrees that New Relic and its affiliates have the right to collect Usage Data from Customer through the Software and use Usage Data to support, operate and improve New Relic products and services and for other lawful business purposes. “Usage Data” means diagnostics data related to the use of the Software with New Relic Products, including, without limitation, configuration information, details on diagnostics tasks, New Relic account and application ID numbers and New Relic license keys. For clarity, Usage Data is not considered “Customer Data”, “your Data” or any other similar term as used in any applicable subscription or license agreement for New Relic Products. At Customer’s election, Customer may disable the collection of Usage Data as described in the Software documentation. 5. Disclaimers. New Relic is not obligated to provide any support or maintenance for the Software. ALL USE OF SOFTWARE IS AT CUSTOMER’S OWN RISK. SOFTWARE IS PROVIDED “AS IS,” WITH ALL FAULTS AND WITHOUT WARRANTY OF ANY KIND, EXPRESS, IMPLIED OR STATUTORY, INCLUDING, BUT NOT LIMITED TO, WARRANTIES OF TITLE OR NON-INFRINGEMENT. CUSTOMER MAY HAVE OTHER STATUTORY RIGHTS, HOWEVER, THE DURATION OF STATUTORILY REQUIRED WARRANTIES, IF ANY, WILL BE LIMITED TO THE FULLEST EXTENT PERMITTED BY LAW. 6. Limitation of Liability. TO THE FULLEST EXTENT PERMITTED BY LAW, IN NO EVENT WILL NEW RELIC BE LIABLE FOR ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES OF ANY KIND, REGARDLESS OF THE FORM OF ACTION, WHETHER IN CONTRACT, TORT (INCLUDING NEGLIGENCE), STRICT LIABILITY OR OTHERWISE, EVEN IF INFORMED OF THE POSSIBILITY OF SUCH DAMAGES IN ADVANCE. TO THE EXTENT ANY OF THE ABOVE LIMITATIONS ARE NOT ENFORCEABLE AT APPLICABLE LAW, NEW RELIC’S ENTIRE LIABILITY TO CUSTOMER UNDER THESE TERMS WILL NOT EXCEED $50. THESE LIMITATIONS ON LIABILITY ARE A FUNDAMENTAL BASIS OF THE BARGAIN AND NEW RELIC WOULD NOT BE ABLE TO PROVIDE THE SOFTWARE WITHOUT SUCH LIMITATIONS. THESE LIMITATIONS ON LIABILITY WILL APPLY NOTWITHSTANDING ANY FAILURE OF ESSENTIAL PURPOSE OF ANY LIMITED REMEDY. 7. Changes and Termination. At its discretion, without notice or liability to Customer, New Relic may (a) update, modify or discontinue the Software; (b) modify these Terms, effective upon posting; or (c) terminate or suspend these Terms or Customer’s access to the Software. If Customer does not agree with any modification, its sole remedy is to terminate its use of the Software. Upon any termination or suspension, Customer must stop using the Software. 8. Third Party Code. The Software may contain or be provided with third party code (including code which may be made available to Customer in source code form). A list of third party code and ownership, use, warranty and modification rights with respect to such code may be identified in the documentation or provided by New Relic upon Customer’s written request. New Relic is not responsible for applications and services not licensed by New Relic. 9. Export Compliance. Customer acknowledges that the Software is subject to export restrictions by the U.S. government and import restrictions by certain foreign governments. Customer shall not remove or export from the U.S. or allow the export or re-export of any part of the Software or any direct product thereof: (a) into (or to a national or resident of) any embargoed or terrorist-supporting country; (b) to anyone on the U.S. Commerce Department’s Table of Denial Orders or U.S. Treasury Department’s list of Specially Designated Nationals; (c) to any country to which such export or re-export is restricted or prohibited, or as to which the U.S. government or any agency thereof requires an export license or other governmental approval at the time of export or re-export without first obtaining such license or approval; or (d) otherwise in violation of any export or import restrictions, laws or regulations of any U.S. or foreign agency or authority. Customer agrees to the foregoing and warrants that Customer is not located in, under the control of, or a national or resident of any such prohibited country or on any such prohibited party list. 10. Government End-Users. The Software is commercial computer software. If Customer is an entity of the U.S. government, the use, duplication, reproduction, release, modification, disclosure or transfer of the Software, or any related documentation of any kind, is restricted by a license agreement or by these Terms in accordance with Federal Acquisition Regulation 12.212 for civilian purposes and Defense Federal Acquisition Regulation Supplement 227.7202 for military purposes. The Software was developed fully at private expense. All other use is prohibited. 11. General. These Terms will be governed by and construed under the laws of the State of California and the U.S. without regard to conflicts of law provisions thereof, and without regard to the United Nations Convention on the International Sale of Goods. The jurisdiction and venue for actions arising out of or relating to these Terms shall be in the state and federal courts in San Francisco, California. The parties are independent contractors. Customer may not assign these Terms without New Relic’s prior written consent and any attempt to do so will be void; New Relic may assign these Terms freely to any party without Customer’s consent. If any provision of these Terms is held by a court of competent jurisdiction to be unenforceable or invalid for any reason, that provision shall be limited to the minimum extent necessary so that these Terms shall otherwise remain in effect. These Terms are the entire agreement between the parties relating to the Software, and supersede all prior or contemporaneous agreements (oral or written) relating to the Software. Any separate agreement Customer has for New Relic Products does not apply to the Software. Open-source licenses We love open-source software, and use the following in New Relic Diagnostics. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License clbanning/mxj MIT go-yaml/yaml Apache 2.0 StackExchange/wmi MIT go-ole/go-ole MIT shirou/gopsutil BSD-3-Clause shirou/w32 BSD-3-Clause cheggaaa/pb BSD-3-Clause google/uuid BSD-3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.0031,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Diagnostics <em>licenses</em>",
        "sections": "New Relic Diagnostics <em>licenses</em>",
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": ") use the Software to develop <em>services</em> or products for sale or include any components of the Software in any product; (d) remove any product identification, proprietary, copyright or other notices in the Software; or (e) publicly disseminate performance <em>information</em> or analysis (including benchmarks"
      },
      "id": "604505ad28ccbc457e2c60b4"
    }
  ],
  "/docs/licenses/license-information/special-services-licenses/new-relic-priority-support": [
    {
      "sections": [
        "Data collector licenses"
      ],
      "title": "Data collector licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "8eeb19ae388c1f4fd6856084084467a037861675",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/data-collector-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-03-16T06:20:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in New Relic data collectors. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Package Licenses annotations Apache 2.0 antlr BSD apache-log4j-extras Apache 2.0 apache-mime4j Apache 2.0 bonecp Apache 2.0 bonecp-provider Apache 2.0 bytelist MIT c3p0 Eclipse 1.0 commons-beanutils Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-digester Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-lang3 Apache 2.0 commons-logging Apache 2.0 commons-math Apache 2.0 commons-pool Apache 2.0 constantine MIT dom4j BSD ehcache Apache 2.0 gson Apache 2.0 guava Apache 2.0 hamcrest-core BSD-3-Clause hibernate-commons-annotations GNU LGPL 2.1 hibernate-core GNU LGPL 2.1 hibernate-ehcache GNU LGPL 2.1 hibernate-jpa-2.0-api GNU LGPL 2.1 hibernate-c3p0 GNU LGPL 2.1 hibernate-ehcache GNU LGPL 2.1 hibernate-jpa-2.0-api GNU LGPL 2.1 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 hystrix Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 jaffl GNU LGPL 3.0 java-driver Apache 2.0 javassist MPL 1.1, GNU GPL 2.1, Apache 2.0 javax.servlet Apache 2.0, Eclipse 1.0 javax.servlet-api CDDL + GPLv2 with classpath exception jboss-logging GNU LGPL 2.1 jboss-transaction-api_1.1_spec GNU LGPL 2.1 jcodings Common Public License 1.0, GNU GPL 2, GNU LGPL 2.1 jedis MIT jetty Apache 2.0, Eclipse 1.0 jffi GNU LGPL 3.0 jline BSD 2-Clause joni MIT jnr-netdb GNU LGPL 3.0 jnr-posix Common Public License 1.0, GNU GPL 2, GNU LGPL 2.1 joda-time Apache 2.0 jopt-simple MIT json-simple Apache 2.0 jsr305 Apache 2.0 junit Common Public License 1.0 kafka Apache 2.0 libthrift Apache 2.0 log4j Apache 2.0 logback-classic Eclipse 1.0 logback-core Eclipse 1.0 metrics-annotation Apache 2.0 mockito-all MIT msgpack Apache 2.0 mysql-connector-java GNU GPL 2 reflections WTFPL scala-library Apache 2.0 scannotation Apache 2.0 slf4j-api MIT slf4j-over-log4j MIT snakeyaml Apache 2.0 snappy Apache 2.0 syslog4j LGPL xml-apis Apache 2.0 yamlbeans MIT zkclient Apache 2.0 zookeeper Apache 2.0",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.7605,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Data collector <em>licenses</em>",
        "sections": "Data collector <em>licenses</em>",
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in New Relic data collectors. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Package <em>Licenses</em> annotations"
      },
      "id": "603eb41d64441fd7f74e8893"
    },
    {
      "sections": [
        "New Relic Premium Support"
      ],
      "title": "New Relic Premium Support",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "db095214148ca053cdabd9815dc74b04299dbe7b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-premium-support/",
      "published_at": "2021-05-05T16:20:33Z",
      "updated_at": "2021-03-16T04:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download the New Relic Premium Support document as a PDF (248 KB). The services described in this document only apply to initial orders entered after April 1, 2018. If you have questions about New Relic Premium Support, contact your New Relic account representative.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.70872,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "Download the New Relic Premium Support document as a PDF (248 KB). The <em>services</em> described in this document only apply to initial orders entered after April 1, 2018. If you have questions about New Relic Premium Support, contact your New Relic account representative."
      },
      "id": "603ea8c964441fe48b4e88af"
    },
    {
      "sections": [
        "New Relic Diagnostics licenses",
        "Proprietary license",
        "New Relic Diagnostics license terms",
        "Open-source licenses"
      ],
      "title": "New Relic Diagnostics licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "6d86f8f63d372be98270fadc8634f9da8da2a893",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-diagnostics-licenses/",
      "published_at": "2021-05-05T16:21:23Z",
      "updated_at": "2021-03-13T03:25:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Proprietary license New Relic Diagnostics license terms These New Relic Diagnostics License Terms (“Terms”) set forth the terms and conditions under which you (“Customer”) may use New Relic Diagnostics (the “Software”), as made available by New Relic, Inc. (“New Relic”). By clicking “accept” or downloading or using the Software, you agree to be bound by these Terms. If you are agreeing to these Terms on behalf of your company, then “Customer” means your company and you are binding your company to these Terms. 1. License Grant. Subject to all of the terms and conditions of these Terms, New Relic grants Customer a limited, non-exclusive, non-transferable, non-sublicensable license to use the Software in accordance with its documentation in support of Customer’s use of New Relic products to which Customer has a separate subscription (“New Relic Products”). Unless otherwise specified, there is no fee for use of the Software. 2. License Restrictions. Customer will not (a) sell, rent, sublicense, transfer, time-share or otherwise provide access to any copies of the Software, or portions thereof, to a third party; (b) modify, decompile, disassemble or reverse engineer the Software; (c) use the Software to develop services or products for sale or include any components of the Software in any product; (d) remove any product identification, proprietary, copyright or other notices in the Software; or (e) publicly disseminate performance information or analysis (including benchmarks) relating to the Software. 3. Ownership. Except for the limited license rights expressly provided herein, New Relic and its suppliers have and will retain all right, title and interest in and to the Software, and all copies, updates, modifications and derivative works thereof. Customer acknowledges that it is obtaining only a limited license right to the Software and no ownership rights are being conveyed to Customer under these Terms or otherwise. 4. Usage Data. Customer agrees that New Relic and its affiliates have the right to collect Usage Data from Customer through the Software and use Usage Data to support, operate and improve New Relic products and services and for other lawful business purposes. “Usage Data” means diagnostics data related to the use of the Software with New Relic Products, including, without limitation, configuration information, details on diagnostics tasks, New Relic account and application ID numbers and New Relic license keys. For clarity, Usage Data is not considered “Customer Data”, “your Data” or any other similar term as used in any applicable subscription or license agreement for New Relic Products. At Customer’s election, Customer may disable the collection of Usage Data as described in the Software documentation. 5. Disclaimers. New Relic is not obligated to provide any support or maintenance for the Software. ALL USE OF SOFTWARE IS AT CUSTOMER’S OWN RISK. SOFTWARE IS PROVIDED “AS IS,” WITH ALL FAULTS AND WITHOUT WARRANTY OF ANY KIND, EXPRESS, IMPLIED OR STATUTORY, INCLUDING, BUT NOT LIMITED TO, WARRANTIES OF TITLE OR NON-INFRINGEMENT. CUSTOMER MAY HAVE OTHER STATUTORY RIGHTS, HOWEVER, THE DURATION OF STATUTORILY REQUIRED WARRANTIES, IF ANY, WILL BE LIMITED TO THE FULLEST EXTENT PERMITTED BY LAW. 6. Limitation of Liability. TO THE FULLEST EXTENT PERMITTED BY LAW, IN NO EVENT WILL NEW RELIC BE LIABLE FOR ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES OF ANY KIND, REGARDLESS OF THE FORM OF ACTION, WHETHER IN CONTRACT, TORT (INCLUDING NEGLIGENCE), STRICT LIABILITY OR OTHERWISE, EVEN IF INFORMED OF THE POSSIBILITY OF SUCH DAMAGES IN ADVANCE. TO THE EXTENT ANY OF THE ABOVE LIMITATIONS ARE NOT ENFORCEABLE AT APPLICABLE LAW, NEW RELIC’S ENTIRE LIABILITY TO CUSTOMER UNDER THESE TERMS WILL NOT EXCEED $50. THESE LIMITATIONS ON LIABILITY ARE A FUNDAMENTAL BASIS OF THE BARGAIN AND NEW RELIC WOULD NOT BE ABLE TO PROVIDE THE SOFTWARE WITHOUT SUCH LIMITATIONS. THESE LIMITATIONS ON LIABILITY WILL APPLY NOTWITHSTANDING ANY FAILURE OF ESSENTIAL PURPOSE OF ANY LIMITED REMEDY. 7. Changes and Termination. At its discretion, without notice or liability to Customer, New Relic may (a) update, modify or discontinue the Software; (b) modify these Terms, effective upon posting; or (c) terminate or suspend these Terms or Customer’s access to the Software. If Customer does not agree with any modification, its sole remedy is to terminate its use of the Software. Upon any termination or suspension, Customer must stop using the Software. 8. Third Party Code. The Software may contain or be provided with third party code (including code which may be made available to Customer in source code form). A list of third party code and ownership, use, warranty and modification rights with respect to such code may be identified in the documentation or provided by New Relic upon Customer’s written request. New Relic is not responsible for applications and services not licensed by New Relic. 9. Export Compliance. Customer acknowledges that the Software is subject to export restrictions by the U.S. government and import restrictions by certain foreign governments. Customer shall not remove or export from the U.S. or allow the export or re-export of any part of the Software or any direct product thereof: (a) into (or to a national or resident of) any embargoed or terrorist-supporting country; (b) to anyone on the U.S. Commerce Department’s Table of Denial Orders or U.S. Treasury Department’s list of Specially Designated Nationals; (c) to any country to which such export or re-export is restricted or prohibited, or as to which the U.S. government or any agency thereof requires an export license or other governmental approval at the time of export or re-export without first obtaining such license or approval; or (d) otherwise in violation of any export or import restrictions, laws or regulations of any U.S. or foreign agency or authority. Customer agrees to the foregoing and warrants that Customer is not located in, under the control of, or a national or resident of any such prohibited country or on any such prohibited party list. 10. Government End-Users. The Software is commercial computer software. If Customer is an entity of the U.S. government, the use, duplication, reproduction, release, modification, disclosure or transfer of the Software, or any related documentation of any kind, is restricted by a license agreement or by these Terms in accordance with Federal Acquisition Regulation 12.212 for civilian purposes and Defense Federal Acquisition Regulation Supplement 227.7202 for military purposes. The Software was developed fully at private expense. All other use is prohibited. 11. General. These Terms will be governed by and construed under the laws of the State of California and the U.S. without regard to conflicts of law provisions thereof, and without regard to the United Nations Convention on the International Sale of Goods. The jurisdiction and venue for actions arising out of or relating to these Terms shall be in the state and federal courts in San Francisco, California. The parties are independent contractors. Customer may not assign these Terms without New Relic’s prior written consent and any attempt to do so will be void; New Relic may assign these Terms freely to any party without Customer’s consent. If any provision of these Terms is held by a court of competent jurisdiction to be unenforceable or invalid for any reason, that provision shall be limited to the minimum extent necessary so that these Terms shall otherwise remain in effect. These Terms are the entire agreement between the parties relating to the Software, and supersede all prior or contemporaneous agreements (oral or written) relating to the Software. Any separate agreement Customer has for New Relic Products does not apply to the Software. Open-source licenses We love open-source software, and use the following in New Relic Diagnostics. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License clbanning/mxj MIT go-yaml/yaml Apache 2.0 StackExchange/wmi MIT go-ole/go-ole MIT shirou/gopsutil BSD-3-Clause shirou/w32 BSD-3-Clause cheggaaa/pb BSD-3-Clause google/uuid BSD-3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.0031,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Diagnostics <em>licenses</em>",
        "sections": "New Relic Diagnostics <em>licenses</em>",
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": ") use the Software to develop <em>services</em> or products for sale or include any components of the Software in any product; (d) remove any product identification, proprietary, copyright or other notices in the Software; or (e) publicly disseminate performance <em>information</em> or analysis (including benchmarks"
      },
      "id": "604505ad28ccbc457e2c60b4"
    }
  ],
  "/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions": [
    {
      "sections": [
        "Product-based pricing usage and New Relic Platform Pricing Usage Plan",
        "Important",
        "Usage Plan: New Relic Platform Pricing",
        "Eligible Services",
        "Eligible Services (Partners)",
        "Subscriptions with indeterminate pricing or usage quantities",
        "Product Usage Ratio"
      ],
      "title": "Product-based pricing usage and New Relic Platform Pricing Usage Plan",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "e2686dc773c4e844544ce633a9a41a16f15edf5a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/product-based-pricing-usage-new-relic-platform-pricing-usage-plan/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-03-16T04:22:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc explains our original product-based pricing plan. For more about pricing changes, see Overview of pricing changes. The following provisions are applicable to existing customers (i) that have existing Terms, and (ii) that to the extent its subscription to the New Relic products reference the usage plans set forth below or where a subscription has indeterminate product pricing or usage quantities. New customers are eligible for New Relic One pricing as described here. Capitalized terms not defined below shall take on the meaning set forth in such New Relic order form. Usage Plan: New Relic Platform Pricing The following Eligible Services with New Relic are products that are referenced in specific order forms for New Relic Platform Pricing. For more information, contact your New Relic account representative. Eligible Services Eligible Services Per Unit Unit of Measure Monthly Standard Fee Rate New Relic APM Pro CU Annual* 10,000 Compute Units $166.70 New Relic APM Pro Host Annual* 1 Hosts $149 New Relic Insights Pro Annual 50,000,000 Events $165 New Relic Infrastructure Pro Annual 10,000 Compute Units $12 New Relic Browser Pro Annual 500,000 Page Views $149 New Relic Logs Annual - 8 Days* * 1 Per GB Daily $55 New Relic Logs Annual - 15 Days* * 1 Per GB Daily $65 New Relic Logs Annual - 30 Days* * 1 Per GB Daily $75 New Relic Metrics Annual 1,000 Data Points per Minute $25 New Relic Mobile Enterprise Annual 50,000 Total Users $499 New Relic Serverless for AWS Lambda Annual 1,000,000 AWS Lambda Events $15 New Relic Synthetics Pro Annual 10,000 Checks $69 New Relic Synthetics private locations (for New Relic Synthetics Pro Annual product) Fixed fee N/A $1,000 New Relic Traces Annual 1,000,000 Spans $1 New Relic AI Incident Intelligence Annual 1,000 Incident Events $500 New Relic AI Proactive Detection Annual 1,000,000,000 App Transactions $250 * Customer may utilize either New Relic APM Pro Annual or New Relic APM Pro CUs Annual, but not both. Customer will be provisioned New Relic APM Pro CUs Annual by default, unless otherwise stated in the relevant Order Form. * * Customer may utilize only one of New Relic Logs Annual - 8 Days, New Relic Logs Annual - 15 Days, or New Relic Logs Annual - 30 days. For the avoidance of doubt, Customer may not utilize New Relic Logs Annual with varying numbers of days retention concurrently. Customer will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. For more information about units of measures, see Product definitions. Eligible Services (Partners) Eligible services for New Relic Partners Measurement New Relic APM Pro CU Annual* Sold in Units of 8,900 Compute Units New Relic APM Pro Host Annual* Sold in Units of 1 Host New Relic Browser Pro Annual Sold in Units of 500,000 Page Views New Relic Infrastructure Pro Annual Sold in Units of 125,000 Compute Units New Relic Insights Pro Annual Sold in Units of 45,000,000 Events New Relic Logs Annual - 8 Days* * Sold in Units of 3 GB Daily New Relic Logs Annual - 15 Days* * Sold in Units of 2.5 GB Daily New Relic Logs Annual - 30 Days* * Sold in Units of 2 GB Daily New Relic Metrics Annual Sold in Units of 6,000 Data Points per Minute New Relic Mobile Enterprise Annual Sold in Units of 15,000 Total Users New Relic Serverless for AWS Lambda Annual Sold in Units of 10,000,000 AWS Lambda Events New Relic Synthetics Pro with Private Locations Annual Sold in Units of 22,000 Checks New Relic Traces Annual Sold in Units of 149,000,000 Spans * Customer and/or Partner may utilize either New Relic APM Pro Annual or New Relic APM Pro CUs Annual, but not both. Customer and/or Partner will be provisioned New Relic APM Pro CUs Annual by default, unless otherwise stated in the relevant Order Form. * * Customer and/or Partner may utilize only one of New Relic Logs Annual - 8 Days, New Relic Logs Annual - 15 Days, or New Relic Logs Annual - 30 days. For the avoidance of doubt, Customer may not utilize New Relic Logs Annual with varying numbers of days retention concurrently. Customer and/or Partner will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. Subscriptions with indeterminate pricing or usage quantities Product Usage Ratio Where a Customer subscription to the Products contain no specific pricing or quantities, Product-specific usage for a specific calendar month shall be determined through the calculation of the following ratio (the “Product Usage Ratio”) where: (1) the numerator shall be the Product specific usage for such calendar month multiplied by such Product’s list price, and (2) the denominator shall be the the aggregate Customer usage of all Products during such calendar month multiplied by all such Product(s) list price. The Product Usage Ratio shall be the percentage of usage for a specific Product for a calendar month period, or if usage cannot be measured for a period, the last Product Usage Ratio that can be calculated shall be assumed constant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.21515,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Product-based pricing <em>usage</em> and New Relic Platform Pricing <em>Usage</em> <em>Plan</em>",
        "sections": "Product-based pricing <em>usage</em> and New Relic Platform Pricing <em>Usage</em> <em>Plan</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " reference the <em>usage</em> <em>plans</em> set forth below or where a subscription has indeterminate product pricing or <em>usage</em> quantities. New customers are eligible for New Relic One pricing as described here. Capitalized terms not defined below shall take on the meaning set forth in such New Relic order form. <em>Usage</em>"
      },
      "id": "603ea32a28ccbc7e22eba768"
    },
    {
      "sections": [
        "New Relic One pricing: Definitions",
        "Account",
        "Commitment Term",
        "Customer Data",
        "Customer Properties",
        "Documentation",
        "GB Ingested",
        "Login Credentials",
        "Monthly Provisioned User",
        "Order",
        "Paid Terms of Service",
        "Product(s)",
        "Software",
        "Terms",
        "Third-Party Services",
        "Unpaid Terms of Service",
        "Usage Plan"
      ],
      "title": "New Relic One pricing: Definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "609575acd671fecf7899378157eabc57bc8d68e2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-04-22T16:06:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for organizations on our New Relic One pricing plan. For terms used in our original pricing plan, see Original pricing plan definitions. Account Account refers to the online account or subaccounts that New Relic provides for customers to manage their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, information, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer Properties Customer Properties means Customer’s websites, infrastructure, networks, mobile applications, or other systems, as well as Customer accounts on Third-Party Services. Documentation Documentation means the New Relic technical guides and documentation made available from the dedicated ‘Documentation’ page of the New Relic website. GB Ingested A GB Ingested is a measurement of the volume of metrics, events, logs, traces, or other telemetry data sent to or generated by the Products for the benefit of the Customer, including from the Software, the Customer Properties, or Third-Party Services. In this context, a GB is defined as 1 billion bytes. Login Credentials Login Credentials means the username, email address, password, or other personal information that is provided by a Customer user in order to manage an Account. Monthly Provisioned User A Monthly Provisioned User is any user who can log into Customer’s Account(s) and access the New Relic One Product functionality as specified in an Order and the Documentation. Order Order means the purchasing order for access to the Service or related services that: (1) is either executed by the Parties or entered into by you via self-service, and references this Agreement, or (2) is entered into by you and a Channel Partner. Paid Terms of Service Paid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/paid. Product(s) Product(s) mean the purchase of the New Relic subscription products described in the applicable Order and any updates, corrections, bug fixes, modifications, improvements, related services, new features, and functionality (made generally available to New Relic’s customer base) thereto. Software Software means the distributed software, APIs, scripts, or other code proprietary to New Relic provided with the Products. Terms Terms means the underlying Customer-New Relic agreement and the Order. Third-Party Services Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/unpaid. Usage Plan Usage Plan refers to the Service or Product pricing, invoicing related information, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.71112,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Usage</em> <em>Plan</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https:&#x2F;&#x2F;newrelic.com&#x2F;termsandconditions&#x2F;unpaid. <em>Usage</em> <em>Plan</em> <em>Usage</em> <em>Plan</em> refers to the Service or Product pricing, invoicing related <em>information</em>, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation."
      },
      "id": "6044e6e528ccbc26f22c6084"
    },
    {
      "sections": [
        "Original product-based pricing definitions",
        "App",
        "App transaction",
        "AWS Lambda event",
        "Check",
        "Compute unit",
        "Datapoints per minute",
        "Event",
        "Host",
        "Incident event",
        "Page view",
        "Per GB daily",
        "Span",
        "User"
      ],
      "title": "Original product-based pricing definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "42087e53167736831855bf9a4c2967c465677b45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/legacy-product-definitions/",
      "published_at": "2021-05-05T16:22:53Z",
      "updated_at": "2021-04-22T16:04:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our original product-based pricing. For New Relic One pricing plan terms, see New Relic One pricing definitions. App An app means the application software designed to run on smartphones, tablet computers, and other mobile devices. Each app includes a predefined number of users. App transaction An app transaction is an APM application's attempt to process a web or non-web request. In APM these manifest as throughput TIMESERIES or individually as events in the Transaction event type. AWS Lambda event An AWS Lambda event means the row of data collected from the customer's AWS Lambda function by the New Relic agent or sent from an external service into the New Relic platform. It consists of the AwsLambdaInvocation, AwsLambdaInvocationError, or custom event types. Check A check means the single instance of a Synthetics monitor running in New Relic's monitoring network and reporting back response time, and whether the check was a success or failure. Compute unit A compute unit means the measure of resources associated with a unit of computation on a physical or virtual host. Datapoints per minute Datapoints per minute (DPM) refers to the per-minute rate at which individual metric values are sent to the New Relic Metric Ingest API. For billing purposes, datapoints per minute are calculated as a monthly average value by summing the datapoints ingested during a 30 day period and dividing by the number of minutes in that period (43,200). Event An event means the row of data collected from the customer's application by the New Relic agent or sent from an external service into the Insights event database. Host A host means the physical computer or virtual machine instance running a single copy of an operating system. Host usage is tracked monthly by summing the hours that every host in the account is connected to New Relic and dividing by 750. A host is counted if it is connected any time during an hour. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic AI platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Page view A page view means the full page load (triggering an onLoad event) or a recorded URL change (state change). Per GB daily Per GB daily represents a daily average of Log data sent to New Relic over a 30 day period. Span A span represents an operation summary collected from the customer's application via the New Relic APM agent or New Relic Serverless for AWS Lambda agent, or sent from other tracing tools to the New Relic Trace API. User A user means the individual that connects to your app from a single device. Each unique device is considered as a unique user.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.70935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": "This is a glossary of terms that appear in contracts for our original product-based pricing. For New Relic One pricing <em>plan</em> terms, see New Relic One pricing definitions. App An app means the application software designed to run on smartphones, tablet computers, and other mobile devices. Each app"
      },
      "id": "603ebacc64441f77774e8872"
    }
  ],
  "/docs/licenses/license-information/usage-plans/product-based-pricing-usage-new-relic-platform-pricing-usage-plan": [
    {
      "sections": [
        "New Relic One Usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions"
      ],
      "title": "New Relic One Usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-05-05T13:27:48Z",
      "updated_at": "2021-03-13T04:19:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription. New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as February 19, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (“Pay As You Go” or “PAYG”), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customer’s usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customer’s Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (“Monthly Product Usage”). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (“Annual Pool of Funds” or “APoF”) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customer’s Monthly Product Usage. New Relic will invoice the Commitment Fee as per the ‘Billing Terms’ described in an Order. On a monthly cadence during the Commitment Term, Customer’s Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (“Monthly Product Usage”). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (“Additional Usage”), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (“PO”) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relic’s use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to New Relic Full Stack Observability Pro or Enterprise Products, you agree that during the Commitment Term the applicable service level availability commitment set forth on the ‘Service level availability commitment’ page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the New Relic Full Stack Observability Pro or Enterprise Products. If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make New Relic Full Stack Observability Standard and Telemetry Data Platform available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users (Full Stack Observability), New Relic provides an updated support plan commitment. By subscribing to New Relic One Users (Full Stack Observability), you agree that during the Commitment Term the applicable Support Plan set forth on the ‘Support plan’ page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, ‘lite’, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relic’s Products in the free tier only, or on a no-charge, or a ‘lite’ or ‘preview access’ basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the New Relic One - Standard User (Full Stack Observability Standard) Product, you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.62543,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic One <em>Usage</em> <em>plan</em> descriptions",
        "sections": "New Relic One <em>Usage</em> <em>plan</em> descriptions",
        "tags": "<em>License</em> <em>information</em>",
        "body": "The <em>Usage</em> <em>Plan</em> applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription. New Relic may modify the <em>Usage</em> <em>Plan</em> from time to time. Any changes to the <em>Usage</em> <em>Plan</em> will become effective immediately for changes that provide a benefit or right"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    },
    {
      "sections": [
        "New Relic One pricing: Definitions",
        "Account",
        "Commitment Term",
        "Customer Data",
        "Customer Properties",
        "Documentation",
        "GB Ingested",
        "Login Credentials",
        "Monthly Provisioned User",
        "Order",
        "Paid Terms of Service",
        "Product(s)",
        "Software",
        "Terms",
        "Third-Party Services",
        "Unpaid Terms of Service",
        "Usage Plan"
      ],
      "title": "New Relic One pricing: Definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "609575acd671fecf7899378157eabc57bc8d68e2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-04-22T16:06:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for organizations on our New Relic One pricing plan. For terms used in our original pricing plan, see Original pricing plan definitions. Account Account refers to the online account or subaccounts that New Relic provides for customers to manage their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, information, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer Properties Customer Properties means Customer’s websites, infrastructure, networks, mobile applications, or other systems, as well as Customer accounts on Third-Party Services. Documentation Documentation means the New Relic technical guides and documentation made available from the dedicated ‘Documentation’ page of the New Relic website. GB Ingested A GB Ingested is a measurement of the volume of metrics, events, logs, traces, or other telemetry data sent to or generated by the Products for the benefit of the Customer, including from the Software, the Customer Properties, or Third-Party Services. In this context, a GB is defined as 1 billion bytes. Login Credentials Login Credentials means the username, email address, password, or other personal information that is provided by a Customer user in order to manage an Account. Monthly Provisioned User A Monthly Provisioned User is any user who can log into Customer’s Account(s) and access the New Relic One Product functionality as specified in an Order and the Documentation. Order Order means the purchasing order for access to the Service or related services that: (1) is either executed by the Parties or entered into by you via self-service, and references this Agreement, or (2) is entered into by you and a Channel Partner. Paid Terms of Service Paid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/paid. Product(s) Product(s) mean the purchase of the New Relic subscription products described in the applicable Order and any updates, corrections, bug fixes, modifications, improvements, related services, new features, and functionality (made generally available to New Relic’s customer base) thereto. Software Software means the distributed software, APIs, scripts, or other code proprietary to New Relic provided with the Products. Terms Terms means the underlying Customer-New Relic agreement and the Order. Third-Party Services Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/unpaid. Usage Plan Usage Plan refers to the Service or Product pricing, invoicing related information, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.71109,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Usage</em> <em>Plan</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https:&#x2F;&#x2F;newrelic.com&#x2F;termsandconditions&#x2F;unpaid. <em>Usage</em> <em>Plan</em> <em>Usage</em> <em>Plan</em> refers to the Service or Product pricing, invoicing related <em>information</em>, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation."
      },
      "id": "6044e6e528ccbc26f22c6084"
    },
    {
      "sections": [
        "Original product-based pricing definitions",
        "App",
        "App transaction",
        "AWS Lambda event",
        "Check",
        "Compute unit",
        "Datapoints per minute",
        "Event",
        "Host",
        "Incident event",
        "Page view",
        "Per GB daily",
        "Span",
        "User"
      ],
      "title": "Original product-based pricing definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "42087e53167736831855bf9a4c2967c465677b45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/legacy-product-definitions/",
      "published_at": "2021-05-05T16:22:53Z",
      "updated_at": "2021-04-22T16:04:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our original product-based pricing. For New Relic One pricing plan terms, see New Relic One pricing definitions. App An app means the application software designed to run on smartphones, tablet computers, and other mobile devices. Each app includes a predefined number of users. App transaction An app transaction is an APM application's attempt to process a web or non-web request. In APM these manifest as throughput TIMESERIES or individually as events in the Transaction event type. AWS Lambda event An AWS Lambda event means the row of data collected from the customer's AWS Lambda function by the New Relic agent or sent from an external service into the New Relic platform. It consists of the AwsLambdaInvocation, AwsLambdaInvocationError, or custom event types. Check A check means the single instance of a Synthetics monitor running in New Relic's monitoring network and reporting back response time, and whether the check was a success or failure. Compute unit A compute unit means the measure of resources associated with a unit of computation on a physical or virtual host. Datapoints per minute Datapoints per minute (DPM) refers to the per-minute rate at which individual metric values are sent to the New Relic Metric Ingest API. For billing purposes, datapoints per minute are calculated as a monthly average value by summing the datapoints ingested during a 30 day period and dividing by the number of minutes in that period (43,200). Event An event means the row of data collected from the customer's application by the New Relic agent or sent from an external service into the Insights event database. Host A host means the physical computer or virtual machine instance running a single copy of an operating system. Host usage is tracked monthly by summing the hours that every host in the account is connected to New Relic and dividing by 750. A host is counted if it is connected any time during an hour. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic AI platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Page view A page view means the full page load (triggering an onLoad event) or a recorded URL change (state change). Per GB daily Per GB daily represents a daily average of Log data sent to New Relic over a 30 day period. Span A span represents an operation summary collected from the customer's application via the New Relic APM agent or New Relic Serverless for AWS Lambda agent, or sent from other tracing tools to the New Relic Trace API. User A user means the individual that connects to your app from a single device. Each unique device is considered as a unique user.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.70932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": "This is a glossary of terms that appear in contracts for our original product-based pricing. For New Relic One pricing <em>plan</em> terms, see New Relic One pricing definitions. App An app means the application software designed to run on smartphones, tablet computers, and other mobile devices. Each app"
      },
      "id": "603ebacc64441f77774e8872"
    }
  ],
  "/docs/licenses/product-or-service-licenses/miscellaneous/help-center-documentation-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.6776,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.09726,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.07585,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 410.0293,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS <em>application</em> <em>licenses</em>",
        "sections": "iOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic iOS <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Analytics MIT Copyright © 2016 Segment.io, Inc. CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me LoginManagerSDK New Relic License © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 410.02905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS <em>application</em> <em>licenses</em>",
        "sections": "tvOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic for TV <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses": [
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 410.06384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android <em>application</em> <em>licenses</em>",
        "sections": "Android <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Android <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Analytics MIT Copyright © 2016 Segment.io, Inc. CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me LoginManagerSDK New Relic License © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 410.02905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS <em>application</em> <em>licenses</em>",
        "sections": "tvOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic for TV <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses": [
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 410.0636,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android <em>application</em> <em>licenses</em>",
        "sections": "Android <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Android <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 410.02905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS <em>application</em> <em>licenses</em>",
        "sections": "iOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic iOS <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/apm-agent-sdk-licenses": [
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.1521,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": ". Go plugins for Logs The following <em>licenses</em> are for the plugins used link your logs and <em>APM</em> data using <em>New</em> <em>Relic</em>&#x27;s Go agent. For Go <em>licenses</em>, see Go agent <em>licenses</em>. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.8053,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/c-sdk-licenses": [
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.1519,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": ". Go plugins for Logs The following <em>licenses</em> are for the plugins used link your logs and <em>APM</em> data using <em>New</em> <em>Relic</em>&#x27;s Go agent. For Go <em>licenses</em>, see Go agent <em>licenses</em>. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.80515,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses": [
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.1519,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": ". Go plugins for Logs The following <em>licenses</em> are for the plugins used link your logs and <em>APM</em> data using <em>New</em> <em>Relic</em>&#x27;s Go agent. For Go <em>licenses</em>, see Go agent <em>licenses</em>. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.80515,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/java-agent-licenses": [
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.15167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.9532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": ". Go plugins for Logs The following <em>licenses</em> are for the plugins used link your logs and <em>APM</em> data using <em>New</em> <em>Relic</em>&#x27;s Go agent. For Go <em>licenses</em>, see Go agent <em>licenses</em>. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.805,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-licenses": [
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.15167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.9532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": ". Go plugins for Logs The following <em>licenses</em> are for the plugins used link your logs and <em>APM</em> data using <em>New</em> <em>Relic</em>&#x27;s Go agent. For Go <em>licenses</em>, see Go agent <em>licenses</em>. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.805,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses": [
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.15143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.953,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": ". Go plugins for Logs The following <em>licenses</em> are for the plugins used link your logs and <em>APM</em> data using <em>New</em> <em>Relic</em>&#x27;s Go agent. For Go <em>licenses</em>, see Go agent <em>licenses</em>. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.8048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-resource-provider-licenses": [
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.15143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.953,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": ". Go plugins for Logs The following <em>licenses</em> are for the plugins used link your logs and <em>APM</em> data using <em>New</em> <em>Relic</em>&#x27;s Go agent. For Go <em>licenses</em>, see Go agent <em>licenses</em>. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.8048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses": [
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.15125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95282,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": ". Go plugins for Logs The following <em>licenses</em> are for the plugins used link your logs and <em>APM</em> data using <em>New</em> <em>Relic</em>&#x27;s Go agent. For Go <em>licenses</em>, see Go agent <em>licenses</em>. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.80466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/nodejs-agent-licenses": [
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.15125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95282,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": ". Go plugins for Logs The following <em>licenses</em> are for the plugins used link your logs and <em>APM</em> data using <em>New</em> <em>Relic</em>&#x27;s Go agent. For Go <em>licenses</em>, see Go agent <em>licenses</em>. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.80466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/php-agent-licenses": [
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.151,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95264,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": ". Go plugins for Logs The following <em>licenses</em> are for the plugins used link your logs and <em>APM</em> data using <em>New</em> <em>Relic</em>&#x27;s Go agent. For Go <em>licenses</em>, see Go agent <em>licenses</em>. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.8045,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95264,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": ". Go plugins for Logs The following <em>licenses</em> are for the plugins used link your logs and <em>APM</em> data using <em>New</em> <em>Relic</em>&#x27;s Go agent. For Go <em>licenses</em>, see Go agent <em>licenses</em>. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.8045,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.78278,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/ruby-agent-licenses": [
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-05-05T16:20:32Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.1508,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": ". Go plugins for Logs The following <em>licenses</em> are for the plugins used link your logs and <em>APM</em> data using <em>New</em> <em>Relic</em>&#x27;s Go agent. For Go <em>licenses</em>, see Go agent <em>licenses</em>. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.80432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-browser/browser-agent-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.67615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.09595,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.07455,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-browser/new-relic-browser-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.67596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.0958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.07439,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-edition": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.9521,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.7823,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-program-resources": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.9521,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.7823,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-infrastructure/new-relic-infrastructure-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.6756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.09546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.07405,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-insights/new-relic-insights-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.6756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.09546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.07405,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-logs/logs-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 392.93994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logs</em> plugin <em>licenses</em>",
        "sections": "<em>Logs</em> plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " used for <em>New</em> <em>Relic</em> <em>Logs</em>, see <em>Logs</em> <em>licenses</em>. Plugins for <em>Logs</em> The following <em>licenses</em> are for the plugins used to connects your <em>log</em> data with <em>New</em> <em>Relic</em> <em>Logs</em>. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 <em>New</em> <em>Relic</em>, Inc. Fluentd Library License Copyright Fluentd Apache"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.80365,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.78192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses": [
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.80365,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.78192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Analytics MIT Copyright © 2016 Segment.io, Inc. CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me LoginManagerSDK New Relic License © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.78177,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses": [
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 291.09064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95154,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.78177,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-mobile/ios-sdk-new-relic-mobile-licenses": [
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 291.09064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95154,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.78177,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95135,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.80334,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.78162,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-plugins/plugins-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.00003,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs <em>plugin</em> <em>licenses</em>",
        "sections": "Logs <em>plugin</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs <em>plugins</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.80334,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.78162,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-synthetics/new-relic-synthetics-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.95117,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-05-05T16:29:06Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.80316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-05-05T16:26:54Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.78143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.30692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: <em>Configure</em> with <em>Log4j</em> 1.x",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>New</em> <em>Relic</em> offers a <em>Log</em>4j 1.x extension for <em>New</em> <em>Relic</em> <em>log</em> <em>management</em>, allowing you link to your <em>log</em> data with related data across the rest of the <em>New</em> <em>Relic</em> platform. This document explains how to <em>configure</em> <em>logs</em> in <em>context</em> and start getting <em>log</em> data. The code and an example application are available"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Node.js: Configure with Winston",
        "Compatibility and requirements",
        "Configure logs in context with log monitoring",
        "Enable log monitoring",
        "Install or update the Node.js agent",
        "Configure the Winston extension",
        "Check for logging data",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Node.js: Configure with Winston",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Node.js"
      ],
      "external_id": "0ed58684c33d758f2bdc599295fa356d9418702e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-nodejs/nodejs-configure-winston/",
      "published_at": "2021-05-06T04:23:51Z",
      "updated_at": "2021-03-13T01:09:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Winston extension to link your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with Winston, ensure your configuration meets the following requirements: Node.js agent 6.2.0 or higher: Install or update Winston version 3.0.0 or higher Configure logs in context with log monitoring To configure logs in context with Winston: Enable log monitoring with a compatible log forwarding plugin. Install or update the Node.js agent. Configure the Winston extension. Check for logging data. Enable log monitoring Confirm that you have log monitoring enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Node.js agent Install or update to the most recent Node.js agent version, and enable Distributed tracing. Configure the Winston extension To configure logs in context with the Winston extension, complete the following steps: To install the New Relic Winston log enricher, enter the following command into your terminal or command line interface: npm install @newrelic/winston-enricher Copy In your application code, update your logging configuration to add the newrelicFormatter as shown below: // index.js require('newrelic') const newrelicFormatter = require('@newrelic/winston-enricher') Copy The New Relic formatter can be used individually or combined with other formatters as the final format. format: winston.format.combine( winston.format.label({label: 'test'}), newrelicFormatter() ) Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. Troubleshooting Problem Not all log data in a message or for a specific attribute is being displayed. Cause The stack trace will be written to the error.stack property. To accommodate the 4000 character log line limit for New Relic Logs, the stack and trace properties will be removed and the message, error.message and error.stack values will be truncated to 1024 characters. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.9537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Node.js: <em>Configure</em> with Winston",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> monitoring",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " version, and <em>enable</em> Distributed tracing. <em>Configure</em> the Winston extension To <em>configure</em> <em>logs</em> in <em>context</em> with the Winston extension, complete the following steps: To install the <em>New</em> <em>Relic</em> Winston <em>log</em> enricher, enter the following command into your terminal or command line interface: npm install"
      },
      "id": "60450d71196a675ce1960f82"
    },
    {
      "sections": [
        "Configure logs in context for Go",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Go agent",
        "Configure logs in context using the Logrus extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Configure logs in context for Go",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Go"
      ],
      "external_id": "b99217c9f669b61dc96bdc21f3a183b84ab0c801",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-go/configure-logs-context-go/",
      "published_at": "2021-05-06T03:34:12Z",
      "updated_at": "2021-03-16T08:39:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Go agent connects your logs and APM data in New Relic, giving full context to high-level events, as well as providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use log management with the Go agent, ensure your configuration meets the following requirements: Go agent 2.12 or higher: Install or update Logrus logging framework v1.4.0 or higher Configure logs in context with log management To configure New Relic logs in context with Go: Enable log management with a compatible log forwarding plugin. Install or update the Go agent. Configure logs in context using the Logrus extension. Optional: Configure the Logrus extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Go agent Install or update to the most recent Go agent version, and enable Distributed tracing. Configure logs in context using the Logrus extension To configure the Logrus plugin: This step assumes that you have imported the following packages in files where Logrus is configured: import ( log \"github.com/sirupsen/logrus\" \"github.com/newrelic/go-agent/v3/integrations/logcontext/nrlogrusplugin\" \"github.com/newrelic/go-agent/v3/newrelic\" ) Copy Set the Logrus formatter to nrlogrusplugin.ContextFormatter: logger := log.New() logger.SetFormatter(nrlogrusplugin.ContextFormatter{}) Copy Or, if you are using the Logrus standard logger: log.SetFormatter(nrlogrusplugin.ContextFormatter{}) Copy The logger will now look for a newrelic.Transaction inside its context and decorate logs accordingly. Update your standard logging call to include contextual logging and pass this to the logger. For example, instead of logger.Info(\"Hello New Relic!\"), use ctx := newrelic.NewContext(context.Background(), txn) logger.WithContext(ctx).Info(\"Hello New Relic!\") Copy where txn is the current running transaction. Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has:span.id OR has:trace.id What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.30136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> for Go",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> with the Go agent, ensure your configuration meets the following requirements: Go agent 2.12 or higher: Install or update Logrus logging framework v1.4.0 or higher <em>Configure</em> <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To <em>configure</em> <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Go: <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ea67c28ccbc0c01eba74e"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-firelens-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.81195,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.01868,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "AWS Lambda for sending CloudWatch logs",
        "Requirements",
        "Install and configure the Cloudwatch logs Lambda function",
        "Tip",
        "Create a Lambda trigger",
        "Configure retries (optional)",
        "Resources created by the SAM template",
        "View log data",
        "What's next?"
      ],
      "title": "AWS Lambda for sending CloudWatch logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "7e097c6c48cd7e02d55ed7ce2c63982ba003b1d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs/",
      "published_at": "2021-05-05T17:48:20Z",
      "updated_at": "2021-04-16T03:34:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your CloudWatch logs to New Relic using our AWS Lambda function, newrelic-log-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch logs Lambda function, you only need a New Relic license key. Install and configure the Cloudwatch logs Lambda function Tip The following setup shows one approach to configuring environment variables. You can also configure them from the Functions page. Complete the following: Open the AWS Serverless Application Repository in your browser. Search for newrelic and check Show apps that create custom IAM roles or resource policies to find newrelic-log-ingestion. Open the newrelic-log-ingestion details and click Deploy. Scroll to the Application settings and configure log forwarding using the following environment variables: Key Description Value DEBUG_LOGGING_ENABLED A boolean to determine if you want to output debug messages in the CloudWatch console. Optional. To turn on debug logs, set this to true. By default, it is false. LICENSE_KEY New Relic License key is used for sending data to New Relic Infrastructure and Logs. Required. Your New Relic license key. LOGGING_ENABLED Determines if logs are forwarded to New Relic. Required. To turn on logging, set this to true. NR_LOGGING_ENDPOINT New Relic ingestion endpoint for Logs. Required. Two endpoints are available: US: https://log-api.newrelic.com/log/v1 EU: https://log-api.eu.newrelic.com/log/v1 NR_TAGS Specify tags to be added to all log events. Optional. Each tag is composed of a colon delimited key and value. Multiple key-value pairs are semi-colon delimited, for example, env:prod;team:myTeam Acknowledge that the app creates custom IAM roles and then click Deploy. Once the process completes, follow the steps below in Create a Lambda trigger to link your Lambda function to CloudWatch Logs. Create a Lambda trigger To get your logs streaming to New Relic you will need to attach a trigger to the Lambda: From the left side menu, select Functions. Find and select the previously created newrelic-log-ingestion function. Under Designer, click Add Triggers, and select Cloudwatch Logs from the dropdown. Select the the appropriate Log group for your application. Enter a name for your filter. Optional: Enter a filter pattern. Check the Enable trigger checkbox, then click Add to create the trigger. Configure retries (optional) You can configure the number of retries you want to perform in case the function fails to send the data in case of communication issues. Recommended number is 3 retries, but you can change the retry behavior by changing the below parameters: Tip Be aware that more number of retries can make the function run for longer time and therefore increases the probability of having higher costs for Lambda. On the contrary, decreasing the number of retries could increase the probability of data loss. MAX_RETRIES = 3 # Defines the number of retries after lambda failure to deliver data INITIAL_BACKOFF = 1 # Defines the initial wait seconds until next retry is executed BACKOFF_MULTIPLIER = 2 # Time multiplier between the retries As an example, in default above configuration, first retry will happen after 1 second, second retry after 2 seconds and third retry will happen after 4 seconds. Copy Resources created by the SAM template There are few resources that will be created when you create the application from the repository: The Lambda function itself A Role used to give execution permissions to the Lambda function based in CloudWatch Logs. All other lambda configurations not listed in the steps above can be left as the defaults. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.37512,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda for sending CloudWatch <em>logs</em>",
        "sections": "<em>Install</em> and configure the Cloudwatch <em>logs</em> Lambda function",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your CloudWatch <em>logs</em> to <em>New</em> <em>Relic</em> using our AWS Lambda function, newrelic-<em>log</em>-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch <em>logs</em> Lambda function, you only need a <em>New</em> <em>Relic</em> license key. Install and configure"
      },
      "id": "603ea6bb28ccbc228deba74c"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.81195,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.01868,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "Fluent Bit plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Fluent Bit for log management",
        "Recommended usage",
        "Install the Fluent Bit plugin",
        "Tip",
        "Configure the Fluent Bit plugin",
        "Important",
        "Test the Fluent Bit plugin",
        "Associate logs with entities",
        "Optional: Configure plugin attributes",
        "Plugin configuration",
        "View log data",
        "What's next?"
      ],
      "title": "Fluent Bit plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "380a8e60174fa7a999e9f032e098cdc9aa93625a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/fluent-bit-plugin-log-forwarding/",
      "published_at": "2021-05-05T17:44:07Z",
      "updated_at": "2021-04-06T08:57:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Fluent Bit output plugin to connect your Fluent Bit monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To use New Relic Logs with Fluent Bit, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Fluent Bit 0.12 or higher is supported; however, version 1.0 or higher is recommended. Enable Fluent Bit for log management To forward your logs to New Relic using Fluent Bit: Install the Fluent Bit plugin. Configure the Fluent Bit plugin. Test the Fluent Bit plugin. Generate some traffic and wait a few minutes, then check your account for data. Recommended usage We have published a container with the plugin installed. It serves as a base image to be used by our Kubernetes integration. We recommend you use this base image and layer your own custom configuration files. Install the Fluent Bit plugin To install the Fluent Bit plugin: Navigate to New Relic's Fluent Bit plugin repository on GitHub. From the repository page, clone or download the repository. Run the following command to build your plugin: cd newrelic-fluent-bit-output && make all Copy Make sure to store out_newrelic.so or out_newrelic_winXX.dll at a location that can be accessed by the fluent-bit daemon. Tip If you'd rather not compile the plugin yourself, you can download pre-compiled versions from our repository's releases page. Configure the Fluent Bit plugin Fluent Bit needs to know the location of the New Relic plugin and the New Relic license key (recommended) or Insert API key to output data to New Relic. To configure your Fluent Bit plugin: Important Pay attention to white space when editing your config files. Be sure to use four spaces to indent and one space between keys and values. Locate or create a plugins.conf file in your plugins directory. In the plugins.conf file, add a reference to out_newrelic.so, adjacent to your fluent-bit.conf file: [PLUGINS] Path /PATH/TO/newrelic-fluent-bit-output/out_newrelic.so Copy In the fluent-bit.conf file, add the following line under the service block: [SERVICE] # This is the main configuration block for fluent bit. # Ensure the follow line exists somewhere in the SERVICE block Plugins_File plugins.conf Copy At the bottom of the fluent-bit.conf file, add the following to set up the input and output filters. Replace the placeholder text with your New Relic license key (recommended) or Insert API key: [INPUT] Name tail Path /PATH/TO/YOUR/LOG/FILE [OUTPUT] Name newrelic Match * licenseKey YOUR_LICENSE_KEY # Optional maxBufferSize 256000 maxRecords 1024 Copy Restart your Fluent Bit instance with the following command: fluent-bit -c /PATH/TO/fluent-bit.conf Copy Test the Fluent Bit plugin To test if your Fluent Bit plugin is receiving input from a log file: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. Associate logs with entities To associate a log line with an entity, such as an infrastructure host, add a FILTER block: [FILTER] Name modify Match * # Or specify a match Add entity.guids <Your Entity GUID ID> # Optional Add hostname <Your hostname> # Optional Copy For more options, visit Fluent Bit modify filter documentation and Forward your logs using the infrastructure agent. Optional: Configure plugin attributes Plugin configuration Once you have installed and configured the Fluent Bit plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Key Description licenseKey The New Relic license key. Use either licenseKey (recommended) or apiKey, not both. Default: none maxBufferSize The maximum size the payloads sent, in bytes. Default: 256000 maxRecords The maximum number of records to send at a time. Default: 1024 apiKey New Relic's Insert API key. Use either licenseKey (recommended) or apiKey, not both. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.04855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Fluent Bit plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> Fluent Bit for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " key (recommended) or Insert API key Fluent Bit 0.12 or higher is supported; however, version 1.0 or higher is recommended. <em>Enable</em> Fluent Bit for <em>log</em> <em>management</em> To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Fluent Bit: Install the Fluent Bit plugin. Configure the Fluent Bit plugin. Test the Fluent Bit plugin"
      },
      "id": "603ea7ec28ccbce542eba791"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-logs-s3": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.81177,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.01862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "AWS Lambda for sending CloudWatch logs",
        "Requirements",
        "Install and configure the Cloudwatch logs Lambda function",
        "Tip",
        "Create a Lambda trigger",
        "Configure retries (optional)",
        "Resources created by the SAM template",
        "View log data",
        "What's next?"
      ],
      "title": "AWS Lambda for sending CloudWatch logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "7e097c6c48cd7e02d55ed7ce2c63982ba003b1d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs/",
      "published_at": "2021-05-05T17:48:20Z",
      "updated_at": "2021-04-16T03:34:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your CloudWatch logs to New Relic using our AWS Lambda function, newrelic-log-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch logs Lambda function, you only need a New Relic license key. Install and configure the Cloudwatch logs Lambda function Tip The following setup shows one approach to configuring environment variables. You can also configure them from the Functions page. Complete the following: Open the AWS Serverless Application Repository in your browser. Search for newrelic and check Show apps that create custom IAM roles or resource policies to find newrelic-log-ingestion. Open the newrelic-log-ingestion details and click Deploy. Scroll to the Application settings and configure log forwarding using the following environment variables: Key Description Value DEBUG_LOGGING_ENABLED A boolean to determine if you want to output debug messages in the CloudWatch console. Optional. To turn on debug logs, set this to true. By default, it is false. LICENSE_KEY New Relic License key is used for sending data to New Relic Infrastructure and Logs. Required. Your New Relic license key. LOGGING_ENABLED Determines if logs are forwarded to New Relic. Required. To turn on logging, set this to true. NR_LOGGING_ENDPOINT New Relic ingestion endpoint for Logs. Required. Two endpoints are available: US: https://log-api.newrelic.com/log/v1 EU: https://log-api.eu.newrelic.com/log/v1 NR_TAGS Specify tags to be added to all log events. Optional. Each tag is composed of a colon delimited key and value. Multiple key-value pairs are semi-colon delimited, for example, env:prod;team:myTeam Acknowledge that the app creates custom IAM roles and then click Deploy. Once the process completes, follow the steps below in Create a Lambda trigger to link your Lambda function to CloudWatch Logs. Create a Lambda trigger To get your logs streaming to New Relic you will need to attach a trigger to the Lambda: From the left side menu, select Functions. Find and select the previously created newrelic-log-ingestion function. Under Designer, click Add Triggers, and select Cloudwatch Logs from the dropdown. Select the the appropriate Log group for your application. Enter a name for your filter. Optional: Enter a filter pattern. Check the Enable trigger checkbox, then click Add to create the trigger. Configure retries (optional) You can configure the number of retries you want to perform in case the function fails to send the data in case of communication issues. Recommended number is 3 retries, but you can change the retry behavior by changing the below parameters: Tip Be aware that more number of retries can make the function run for longer time and therefore increases the probability of having higher costs for Lambda. On the contrary, decreasing the number of retries could increase the probability of data loss. MAX_RETRIES = 3 # Defines the number of retries after lambda failure to deliver data INITIAL_BACKOFF = 1 # Defines the initial wait seconds until next retry is executed BACKOFF_MULTIPLIER = 2 # Time multiplier between the retries As an example, in default above configuration, first retry will happen after 1 second, second retry after 2 seconds and third retry will happen after 4 seconds. Copy Resources created by the SAM template There are few resources that will be created when you create the application from the repository: The Lambda function itself A Role used to give execution permissions to the Lambda function based in CloudWatch Logs. All other lambda configurations not listed in the steps above can be left as the defaults. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.37509,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda for sending CloudWatch <em>logs</em>",
        "sections": "<em>Install</em> and configure the Cloudwatch <em>logs</em> Lambda function",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your CloudWatch <em>logs</em> to <em>New</em> <em>Relic</em> using our AWS Lambda function, newrelic-<em>log</em>-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch <em>logs</em> Lambda function, you only need a <em>New</em> <em>Relic</em> license key. Install and configure"
      },
      "id": "603ea6bb28ccbc228deba74c"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/enable-log-management-new-relic": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.81177,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.01862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "AWS Lambda for sending CloudWatch logs",
        "Requirements",
        "Install and configure the Cloudwatch logs Lambda function",
        "Tip",
        "Create a Lambda trigger",
        "Configure retries (optional)",
        "Resources created by the SAM template",
        "View log data",
        "What's next?"
      ],
      "title": "AWS Lambda for sending CloudWatch logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "7e097c6c48cd7e02d55ed7ce2c63982ba003b1d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs/",
      "published_at": "2021-05-05T17:48:20Z",
      "updated_at": "2021-04-16T03:34:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your CloudWatch logs to New Relic using our AWS Lambda function, newrelic-log-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch logs Lambda function, you only need a New Relic license key. Install and configure the Cloudwatch logs Lambda function Tip The following setup shows one approach to configuring environment variables. You can also configure them from the Functions page. Complete the following: Open the AWS Serverless Application Repository in your browser. Search for newrelic and check Show apps that create custom IAM roles or resource policies to find newrelic-log-ingestion. Open the newrelic-log-ingestion details and click Deploy. Scroll to the Application settings and configure log forwarding using the following environment variables: Key Description Value DEBUG_LOGGING_ENABLED A boolean to determine if you want to output debug messages in the CloudWatch console. Optional. To turn on debug logs, set this to true. By default, it is false. LICENSE_KEY New Relic License key is used for sending data to New Relic Infrastructure and Logs. Required. Your New Relic license key. LOGGING_ENABLED Determines if logs are forwarded to New Relic. Required. To turn on logging, set this to true. NR_LOGGING_ENDPOINT New Relic ingestion endpoint for Logs. Required. Two endpoints are available: US: https://log-api.newrelic.com/log/v1 EU: https://log-api.eu.newrelic.com/log/v1 NR_TAGS Specify tags to be added to all log events. Optional. Each tag is composed of a colon delimited key and value. Multiple key-value pairs are semi-colon delimited, for example, env:prod;team:myTeam Acknowledge that the app creates custom IAM roles and then click Deploy. Once the process completes, follow the steps below in Create a Lambda trigger to link your Lambda function to CloudWatch Logs. Create a Lambda trigger To get your logs streaming to New Relic you will need to attach a trigger to the Lambda: From the left side menu, select Functions. Find and select the previously created newrelic-log-ingestion function. Under Designer, click Add Triggers, and select Cloudwatch Logs from the dropdown. Select the the appropriate Log group for your application. Enter a name for your filter. Optional: Enter a filter pattern. Check the Enable trigger checkbox, then click Add to create the trigger. Configure retries (optional) You can configure the number of retries you want to perform in case the function fails to send the data in case of communication issues. Recommended number is 3 retries, but you can change the retry behavior by changing the below parameters: Tip Be aware that more number of retries can make the function run for longer time and therefore increases the probability of having higher costs for Lambda. On the contrary, decreasing the number of retries could increase the probability of data loss. MAX_RETRIES = 3 # Defines the number of retries after lambda failure to deliver data INITIAL_BACKOFF = 1 # Defines the initial wait seconds until next retry is executed BACKOFF_MULTIPLIER = 2 # Time multiplier between the retries As an example, in default above configuration, first retry will happen after 1 second, second retry after 2 seconds and third retry will happen after 4 seconds. Copy Resources created by the SAM template There are few resources that will be created when you create the application from the repository: The Lambda function itself A Role used to give execution permissions to the Lambda function based in CloudWatch Logs. All other lambda configurations not listed in the steps above can be left as the defaults. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.37509,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda for sending CloudWatch <em>logs</em>",
        "sections": "<em>Install</em> and configure the Cloudwatch <em>logs</em> Lambda function",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your CloudWatch <em>logs</em> to <em>New</em> <em>Relic</em> using our AWS Lambda function, newrelic-<em>log</em>-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch <em>logs</em> Lambda function, you only need a <em>New</em> <em>Relic</em> license key. Install and configure"
      },
      "id": "603ea6bb28ccbc228deba74c"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/fluent-bit-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.81152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.01852,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "AWS Lambda for sending CloudWatch logs",
        "Requirements",
        "Install and configure the Cloudwatch logs Lambda function",
        "Tip",
        "Create a Lambda trigger",
        "Configure retries (optional)",
        "Resources created by the SAM template",
        "View log data",
        "What's next?"
      ],
      "title": "AWS Lambda for sending CloudWatch logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "7e097c6c48cd7e02d55ed7ce2c63982ba003b1d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs/",
      "published_at": "2021-05-05T17:48:20Z",
      "updated_at": "2021-04-16T03:34:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your CloudWatch logs to New Relic using our AWS Lambda function, newrelic-log-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch logs Lambda function, you only need a New Relic license key. Install and configure the Cloudwatch logs Lambda function Tip The following setup shows one approach to configuring environment variables. You can also configure them from the Functions page. Complete the following: Open the AWS Serverless Application Repository in your browser. Search for newrelic and check Show apps that create custom IAM roles or resource policies to find newrelic-log-ingestion. Open the newrelic-log-ingestion details and click Deploy. Scroll to the Application settings and configure log forwarding using the following environment variables: Key Description Value DEBUG_LOGGING_ENABLED A boolean to determine if you want to output debug messages in the CloudWatch console. Optional. To turn on debug logs, set this to true. By default, it is false. LICENSE_KEY New Relic License key is used for sending data to New Relic Infrastructure and Logs. Required. Your New Relic license key. LOGGING_ENABLED Determines if logs are forwarded to New Relic. Required. To turn on logging, set this to true. NR_LOGGING_ENDPOINT New Relic ingestion endpoint for Logs. Required. Two endpoints are available: US: https://log-api.newrelic.com/log/v1 EU: https://log-api.eu.newrelic.com/log/v1 NR_TAGS Specify tags to be added to all log events. Optional. Each tag is composed of a colon delimited key and value. Multiple key-value pairs are semi-colon delimited, for example, env:prod;team:myTeam Acknowledge that the app creates custom IAM roles and then click Deploy. Once the process completes, follow the steps below in Create a Lambda trigger to link your Lambda function to CloudWatch Logs. Create a Lambda trigger To get your logs streaming to New Relic you will need to attach a trigger to the Lambda: From the left side menu, select Functions. Find and select the previously created newrelic-log-ingestion function. Under Designer, click Add Triggers, and select Cloudwatch Logs from the dropdown. Select the the appropriate Log group for your application. Enter a name for your filter. Optional: Enter a filter pattern. Check the Enable trigger checkbox, then click Add to create the trigger. Configure retries (optional) You can configure the number of retries you want to perform in case the function fails to send the data in case of communication issues. Recommended number is 3 retries, but you can change the retry behavior by changing the below parameters: Tip Be aware that more number of retries can make the function run for longer time and therefore increases the probability of having higher costs for Lambda. On the contrary, decreasing the number of retries could increase the probability of data loss. MAX_RETRIES = 3 # Defines the number of retries after lambda failure to deliver data INITIAL_BACKOFF = 1 # Defines the initial wait seconds until next retry is executed BACKOFF_MULTIPLIER = 2 # Time multiplier between the retries As an example, in default above configuration, first retry will happen after 1 second, second retry after 2 seconds and third retry will happen after 4 seconds. Copy Resources created by the SAM template There are few resources that will be created when you create the application from the repository: The Lambda function itself A Role used to give execution permissions to the Lambda function based in CloudWatch Logs. All other lambda configurations not listed in the steps above can be left as the defaults. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.37506,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda for sending CloudWatch <em>logs</em>",
        "sections": "<em>Install</em> and configure the Cloudwatch <em>logs</em> Lambda function",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your CloudWatch <em>logs</em> to <em>New</em> <em>Relic</em> using our AWS Lambda function, newrelic-<em>log</em>-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch <em>logs</em> Lambda function, you only need a <em>New</em> <em>Relic</em> license key. Install and configure"
      },
      "id": "603ea6bb28ccbc228deba74c"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/fluentd-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.81152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.01852,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "AWS Lambda for sending CloudWatch logs",
        "Requirements",
        "Install and configure the Cloudwatch logs Lambda function",
        "Tip",
        "Create a Lambda trigger",
        "Configure retries (optional)",
        "Resources created by the SAM template",
        "View log data",
        "What's next?"
      ],
      "title": "AWS Lambda for sending CloudWatch logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "7e097c6c48cd7e02d55ed7ce2c63982ba003b1d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs/",
      "published_at": "2021-05-05T17:48:20Z",
      "updated_at": "2021-04-16T03:34:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your CloudWatch logs to New Relic using our AWS Lambda function, newrelic-log-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch logs Lambda function, you only need a New Relic license key. Install and configure the Cloudwatch logs Lambda function Tip The following setup shows one approach to configuring environment variables. You can also configure them from the Functions page. Complete the following: Open the AWS Serverless Application Repository in your browser. Search for newrelic and check Show apps that create custom IAM roles or resource policies to find newrelic-log-ingestion. Open the newrelic-log-ingestion details and click Deploy. Scroll to the Application settings and configure log forwarding using the following environment variables: Key Description Value DEBUG_LOGGING_ENABLED A boolean to determine if you want to output debug messages in the CloudWatch console. Optional. To turn on debug logs, set this to true. By default, it is false. LICENSE_KEY New Relic License key is used for sending data to New Relic Infrastructure and Logs. Required. Your New Relic license key. LOGGING_ENABLED Determines if logs are forwarded to New Relic. Required. To turn on logging, set this to true. NR_LOGGING_ENDPOINT New Relic ingestion endpoint for Logs. Required. Two endpoints are available: US: https://log-api.newrelic.com/log/v1 EU: https://log-api.eu.newrelic.com/log/v1 NR_TAGS Specify tags to be added to all log events. Optional. Each tag is composed of a colon delimited key and value. Multiple key-value pairs are semi-colon delimited, for example, env:prod;team:myTeam Acknowledge that the app creates custom IAM roles and then click Deploy. Once the process completes, follow the steps below in Create a Lambda trigger to link your Lambda function to CloudWatch Logs. Create a Lambda trigger To get your logs streaming to New Relic you will need to attach a trigger to the Lambda: From the left side menu, select Functions. Find and select the previously created newrelic-log-ingestion function. Under Designer, click Add Triggers, and select Cloudwatch Logs from the dropdown. Select the the appropriate Log group for your application. Enter a name for your filter. Optional: Enter a filter pattern. Check the Enable trigger checkbox, then click Add to create the trigger. Configure retries (optional) You can configure the number of retries you want to perform in case the function fails to send the data in case of communication issues. Recommended number is 3 retries, but you can change the retry behavior by changing the below parameters: Tip Be aware that more number of retries can make the function run for longer time and therefore increases the probability of having higher costs for Lambda. On the contrary, decreasing the number of retries could increase the probability of data loss. MAX_RETRIES = 3 # Defines the number of retries after lambda failure to deliver data INITIAL_BACKOFF = 1 # Defines the initial wait seconds until next retry is executed BACKOFF_MULTIPLIER = 2 # Time multiplier between the retries As an example, in default above configuration, first retry will happen after 1 second, second retry after 2 seconds and third retry will happen after 4 seconds. Copy Resources created by the SAM template There are few resources that will be created when you create the application from the repository: The Lambda function itself A Role used to give execution permissions to the Lambda function based in CloudWatch Logs. All other lambda configurations not listed in the steps above can be left as the defaults. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.37506,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda for sending CloudWatch <em>logs</em>",
        "sections": "<em>Install</em> and configure the Cloudwatch <em>logs</em> Lambda function",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your CloudWatch <em>logs</em> to <em>New</em> <em>Relic</em> using our AWS Lambda function, newrelic-<em>log</em>-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch <em>logs</em> Lambda function, you only need a <em>New</em> <em>Relic</em> license key. Install and configure"
      },
      "id": "603ea6bb28ccbc228deba74c"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent": [
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.01846,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "AWS Lambda for sending CloudWatch logs",
        "Requirements",
        "Install and configure the Cloudwatch logs Lambda function",
        "Tip",
        "Create a Lambda trigger",
        "Configure retries (optional)",
        "Resources created by the SAM template",
        "View log data",
        "What's next?"
      ],
      "title": "AWS Lambda for sending CloudWatch logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "7e097c6c48cd7e02d55ed7ce2c63982ba003b1d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs/",
      "published_at": "2021-05-05T17:48:20Z",
      "updated_at": "2021-04-16T03:34:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your CloudWatch logs to New Relic using our AWS Lambda function, newrelic-log-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch logs Lambda function, you only need a New Relic license key. Install and configure the Cloudwatch logs Lambda function Tip The following setup shows one approach to configuring environment variables. You can also configure them from the Functions page. Complete the following: Open the AWS Serverless Application Repository in your browser. Search for newrelic and check Show apps that create custom IAM roles or resource policies to find newrelic-log-ingestion. Open the newrelic-log-ingestion details and click Deploy. Scroll to the Application settings and configure log forwarding using the following environment variables: Key Description Value DEBUG_LOGGING_ENABLED A boolean to determine if you want to output debug messages in the CloudWatch console. Optional. To turn on debug logs, set this to true. By default, it is false. LICENSE_KEY New Relic License key is used for sending data to New Relic Infrastructure and Logs. Required. Your New Relic license key. LOGGING_ENABLED Determines if logs are forwarded to New Relic. Required. To turn on logging, set this to true. NR_LOGGING_ENDPOINT New Relic ingestion endpoint for Logs. Required. Two endpoints are available: US: https://log-api.newrelic.com/log/v1 EU: https://log-api.eu.newrelic.com/log/v1 NR_TAGS Specify tags to be added to all log events. Optional. Each tag is composed of a colon delimited key and value. Multiple key-value pairs are semi-colon delimited, for example, env:prod;team:myTeam Acknowledge that the app creates custom IAM roles and then click Deploy. Once the process completes, follow the steps below in Create a Lambda trigger to link your Lambda function to CloudWatch Logs. Create a Lambda trigger To get your logs streaming to New Relic you will need to attach a trigger to the Lambda: From the left side menu, select Functions. Find and select the previously created newrelic-log-ingestion function. Under Designer, click Add Triggers, and select Cloudwatch Logs from the dropdown. Select the the appropriate Log group for your application. Enter a name for your filter. Optional: Enter a filter pattern. Check the Enable trigger checkbox, then click Add to create the trigger. Configure retries (optional) You can configure the number of retries you want to perform in case the function fails to send the data in case of communication issues. Recommended number is 3 retries, but you can change the retry behavior by changing the below parameters: Tip Be aware that more number of retries can make the function run for longer time and therefore increases the probability of having higher costs for Lambda. On the contrary, decreasing the number of retries could increase the probability of data loss. MAX_RETRIES = 3 # Defines the number of retries after lambda failure to deliver data INITIAL_BACKOFF = 1 # Defines the initial wait seconds until next retry is executed BACKOFF_MULTIPLIER = 2 # Time multiplier between the retries As an example, in default above configuration, first retry will happen after 1 second, second retry after 2 seconds and third retry will happen after 4 seconds. Copy Resources created by the SAM template There are few resources that will be created when you create the application from the repository: The Lambda function itself A Role used to give execution permissions to the Lambda function based in CloudWatch Logs. All other lambda configurations not listed in the steps above can be left as the defaults. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.37505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda for sending CloudWatch <em>logs</em>",
        "sections": "<em>Install</em> and configure the Cloudwatch <em>logs</em> Lambda function",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your CloudWatch <em>logs</em> to <em>New</em> <em>Relic</em> using our AWS Lambda function, newrelic-<em>log</em>-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch <em>logs</em> Lambda function, you only need a <em>New</em> <em>Relic</em> license key. Install and configure"
      },
      "id": "603ea6bb28ccbc228deba74c"
    },
    {
      "sections": [
        "Fluent Bit plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Fluent Bit for log management",
        "Recommended usage",
        "Install the Fluent Bit plugin",
        "Tip",
        "Configure the Fluent Bit plugin",
        "Important",
        "Test the Fluent Bit plugin",
        "Associate logs with entities",
        "Optional: Configure plugin attributes",
        "Plugin configuration",
        "View log data",
        "What's next?"
      ],
      "title": "Fluent Bit plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "380a8e60174fa7a999e9f032e098cdc9aa93625a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/fluent-bit-plugin-log-forwarding/",
      "published_at": "2021-05-05T17:44:07Z",
      "updated_at": "2021-04-06T08:57:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Fluent Bit output plugin to connect your Fluent Bit monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To use New Relic Logs with Fluent Bit, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Fluent Bit 0.12 or higher is supported; however, version 1.0 or higher is recommended. Enable Fluent Bit for log management To forward your logs to New Relic using Fluent Bit: Install the Fluent Bit plugin. Configure the Fluent Bit plugin. Test the Fluent Bit plugin. Generate some traffic and wait a few minutes, then check your account for data. Recommended usage We have published a container with the plugin installed. It serves as a base image to be used by our Kubernetes integration. We recommend you use this base image and layer your own custom configuration files. Install the Fluent Bit plugin To install the Fluent Bit plugin: Navigate to New Relic's Fluent Bit plugin repository on GitHub. From the repository page, clone or download the repository. Run the following command to build your plugin: cd newrelic-fluent-bit-output && make all Copy Make sure to store out_newrelic.so or out_newrelic_winXX.dll at a location that can be accessed by the fluent-bit daemon. Tip If you'd rather not compile the plugin yourself, you can download pre-compiled versions from our repository's releases page. Configure the Fluent Bit plugin Fluent Bit needs to know the location of the New Relic plugin and the New Relic license key (recommended) or Insert API key to output data to New Relic. To configure your Fluent Bit plugin: Important Pay attention to white space when editing your config files. Be sure to use four spaces to indent and one space between keys and values. Locate or create a plugins.conf file in your plugins directory. In the plugins.conf file, add a reference to out_newrelic.so, adjacent to your fluent-bit.conf file: [PLUGINS] Path /PATH/TO/newrelic-fluent-bit-output/out_newrelic.so Copy In the fluent-bit.conf file, add the following line under the service block: [SERVICE] # This is the main configuration block for fluent bit. # Ensure the follow line exists somewhere in the SERVICE block Plugins_File plugins.conf Copy At the bottom of the fluent-bit.conf file, add the following to set up the input and output filters. Replace the placeholder text with your New Relic license key (recommended) or Insert API key: [INPUT] Name tail Path /PATH/TO/YOUR/LOG/FILE [OUTPUT] Name newrelic Match * licenseKey YOUR_LICENSE_KEY # Optional maxBufferSize 256000 maxRecords 1024 Copy Restart your Fluent Bit instance with the following command: fluent-bit -c /PATH/TO/fluent-bit.conf Copy Test the Fluent Bit plugin To test if your Fluent Bit plugin is receiving input from a log file: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. Associate logs with entities To associate a log line with an entity, such as an infrastructure host, add a FILTER block: [FILTER] Name modify Match * # Or specify a match Add entity.guids <Your Entity GUID ID> # Optional Add hostname <Your hostname> # Optional Copy For more options, visit Fluent Bit modify filter documentation and Forward your logs using the infrastructure agent. Optional: Configure plugin attributes Plugin configuration Once you have installed and configured the Fluent Bit plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Key Description licenseKey The New Relic license key. Use either licenseKey (recommended) or apiKey, not both. Default: none maxBufferSize The maximum size the payloads sent, in bytes. Default: 256000 maxRecords The maximum number of records to send at a time. Default: 1024 apiKey New Relic's Insert API key. Use either licenseKey (recommended) or apiKey, not both. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.04851,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Fluent Bit plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> Fluent Bit for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " key (recommended) or Insert API key Fluent Bit 0.12 or higher is supported; however, version 1.0 or higher is recommended. <em>Enable</em> Fluent Bit for <em>log</em> <em>management</em> To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Fluent Bit: Install the Fluent Bit plugin. Configure the Fluent Bit plugin. Test the Fluent Bit plugin"
      },
      "id": "603ea7ec28ccbce542eba791"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.81113,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "AWS Lambda for sending CloudWatch logs",
        "Requirements",
        "Install and configure the Cloudwatch logs Lambda function",
        "Tip",
        "Create a Lambda trigger",
        "Configure retries (optional)",
        "Resources created by the SAM template",
        "View log data",
        "What's next?"
      ],
      "title": "AWS Lambda for sending CloudWatch logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "7e097c6c48cd7e02d55ed7ce2c63982ba003b1d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs/",
      "published_at": "2021-05-05T17:48:20Z",
      "updated_at": "2021-04-16T03:34:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your CloudWatch logs to New Relic using our AWS Lambda function, newrelic-log-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch logs Lambda function, you only need a New Relic license key. Install and configure the Cloudwatch logs Lambda function Tip The following setup shows one approach to configuring environment variables. You can also configure them from the Functions page. Complete the following: Open the AWS Serverless Application Repository in your browser. Search for newrelic and check Show apps that create custom IAM roles or resource policies to find newrelic-log-ingestion. Open the newrelic-log-ingestion details and click Deploy. Scroll to the Application settings and configure log forwarding using the following environment variables: Key Description Value DEBUG_LOGGING_ENABLED A boolean to determine if you want to output debug messages in the CloudWatch console. Optional. To turn on debug logs, set this to true. By default, it is false. LICENSE_KEY New Relic License key is used for sending data to New Relic Infrastructure and Logs. Required. Your New Relic license key. LOGGING_ENABLED Determines if logs are forwarded to New Relic. Required. To turn on logging, set this to true. NR_LOGGING_ENDPOINT New Relic ingestion endpoint for Logs. Required. Two endpoints are available: US: https://log-api.newrelic.com/log/v1 EU: https://log-api.eu.newrelic.com/log/v1 NR_TAGS Specify tags to be added to all log events. Optional. Each tag is composed of a colon delimited key and value. Multiple key-value pairs are semi-colon delimited, for example, env:prod;team:myTeam Acknowledge that the app creates custom IAM roles and then click Deploy. Once the process completes, follow the steps below in Create a Lambda trigger to link your Lambda function to CloudWatch Logs. Create a Lambda trigger To get your logs streaming to New Relic you will need to attach a trigger to the Lambda: From the left side menu, select Functions. Find and select the previously created newrelic-log-ingestion function. Under Designer, click Add Triggers, and select Cloudwatch Logs from the dropdown. Select the the appropriate Log group for your application. Enter a name for your filter. Optional: Enter a filter pattern. Check the Enable trigger checkbox, then click Add to create the trigger. Configure retries (optional) You can configure the number of retries you want to perform in case the function fails to send the data in case of communication issues. Recommended number is 3 retries, but you can change the retry behavior by changing the below parameters: Tip Be aware that more number of retries can make the function run for longer time and therefore increases the probability of having higher costs for Lambda. On the contrary, decreasing the number of retries could increase the probability of data loss. MAX_RETRIES = 3 # Defines the number of retries after lambda failure to deliver data INITIAL_BACKOFF = 1 # Defines the initial wait seconds until next retry is executed BACKOFF_MULTIPLIER = 2 # Time multiplier between the retries As an example, in default above configuration, first retry will happen after 1 second, second retry after 2 seconds and third retry will happen after 4 seconds. Copy Resources created by the SAM template There are few resources that will be created when you create the application from the repository: The Lambda function itself A Role used to give execution permissions to the Lambda function based in CloudWatch Logs. All other lambda configurations not listed in the steps above can be left as the defaults. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.37503,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda for sending CloudWatch <em>logs</em>",
        "sections": "<em>Install</em> and configure the Cloudwatch <em>logs</em> Lambda function",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your CloudWatch <em>logs</em> to <em>New</em> <em>Relic</em> using our AWS Lambda function, newrelic-<em>log</em>-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch <em>logs</em> Lambda function, you only need a <em>New</em> <em>Relic</em> license key. Install and configure"
      },
      "id": "603ea6bb28ccbc228deba74c"
    },
    {
      "sections": [
        "Fluent Bit plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Fluent Bit for log management",
        "Recommended usage",
        "Install the Fluent Bit plugin",
        "Tip",
        "Configure the Fluent Bit plugin",
        "Important",
        "Test the Fluent Bit plugin",
        "Associate logs with entities",
        "Optional: Configure plugin attributes",
        "Plugin configuration",
        "View log data",
        "What's next?"
      ],
      "title": "Fluent Bit plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "380a8e60174fa7a999e9f032e098cdc9aa93625a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/fluent-bit-plugin-log-forwarding/",
      "published_at": "2021-05-05T17:44:07Z",
      "updated_at": "2021-04-06T08:57:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Fluent Bit output plugin to connect your Fluent Bit monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To use New Relic Logs with Fluent Bit, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Fluent Bit 0.12 or higher is supported; however, version 1.0 or higher is recommended. Enable Fluent Bit for log management To forward your logs to New Relic using Fluent Bit: Install the Fluent Bit plugin. Configure the Fluent Bit plugin. Test the Fluent Bit plugin. Generate some traffic and wait a few minutes, then check your account for data. Recommended usage We have published a container with the plugin installed. It serves as a base image to be used by our Kubernetes integration. We recommend you use this base image and layer your own custom configuration files. Install the Fluent Bit plugin To install the Fluent Bit plugin: Navigate to New Relic's Fluent Bit plugin repository on GitHub. From the repository page, clone or download the repository. Run the following command to build your plugin: cd newrelic-fluent-bit-output && make all Copy Make sure to store out_newrelic.so or out_newrelic_winXX.dll at a location that can be accessed by the fluent-bit daemon. Tip If you'd rather not compile the plugin yourself, you can download pre-compiled versions from our repository's releases page. Configure the Fluent Bit plugin Fluent Bit needs to know the location of the New Relic plugin and the New Relic license key (recommended) or Insert API key to output data to New Relic. To configure your Fluent Bit plugin: Important Pay attention to white space when editing your config files. Be sure to use four spaces to indent and one space between keys and values. Locate or create a plugins.conf file in your plugins directory. In the plugins.conf file, add a reference to out_newrelic.so, adjacent to your fluent-bit.conf file: [PLUGINS] Path /PATH/TO/newrelic-fluent-bit-output/out_newrelic.so Copy In the fluent-bit.conf file, add the following line under the service block: [SERVICE] # This is the main configuration block for fluent bit. # Ensure the follow line exists somewhere in the SERVICE block Plugins_File plugins.conf Copy At the bottom of the fluent-bit.conf file, add the following to set up the input and output filters. Replace the placeholder text with your New Relic license key (recommended) or Insert API key: [INPUT] Name tail Path /PATH/TO/YOUR/LOG/FILE [OUTPUT] Name newrelic Match * licenseKey YOUR_LICENSE_KEY # Optional maxBufferSize 256000 maxRecords 1024 Copy Restart your Fluent Bit instance with the following command: fluent-bit -c /PATH/TO/fluent-bit.conf Copy Test the Fluent Bit plugin To test if your Fluent Bit plugin is receiving input from a log file: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. Associate logs with entities To associate a log line with an entity, such as an infrastructure host, add a FILTER block: [FILTER] Name modify Match * # Or specify a match Add entity.guids <Your Entity GUID ID> # Optional Add hostname <Your hostname> # Optional Copy For more options, visit Fluent Bit modify filter documentation and Forward your logs using the infrastructure agent. Optional: Configure plugin attributes Plugin configuration Once you have installed and configured the Fluent Bit plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Key Description licenseKey The New Relic license key. Use either licenseKey (recommended) or apiKey, not both. Default: none maxBufferSize The maximum size the payloads sent, in bytes. Default: 256000 maxRecords The maximum number of records to send at a time. Default: 1024 apiKey New Relic's Insert API key. Use either licenseKey (recommended) or apiKey, not both. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.0485,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Fluent Bit plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> Fluent Bit for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " key (recommended) or Insert API key Fluent Bit 0.12 or higher is supported; however, version 1.0 or higher is recommended. <em>Enable</em> Fluent Bit for <em>log</em> <em>management</em> To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Fluent Bit: Install the Fluent Bit plugin. Configure the Fluent Bit plugin. Test the Fluent Bit plugin"
      },
      "id": "603ea7ec28ccbce542eba791"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/kubernetes-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.81113,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.01837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "AWS Lambda for sending CloudWatch logs",
        "Requirements",
        "Install and configure the Cloudwatch logs Lambda function",
        "Tip",
        "Create a Lambda trigger",
        "Configure retries (optional)",
        "Resources created by the SAM template",
        "View log data",
        "What's next?"
      ],
      "title": "AWS Lambda for sending CloudWatch logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "7e097c6c48cd7e02d55ed7ce2c63982ba003b1d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs/",
      "published_at": "2021-05-05T17:48:20Z",
      "updated_at": "2021-04-16T03:34:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your CloudWatch logs to New Relic using our AWS Lambda function, newrelic-log-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch logs Lambda function, you only need a New Relic license key. Install and configure the Cloudwatch logs Lambda function Tip The following setup shows one approach to configuring environment variables. You can also configure them from the Functions page. Complete the following: Open the AWS Serverless Application Repository in your browser. Search for newrelic and check Show apps that create custom IAM roles or resource policies to find newrelic-log-ingestion. Open the newrelic-log-ingestion details and click Deploy. Scroll to the Application settings and configure log forwarding using the following environment variables: Key Description Value DEBUG_LOGGING_ENABLED A boolean to determine if you want to output debug messages in the CloudWatch console. Optional. To turn on debug logs, set this to true. By default, it is false. LICENSE_KEY New Relic License key is used for sending data to New Relic Infrastructure and Logs. Required. Your New Relic license key. LOGGING_ENABLED Determines if logs are forwarded to New Relic. Required. To turn on logging, set this to true. NR_LOGGING_ENDPOINT New Relic ingestion endpoint for Logs. Required. Two endpoints are available: US: https://log-api.newrelic.com/log/v1 EU: https://log-api.eu.newrelic.com/log/v1 NR_TAGS Specify tags to be added to all log events. Optional. Each tag is composed of a colon delimited key and value. Multiple key-value pairs are semi-colon delimited, for example, env:prod;team:myTeam Acknowledge that the app creates custom IAM roles and then click Deploy. Once the process completes, follow the steps below in Create a Lambda trigger to link your Lambda function to CloudWatch Logs. Create a Lambda trigger To get your logs streaming to New Relic you will need to attach a trigger to the Lambda: From the left side menu, select Functions. Find and select the previously created newrelic-log-ingestion function. Under Designer, click Add Triggers, and select Cloudwatch Logs from the dropdown. Select the the appropriate Log group for your application. Enter a name for your filter. Optional: Enter a filter pattern. Check the Enable trigger checkbox, then click Add to create the trigger. Configure retries (optional) You can configure the number of retries you want to perform in case the function fails to send the data in case of communication issues. Recommended number is 3 retries, but you can change the retry behavior by changing the below parameters: Tip Be aware that more number of retries can make the function run for longer time and therefore increases the probability of having higher costs for Lambda. On the contrary, decreasing the number of retries could increase the probability of data loss. MAX_RETRIES = 3 # Defines the number of retries after lambda failure to deliver data INITIAL_BACKOFF = 1 # Defines the initial wait seconds until next retry is executed BACKOFF_MULTIPLIER = 2 # Time multiplier between the retries As an example, in default above configuration, first retry will happen after 1 second, second retry after 2 seconds and third retry will happen after 4 seconds. Copy Resources created by the SAM template There are few resources that will be created when you create the application from the repository: The Lambda function itself A Role used to give execution permissions to the Lambda function based in CloudWatch Logs. All other lambda configurations not listed in the steps above can be left as the defaults. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.37503,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda for sending CloudWatch <em>logs</em>",
        "sections": "<em>Install</em> and configure the Cloudwatch <em>logs</em> Lambda function",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your CloudWatch <em>logs</em> to <em>New</em> <em>Relic</em> using our AWS Lambda function, newrelic-<em>log</em>-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch <em>logs</em> Lambda function, you only need a <em>New</em> <em>Relic</em> license key. Install and configure"
      },
      "id": "603ea6bb28ccbc228deba74c"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.8109,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.0183,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "AWS Lambda for sending CloudWatch logs",
        "Requirements",
        "Install and configure the Cloudwatch logs Lambda function",
        "Tip",
        "Create a Lambda trigger",
        "Configure retries (optional)",
        "Resources created by the SAM template",
        "View log data",
        "What's next?"
      ],
      "title": "AWS Lambda for sending CloudWatch logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "7e097c6c48cd7e02d55ed7ce2c63982ba003b1d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs/",
      "published_at": "2021-05-05T17:48:20Z",
      "updated_at": "2021-04-16T03:34:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your CloudWatch logs to New Relic using our AWS Lambda function, newrelic-log-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch logs Lambda function, you only need a New Relic license key. Install and configure the Cloudwatch logs Lambda function Tip The following setup shows one approach to configuring environment variables. You can also configure them from the Functions page. Complete the following: Open the AWS Serverless Application Repository in your browser. Search for newrelic and check Show apps that create custom IAM roles or resource policies to find newrelic-log-ingestion. Open the newrelic-log-ingestion details and click Deploy. Scroll to the Application settings and configure log forwarding using the following environment variables: Key Description Value DEBUG_LOGGING_ENABLED A boolean to determine if you want to output debug messages in the CloudWatch console. Optional. To turn on debug logs, set this to true. By default, it is false. LICENSE_KEY New Relic License key is used for sending data to New Relic Infrastructure and Logs. Required. Your New Relic license key. LOGGING_ENABLED Determines if logs are forwarded to New Relic. Required. To turn on logging, set this to true. NR_LOGGING_ENDPOINT New Relic ingestion endpoint for Logs. Required. Two endpoints are available: US: https://log-api.newrelic.com/log/v1 EU: https://log-api.eu.newrelic.com/log/v1 NR_TAGS Specify tags to be added to all log events. Optional. Each tag is composed of a colon delimited key and value. Multiple key-value pairs are semi-colon delimited, for example, env:prod;team:myTeam Acknowledge that the app creates custom IAM roles and then click Deploy. Once the process completes, follow the steps below in Create a Lambda trigger to link your Lambda function to CloudWatch Logs. Create a Lambda trigger To get your logs streaming to New Relic you will need to attach a trigger to the Lambda: From the left side menu, select Functions. Find and select the previously created newrelic-log-ingestion function. Under Designer, click Add Triggers, and select Cloudwatch Logs from the dropdown. Select the the appropriate Log group for your application. Enter a name for your filter. Optional: Enter a filter pattern. Check the Enable trigger checkbox, then click Add to create the trigger. Configure retries (optional) You can configure the number of retries you want to perform in case the function fails to send the data in case of communication issues. Recommended number is 3 retries, but you can change the retry behavior by changing the below parameters: Tip Be aware that more number of retries can make the function run for longer time and therefore increases the probability of having higher costs for Lambda. On the contrary, decreasing the number of retries could increase the probability of data loss. MAX_RETRIES = 3 # Defines the number of retries after lambda failure to deliver data INITIAL_BACKOFF = 1 # Defines the initial wait seconds until next retry is executed BACKOFF_MULTIPLIER = 2 # Time multiplier between the retries As an example, in default above configuration, first retry will happen after 1 second, second retry after 2 seconds and third retry will happen after 4 seconds. Copy Resources created by the SAM template There are few resources that will be created when you create the application from the repository: The Lambda function itself A Role used to give execution permissions to the Lambda function based in CloudWatch Logs. All other lambda configurations not listed in the steps above can be left as the defaults. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda for sending CloudWatch <em>logs</em>",
        "sections": "<em>Install</em> and configure the Cloudwatch <em>logs</em> Lambda function",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your CloudWatch <em>logs</em> to <em>New</em> <em>Relic</em> using our AWS Lambda function, newrelic-<em>log</em>-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch <em>logs</em> Lambda function, you only need a <em>New</em> <em>Relic</em> license key. Install and configure"
      },
      "id": "603ea6bb28ccbc228deba74c"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.8109,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.0183,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "AWS Lambda for sending CloudWatch logs",
        "Requirements",
        "Install and configure the Cloudwatch logs Lambda function",
        "Tip",
        "Create a Lambda trigger",
        "Configure retries (optional)",
        "Resources created by the SAM template",
        "View log data",
        "What's next?"
      ],
      "title": "AWS Lambda for sending CloudWatch logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "7e097c6c48cd7e02d55ed7ce2c63982ba003b1d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs/",
      "published_at": "2021-05-05T17:48:20Z",
      "updated_at": "2021-04-16T03:34:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your CloudWatch logs to New Relic using our AWS Lambda function, newrelic-log-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch logs Lambda function, you only need a New Relic license key. Install and configure the Cloudwatch logs Lambda function Tip The following setup shows one approach to configuring environment variables. You can also configure them from the Functions page. Complete the following: Open the AWS Serverless Application Repository in your browser. Search for newrelic and check Show apps that create custom IAM roles or resource policies to find newrelic-log-ingestion. Open the newrelic-log-ingestion details and click Deploy. Scroll to the Application settings and configure log forwarding using the following environment variables: Key Description Value DEBUG_LOGGING_ENABLED A boolean to determine if you want to output debug messages in the CloudWatch console. Optional. To turn on debug logs, set this to true. By default, it is false. LICENSE_KEY New Relic License key is used for sending data to New Relic Infrastructure and Logs. Required. Your New Relic license key. LOGGING_ENABLED Determines if logs are forwarded to New Relic. Required. To turn on logging, set this to true. NR_LOGGING_ENDPOINT New Relic ingestion endpoint for Logs. Required. Two endpoints are available: US: https://log-api.newrelic.com/log/v1 EU: https://log-api.eu.newrelic.com/log/v1 NR_TAGS Specify tags to be added to all log events. Optional. Each tag is composed of a colon delimited key and value. Multiple key-value pairs are semi-colon delimited, for example, env:prod;team:myTeam Acknowledge that the app creates custom IAM roles and then click Deploy. Once the process completes, follow the steps below in Create a Lambda trigger to link your Lambda function to CloudWatch Logs. Create a Lambda trigger To get your logs streaming to New Relic you will need to attach a trigger to the Lambda: From the left side menu, select Functions. Find and select the previously created newrelic-log-ingestion function. Under Designer, click Add Triggers, and select Cloudwatch Logs from the dropdown. Select the the appropriate Log group for your application. Enter a name for your filter. Optional: Enter a filter pattern. Check the Enable trigger checkbox, then click Add to create the trigger. Configure retries (optional) You can configure the number of retries you want to perform in case the function fails to send the data in case of communication issues. Recommended number is 3 retries, but you can change the retry behavior by changing the below parameters: Tip Be aware that more number of retries can make the function run for longer time and therefore increases the probability of having higher costs for Lambda. On the contrary, decreasing the number of retries could increase the probability of data loss. MAX_RETRIES = 3 # Defines the number of retries after lambda failure to deliver data INITIAL_BACKOFF = 1 # Defines the initial wait seconds until next retry is executed BACKOFF_MULTIPLIER = 2 # Time multiplier between the retries As an example, in default above configuration, first retry will happen after 1 second, second retry after 2 seconds and third retry will happen after 4 seconds. Copy Resources created by the SAM template There are few resources that will be created when you create the application from the repository: The Lambda function itself A Role used to give execution permissions to the Lambda function based in CloudWatch Logs. All other lambda configurations not listed in the steps above can be left as the defaults. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda for sending CloudWatch <em>logs</em>",
        "sections": "<em>Install</em> and configure the Cloudwatch <em>logs</em> Lambda function",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your CloudWatch <em>logs</em> to <em>New</em> <em>Relic</em> using our AWS Lambda function, newrelic-<em>log</em>-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch <em>logs</em> Lambda function, you only need a <em>New</em> <em>Relic</em> license key. Install and configure"
      },
      "id": "603ea6bb28ccbc228deba74c"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.81073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.01822,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "AWS Lambda for sending CloudWatch logs",
        "Requirements",
        "Install and configure the Cloudwatch logs Lambda function",
        "Tip",
        "Create a Lambda trigger",
        "Configure retries (optional)",
        "Resources created by the SAM template",
        "View log data",
        "What's next?"
      ],
      "title": "AWS Lambda for sending CloudWatch logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "7e097c6c48cd7e02d55ed7ce2c63982ba003b1d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs/",
      "published_at": "2021-05-05T17:48:20Z",
      "updated_at": "2021-04-16T03:34:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your CloudWatch logs to New Relic using our AWS Lambda function, newrelic-log-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch logs Lambda function, you only need a New Relic license key. Install and configure the Cloudwatch logs Lambda function Tip The following setup shows one approach to configuring environment variables. You can also configure them from the Functions page. Complete the following: Open the AWS Serverless Application Repository in your browser. Search for newrelic and check Show apps that create custom IAM roles or resource policies to find newrelic-log-ingestion. Open the newrelic-log-ingestion details and click Deploy. Scroll to the Application settings and configure log forwarding using the following environment variables: Key Description Value DEBUG_LOGGING_ENABLED A boolean to determine if you want to output debug messages in the CloudWatch console. Optional. To turn on debug logs, set this to true. By default, it is false. LICENSE_KEY New Relic License key is used for sending data to New Relic Infrastructure and Logs. Required. Your New Relic license key. LOGGING_ENABLED Determines if logs are forwarded to New Relic. Required. To turn on logging, set this to true. NR_LOGGING_ENDPOINT New Relic ingestion endpoint for Logs. Required. Two endpoints are available: US: https://log-api.newrelic.com/log/v1 EU: https://log-api.eu.newrelic.com/log/v1 NR_TAGS Specify tags to be added to all log events. Optional. Each tag is composed of a colon delimited key and value. Multiple key-value pairs are semi-colon delimited, for example, env:prod;team:myTeam Acknowledge that the app creates custom IAM roles and then click Deploy. Once the process completes, follow the steps below in Create a Lambda trigger to link your Lambda function to CloudWatch Logs. Create a Lambda trigger To get your logs streaming to New Relic you will need to attach a trigger to the Lambda: From the left side menu, select Functions. Find and select the previously created newrelic-log-ingestion function. Under Designer, click Add Triggers, and select Cloudwatch Logs from the dropdown. Select the the appropriate Log group for your application. Enter a name for your filter. Optional: Enter a filter pattern. Check the Enable trigger checkbox, then click Add to create the trigger. Configure retries (optional) You can configure the number of retries you want to perform in case the function fails to send the data in case of communication issues. Recommended number is 3 retries, but you can change the retry behavior by changing the below parameters: Tip Be aware that more number of retries can make the function run for longer time and therefore increases the probability of having higher costs for Lambda. On the contrary, decreasing the number of retries could increase the probability of data loss. MAX_RETRIES = 3 # Defines the number of retries after lambda failure to deliver data INITIAL_BACKOFF = 1 # Defines the initial wait seconds until next retry is executed BACKOFF_MULTIPLIER = 2 # Time multiplier between the retries As an example, in default above configuration, first retry will happen after 1 second, second retry after 2 seconds and third retry will happen after 4 seconds. Copy Resources created by the SAM template There are few resources that will be created when you create the application from the repository: The Lambda function itself A Role used to give execution permissions to the Lambda function based in CloudWatch Logs. All other lambda configurations not listed in the steps above can be left as the defaults. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.37497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda for sending CloudWatch <em>logs</em>",
        "sections": "<em>Install</em> and configure the Cloudwatch <em>logs</em> Lambda function",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your CloudWatch <em>logs</em> to <em>New</em> <em>Relic</em> using our AWS Lambda function, newrelic-<em>log</em>-ingestion, which can be easily deployed from the AWS Serverless application repository. Requirements To use our CloudWatch <em>logs</em> Lambda function, you only need a <em>New</em> <em>Relic</em> license key. Install and configure"
      },
      "id": "603ea6bb28ccbc228deba74c"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-agent-apis/annotate-logs-logs-context-using-apm-agent-apis": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.23659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring <em>agent</em>. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.92291,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure <em>with</em> <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>with</em> <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the Java <em>agent</em>. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.38658,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert <em>API</em> Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-go/configure-logs-context-go": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.25844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.47885,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>New</em> <em>Relic</em> offers a <em>Log</em>4j 1.x extension for <em>New</em> <em>Relic</em> <em>log</em> <em>management</em>, allowing you link to your <em>log</em> data with related data across the rest of the <em>New</em> <em>Relic</em> platform. This document explains how to configure <em>logs</em> in <em>context</em> and start getting <em>log</em> data. The code and an example application are available"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.79199,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-java/configure-logs-context-java": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.42752,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Logback",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Logback extension",
        "Important",
        "Example configuration files",
        "Single console appender example",
        "Two-appender example",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Logback",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "d43c55efa817768e3840897678b966f896fd268d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback/",
      "published_at": "2021-05-06T03:34:12Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Logback extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Logback, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update Logback 1.2.0 or higher installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Logback: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Logback extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Logback extension To configure logs in context with the Logback extension, complete the following steps: Update your project's dependencies to include the Logback extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing < encoder> element as shown below. If you are logging to the console (stdout/stderr), look for ConsoleAppender and replace : <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you are logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Important It's important that the NewRelicAsyncAppender be the first appender to see the log message. List any other appenders after the NewRelicAsyncAppender in the <root> list. Example configuration files You can find a working example in GitHub. Here are examples of an updated logging .xml file for the Logback extension. Single console appender example Example configuration file after adding in the logging extension information. <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two-appender example This example sends New Relic logging to a file, but still sends standard logging to the console. <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Logback</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Logback: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Logback extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em>"
      },
      "id": "603ead8a196a679235a83d96"
    },
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-dropwizard": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.42752,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Logback",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Logback extension",
        "Important",
        "Example configuration files",
        "Single console appender example",
        "Two-appender example",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Logback",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "d43c55efa817768e3840897678b966f896fd268d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback/",
      "published_at": "2021-05-06T03:34:12Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Logback extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Logback, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update Logback 1.2.0 or higher installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Logback: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Logback extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Logback extension To configure logs in context with the Logback extension, complete the following steps: Update your project's dependencies to include the Logback extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing < encoder> element as shown below. If you are logging to the console (stdout/stderr), look for ConsoleAppender and replace : <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you are logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Important It's important that the NewRelicAsyncAppender be the first appender to see the log message. List any other appenders after the NewRelicAsyncAppender in the <root> list. Example configuration files You can find a working example in GitHub. Here are examples of an updated logging .xml file for the Logback extension. Single console appender example Example configuration file after adding in the logging extension information. <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two-appender example This example sends New Relic logging to a file, but still sends standard logging to the console. <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Logback</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Logback: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Logback extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em>"
      },
      "id": "603ead8a196a679235a83d96"
    },
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-javautillogging": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.4275,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Logback",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Logback extension",
        "Important",
        "Example configuration files",
        "Single console appender example",
        "Two-appender example",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Logback",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "d43c55efa817768e3840897678b966f896fd268d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback/",
      "published_at": "2021-05-06T03:34:12Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Logback extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Logback, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update Logback 1.2.0 or higher installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Logback: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Logback extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Logback extension To configure logs in context with the Logback extension, complete the following steps: Update your project's dependencies to include the Logback extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing < encoder> element as shown below. If you are logging to the console (stdout/stderr), look for ConsoleAppender and replace : <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you are logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Important It's important that the NewRelicAsyncAppender be the first appender to see the log message. List any other appenders after the NewRelicAsyncAppender in the <root> list. Example configuration files You can find a working example in GitHub. Here are examples of an updated logging .xml file for the Logback extension. Single console appender example Example configuration file after adding in the logging extension information. <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two-appender example This example sends New Relic logging to a file, but still sends standard logging to the console. <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Logback</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Logback: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Logback extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em>"
      },
      "id": "603ead8a196a679235a83d96"
    },
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x": [
    {
      "sections": [
        "Java: Configure with Logback",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Logback extension",
        "Important",
        "Example configuration files",
        "Single console appender example",
        "Two-appender example",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Logback",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "d43c55efa817768e3840897678b966f896fd268d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback/",
      "published_at": "2021-05-06T03:34:12Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Logback extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Logback, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update Logback 1.2.0 or higher installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Logback: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Logback extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Logback extension To configure logs in context with the Logback extension, complete the following steps: Update your project's dependencies to include the Logback extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing < encoder> element as shown below. If you are logging to the console (stdout/stderr), look for ConsoleAppender and replace : <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you are logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Important It's important that the NewRelicAsyncAppender be the first appender to see the log message. List any other appenders after the NewRelicAsyncAppender in the <root> list. Example configuration files You can find a working example in GitHub. Here are examples of an updated logging .xml file for the Logback extension. Single console appender example Example configuration file after adding in the logging extension information. <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two-appender example This example sends New Relic logging to a file, but still sends standard logging to the console. <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Logback</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Logback: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Logback extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em>"
      },
      "id": "603ead8a196a679235a83d96"
    },
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    },
    {
      "sections": [
        "Java: Configure with Dropwizard",
        "Compatibility and requirements",
        "Configure logs in context with New Relic Logs",
        "Enable log monitoring",
        "Install or update the Java agent",
        "Configure the Dropwizard extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Dropwizard",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "700d46a4ac4cc727bd5b5dfc41a73ea30167ef56",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-dropwizard/",
      "published_at": "2021-05-06T03:35:09Z",
      "updated_at": "2021-03-16T09:21:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Dropwizard extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Dropwizard 1.3, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Dropwizard 1.3 package installed and working on the application, with the original Dropwizard appenders and logging factory. Configure logs in context with New Relic Logs To configure logs in context with Dropwizard: Enable log monitoring with a compatible log forwarding plugin. Install or update the Java agent. Configure the Dropwizard extension. Check for logging data. Enable log monitoring Confirm that you have log monitoring enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Dropwizard extension To configure logs in context with the Dropwizard 1.3 extension, complete the following steps: Update your project's dependencies to include the Dropwizard 1.3 extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:dropwizard:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>dropwizard</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your Dropwizard .yaml configuration file with a newrelic-json layout, replacing the currently used type: console or type: file with either type: newrelic-console or type: newrelic-file as appropriate. For example: logging: appenders: - type: newrelic-console # Add the two lines below if you don't have a layout specified on the appender. # If you have a layout, remove all parameters to the layout and set the type. layout: type: newrelic-json Copy Alternatively, the New Relic Dropwizard extension also supports a log-format layout type that uses the standard Dropwizard logging. For testing purposes, you can change the type of the layout with a one-line change logging: appenders: - type: newrelic-file # This format will be ignored by the newrelic-json layout, but used by the log-format layout. logFormat: \"%date{ISO8601} %c %-5p: %m trace.id=%mdc{trace.id} span.id=%mdc{span.id}%n\" layout: # type: newrelic-json type: log-format Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with Dropwizard",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application, with the original Dropwizard appenders and logging factory. Configure <em>logs</em> in <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em> To configure <em>logs</em> in <em>context</em> with Dropwizard: <em>Enable</em> <em>log</em> monitoring with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Dropwizard extension. Check"
      },
      "id": "603eadcb28ccbcdb1deba797"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.42746,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Logback",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Logback extension",
        "Important",
        "Example configuration files",
        "Single console appender example",
        "Two-appender example",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Logback",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "d43c55efa817768e3840897678b966f896fd268d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback/",
      "published_at": "2021-05-06T03:34:12Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Logback extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Logback, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update Logback 1.2.0 or higher installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Logback: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Logback extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Logback extension To configure logs in context with the Logback extension, complete the following steps: Update your project's dependencies to include the Logback extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing < encoder> element as shown below. If you are logging to the console (stdout/stderr), look for ConsoleAppender and replace : <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you are logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Important It's important that the NewRelicAsyncAppender be the first appender to see the log message. List any other appenders after the NewRelicAsyncAppender in the <root> list. Example configuration files You can find a working example in GitHub. Here are examples of an updated logging .xml file for the Logback extension. Single console appender example Example configuration file after adding in the logging extension information. <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two-appender example This example sends New Relic logging to a file, but still sends standard logging to the console. <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Logback</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Logback: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Logback extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em>"
      },
      "id": "603ead8a196a679235a83d96"
    },
    {
      "sections": [
        "Java: Configure with Dropwizard",
        "Compatibility and requirements",
        "Configure logs in context with New Relic Logs",
        "Enable log monitoring",
        "Install or update the Java agent",
        "Configure the Dropwizard extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Dropwizard",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "700d46a4ac4cc727bd5b5dfc41a73ea30167ef56",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-dropwizard/",
      "published_at": "2021-05-06T03:35:09Z",
      "updated_at": "2021-03-16T09:21:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Dropwizard extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Dropwizard 1.3, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Dropwizard 1.3 package installed and working on the application, with the original Dropwizard appenders and logging factory. Configure logs in context with New Relic Logs To configure logs in context with Dropwizard: Enable log monitoring with a compatible log forwarding plugin. Install or update the Java agent. Configure the Dropwizard extension. Check for logging data. Enable log monitoring Confirm that you have log monitoring enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Dropwizard extension To configure logs in context with the Dropwizard 1.3 extension, complete the following steps: Update your project's dependencies to include the Dropwizard 1.3 extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:dropwizard:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>dropwizard</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your Dropwizard .yaml configuration file with a newrelic-json layout, replacing the currently used type: console or type: file with either type: newrelic-console or type: newrelic-file as appropriate. For example: logging: appenders: - type: newrelic-console # Add the two lines below if you don't have a layout specified on the appender. # If you have a layout, remove all parameters to the layout and set the type. layout: type: newrelic-json Copy Alternatively, the New Relic Dropwizard extension also supports a log-format layout type that uses the standard Dropwizard logging. For testing purposes, you can change the type of the layout with a one-line change logging: appenders: - type: newrelic-file # This format will be ignored by the newrelic-json layout, but used by the log-format layout. logFormat: \"%date{ISO8601} %c %-5p: %m trace.id=%mdc{trace.id} span.id=%mdc{span.id}%n\" layout: # type: newrelic-json type: log-format Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with Dropwizard",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application, with the original Dropwizard appenders and logging factory. Configure <em>logs</em> in <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em> To configure <em>logs</em> in <em>context</em> with Dropwizard: <em>Enable</em> <em>log</em> monitoring with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Dropwizard extension. Check"
      },
      "id": "603eadcb28ccbcdb1deba797"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.42746,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    },
    {
      "sections": [
        "Java: Configure with Dropwizard",
        "Compatibility and requirements",
        "Configure logs in context with New Relic Logs",
        "Enable log monitoring",
        "Install or update the Java agent",
        "Configure the Dropwizard extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Dropwizard",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "700d46a4ac4cc727bd5b5dfc41a73ea30167ef56",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-dropwizard/",
      "published_at": "2021-05-06T03:35:09Z",
      "updated_at": "2021-03-16T09:21:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Dropwizard extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Dropwizard 1.3, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Dropwizard 1.3 package installed and working on the application, with the original Dropwizard appenders and logging factory. Configure logs in context with New Relic Logs To configure logs in context with Dropwizard: Enable log monitoring with a compatible log forwarding plugin. Install or update the Java agent. Configure the Dropwizard extension. Check for logging data. Enable log monitoring Confirm that you have log monitoring enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Dropwizard extension To configure logs in context with the Dropwizard 1.3 extension, complete the following steps: Update your project's dependencies to include the Dropwizard 1.3 extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:dropwizard:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>dropwizard</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your Dropwizard .yaml configuration file with a newrelic-json layout, replacing the currently used type: console or type: file with either type: newrelic-console or type: newrelic-file as appropriate. For example: logging: appenders: - type: newrelic-console # Add the two lines below if you don't have a layout specified on the appender. # If you have a layout, remove all parameters to the layout and set the type. layout: type: newrelic-json Copy Alternatively, the New Relic Dropwizard extension also supports a log-format layout type that uses the standard Dropwizard logging. For testing purposes, you can change the type of the layout with a one-line change logging: appenders: - type: newrelic-file # This format will be ignored by the newrelic-json layout, but used by the log-format layout. logFormat: \"%date{ISO8601} %c %-5p: %m trace.id=%mdc{trace.id} span.id=%mdc{span.id}%n\" layout: # type: newrelic-json type: log-format Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with Dropwizard",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application, with the original Dropwizard appenders and logging factory. Configure <em>logs</em> in <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em> To configure <em>logs</em> in <em>context</em> with Dropwizard: <em>Enable</em> <em>log</em> monitoring with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Dropwizard extension. Check"
      },
      "id": "603eadcb28ccbcdb1deba797"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-spring-spring-boot": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.42743,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Logback",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Logback extension",
        "Important",
        "Example configuration files",
        "Single console appender example",
        "Two-appender example",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Logback",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "d43c55efa817768e3840897678b966f896fd268d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback/",
      "published_at": "2021-05-06T03:34:12Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Logback extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Logback, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update Logback 1.2.0 or higher installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Logback: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Logback extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Logback extension To configure logs in context with the Logback extension, complete the following steps: Update your project's dependencies to include the Logback extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing < encoder> element as shown below. If you are logging to the console (stdout/stderr), look for ConsoleAppender and replace : <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you are logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Important It's important that the NewRelicAsyncAppender be the first appender to see the log message. List any other appenders after the NewRelicAsyncAppender in the <root> list. Example configuration files You can find a working example in GitHub. Here are examples of an updated logging .xml file for the Logback extension. Single console appender example Example configuration file after adding in the logging extension information. <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two-appender example This example sends New Relic logging to a file, but still sends standard logging to the console. <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Logback</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Logback: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Logback extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em>"
      },
      "id": "603ead8a196a679235a83d96"
    },
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-net/configure-logs-context-net": [
    {
      "sections": [
        ".NET: Configure with Serilog",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the .NET agent",
        "Configure the Serilog extension",
        "Caution",
        "Important",
        "File-based configuration",
        "appsettings.json based configuration",
        ".Config based configuration",
        "What's next?"
      ],
      "title": ".NET: Configure with Serilog",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "f3d5ac2ad158b199811541f699cb3c1a8139aa3b",
      "image": "https://docs.newrelic.com/static/783ba8b8cb8b25e4c8ee8aecf0464395/29d31/LogsInContext---Serilog-%25282%2529_0.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-serilog/",
      "published_at": "2021-05-06T04:22:43Z",
      "updated_at": "2021-03-13T03:17:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with Serilog, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Serilog 2.5+ Serilog File Sinks v4.0+ Overview Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events, while Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. This diagram illustrates the flow of log messages through Serilog. This diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. The above diagram highlights several components of the Serilog extension: New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the Log Forwarder expects. New Relic Log Forwarder: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. The example below uses the New Relic Fluentd log forwarded, however there are many other log forwarders that can be used. For more information, see Introduction to log management. For more information about Serilog log events, see the Serilog Getting started documentation. Configure logs in context with log management To configure New Relic logs in context with Serilog: Enable log management with a compatible log forwarding plugin. Install or update the .NET agent. Configure the Serilog extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the Serilog extension To configure logs in context with the Serilog extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the Log Forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy Caution The above configuration results in new JSON files that are written to disk. Some of these configuration options may be useful in managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Important Though not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic Logs. See below for an example of this configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy File-based configuration Configuration of the New Relic Logs Serilog extension may also be accomplished with file-based configuration providers. appsettings.json based configuration The example code below creates a logger based on settings contained in an appSettings.json file. Important The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration Instantiating Logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy .Config based configuration The example code below creates a logger based on settings contained in an web.config file. Important The Serilog.Settings.AppSettings NuGet Package is required. Instantiating Logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.96457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with Serilog",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " documentation. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Serilog: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the .<em>NET</em> agent. Configure the Serilog extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm"
      },
      "id": "60450d33e7b9d2773f5799c7"
    },
    {
      "sections": [
        ".NET: Configure with NLog",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the .NET agent",
        "Configure the NLog extension",
        "Caution",
        "Important",
        "File-based configuration",
        ".Config based configuration",
        "What's next?"
      ],
      "title": ".NET: Configure with NLog",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "4320e73b1b248d30e66c1e4ce701a733256cc19d",
      "image": "https://docs.newrelic.com/static/82029cf4cbc1cf0a2eb07844326dd8bb/29d31/LogsInContext---NLog.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-nlog/",
      "published_at": "2021-05-06T04:23:25Z",
      "updated_at": "2021-03-13T01:59:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our NLog extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with NLog, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ NLog 4.5+ Overview NLog works by having Layouts (which guide what data is added to log events and in what format) and Targets (which control where logging data is sent.) The New Relic NLog extension provides a NewRelicJsonLayout which formats a log event in the way required by the New Relic logging endpoint, and adds contextual information from the .NET agent when attached to your application. A target can then be configured to write logging data to an output folder, which can be monitored by a log forwarder to incrementally send log information to New Relic. This diagram illustrates the flow of log messages through NLog: This diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. The above diagram highlights the main components of the NLog Logs-in-Context solution: New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. File Target: A FileTarget defines a file on disk where log messages will be written. Adding the NewRelicJsonLayout to that target will cause the output to be formatted correctly for forwarding to New Relic. New Relic Log Forwarder: The log forwarder is configured to send the log data from the FileTarget's output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information, see Introduction to log management. For more information about logging with NLog, see the NLog Getting started documentation. Configure logs in context with log management To configure logs in context with NLog: Enable log management with a compatible log forwarding plugin. Install or update the .NET agent. Configure the NLog extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the NLog extension To configure logs in context with the NLog extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the Log Forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Caution The above configuration results in new JSON files that are written to disk. Some of these configuration options may be useful in managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Important Though not required, using the NLog AsyncWrapper Target may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. See below for an example of this configuration using the Fluentd plugin for New Relic's log management: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy File-based configuration Configuration of the New Relic NLog extension may also be accomplished with file based configuration providers. .Config based configuration The example code below creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.9314,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with NLog",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " plugin. Install or update the .<em>NET</em> agent. Configure the NLog extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update the .<em>NET</em> agent Install"
      },
      "id": "60450d32196a67923c960f6f"
    },
    {
      "sections": [
        ".NET: Configure with log4net",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with New Relic Logs",
        "Enable New Relic Logs",
        "Install or update the .NET agent",
        "Configure the log4net extension",
        "What's next?"
      ],
      "title": ".NET: Configure with log4net",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "ccffdaabc7111e7bd5a13239e1d9c927d26a4bd1",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext---Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-log4net/",
      "published_at": "2021-05-06T02:45:39Z",
      "updated_at": "2021-03-13T01:10:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Apache log4net extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with log4net, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Log4net 2.0.8+ Overview Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders for specific use case log message handle. Log4net also provides NewRelicLayout to output log messages in the way required by the New Relic logging endpoint. A target can then be configured to write logging data to an output folder, which can be monitored by a log forwarder to incrementally send log information to New Relic. This diagram illustrates the flow of log messages through log4net: This diagram illustrates the flow of log messages through log4net, highlighting specific components of the New Relic log4net extension. The above diagram highlights the main components of the log4net logs in context solution: New Relic Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched Log Events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain and requires another appender that can write to an actual output destination as its child in order to work. New Relic Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted Log information to the New Relic Logging Endpoint. There are many log-forwarders available. For our examples, we will use Fluentd. For more information about logging with log4net, see the Apache log4net Getting started documentation. Configure logs in context with New Relic Logs To configure New Relic logs in context with Enable New Relic Logs with a compatible log forwarding plugin. Install or update the .NET agent. Configure the log4net extension. Check for logging data. Enable New Relic Logs Confirm that you have New Relic Logs enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the log4net extension To configure logs in context with the log4net extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. You also need to replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout . The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy Once you have configured the log4net extension and updated your logging file, you can configure your extension to send data to New Relic Logs. See below for an example of this configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.91055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with <em>log4net</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". There are many <em>log</em>-forwarders available. For our examples, we will use Fluentd. For more information about logging with <em>log4net</em>, see the Apache <em>log4net</em> Getting started documentation. Configure <em>logs</em> in <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>"
      },
      "id": "60450d7164441f0d80378f09"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-log4net": [
    {
      "sections": [
        "Configure logs in context for .NET",
        "Compatibility and requirements",
        "What's next?"
      ],
      "title": "Configure logs in context for .NET",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "777ae1eb11df98af5d4ed37061399ff4bca00889",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/configure-logs-context-net/",
      "published_at": "2021-05-05T03:57:03Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your Logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich log data. Compatibility and requirements To use New Relic Logs with the .NET agent, ensure your configuration meets the following requirements: Log management enabled, with a compatible log forwarding plugin installed New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Microsoft .NET Framework 4.5+ or .NET Core 2.0+ Configure logs in context for .NET Choose a extension to see specific instructions: log4net NLog Serilog What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.07367,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> .<em>NET</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> .<em>NET</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " with the .<em>NET</em> agent, ensure your configuration meets the following requirements: <em>Log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed <em>New</em> <em>Relic</em> .<em>NET</em> agent 8.21+ <em>New</em> <em>Relic</em> .<em>NET</em> agent API 8.21+ Microsoft .<em>NET</em> Framework 4.5+ or .<em>NET</em> Core 2.0+ Configure <em>logs</em> in <em>context</em> for .<em>NET</em>"
      },
      "id": "603e7f60196a67185ea83d81"
    },
    {
      "sections": [
        ".NET: Configure with Serilog",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the .NET agent",
        "Configure the Serilog extension",
        "Caution",
        "Important",
        "File-based configuration",
        "appsettings.json based configuration",
        ".Config based configuration",
        "What's next?"
      ],
      "title": ".NET: Configure with Serilog",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "f3d5ac2ad158b199811541f699cb3c1a8139aa3b",
      "image": "https://docs.newrelic.com/static/783ba8b8cb8b25e4c8ee8aecf0464395/29d31/LogsInContext---Serilog-%25282%2529_0.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-serilog/",
      "published_at": "2021-05-06T04:22:43Z",
      "updated_at": "2021-03-13T03:17:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with Serilog, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Serilog 2.5+ Serilog File Sinks v4.0+ Overview Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events, while Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. This diagram illustrates the flow of log messages through Serilog. This diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. The above diagram highlights several components of the Serilog extension: New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the Log Forwarder expects. New Relic Log Forwarder: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. The example below uses the New Relic Fluentd log forwarded, however there are many other log forwarders that can be used. For more information, see Introduction to log management. For more information about Serilog log events, see the Serilog Getting started documentation. Configure logs in context with log management To configure New Relic logs in context with Serilog: Enable log management with a compatible log forwarding plugin. Install or update the .NET agent. Configure the Serilog extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the Serilog extension To configure logs in context with the Serilog extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the Log Forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy Caution The above configuration results in new JSON files that are written to disk. Some of these configuration options may be useful in managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Important Though not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic Logs. See below for an example of this configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy File-based configuration Configuration of the New Relic Logs Serilog extension may also be accomplished with file-based configuration providers. appsettings.json based configuration The example code below creates a logger based on settings contained in an appSettings.json file. Important The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration Instantiating Logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy .Config based configuration The example code below creates a logger based on settings contained in an web.config file. Important The Serilog.Settings.AppSettings NuGet Package is required. Instantiating Logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.96457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with Serilog",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " documentation. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Serilog: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the .<em>NET</em> agent. Configure the Serilog extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm"
      },
      "id": "60450d33e7b9d2773f5799c7"
    },
    {
      "sections": [
        ".NET: Configure with NLog",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the .NET agent",
        "Configure the NLog extension",
        "Caution",
        "Important",
        "File-based configuration",
        ".Config based configuration",
        "What's next?"
      ],
      "title": ".NET: Configure with NLog",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "4320e73b1b248d30e66c1e4ce701a733256cc19d",
      "image": "https://docs.newrelic.com/static/82029cf4cbc1cf0a2eb07844326dd8bb/29d31/LogsInContext---NLog.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-nlog/",
      "published_at": "2021-05-06T04:23:25Z",
      "updated_at": "2021-03-13T01:59:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our NLog extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with NLog, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ NLog 4.5+ Overview NLog works by having Layouts (which guide what data is added to log events and in what format) and Targets (which control where logging data is sent.) The New Relic NLog extension provides a NewRelicJsonLayout which formats a log event in the way required by the New Relic logging endpoint, and adds contextual information from the .NET agent when attached to your application. A target can then be configured to write logging data to an output folder, which can be monitored by a log forwarder to incrementally send log information to New Relic. This diagram illustrates the flow of log messages through NLog: This diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. The above diagram highlights the main components of the NLog Logs-in-Context solution: New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. File Target: A FileTarget defines a file on disk where log messages will be written. Adding the NewRelicJsonLayout to that target will cause the output to be formatted correctly for forwarding to New Relic. New Relic Log Forwarder: The log forwarder is configured to send the log data from the FileTarget's output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information, see Introduction to log management. For more information about logging with NLog, see the NLog Getting started documentation. Configure logs in context with log management To configure logs in context with NLog: Enable log management with a compatible log forwarding plugin. Install or update the .NET agent. Configure the NLog extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the NLog extension To configure logs in context with the NLog extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the Log Forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Caution The above configuration results in new JSON files that are written to disk. Some of these configuration options may be useful in managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Important Though not required, using the NLog AsyncWrapper Target may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. See below for an example of this configuration using the Fluentd plugin for New Relic's log management: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy File-based configuration Configuration of the New Relic NLog extension may also be accomplished with file based configuration providers. .Config based configuration The example code below creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.9314,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with NLog",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " plugin. Install or update the .<em>NET</em> agent. Configure the NLog extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update the .<em>NET</em> agent Install"
      },
      "id": "60450d32196a67923c960f6f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-nlog": [
    {
      "sections": [
        "Configure logs in context for .NET",
        "Compatibility and requirements",
        "What's next?"
      ],
      "title": "Configure logs in context for .NET",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "777ae1eb11df98af5d4ed37061399ff4bca00889",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/configure-logs-context-net/",
      "published_at": "2021-05-05T03:57:03Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your Logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich log data. Compatibility and requirements To use New Relic Logs with the .NET agent, ensure your configuration meets the following requirements: Log management enabled, with a compatible log forwarding plugin installed New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Microsoft .NET Framework 4.5+ or .NET Core 2.0+ Configure logs in context for .NET Choose a extension to see specific instructions: log4net NLog Serilog What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.07367,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> .<em>NET</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> .<em>NET</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " with the .<em>NET</em> agent, ensure your configuration meets the following requirements: <em>Log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed <em>New</em> <em>Relic</em> .<em>NET</em> agent 8.21+ <em>New</em> <em>Relic</em> .<em>NET</em> agent API 8.21+ Microsoft .<em>NET</em> Framework 4.5+ or .<em>NET</em> Core 2.0+ Configure <em>logs</em> in <em>context</em> for .<em>NET</em>"
      },
      "id": "603e7f60196a67185ea83d81"
    },
    {
      "sections": [
        ".NET: Configure with Serilog",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the .NET agent",
        "Configure the Serilog extension",
        "Caution",
        "Important",
        "File-based configuration",
        "appsettings.json based configuration",
        ".Config based configuration",
        "What's next?"
      ],
      "title": ".NET: Configure with Serilog",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "f3d5ac2ad158b199811541f699cb3c1a8139aa3b",
      "image": "https://docs.newrelic.com/static/783ba8b8cb8b25e4c8ee8aecf0464395/29d31/LogsInContext---Serilog-%25282%2529_0.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-serilog/",
      "published_at": "2021-05-06T04:22:43Z",
      "updated_at": "2021-03-13T03:17:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with Serilog, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Serilog 2.5+ Serilog File Sinks v4.0+ Overview Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events, while Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. This diagram illustrates the flow of log messages through Serilog. This diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. The above diagram highlights several components of the Serilog extension: New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the Log Forwarder expects. New Relic Log Forwarder: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. The example below uses the New Relic Fluentd log forwarded, however there are many other log forwarders that can be used. For more information, see Introduction to log management. For more information about Serilog log events, see the Serilog Getting started documentation. Configure logs in context with log management To configure New Relic logs in context with Serilog: Enable log management with a compatible log forwarding plugin. Install or update the .NET agent. Configure the Serilog extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the Serilog extension To configure logs in context with the Serilog extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the Log Forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy Caution The above configuration results in new JSON files that are written to disk. Some of these configuration options may be useful in managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Important Though not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic Logs. See below for an example of this configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy File-based configuration Configuration of the New Relic Logs Serilog extension may also be accomplished with file-based configuration providers. appsettings.json based configuration The example code below creates a logger based on settings contained in an appSettings.json file. Important The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration Instantiating Logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy .Config based configuration The example code below creates a logger based on settings contained in an web.config file. Important The Serilog.Settings.AppSettings NuGet Package is required. Instantiating Logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.96454,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with Serilog",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " documentation. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Serilog: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the .<em>NET</em> agent. Configure the Serilog extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm"
      },
      "id": "60450d33e7b9d2773f5799c7"
    },
    {
      "sections": [
        ".NET: Configure with log4net",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with New Relic Logs",
        "Enable New Relic Logs",
        "Install or update the .NET agent",
        "Configure the log4net extension",
        "What's next?"
      ],
      "title": ".NET: Configure with log4net",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "ccffdaabc7111e7bd5a13239e1d9c927d26a4bd1",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext---Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-log4net/",
      "published_at": "2021-05-06T02:45:39Z",
      "updated_at": "2021-03-13T01:10:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Apache log4net extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with log4net, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Log4net 2.0.8+ Overview Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders for specific use case log message handle. Log4net also provides NewRelicLayout to output log messages in the way required by the New Relic logging endpoint. A target can then be configured to write logging data to an output folder, which can be monitored by a log forwarder to incrementally send log information to New Relic. This diagram illustrates the flow of log messages through log4net: This diagram illustrates the flow of log messages through log4net, highlighting specific components of the New Relic log4net extension. The above diagram highlights the main components of the log4net logs in context solution: New Relic Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched Log Events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain and requires another appender that can write to an actual output destination as its child in order to work. New Relic Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted Log information to the New Relic Logging Endpoint. There are many log-forwarders available. For our examples, we will use Fluentd. For more information about logging with log4net, see the Apache log4net Getting started documentation. Configure logs in context with New Relic Logs To configure New Relic logs in context with Enable New Relic Logs with a compatible log forwarding plugin. Install or update the .NET agent. Configure the log4net extension. Check for logging data. Enable New Relic Logs Confirm that you have New Relic Logs enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the log4net extension To configure logs in context with the log4net extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. You also need to replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout . The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy Once you have configured the log4net extension and updated your logging file, you can configure your extension to send data to New Relic Logs. See below for an example of this configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.91052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with <em>log4net</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". There are many <em>log</em>-forwarders available. For our examples, we will use Fluentd. For more information about logging with <em>log4net</em>, see the Apache <em>log4net</em> Getting started documentation. Configure <em>logs</em> in <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>"
      },
      "id": "60450d7164441f0d80378f09"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-serilog": [
    {
      "sections": [
        "Configure logs in context for .NET",
        "Compatibility and requirements",
        "What's next?"
      ],
      "title": "Configure logs in context for .NET",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "777ae1eb11df98af5d4ed37061399ff4bca00889",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/configure-logs-context-net/",
      "published_at": "2021-05-05T03:57:03Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your Logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich log data. Compatibility and requirements To use New Relic Logs with the .NET agent, ensure your configuration meets the following requirements: Log management enabled, with a compatible log forwarding plugin installed New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Microsoft .NET Framework 4.5+ or .NET Core 2.0+ Configure logs in context for .NET Choose a extension to see specific instructions: log4net NLog Serilog What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.07367,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> .<em>NET</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> .<em>NET</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " with the .<em>NET</em> agent, ensure your configuration meets the following requirements: <em>Log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed <em>New</em> <em>Relic</em> .<em>NET</em> agent 8.21+ <em>New</em> <em>Relic</em> .<em>NET</em> agent API 8.21+ Microsoft .<em>NET</em> Framework 4.5+ or .<em>NET</em> Core 2.0+ Configure <em>logs</em> in <em>context</em> for .<em>NET</em>"
      },
      "id": "603e7f60196a67185ea83d81"
    },
    {
      "sections": [
        ".NET: Configure with NLog",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the .NET agent",
        "Configure the NLog extension",
        "Caution",
        "Important",
        "File-based configuration",
        ".Config based configuration",
        "What's next?"
      ],
      "title": ".NET: Configure with NLog",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "4320e73b1b248d30e66c1e4ce701a733256cc19d",
      "image": "https://docs.newrelic.com/static/82029cf4cbc1cf0a2eb07844326dd8bb/29d31/LogsInContext---NLog.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-nlog/",
      "published_at": "2021-05-06T04:23:25Z",
      "updated_at": "2021-03-13T01:59:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our NLog extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with NLog, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ NLog 4.5+ Overview NLog works by having Layouts (which guide what data is added to log events and in what format) and Targets (which control where logging data is sent.) The New Relic NLog extension provides a NewRelicJsonLayout which formats a log event in the way required by the New Relic logging endpoint, and adds contextual information from the .NET agent when attached to your application. A target can then be configured to write logging data to an output folder, which can be monitored by a log forwarder to incrementally send log information to New Relic. This diagram illustrates the flow of log messages through NLog: This diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. The above diagram highlights the main components of the NLog Logs-in-Context solution: New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. File Target: A FileTarget defines a file on disk where log messages will be written. Adding the NewRelicJsonLayout to that target will cause the output to be formatted correctly for forwarding to New Relic. New Relic Log Forwarder: The log forwarder is configured to send the log data from the FileTarget's output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information, see Introduction to log management. For more information about logging with NLog, see the NLog Getting started documentation. Configure logs in context with log management To configure logs in context with NLog: Enable log management with a compatible log forwarding plugin. Install or update the .NET agent. Configure the NLog extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the NLog extension To configure logs in context with the NLog extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the Log Forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Caution The above configuration results in new JSON files that are written to disk. Some of these configuration options may be useful in managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Important Though not required, using the NLog AsyncWrapper Target may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. See below for an example of this configuration using the Fluentd plugin for New Relic's log management: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy File-based configuration Configuration of the New Relic NLog extension may also be accomplished with file based configuration providers. .Config based configuration The example code below creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.93137,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with NLog",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " plugin. Install or update the .<em>NET</em> agent. Configure the NLog extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update the .<em>NET</em> agent Install"
      },
      "id": "60450d32196a67923c960f6f"
    },
    {
      "sections": [
        ".NET: Configure with log4net",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with New Relic Logs",
        "Enable New Relic Logs",
        "Install or update the .NET agent",
        "Configure the log4net extension",
        "What's next?"
      ],
      "title": ".NET: Configure with log4net",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "ccffdaabc7111e7bd5a13239e1d9c927d26a4bd1",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext---Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-log4net/",
      "published_at": "2021-05-06T02:45:39Z",
      "updated_at": "2021-03-13T01:10:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Apache log4net extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with log4net, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Log4net 2.0.8+ Overview Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders for specific use case log message handle. Log4net also provides NewRelicLayout to output log messages in the way required by the New Relic logging endpoint. A target can then be configured to write logging data to an output folder, which can be monitored by a log forwarder to incrementally send log information to New Relic. This diagram illustrates the flow of log messages through log4net: This diagram illustrates the flow of log messages through log4net, highlighting specific components of the New Relic log4net extension. The above diagram highlights the main components of the log4net logs in context solution: New Relic Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched Log Events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain and requires another appender that can write to an actual output destination as its child in order to work. New Relic Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted Log information to the New Relic Logging Endpoint. There are many log-forwarders available. For our examples, we will use Fluentd. For more information about logging with log4net, see the Apache log4net Getting started documentation. Configure logs in context with New Relic Logs To configure New Relic logs in context with Enable New Relic Logs with a compatible log forwarding plugin. Install or update the .NET agent. Configure the log4net extension. Check for logging data. Enable New Relic Logs Confirm that you have New Relic Logs enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the log4net extension To configure logs in context with the log4net extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. You also need to replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout . The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy Once you have configured the log4net extension and updated your logging file, you can configure your extension to send data to New Relic Logs. See below for an example of this configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.91052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with <em>log4net</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". There are many <em>log</em>-forwarders available. For our examples, we will use Fluentd. For more information about logging with <em>log4net</em>, see the Apache <em>log4net</em> Getting started documentation. Configure <em>logs</em> in <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>"
      },
      "id": "60450d7164441f0d80378f09"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-nodejs/configure-logs-context-nodejs": [
    {
      "sections": [
        "Node.js: Configure with Winston",
        "Compatibility and requirements",
        "Configure logs in context with log monitoring",
        "Enable log monitoring",
        "Install or update the Node.js agent",
        "Configure the Winston extension",
        "Check for logging data",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Node.js: Configure with Winston",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Node.js"
      ],
      "external_id": "0ed58684c33d758f2bdc599295fa356d9418702e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-nodejs/nodejs-configure-winston/",
      "published_at": "2021-05-06T04:23:51Z",
      "updated_at": "2021-03-13T01:09:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Winston extension to link your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with Winston, ensure your configuration meets the following requirements: Node.js agent 6.2.0 or higher: Install or update Winston version 3.0.0 or higher Configure logs in context with log monitoring To configure logs in context with Winston: Enable log monitoring with a compatible log forwarding plugin. Install or update the Node.js agent. Configure the Winston extension. Check for logging data. Enable log monitoring Confirm that you have log monitoring enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Node.js agent Install or update to the most recent Node.js agent version, and enable Distributed tracing. Configure the Winston extension To configure logs in context with the Winston extension, complete the following steps: To install the New Relic Winston log enricher, enter the following command into your terminal or command line interface: npm install @newrelic/winston-enricher Copy In your application code, update your logging configuration to add the newrelicFormatter as shown below: // index.js require('newrelic') const newrelicFormatter = require('@newrelic/winston-enricher') Copy The New Relic formatter can be used individually or combined with other formatters as the final format. format: winston.format.combine( winston.format.label({label: 'test'}), newrelicFormatter() ) Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. Troubleshooting Problem Not all log data in a message or for a specific attribute is being displayed. Cause The stack trace will be written to the error.stack property. To accommodate the 4000 character log line limit for New Relic Logs, the stack and trace properties will be removed and the message, error.message and error.stack values will be truncated to 1024 characters. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.299,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Node.js</em>: Configure with Winston",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> monitoring",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". Configure the Winston extension. Check for logging data. <em>Enable</em> <em>log</em> monitoring Confirm that you have <em>log</em> monitoring enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update the <em>Node.js</em> agent Install or update to the most recent <em>Node.js</em> agent"
      },
      "id": "60450d71196a675ce1960f82"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.23566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.92276,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>New</em> <em>Relic</em> offers a <em>Log</em>4j 1.x extension for <em>New</em> <em>Relic</em> <em>log</em> <em>management</em>, allowing you link to your <em>log</em> data with related data across the rest of the <em>New</em> <em>Relic</em> platform. This document explains how to configure <em>logs</em> in <em>context</em> and start getting <em>log</em> data. The code and an example application are available"
      },
      "id": "603ead8b196a675ad7a83dd6"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-nodejs/nodejs-configure-winston": [
    {
      "sections": [
        "Configure logs in context for Node.js",
        "Compatibility and requirements",
        "What's next?"
      ],
      "title": "Configure logs in context for Node.js",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Node.js"
      ],
      "external_id": "fcb49eac4608f936beb447ec385aba16d31ebf8b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-nodejs/configure-logs-context-nodejs/",
      "published_at": "2021-05-06T04:23:26Z",
      "updated_at": "2021-03-13T00:59:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Node.js agent connects your Logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Compatibility and requirements To use log management with the Node.js agent, ensure your configuration meets the following requirements: Log management enabled, with a compatible log forwarding plugin installed Node.js agent 6.2.0 or higher: Install or update Configure logs in context for Node.js Choose a extension to see specific instructions: Winston What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.29474,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> <em>Node.js</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> <em>Node.js</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the <em>Node.js</em> agent connects your <em>Logs</em> and APM data in <em>New</em> <em>Relic</em>, giving full <em>context</em> to high-level events and providing high value data to specific <em>log</em> lines. Compatibility and requirements To use <em>log</em> <em>management</em> with the <em>Node.js</em> agent, ensure your configuration meets"
      },
      "id": "60450dae28ccbcd15d2c60c4"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.23566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.92276,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>New</em> <em>Relic</em> offers a <em>Log</em>4j 1.x extension for <em>New</em> <em>Relic</em> <em>log</em> <em>management</em>, allowing you link to your <em>log</em> data with related data across the rest of the <em>New</em> <em>Relic</em> platform. This document explains how to configure <em>logs</em> in <em>context</em> and start getting <em>log</em> data. The code and an example application are available"
      },
      "id": "603ead8b196a675ad7a83dd6"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-php/configure-logs-context-php": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.23553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.92273,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>New</em> <em>Relic</em> offers a <em>Log</em>4j 1.x extension for <em>New</em> <em>Relic</em> <em>log</em> <em>management</em>, allowing you link to your <em>log</em> data with related data across the rest of the <em>New</em> <em>Relic</em> platform. This document explains how to configure <em>logs</em> in <em>context</em> and start getting <em>log</em> data. The code and an example application are available"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.3862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-python/configure-logs-context-python": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.23541,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.92271,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>New</em> <em>Relic</em> offers a <em>Log</em>4j 1.x extension for <em>New</em> <em>Relic</em> <em>log</em> <em>management</em>, allowing you link to your <em>log</em> data with related data across the rest of the <em>New</em> <em>Relic</em> platform. This document explains how to configure <em>logs</em> in <em>context</em> and start getting <em>log</em> data. The code and an example application are available"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.38615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-ruby/configure-logs-context-ruby": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "What you need",
        "Install the infrastructure agent",
        "Test log forwarding",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "name",
        "attributes",
        "file",
        "Important",
        "systemd (Linux only)",
        "syslog (Linux only)",
        "tcp",
        "max_line_kb",
        "winlog",
        "pattern",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Log attributes automatically inserted by the infrastructure agent",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-05-05T00:28:53Z",
      "updated_at": "2021-05-05T00:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by checking what you need. Install the infrastructure agent, version 1.11.4 or higher. Configure your log sources and other parameters in the logging.d directory. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. What you need The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher Windows: Install the Microsoft Visual C++ Redistributable: x64 or x86. OpenSSL library 1.1.0 (or higher) is a requirement for infra-agent v1.16.4 or higher. Operating systems previous to year 2016 (like Suse12 or CentOS7) need to update OpenSSL from 1.0. to 1.1.. The log forwarding feature is not supported on containerized agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Test log forwarding To quickly check that the log forwarding feature works, follow these steps. If you're running the infrastructure monitoring agent in privileged or non-privileged modes, make sure that the user executing nri-agent has read permissions for the data sources. Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file (for example, logs.yml) with this content: Linux example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: /var/log/test.log Copy Windows example: # Remember to only use spaces for indentation logs: - name: \"test_log\" file: 'C:\\ProgramData\\New Relic\\newrelic-infra\\newrelic-infra.log' Copy Run the following command to append a test log message to your log file: echo \"This is a test message.\" >> /PATH/TO/YOUR/LOG/FILE Copy For example: echo \"This is a test message.\" >> /var/log/test.log Copy Search New Relic Logs for test message. Configure the infrastructure agent Configuration files describe which log sources are forwarded. You can add as many config files as you want, and set as many sources as you need per config file. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a configuration file with the parameters you need. Use our sample config file as reference. The agent automatically processes new configuration files without having to restart it. Log forwarding parameters The log forwarder config supports the following parameters (for examples, see the sample configuration). name Name of the log or logs. attributes List of custom attributes, as key-value pairs, that can be used to send additional data with the logs which you can then query. For example, you can enable built-in parsing rules by setting the logtype attribute. Example: ... - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 format: none separator: \\t attributes: # You can add custom attributes to any source of logs tcpFormat: none logtype: nginx # See https://docs.newrelic.com/docs/logs/log-management/ui-data/new-relic-logs-parsing-built-rules-custom-parsing someOtherAttribute: associatedValue Copy file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Your file can point to a specific log file or multiple ones by using wildcards applied to names and extensions; for example, /logs/*.log Example: logs: - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern pattern: Error # Regular expression to filter log entries Copy Wildcards can also be used in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files pattern: redis # Regular expression to filter log entries Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy Once you add these changes, reboot the host to ensure your changes are applied. systemd (Linux only) Service name. Once the systemd input is activated, log messages are collected from the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog (Linux only) Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the Infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while other depend on the configuration parameters you used while setting up the Log Forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the Entity GUID of infrastructure as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the Infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\":  first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic The infrastructure agent can be configured to send its own logs to New Relic. This can be useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent so that the new settings can be loaded. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get this error: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory update OpenSSL to 1.1.0 or higher. Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.23541,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.92271,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>New</em> <em>Relic</em> offers a <em>Log</em>4j 1.x extension for <em>New</em> <em>Relic</em> <em>log</em> <em>management</em>, allowing you link to your <em>log</em> data with related data across the rest of the <em>New</em> <em>Relic</em> platform. This document explains how to configure <em>logs</em> in <em>context</em> and start getting <em>log</em> data. The code and an example application are available"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-04-28T07:46:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. The account you wish to send logs to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Select an Insights insert API key from the drop-down. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.38615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. The account you wish to send <em>logs</em> to has at least one Insights Insert API Key associated with it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI"
      },
      "id": "60506f58196a677d432d1622"
    }
  ],
  "/docs/logs/enable-log-monitoring-new-relic/logs-context-java/java-adding-classpath": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.42722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Logback",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Logback extension",
        "Important",
        "Example configuration files",
        "Single console appender example",
        "Two-appender example",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Logback",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "d43c55efa817768e3840897678b966f896fd268d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback/",
      "published_at": "2021-05-06T03:34:12Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Logback extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Logback, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update Logback 1.2.0 or higher installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Logback: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Logback extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Logback extension To configure logs in context with the Logback extension, complete the following steps: Update your project's dependencies to include the Logback extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing < encoder> element as shown below. If you are logging to the console (stdout/stderr), look for ConsoleAppender and replace : <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you are logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Important It's important that the NewRelicAsyncAppender be the first appender to see the log message. List any other appenders after the NewRelicAsyncAppender in the <root> list. Example configuration files You can find a working example in GitHub. Here are examples of an updated logging .xml file for the Logback extension. Single console appender example Example configuration file after adding in the logging extension information. <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two-appender example This example sends New Relic logging to a file, but still sends standard logging to the console. <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Logback</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Logback: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Logback extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em>"
      },
      "id": "603ead8a196a679235a83d96"
    },
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-05-06T03:35:10Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.03632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    }
  ],
  "/docs/logs/index": [
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/62ef55a62dd87f45ce7e15d7b57fc980/38af3/NRDB2.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-05-05T19:48:50Z",
      "updated_at": "2021-05-05T19:48:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, log data can be parsed, transformed, or dropped before being stored. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.84389,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Drop <em>log</em> events",
        "tags": "<em>Logs</em>",
        "body": "After <em>log</em> event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> UI, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-05-05T19:48:49Z",
      "updated_at": "2021-05-05T19:48:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com > Logs: Each log's summary provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Logs queries are based on the Lucene query language. For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.843834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Logs</em>",
        "body": "Use our <em>Logs</em> UI in New Relic One to quickly search through your <em>log</em> data in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com &gt; <em>Logs</em>: Each <em>log</em>&#x27;s summary provides query options to add"
      },
      "id": "603ec00128ccbc853ceba7b8"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-05-05T01:24:57Z",
      "updated_at": "2021-05-05T01:24:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. one.newrelic.com > Logs: From the left nav in the Logs UI, select Parsing, then create a your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. one.newrelic.com > Logs: From the left nav in the Logs UI, select Parsing, then create a your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 81.428505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logstash</em> example",
        "tags": "<em>Logs</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> data into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. one.newrelic.com &gt; <em>Logs</em>: From the left nav in the <em>Logs</em> UI, select Parsing, then create"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/get-started/get-started-log-management": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-05-05T00:22:24Z",
      "updated_at": "2021-05-05T00:22:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Currently the patterns feature is opt-in; if you see Patterns are turned off in your Log management Patterns UI, contact your account representative and ask to have it enabled. There will be up to a 24 hour lead time before the machine learning (ML) system generates a customized model for your account. Patterns will be available for all customers to enable or disable on demand at the end of April 2021. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.30432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you <em>get</em>. For more information, see our documentation about parsing limits. <em>Get</em> <em>started</em> To <em>start</em> examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown to select"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/62ef55a62dd87f45ce7e15d7b57fc980/38af3/NRDB2.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-05-05T19:48:50Z",
      "updated_at": "2021-05-05T19:48:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, log data can be parsed, transformed, or dropped before being stored. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.4957,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Drop <em>log</em> events",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> UI, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-05-05T19:48:49Z",
      "updated_at": "2021-05-05T19:48:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com > Logs: Each log's summary provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Logs queries are based on the Lucene query language. For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.49557,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> UI in New Relic One to quickly search through your <em>log</em> data in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com &gt; <em>Logs</em>: Each <em>log</em>&#x27;s summary provides query options to add"
      },
      "id": "603ec00128ccbc853ceba7b8"
    }
  ],
  "/docs/logs/log-management/get-started/new-relics-log-management-security-privacy": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-05-05T00:22:24Z",
      "updated_at": "2021-05-05T00:22:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Currently the patterns feature is opt-in; if you see Patterns are turned off in your Log management Patterns UI, contact your account representative and ask to have it enabled. There will be up to a 24 hour lead time before the machine learning (ML) system generates a customized model for your account. Patterns will be available for all customers to enable or disable on demand at the end of April 2021. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.30432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you <em>get</em>. For more information, see our documentation about parsing limits. <em>Get</em> <em>started</em> To <em>start</em> examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown to select"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/62ef55a62dd87f45ce7e15d7b57fc980/38af3/NRDB2.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-05-05T19:48:50Z",
      "updated_at": "2021-05-05T19:48:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, log data can be parsed, transformed, or dropped before being stored. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.4957,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Drop <em>log</em> events",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> UI, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-05-05T19:48:49Z",
      "updated_at": "2021-05-05T19:48:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com > Logs: Each log's summary provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Logs queries are based on the Lucene query language. For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.49557,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> UI in New Relic One to quickly search through your <em>log</em> data in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com &gt; <em>Logs</em>: Each <em>log</em>&#x27;s summary provides query options to add"
      },
      "id": "603ec00128ccbc853ceba7b8"
    }
  ],
  "/docs/logs/log-management/log-api/introduction-log-api": [
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-05-05T01:24:57Z",
      "updated_at": "2021-05-05T01:24:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. one.newrelic.com > Logs: From the left nav in the Logs UI, select Parsing, then create a your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. one.newrelic.com > Logs: From the left nav in the Logs UI, select Parsing, then create a your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.3153,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logs</em> <em>API</em> example",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the <em>Logs</em> <em>API</em>. POST &#x2F;<em>log</em>&#x2F;v1 HTTP&#x2F;1.1 Host: <em>log</em>-<em>api</em>.newrelic.com Content-Type: application&#x2F;json X-License-Key: YOUR_LICENSE_KEY Accept: *&#x2F;* Content-Length: 133"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/62ef55a62dd87f45ce7e15d7b57fc980/38af3/NRDB2.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-05-05T19:48:50Z",
      "updated_at": "2021-05-05T19:48:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, log data can be parsed, transformed, or dropped before being stored. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.66376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Drop <em>log</em> events",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> UI, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-05-05T19:48:49Z",
      "updated_at": "2021-05-05T19:48:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com > Logs: Each log's summary provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Logs queries are based on the Lucene query language. For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.66364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> UI in New Relic One to quickly search through your <em>log</em> data in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com &gt; <em>Logs</em>: Each <em>log</em>&#x27;s summary provides query options to add"
      },
      "id": "603ec00128ccbc853ceba7b8"
    }
  ],
  "/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic": [
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-05-05T01:24:57Z",
      "updated_at": "2021-05-05T01:24:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. one.newrelic.com > Logs: From the left nav in the Logs UI, select Parsing, then create a your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. one.newrelic.com > Logs: From the left nav in the Logs UI, select Parsing, then create a your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.3153,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logs</em> <em>API</em> example",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the <em>Logs</em> <em>API</em>. POST &#x2F;<em>log</em>&#x2F;v1 HTTP&#x2F;1.1 Host: <em>log</em>-<em>api</em>.newrelic.com Content-Type: application&#x2F;json X-License-Key: YOUR_LICENSE_KEY Accept: *&#x2F;* Content-Length: 133"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/62ef55a62dd87f45ce7e15d7b57fc980/38af3/NRDB2.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-05-05T19:48:50Z",
      "updated_at": "2021-05-05T19:48:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, log data can be parsed, transformed, or dropped before being stored. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.66376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Drop <em>log</em> events",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> UI, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-05-05T19:48:49Z",
      "updated_at": "2021-05-05T19:48:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com > Logs: Each log's summary provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Logs queries are based on the Lucene query language. For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.66364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> UI in New Relic One to quickly search through your <em>log</em> data in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com &gt; <em>Logs</em>: Each <em>log</em>&#x27;s summary provides query options to add"
      },
      "id": "603ec00128ccbc853ceba7b8"
    }
  ],
  "/docs/logs/log-management/troubleshooting/find-issues-cause-or-impact-surrounding-logs": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-05-05T00:22:24Z",
      "updated_at": "2021-05-05T00:22:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Currently the patterns feature is opt-in; if you see Patterns are turned off in your Log management Patterns UI, contact your account representative and ask to have it enabled. There will be up to a 24 hour lead time before the machine learning (ML) system generates a customized model for your account. Patterns will be available for all customers to enable or disable on demand at the end of April 2021. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.81761,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown to select"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/62ef55a62dd87f45ce7e15d7b57fc980/38af3/NRDB2.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-05-05T19:48:50Z",
      "updated_at": "2021-05-05T19:48:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, log data can be parsed, transformed, or dropped before being stored. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.49545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Drop <em>log</em> events",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> UI, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-05-05T19:48:49Z",
      "updated_at": "2021-05-05T19:48:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com > Logs: Each log's summary provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Logs queries are based on the Lucene query language. For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.49533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> UI in New Relic One to quickly search through your <em>log</em> data in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com &gt; <em>Logs</em>: Each <em>log</em>&#x27;s summary provides query options to add"
      },
      "id": "603ec00128ccbc853ceba7b8"
    }
  ],
  "/docs/logs/log-management/troubleshooting/log-message-truncated": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-05-05T00:22:24Z",
      "updated_at": "2021-05-05T00:22:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Currently the patterns feature is opt-in; if you see Patterns are turned off in your Log management Patterns UI, contact your account representative and ask to have it enabled. There will be up to a 24 hour lead time before the machine learning (ML) system generates a customized model for your account. Patterns will be available for all customers to enable or disable on demand at the end of April 2021. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.8175,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown to select"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/62ef55a62dd87f45ce7e15d7b57fc980/38af3/NRDB2.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-05-05T19:48:50Z",
      "updated_at": "2021-05-05T19:48:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, log data can be parsed, transformed, or dropped before being stored. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.49533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Drop <em>log</em> events",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> UI, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-05-05T19:48:49Z",
      "updated_at": "2021-05-05T19:48:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com > Logs: Each log's summary provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Logs queries are based on the Lucene query language. For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.4952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> UI in New Relic One to quickly search through your <em>log</em> data in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com &gt; <em>Logs</em>: Each <em>log</em>&#x27;s summary provides query options to add"
      },
      "id": "603ec00128ccbc853ceba7b8"
    }
  ],
  "/docs/logs/log-management/troubleshooting/no-log-data-appears-ui": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-05-05T00:22:24Z",
      "updated_at": "2021-05-05T00:22:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Currently the patterns feature is opt-in; if you see Patterns are turned off in your Log management Patterns UI, contact your account representative and ask to have it enabled. There will be up to a 24 hour lead time before the machine learning (ML) system generates a customized model for your account. Patterns will be available for all customers to enable or disable on demand at the end of April 2021. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.8175,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown to select"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/62ef55a62dd87f45ce7e15d7b57fc980/38af3/NRDB2.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-05-05T19:48:50Z",
      "updated_at": "2021-05-05T19:48:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, log data can be parsed, transformed, or dropped before being stored. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.49533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Drop <em>log</em> events",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> UI, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-05-05T19:48:49Z",
      "updated_at": "2021-05-05T19:48:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com > Logs: Each log's summary provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Logs queries are based on the Lucene query language. For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.4952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> UI in New Relic One to quickly search through your <em>log</em> data in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com &gt; <em>Logs</em>: Each <em>log</em>&#x27;s summary provides query options to add"
      },
      "id": "603ec00128ccbc853ceba7b8"
    }
  ],
  "/docs/logs/log-management/troubleshooting/view-log-messages-real-time-live-tail": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-05-05T00:22:24Z",
      "updated_at": "2021-05-05T00:22:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Currently the patterns feature is opt-in; if you see Patterns are turned off in your Log management Patterns UI, contact your account representative and ask to have it enabled. There will be up to a 24 hour lead time before the machine learning (ML) system generates a customized model for your account. Patterns will be available for all customers to enable or disable on demand at the end of April 2021. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.81738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown to select"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/62ef55a62dd87f45ce7e15d7b57fc980/38af3/NRDB2.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-05-05T19:48:50Z",
      "updated_at": "2021-05-05T19:48:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, log data can be parsed, transformed, or dropped before being stored. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.4952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Drop <em>log</em> events",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> UI, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-05-05T19:48:49Z",
      "updated_at": "2021-05-05T19:48:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com > Logs: Each log's summary provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Logs queries are based on the Lucene query language. For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.49506,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> UI in New Relic One to quickly search through your <em>log</em> data in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com &gt; <em>Logs</em>: Each <em>log</em>&#x27;s summary provides query options to add"
      },
      "id": "603ec00128ccbc853ceba7b8"
    }
  ],
  "/docs/logs/log-management/ui-data/built-log-parsing-rulesets": [
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/62ef55a62dd87f45ce7e15d7b57fc980/38af3/NRDB2.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-05-05T19:48:50Z",
      "updated_at": "2021-05-05T19:48:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, log data can be parsed, transformed, or dropped before being stored. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 351.15387,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-05-05T19:48:49Z",
      "updated_at": "2021-05-05T19:48:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com > Logs: Each log's summary provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Logs queries are based on the Lucene query language. For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 351.15363,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> <em>UI</em> in New Relic One to quickly search through your <em>log</em> <em>data</em> in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com &gt; <em>Logs</em>: Each <em>log</em>&#x27;s summary provides query options to add"
      },
      "id": "603ec00128ccbc853ceba7b8"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-05-05T01:24:57Z",
      "updated_at": "2021-05-05T01:24:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. one.newrelic.com > Logs: From the left nav in the Logs UI, select Parsing, then create a your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. one.newrelic.com > Logs: From the left nav in the Logs UI, select Parsing, then create a your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 337.0183,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. one.newrelic.com &gt; <em>Logs</em>: From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/ui-data/data-partitions": [
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/62ef55a62dd87f45ce7e15d7b57fc980/38af3/NRDB2.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-05-05T19:48:50Z",
      "updated_at": "2021-05-05T19:48:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, log data can be parsed, transformed, or dropped before being stored. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 351.15363,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-05-05T19:48:49Z",
      "updated_at": "2021-05-05T19:48:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com > Logs: Each log's summary provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Logs queries are based on the Lucene query language. For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 351.15338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> <em>UI</em> in New Relic One to quickly search through your <em>log</em> <em>data</em> in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com &gt; <em>Logs</em>: Each <em>log</em>&#x27;s summary provides query options to add"
      },
      "id": "603ec00128ccbc853ceba7b8"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-05-05T01:24:57Z",
      "updated_at": "2021-05-05T01:24:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. one.newrelic.com > Logs: From the left nav in the Logs UI, select Parsing, then create a your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. one.newrelic.com > Logs: From the left nav in the Logs UI, select Parsing, then create a your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 337.01813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. one.newrelic.com &gt; <em>Logs</em>: From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/ui-data/drop-data-drop-filter-rules": [
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-05-05T19:48:49Z",
      "updated_at": "2021-05-05T19:48:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com > Logs: Each log's summary provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Logs queries are based on the Lucene query language. For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 351.15338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> <em>UI</em> in New Relic One to quickly search through your <em>log</em> <em>data</em> in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com &gt; <em>Logs</em>: Each <em>log</em>&#x27;s summary provides query options to add"
      },
      "id": "603ec00128ccbc853ceba7b8"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-05-05T01:24:57Z",
      "updated_at": "2021-05-05T01:24:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. one.newrelic.com > Logs: From the left nav in the Logs UI, select Parsing, then create a your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. one.newrelic.com > Logs: From the left nav in the Logs UI, select Parsing, then create a your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 337.01813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. one.newrelic.com &gt; <em>Logs</em>: From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-05-05T01:26:06Z",
      "updated_at": "2021-05-05T01:24:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. Explore your log data one.newrelic.com > Logs: Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the log patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". In the search bar, click the plus icon, then select Create an alert from this. Complete the Create alert condition that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click the dashboard icon, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see logs in context. Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 337.0179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query and share the <em>data</em> with charts, add to dashboards, etc. Organize your account&#x27;s <em>log</em> <em>data</em>"
      },
      "id": "603ea62e64441ff7ba4e8854"
    }
  ],
  "/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns": [
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/62ef55a62dd87f45ce7e15d7b57fc980/38af3/NRDB2.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-05-05T19:48:50Z",
      "updated_at": "2021-05-05T19:48:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, log data can be parsed, transformed, or dropped before being stored. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 351.15338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-05-05T19:48:49Z",
      "updated_at": "2021-05-05T19:48:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com > Logs: Each log's summary provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Logs queries are based on the Lucene query language. For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 351.15317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> <em>UI</em> in New Relic One to quickly search through your <em>log</em> <em>data</em> in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com &gt; <em>Logs</em>: Each <em>log</em>&#x27;s summary provides query options to add"
      },
      "id": "603ec00128ccbc853ceba7b8"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-05-05T01:24:57Z",
      "updated_at": "2021-05-05T01:24:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. one.newrelic.com > Logs: From the left nav in the Logs UI, select Parsing, then create a your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule has a matching criteria. We recommend using the logtype attribute name for matching parsing rules to logs. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. one.newrelic.com > Logs: From the left nav in the Logs UI, select Parsing, then create a your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 337.0179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. one.newrelic.com &gt; <em>Logs</em>: From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/ui-data/parsing": [
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/62ef55a62dd87f45ce7e15d7b57fc980/38af3/NRDB2.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-05-05T19:48:50Z",
      "updated_at": "2021-05-05T19:48:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, log data can be parsed, transformed, or dropped before being stored. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 351.15338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Query syntax for logs",
        "Query structure",
        "Tip",
        "Search with text",
        "Text operators",
        "Search with attributes",
        "General operators",
        "Numeric operators"
      ],
      "title": "Query syntax for logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "29dfdceb3e3b369789cf1a3efa01b6b903b209e3",
      "image": "https://docs.newrelic.com/static/f3554eee95e57a6fc6bbad88a6752489/c1b63/log-summary-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/query-syntax-logs/",
      "published_at": "2021-05-05T19:48:49Z",
      "updated_at": "2021-05-05T19:48:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logs UI in New Relic One to quickly search through your log data in seconds. Each log lists available attributes in the log_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com > Logs: Each log's summary provides query options to add, exclude, replace, and more. Query structure Using the Logs UI, you can search through your log data by entering either simple keywords, such as new and relic, or phrases such as new relic agent, directly into the search field. You can also combine keywords or phrases with operators to form more complex queries. Tip Logs queries are based on the Lucene query language. For some helpful examples, check out this Lucene tutorial. General query rules: Log query rules Comments Case sensitive The query syntax is case sensitive for attributes values. Attribute names are always case sensitive. Exception: Wildcard searches are case insensitive for attribute values. Special characters When a term contains special characters, double-quote the term and escape the special characters using a backslash (\\). This includes special characters such as +, -, &, |, !, (, ), {, }, [, ], ^, \", ~, *, ?, :, /, or \\. Example: To query for \"POST /log/v1 HTTP/1.1\" 202, escape the quotes like this: \"\\\"POST /log/v1 HTTP/1.1\\\" 202\" Wildcard searches You can run wildcard searches using an asterisk (*) to replace zero or more characters. Example: new*relic Search with text To return more specific query results, use text searches to join together keywords or phrases. Text operators The Logs query syntax accepts the following text operators: Condition Text operator example Matching (keyword) Search for log results containing keywords entered separately: \"new\" \"relic\" Exact matching (phrase) Search for log results containing the specific phrase entered: \"new relic agent\" Either / Or Search for log results containing either or both of the keywords entered: new OR relic And Search for log results containing both of the keywords entered: new AND relic * Wildcard (zero or more) Search for log results containing both of the keywords entered, with zero or more characters between them: new*relic Negation (keyword) Search for log results that do not contain the specific keyword entered: -new Negation (phrase) Search for log results that do not contain the specific phrase entered. -\"new relic\" Search with attributes Use attribute searches to narrow the query results to a specific attribute or field. General operators The following operators can be used by all types of attributes: Condition General operator example Equal : Search for log results where the attribute equals the keyword specified. Example: The field hostname equals chi: hostname:chi Does not equal - : Search for log results where the attribute does not equal the keyword specified. Example: The field hostname does not equal chi. -hostname:chi Contains * Search for log results where the attribute contains the specified keyword. Example: The field hostname contains chi. hostname:*chi* Does not contain - * Search for log results where the attribute does not contain the specified keyword. Example: The field hostname does not contain chi. -hostname:*chi* Starts with * Search for log results where the attribute starts with the specified keyword specified. Example: The field hostname starts with chi. hostname:chi* Ends with * Search for log results where the attribute ends with the specified keyword specified. Example: The field hostname ends with chi. hostname:*chi Has Search for log results that have the specified field. Example: Has the field user_name. has:user_name Missing Search for log results that are missing the specified field. Example: Missing the field user_name. missing:user_name Numeric operators The following operators can only be used by numeric attributes: Condition Numeric operator example Greater than Search for log results attribute matches that are greater than the given parameter. Example: The field http_response_time_ms is greater than 500. http_response_time_ms:>500 Greater than or equal to Search for log results with attribute matches that are greater than or equal to the given parameter. Example: The field http_response_time_ms is greater than or equal to 500. http_response_time_ms:>=500 Less than Search for log results with attribute matches that are less than the given parameter. Example: The field http_response_time_ms is less than 500. http_response_time_ms:<500 Less than or equal to Search for log results with attribute matches that are less than or equal to the given parameter. Example: The field http_response_time_ms is less than or equal to 500. http_response_time_ms:<=500",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 351.15317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query syntax for <em>logs</em>",
        "sections": "Query syntax for <em>logs</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use our <em>Logs</em> <em>UI</em> in New Relic One to quickly search through your <em>log</em> <em>data</em> in seconds. Each <em>log</em> lists available attributes in the <em>log</em>_summary column. To drill down into additional details, click any highlighted attribute. one.newrelic.com &gt; <em>Logs</em>: Each <em>log</em>&#x27;s summary provides query options to add"
      },
      "id": "603ec00128ccbc853ceba7b8"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-05-05T01:26:06Z",
      "updated_at": "2021-05-05T01:24:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. Explore your log data one.newrelic.com > Logs: Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the log patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". In the search bar, click the plus icon, then select Create an alert from this. Complete the Create alert condition that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click the dashboard icon, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see logs in context. Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 337.0177,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query and share the <em>data</em> with charts, add to dashboards, etc. Organize your account&#x27;s <em>log</em> <em>data</em>"
      },
      "id": "603ea62e64441ff7ba4e8854"
    }
  ]
}