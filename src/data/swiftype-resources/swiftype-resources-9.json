{
  "/docs/browser/new-relic-browser/troubleshooting/ajax-call-fails-cors-redirect-error-message": [
    {
      "sections": [
        "Troubleshoot AJAX data collection",
        "Problem",
        "Solution",
        "1. Verify you use XMLHttpRequest.",
        "2. Verify the object is instrumented.",
        "3. Verify network access.",
        "JSONP requirements"
      ],
      "title": "Troubleshoot AJAX data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "8dc486fa0fbb0a07f5e93c3cf75590e3e03bba2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/troubleshoot-ajax-data-collection/",
      "published_at": "2021-12-19T13:52:53Z",
      "updated_at": "2021-11-13T07:03:46Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are not seeing AJAX data for your browser app. Solution If your application is instrumented with browser monitoring and is correctly collecting data for other Pro features, follow these steps: 1. Verify you use XMLHttpRequest. Check whether your application uses the XMLHttpRequest object to make AJAX calls. Browser monitoring: Other methods (including the newer Fetch API) currently are not supported when using browser Pro. Single-page app monitoring: Fetch is supported for AJAX requests within a browser interaction with SPA monitoring. If you are making requests using JSONP, see JSONP requirements. 2. Verify the object is instrumented. If you are using XMLHttpRequest, use your browser's dev console to verify that the object has been instrumented by New Relic. Enter the object name at your console. If instrumentation has succeeded, the console should return something like: function (t){var e=new p(t);try{u.emit(\"new-xhr\"... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see Troubleshooting browser monitoring installation. If you see a different response, you may be using another script or library that is conflicting with New Relic instrumentation. Contact support at support.newrelic.com. 3. Verify network access. If the object is properly instrumented, try triggering an AJAX call in your application while monitoring network traffic in the browser's developer tools. Wait up to one minute, and look for a call to bam.nr-data.net/jserrors with an xhr parameter. If the call fails, check for network issues. If you don't see this call, if it fails with an error not related to network access, or if it succeeds but you still aren't seeing data, get support at support.newrelic.com. If your requests use JSONP, see requirements and notes on functionality below: JSONP requirements If your requests use JSONP, these requests will not appear on the AJAX UI page. However, you can view them as assets within session traces. If using SPA monitoring, you can view them on the Breakdown tab of the Page views page. Requirements for JSONP to be recognized: Each JSONP request must use a unique callback function. Most popular libraries (like jQuery) generate a unique callback function dynamically for each request. The query string callback must be named \"callback\" or \"cb\" in order to be recognized by New Relic. This is the default behavior in most popular libraries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> AJAX data collection",
        "sections": "<em>Troubleshoot</em> AJAX data collection",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ": function (t){var e=new p(t);try{u.emit(&quot;new-xhr&quot;... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see <em>Troubleshooting</em> <em>browser</em> <em>monitoring</em> installation. If you see a different response, you may"
      },
      "id": "603e902d196a6762dea83d8a"
    },
    {
      "sections": [
        "Browser Summary page",
        "View the Summary page",
        "Core Web Vitals widgets",
        "User time on the site",
        "Initial page load and route change chart",
        "User-centric page load times chart",
        "Throughput chart",
        "Tip",
        "Front end vs. back end chart",
        "First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL",
        "Related Entities widget",
        "View Synthetics monitors"
      ],
      "title": "Browser Summary page",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Getting started"
      ],
      "external_id": "a69bb31a3bff73ef8badce5ce435da62e9e7b644",
      "image": "https://docs.newrelic.com/static/e61bbb246d462250e94c99bf637b9cca/c1b63/browser_summary_page.png",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/getting-started/browser-summary-page/",
      "published_at": "2021-12-19T15:18:58Z",
      "updated_at": "2021-12-10T02:30:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's Summary page summarizes the real-user browser performance of your app. Use the Summary page to: View trends in an app's browser-side performance Quickly troubleshoot page load timing issues Navigate to other browser UI pages View the Summary page To view a summary of browser performance for an app: Go to one.newrelic.com > Explorer > Browser applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com, click Browser, and select an app from the Browser index. From the app's Summary page, use standard New Relic page functions to drill down into detailed information. one.newrelic.com > Browser > (select an app) > Summary: After you select an application from the browser apps index, the Summary page shows a summary of browser performance for that app. The Summary page includes: Core Web Vitals widgets User time on the site Initial page load and route change chart User-centric page load times chart Throughput chart Front end vs. back end chart First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL Related Entities widget View Synthetics monitors Core Web Vitals widgets The Core Web Vitals widgets show how your browser performs according to Google's Core Web Vitals. The Core Web Vitals widgets include: LCP - Largest Contentful Paint FID - First Input Delay CLS - Cumulative Layout Shift User time on the site The User time on the site widget shows the time a user remains on the site. Initial page load and route change chart The Initial page load and route change chart shows the load time of a traditional URL change stemming from a load or reload of a URL. This chart appears with more detail about the page load timing process on the page load time page. User-centric page load times chart The User-centric page load times chart shows the load time of a page for a user. This chart appears with more detail about the page load timing process on the page load time page. Throughput chart The Throughput chart displays browser throughput as pages per minute (ppm). The value in the upper right of the chart is the average value for the selected time range. If you have enabled SPA monitoring enabled and the Summary page shows the SPA load time chart, the Throughput chart will also use SPA data. Tip App server requests per minute (rpm) may show a different measurement than the browser page load timing's pages per minute (ppm). Front end vs. back end chart The Front end vs. back end chart links to the connect APM service application. For details on APM and tracing, see Language agents and distributed tracing. First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL You'll also see summary versions of these metrics from the page load time page and JavaScript errors page: First interaction by device type First interaction by user agent JavaScript errors Longest first input delay by URL Related Entities widget The Related Entities widget shows all the entities that are related to the browser. To understand more about connections between entities, read about Entity relationships. View Synthetics monitors The button directs you to the Synthetics page. To read more about Synthetics, see Synthetic monitoring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.82834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> Summary page",
        "sections": "<em>Browser</em> Summary page",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s Summary page summarizes the real-user <em>browser</em> performance of your app. Use the Summary page to: View trends in an app&#x27;s <em>browser</em>-side performance Quickly <em>troubleshoot</em> page load timing issues Navigate to other <em>browser</em> UI pages View the Summary page To view a summary of <em>browser</em>"
      },
      "id": "60440d9c196a674ac8960f5b"
    },
    {
      "sections": [
        "Install the browser monitoring agent",
        "Enable browser monitoring",
        "Deployment options",
        "Enable an APM-monitored app",
        "Enable with copy/paste",
        "Instrument webpages using the APM agent",
        "Use REST API",
        "Browser agent types: Lite, Pro, Pro+SPA"
      ],
      "title": "Install the browser monitoring agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Installation"
      ],
      "external_id": "bc45bbc86cd4d8b81367ad0904907ddc735717f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/installation/install-browser-monitoring-agent/",
      "published_at": "2021-12-19T15:19:26Z",
      "updated_at": "2021-11-13T06:04:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser uses a JavaScript snippet, also referred to as an \"agent,\" to instrument your app's webpages. The JavaScript collects data for browser monitoring. To install the browser agent, you can choose from a number of deployment options. If you don't have one already, create a New Relic account. It's free, forever. Get an account Enable browser monitoring Browser Pro+SPA is the default agent when you enable browser monitoring. This automatically gives you access to all of our browser monitoring features. For more information about the browser monitoring options, see Browser agent types in this document. To enable browser monitoring: Go to one.newrelic.com, select Browser, and then select Add more data. Follow the instructions in the UI to add browser monitoring to your app. Generate some traffic for your app, then wait a few minutes for data to appear in New Relic. Optional: After installation is complete and you are seeing data, go to the App settings page for additional agent configuration, or to change the browser agent type. It may take several minutes after enabling the browser monitoring agent before your webpage data appear in New Relic. If have problems, follow our troubleshooting tips. Deployment options No matter which option you use to deploy browser monitoring, the end result is the same: the browser monitoring JavaScript snippet (also referred to as the \"agent\") is inserted into your app pages. The method you select depends on your preferences and business needs. Enable an APM-monitored app When enabling browser monitoring, you can use an APM agent to automatically inject the browser monitoring JavaScript snippet for you. This is the easiest way to install the agent for an app that's already being monitored by APM. APM-monitored apps are listed on your APM Applications index. Enable with copy/paste When enabling browser monitoring, you can manually insert the JavaScript snippet into your app's webpages. The copy/paste option gives you control over the exact placement of our JavaScript snippet, which is required to monitor the webpage's performance. This is useful for: Standalone apps, static sites, and cached pages delivered by CDN APM apps that are not as closely coupled to the browser app as with a standard server-side app (for example, when your client-side app talks to a REST API back end) Some tips for using the JavaScript snippet: Placement in your webpage: Copy the code snippet, then paste it inline into your pages as close to the top of the <head> element as possible, but after any position-sensitive <meta> tags (for example, X-UA-Compatible or charset information). For more information on the inline head placement, see JavaScript placement requirements. License key and app ID: Near the bottom of the generated JavaScript is your browser license key and application ID. This is useful with the REST API and API Explorer. Instrument webpages using the APM agent This information applies to apps that are also monitored by APM. Our APM agents can instrument webpages with the required JavaScript for page load timing. If you are using an APM agent's API to manually add the JavaScript snippet to your webpages, insert the instrumentation snippet as close to the top as possible. This allows you to take advantage of detailed information about browser's AJAX calls and JavaScript errors. For more information, see the instructions for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby Use REST API This information applies to apps that are also monitored by APM. The REST API lets you manage deployment outside the browser monitoring UI. This is useful for large organizations deploying multiple apps. Browser agent types: Lite, Pro, Pro+SPA We have three types of browser agents: Lite, Pro, and Pro+SPA. The agent type has no impact on your billing. Browser agent type Comparison Pro+SPA This is the default installed agent when you enable browser monitoring. What it includes: Gives you access to all of the Browser Pro features and to Single Page App (SPA) monitoring. Provides detailed page timing data and the most up-to-date New Relic features, including distributed tracing, for all types of applications. Pro+SPA is not limited only to single page applications. After install, you can downgrade anytime to the less advanced agents if you don't want or need SPA monitoring. Pro What it includes: Gives you access to the Browser Pro features. What it doesn't include: Lacks the functionality designed for single page app monitoring. Lite What it includes: Gives you information about some basic page load timing and browser user information. What it doesn't include: Lacks the Browser Pro features and SPA features. Details about how agent types relate to pricing: New Relic One pricing: This pricing model has data ingest as a billing factor. If you want to reduce data ingest, you may want to consider downgrading to lesser agent types after install. Original pricing: Your access to browser monitoring features is gated by your subscription plan, not by the agent type. This means there is no reason not to use the default Pro+SPA agent. After initial agent installation is finished, you can go to the App settings page to edit your configuration or to change your subscription.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.3862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>browser</em> <em>monitoring</em> agent",
        "sections": "Install the <em>browser</em> <em>monitoring</em> agent",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " <em>troubleshooting</em> tips. Deployment options No matter which option you use to deploy <em>browser</em> <em>monitoring</em>, the end result is the same: the <em>browser</em> <em>monitoring</em> JavaScript snippet (also referred to as the &quot;agent&quot;) is inserted into your app pages. The method you select depends on your preferences and business needs"
      },
      "id": "604429e628ccbcb80b2c60d0"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/angularjs-errors-do-not-appear": [
    {
      "sections": [
        "AJAX call fails with a CORS redirect error message",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "AJAX call fails with a CORS redirect error message",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "a4e478428acefb454ab8969cccb666d03ae458f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/ajax-call-fails-cors-redirect-error-message/",
      "published_at": "2021-12-19T13:56:44Z",
      "updated_at": "2021-11-13T07:04:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem A redirected AJAX call is being rejected with a CORS error message, for example: Access to XMLHttpRequest at 'https://my-domain-2/path' (redirected from 'https://my-domain-1/path') from origin 'https://my-website-domain' has been blocked by CORS policy: Request header field x-newrelic-id is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The browser agent automatically adds custom headers to outgoing same-origin AJAX calls in order to support the Distributed Tracing feature. When the server that receives the AJAX call responds with a redirect status code (such as 302), the browser will automatically make the same AJAX call to the redirected URL. And if this new URL is on a different origin and the call does not pass the CORS preflight, the browser will fail the call with the error message listed above.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The <em>browser</em> agent"
      },
      "id": "603eb41ce7b9d2ce042a07db"
    },
    {
      "sections": [
        "Troubleshoot AJAX data collection",
        "Problem",
        "Solution",
        "1. Verify you use XMLHttpRequest.",
        "2. Verify the object is instrumented.",
        "3. Verify network access.",
        "JSONP requirements"
      ],
      "title": "Troubleshoot AJAX data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "8dc486fa0fbb0a07f5e93c3cf75590e3e03bba2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/troubleshoot-ajax-data-collection/",
      "published_at": "2021-12-19T13:52:53Z",
      "updated_at": "2021-11-13T07:03:46Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are not seeing AJAX data for your browser app. Solution If your application is instrumented with browser monitoring and is correctly collecting data for other Pro features, follow these steps: 1. Verify you use XMLHttpRequest. Check whether your application uses the XMLHttpRequest object to make AJAX calls. Browser monitoring: Other methods (including the newer Fetch API) currently are not supported when using browser Pro. Single-page app monitoring: Fetch is supported for AJAX requests within a browser interaction with SPA monitoring. If you are making requests using JSONP, see JSONP requirements. 2. Verify the object is instrumented. If you are using XMLHttpRequest, use your browser's dev console to verify that the object has been instrumented by New Relic. Enter the object name at your console. If instrumentation has succeeded, the console should return something like: function (t){var e=new p(t);try{u.emit(\"new-xhr\"... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see Troubleshooting browser monitoring installation. If you see a different response, you may be using another script or library that is conflicting with New Relic instrumentation. Contact support at support.newrelic.com. 3. Verify network access. If the object is properly instrumented, try triggering an AJAX call in your application while monitoring network traffic in the browser's developer tools. Wait up to one minute, and look for a call to bam.nr-data.net/jserrors with an xhr parameter. If the call fails, check for network issues. If you don't see this call, if it fails with an error not related to network access, or if it succeeds but you still aren't seeing data, get support at support.newrelic.com. If your requests use JSONP, see requirements and notes on functionality below: JSONP requirements If your requests use JSONP, these requests will not appear on the AJAX UI page. However, you can view them as assets within session traces. If using SPA monitoring, you can view them on the Breakdown tab of the Page views page. Requirements for JSONP to be recognized: Each JSONP request must use a unique callback function. Most popular libraries (like jQuery) generate a unique callback function dynamically for each request. The query string callback must be named \"callback\" or \"cb\" in order to be recognized by New Relic. This is the default behavior in most popular libraries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> AJAX data collection",
        "sections": "<em>Troubleshoot</em> AJAX data collection",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ": function (t){var e=new p(t);try{u.emit(&quot;new-xhr&quot;... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see <em>Troubleshooting</em> <em>browser</em> <em>monitoring</em> installation. If you see a different response, you may"
      },
      "id": "603e902d196a6762dea83d8a"
    },
    {
      "sections": [
        "Browser Summary page",
        "View the Summary page",
        "Core Web Vitals widgets",
        "User time on the site",
        "Initial page load and route change chart",
        "User-centric page load times chart",
        "Throughput chart",
        "Tip",
        "Front end vs. back end chart",
        "First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL",
        "Related Entities widget",
        "View Synthetics monitors"
      ],
      "title": "Browser Summary page",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Getting started"
      ],
      "external_id": "a69bb31a3bff73ef8badce5ce435da62e9e7b644",
      "image": "https://docs.newrelic.com/static/e61bbb246d462250e94c99bf637b9cca/c1b63/browser_summary_page.png",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/getting-started/browser-summary-page/",
      "published_at": "2021-12-19T15:18:58Z",
      "updated_at": "2021-12-10T02:30:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's Summary page summarizes the real-user browser performance of your app. Use the Summary page to: View trends in an app's browser-side performance Quickly troubleshoot page load timing issues Navigate to other browser UI pages View the Summary page To view a summary of browser performance for an app: Go to one.newrelic.com > Explorer > Browser applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com, click Browser, and select an app from the Browser index. From the app's Summary page, use standard New Relic page functions to drill down into detailed information. one.newrelic.com > Browser > (select an app) > Summary: After you select an application from the browser apps index, the Summary page shows a summary of browser performance for that app. The Summary page includes: Core Web Vitals widgets User time on the site Initial page load and route change chart User-centric page load times chart Throughput chart Front end vs. back end chart First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL Related Entities widget View Synthetics monitors Core Web Vitals widgets The Core Web Vitals widgets show how your browser performs according to Google's Core Web Vitals. The Core Web Vitals widgets include: LCP - Largest Contentful Paint FID - First Input Delay CLS - Cumulative Layout Shift User time on the site The User time on the site widget shows the time a user remains on the site. Initial page load and route change chart The Initial page load and route change chart shows the load time of a traditional URL change stemming from a load or reload of a URL. This chart appears with more detail about the page load timing process on the page load time page. User-centric page load times chart The User-centric page load times chart shows the load time of a page for a user. This chart appears with more detail about the page load timing process on the page load time page. Throughput chart The Throughput chart displays browser throughput as pages per minute (ppm). The value in the upper right of the chart is the average value for the selected time range. If you have enabled SPA monitoring enabled and the Summary page shows the SPA load time chart, the Throughput chart will also use SPA data. Tip App server requests per minute (rpm) may show a different measurement than the browser page load timing's pages per minute (ppm). Front end vs. back end chart The Front end vs. back end chart links to the connect APM service application. For details on APM and tracing, see Language agents and distributed tracing. First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL You'll also see summary versions of these metrics from the page load time page and JavaScript errors page: First interaction by device type First interaction by user agent JavaScript errors Longest first input delay by URL Related Entities widget The Related Entities widget shows all the entities that are related to the browser. To understand more about connections between entities, read about Entity relationships. View Synthetics monitors The button directs you to the Synthetics page. To read more about Synthetics, see Synthetic monitoring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.82831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> Summary page",
        "sections": "<em>Browser</em> Summary page",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s Summary page summarizes the real-user <em>browser</em> performance of your app. Use the Summary page to: View trends in an app&#x27;s <em>browser</em>-side performance Quickly <em>troubleshoot</em> page load timing issues Navigate to other <em>browser</em> UI pages View the Summary page To view a summary of <em>browser</em>"
      },
      "id": "60440d9c196a674ac8960f5b"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/app-server-requests-greatly-outnumber-browser-pageview-transactions": [
    {
      "sections": [
        "AJAX call fails with a CORS redirect error message",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "AJAX call fails with a CORS redirect error message",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "a4e478428acefb454ab8969cccb666d03ae458f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/ajax-call-fails-cors-redirect-error-message/",
      "published_at": "2021-12-19T13:56:44Z",
      "updated_at": "2021-11-13T07:04:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem A redirected AJAX call is being rejected with a CORS error message, for example: Access to XMLHttpRequest at 'https://my-domain-2/path' (redirected from 'https://my-domain-1/path') from origin 'https://my-website-domain' has been blocked by CORS policy: Request header field x-newrelic-id is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The browser agent automatically adds custom headers to outgoing same-origin AJAX calls in order to support the Distributed Tracing feature. When the server that receives the AJAX call responds with a redirect status code (such as 302), the browser will automatically make the same AJAX call to the redirected URL. And if this new URL is on a different origin and the call does not pass the CORS preflight, the browser will fail the call with the error message listed above.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The <em>browser</em> agent"
      },
      "id": "603eb41ce7b9d2ce042a07db"
    },
    {
      "sections": [
        "Troubleshoot AJAX data collection",
        "Problem",
        "Solution",
        "1. Verify you use XMLHttpRequest.",
        "2. Verify the object is instrumented.",
        "3. Verify network access.",
        "JSONP requirements"
      ],
      "title": "Troubleshoot AJAX data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "8dc486fa0fbb0a07f5e93c3cf75590e3e03bba2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/troubleshoot-ajax-data-collection/",
      "published_at": "2021-12-19T13:52:53Z",
      "updated_at": "2021-11-13T07:03:46Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are not seeing AJAX data for your browser app. Solution If your application is instrumented with browser monitoring and is correctly collecting data for other Pro features, follow these steps: 1. Verify you use XMLHttpRequest. Check whether your application uses the XMLHttpRequest object to make AJAX calls. Browser monitoring: Other methods (including the newer Fetch API) currently are not supported when using browser Pro. Single-page app monitoring: Fetch is supported for AJAX requests within a browser interaction with SPA monitoring. If you are making requests using JSONP, see JSONP requirements. 2. Verify the object is instrumented. If you are using XMLHttpRequest, use your browser's dev console to verify that the object has been instrumented by New Relic. Enter the object name at your console. If instrumentation has succeeded, the console should return something like: function (t){var e=new p(t);try{u.emit(\"new-xhr\"... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see Troubleshooting browser monitoring installation. If you see a different response, you may be using another script or library that is conflicting with New Relic instrumentation. Contact support at support.newrelic.com. 3. Verify network access. If the object is properly instrumented, try triggering an AJAX call in your application while monitoring network traffic in the browser's developer tools. Wait up to one minute, and look for a call to bam.nr-data.net/jserrors with an xhr parameter. If the call fails, check for network issues. If you don't see this call, if it fails with an error not related to network access, or if it succeeds but you still aren't seeing data, get support at support.newrelic.com. If your requests use JSONP, see requirements and notes on functionality below: JSONP requirements If your requests use JSONP, these requests will not appear on the AJAX UI page. However, you can view them as assets within session traces. If using SPA monitoring, you can view them on the Breakdown tab of the Page views page. Requirements for JSONP to be recognized: Each JSONP request must use a unique callback function. Most popular libraries (like jQuery) generate a unique callback function dynamically for each request. The query string callback must be named \"callback\" or \"cb\" in order to be recognized by New Relic. This is the default behavior in most popular libraries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> AJAX data collection",
        "sections": "<em>Troubleshoot</em> AJAX data collection",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ": function (t){var e=new p(t);try{u.emit(&quot;new-xhr&quot;... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see <em>Troubleshooting</em> <em>browser</em> <em>monitoring</em> installation. If you see a different response, you may"
      },
      "id": "603e902d196a6762dea83d8a"
    },
    {
      "sections": [
        "Browser Summary page",
        "View the Summary page",
        "Core Web Vitals widgets",
        "User time on the site",
        "Initial page load and route change chart",
        "User-centric page load times chart",
        "Throughput chart",
        "Tip",
        "Front end vs. back end chart",
        "First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL",
        "Related Entities widget",
        "View Synthetics monitors"
      ],
      "title": "Browser Summary page",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Getting started"
      ],
      "external_id": "a69bb31a3bff73ef8badce5ce435da62e9e7b644",
      "image": "https://docs.newrelic.com/static/e61bbb246d462250e94c99bf637b9cca/c1b63/browser_summary_page.png",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/getting-started/browser-summary-page/",
      "published_at": "2021-12-19T15:18:58Z",
      "updated_at": "2021-12-10T02:30:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's Summary page summarizes the real-user browser performance of your app. Use the Summary page to: View trends in an app's browser-side performance Quickly troubleshoot page load timing issues Navigate to other browser UI pages View the Summary page To view a summary of browser performance for an app: Go to one.newrelic.com > Explorer > Browser applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com, click Browser, and select an app from the Browser index. From the app's Summary page, use standard New Relic page functions to drill down into detailed information. one.newrelic.com > Browser > (select an app) > Summary: After you select an application from the browser apps index, the Summary page shows a summary of browser performance for that app. The Summary page includes: Core Web Vitals widgets User time on the site Initial page load and route change chart User-centric page load times chart Throughput chart Front end vs. back end chart First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL Related Entities widget View Synthetics monitors Core Web Vitals widgets The Core Web Vitals widgets show how your browser performs according to Google's Core Web Vitals. The Core Web Vitals widgets include: LCP - Largest Contentful Paint FID - First Input Delay CLS - Cumulative Layout Shift User time on the site The User time on the site widget shows the time a user remains on the site. Initial page load and route change chart The Initial page load and route change chart shows the load time of a traditional URL change stemming from a load or reload of a URL. This chart appears with more detail about the page load timing process on the page load time page. User-centric page load times chart The User-centric page load times chart shows the load time of a page for a user. This chart appears with more detail about the page load timing process on the page load time page. Throughput chart The Throughput chart displays browser throughput as pages per minute (ppm). The value in the upper right of the chart is the average value for the selected time range. If you have enabled SPA monitoring enabled and the Summary page shows the SPA load time chart, the Throughput chart will also use SPA data. Tip App server requests per minute (rpm) may show a different measurement than the browser page load timing's pages per minute (ppm). Front end vs. back end chart The Front end vs. back end chart links to the connect APM service application. For details on APM and tracing, see Language agents and distributed tracing. First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL You'll also see summary versions of these metrics from the page load time page and JavaScript errors page: First interaction by device type First interaction by user agent JavaScript errors Longest first input delay by URL Related Entities widget The Related Entities widget shows all the entities that are related to the browser. To understand more about connections between entities, read about Entity relationships. View Synthetics monitors The button directs you to the Synthetics page. To read more about Synthetics, see Synthetic monitoring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.82831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> Summary page",
        "sections": "<em>Browser</em> Summary page",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s Summary page summarizes the real-user <em>browser</em> performance of your app. Use the Summary page to: View trends in an app&#x27;s <em>browser</em>-side performance Quickly <em>troubleshoot</em> page load timing issues Navigate to other <em>browser</em> UI pages View the Summary page To view a summary of <em>browser</em>"
      },
      "id": "60440d9c196a674ac8960f5b"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools": [
    {
      "sections": [
        "AJAX call fails with a CORS redirect error message",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "AJAX call fails with a CORS redirect error message",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "a4e478428acefb454ab8969cccb666d03ae458f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/ajax-call-fails-cors-redirect-error-message/",
      "published_at": "2021-12-19T13:56:44Z",
      "updated_at": "2021-11-13T07:04:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem A redirected AJAX call is being rejected with a CORS error message, for example: Access to XMLHttpRequest at 'https://my-domain-2/path' (redirected from 'https://my-domain-1/path') from origin 'https://my-website-domain' has been blocked by CORS policy: Request header field x-newrelic-id is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The browser agent automatically adds custom headers to outgoing same-origin AJAX calls in order to support the Distributed Tracing feature. When the server that receives the AJAX call responds with a redirect status code (such as 302), the browser will automatically make the same AJAX call to the redirected URL. And if this new URL is on a different origin and the call does not pass the CORS preflight, the browser will fail the call with the error message listed above.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The <em>browser</em> agent"
      },
      "id": "603eb41ce7b9d2ce042a07db"
    },
    {
      "sections": [
        "Troubleshoot AJAX data collection",
        "Problem",
        "Solution",
        "1. Verify you use XMLHttpRequest.",
        "2. Verify the object is instrumented.",
        "3. Verify network access.",
        "JSONP requirements"
      ],
      "title": "Troubleshoot AJAX data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "8dc486fa0fbb0a07f5e93c3cf75590e3e03bba2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/troubleshoot-ajax-data-collection/",
      "published_at": "2021-12-19T13:52:53Z",
      "updated_at": "2021-11-13T07:03:46Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are not seeing AJAX data for your browser app. Solution If your application is instrumented with browser monitoring and is correctly collecting data for other Pro features, follow these steps: 1. Verify you use XMLHttpRequest. Check whether your application uses the XMLHttpRequest object to make AJAX calls. Browser monitoring: Other methods (including the newer Fetch API) currently are not supported when using browser Pro. Single-page app monitoring: Fetch is supported for AJAX requests within a browser interaction with SPA monitoring. If you are making requests using JSONP, see JSONP requirements. 2. Verify the object is instrumented. If you are using XMLHttpRequest, use your browser's dev console to verify that the object has been instrumented by New Relic. Enter the object name at your console. If instrumentation has succeeded, the console should return something like: function (t){var e=new p(t);try{u.emit(\"new-xhr\"... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see Troubleshooting browser monitoring installation. If you see a different response, you may be using another script or library that is conflicting with New Relic instrumentation. Contact support at support.newrelic.com. 3. Verify network access. If the object is properly instrumented, try triggering an AJAX call in your application while monitoring network traffic in the browser's developer tools. Wait up to one minute, and look for a call to bam.nr-data.net/jserrors with an xhr parameter. If the call fails, check for network issues. If you don't see this call, if it fails with an error not related to network access, or if it succeeds but you still aren't seeing data, get support at support.newrelic.com. If your requests use JSONP, see requirements and notes on functionality below: JSONP requirements If your requests use JSONP, these requests will not appear on the AJAX UI page. However, you can view them as assets within session traces. If using SPA monitoring, you can view them on the Breakdown tab of the Page views page. Requirements for JSONP to be recognized: Each JSONP request must use a unique callback function. Most popular libraries (like jQuery) generate a unique callback function dynamically for each request. The query string callback must be named \"callback\" or \"cb\" in order to be recognized by New Relic. This is the default behavior in most popular libraries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> AJAX data collection",
        "sections": "<em>Troubleshoot</em> AJAX data collection",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ": function (t){var e=new p(t);try{u.emit(&quot;new-xhr&quot;... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see <em>Troubleshooting</em> <em>browser</em> <em>monitoring</em> installation. If you see a different response, you may"
      },
      "id": "603e902d196a6762dea83d8a"
    },
    {
      "sections": [
        "Browser Summary page",
        "View the Summary page",
        "Core Web Vitals widgets",
        "User time on the site",
        "Initial page load and route change chart",
        "User-centric page load times chart",
        "Throughput chart",
        "Tip",
        "Front end vs. back end chart",
        "First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL",
        "Related Entities widget",
        "View Synthetics monitors"
      ],
      "title": "Browser Summary page",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Getting started"
      ],
      "external_id": "a69bb31a3bff73ef8badce5ce435da62e9e7b644",
      "image": "https://docs.newrelic.com/static/e61bbb246d462250e94c99bf637b9cca/c1b63/browser_summary_page.png",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/getting-started/browser-summary-page/",
      "published_at": "2021-12-19T15:18:58Z",
      "updated_at": "2021-12-10T02:30:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's Summary page summarizes the real-user browser performance of your app. Use the Summary page to: View trends in an app's browser-side performance Quickly troubleshoot page load timing issues Navigate to other browser UI pages View the Summary page To view a summary of browser performance for an app: Go to one.newrelic.com > Explorer > Browser applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com, click Browser, and select an app from the Browser index. From the app's Summary page, use standard New Relic page functions to drill down into detailed information. one.newrelic.com > Browser > (select an app) > Summary: After you select an application from the browser apps index, the Summary page shows a summary of browser performance for that app. The Summary page includes: Core Web Vitals widgets User time on the site Initial page load and route change chart User-centric page load times chart Throughput chart Front end vs. back end chart First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL Related Entities widget View Synthetics monitors Core Web Vitals widgets The Core Web Vitals widgets show how your browser performs according to Google's Core Web Vitals. The Core Web Vitals widgets include: LCP - Largest Contentful Paint FID - First Input Delay CLS - Cumulative Layout Shift User time on the site The User time on the site widget shows the time a user remains on the site. Initial page load and route change chart The Initial page load and route change chart shows the load time of a traditional URL change stemming from a load or reload of a URL. This chart appears with more detail about the page load timing process on the page load time page. User-centric page load times chart The User-centric page load times chart shows the load time of a page for a user. This chart appears with more detail about the page load timing process on the page load time page. Throughput chart The Throughput chart displays browser throughput as pages per minute (ppm). The value in the upper right of the chart is the average value for the selected time range. If you have enabled SPA monitoring enabled and the Summary page shows the SPA load time chart, the Throughput chart will also use SPA data. Tip App server requests per minute (rpm) may show a different measurement than the browser page load timing's pages per minute (ppm). Front end vs. back end chart The Front end vs. back end chart links to the connect APM service application. For details on APM and tracing, see Language agents and distributed tracing. First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL You'll also see summary versions of these metrics from the page load time page and JavaScript errors page: First interaction by device type First interaction by user agent JavaScript errors Longest first input delay by URL Related Entities widget The Related Entities widget shows all the entities that are related to the browser. To understand more about connections between entities, read about Entity relationships. View Synthetics monitors The button directs you to the Synthetics page. To read more about Synthetics, see Synthetic monitoring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.82831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> Summary page",
        "sections": "<em>Browser</em> Summary page",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s Summary page summarizes the real-user <em>browser</em> performance of your app. Use the Summary page to: View trends in an app&#x27;s <em>browser</em>-side performance Quickly <em>troubleshoot</em> page load timing issues Navigate to other <em>browser</em> UI pages View the Summary page To view a summary of <em>browser</em>"
      },
      "id": "60440d9c196a674ac8960f5b"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/browser-javascript-injection-causes-problems-page": [
    {
      "sections": [
        "AJAX call fails with a CORS redirect error message",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "AJAX call fails with a CORS redirect error message",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "a4e478428acefb454ab8969cccb666d03ae458f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/ajax-call-fails-cors-redirect-error-message/",
      "published_at": "2021-12-19T13:56:44Z",
      "updated_at": "2021-11-13T07:04:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem A redirected AJAX call is being rejected with a CORS error message, for example: Access to XMLHttpRequest at 'https://my-domain-2/path' (redirected from 'https://my-domain-1/path') from origin 'https://my-website-domain' has been blocked by CORS policy: Request header field x-newrelic-id is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The browser agent automatically adds custom headers to outgoing same-origin AJAX calls in order to support the Distributed Tracing feature. When the server that receives the AJAX call responds with a redirect status code (such as 302), the browser will automatically make the same AJAX call to the redirected URL. And if this new URL is on a different origin and the call does not pass the CORS preflight, the browser will fail the call with the error message listed above.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The <em>browser</em> agent"
      },
      "id": "603eb41ce7b9d2ce042a07db"
    },
    {
      "sections": [
        "Troubleshoot AJAX data collection",
        "Problem",
        "Solution",
        "1. Verify you use XMLHttpRequest.",
        "2. Verify the object is instrumented.",
        "3. Verify network access.",
        "JSONP requirements"
      ],
      "title": "Troubleshoot AJAX data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "8dc486fa0fbb0a07f5e93c3cf75590e3e03bba2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/troubleshoot-ajax-data-collection/",
      "published_at": "2021-12-19T13:52:53Z",
      "updated_at": "2021-11-13T07:03:46Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are not seeing AJAX data for your browser app. Solution If your application is instrumented with browser monitoring and is correctly collecting data for other Pro features, follow these steps: 1. Verify you use XMLHttpRequest. Check whether your application uses the XMLHttpRequest object to make AJAX calls. Browser monitoring: Other methods (including the newer Fetch API) currently are not supported when using browser Pro. Single-page app monitoring: Fetch is supported for AJAX requests within a browser interaction with SPA monitoring. If you are making requests using JSONP, see JSONP requirements. 2. Verify the object is instrumented. If you are using XMLHttpRequest, use your browser's dev console to verify that the object has been instrumented by New Relic. Enter the object name at your console. If instrumentation has succeeded, the console should return something like: function (t){var e=new p(t);try{u.emit(\"new-xhr\"... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see Troubleshooting browser monitoring installation. If you see a different response, you may be using another script or library that is conflicting with New Relic instrumentation. Contact support at support.newrelic.com. 3. Verify network access. If the object is properly instrumented, try triggering an AJAX call in your application while monitoring network traffic in the browser's developer tools. Wait up to one minute, and look for a call to bam.nr-data.net/jserrors with an xhr parameter. If the call fails, check for network issues. If you don't see this call, if it fails with an error not related to network access, or if it succeeds but you still aren't seeing data, get support at support.newrelic.com. If your requests use JSONP, see requirements and notes on functionality below: JSONP requirements If your requests use JSONP, these requests will not appear on the AJAX UI page. However, you can view them as assets within session traces. If using SPA monitoring, you can view them on the Breakdown tab of the Page views page. Requirements for JSONP to be recognized: Each JSONP request must use a unique callback function. Most popular libraries (like jQuery) generate a unique callback function dynamically for each request. The query string callback must be named \"callback\" or \"cb\" in order to be recognized by New Relic. This is the default behavior in most popular libraries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> AJAX data collection",
        "sections": "<em>Troubleshoot</em> AJAX data collection",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ": function (t){var e=new p(t);try{u.emit(&quot;new-xhr&quot;... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see <em>Troubleshooting</em> <em>browser</em> <em>monitoring</em> installation. If you see a different response, you may"
      },
      "id": "603e902d196a6762dea83d8a"
    },
    {
      "sections": [
        "Browser Summary page",
        "View the Summary page",
        "Core Web Vitals widgets",
        "User time on the site",
        "Initial page load and route change chart",
        "User-centric page load times chart",
        "Throughput chart",
        "Tip",
        "Front end vs. back end chart",
        "First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL",
        "Related Entities widget",
        "View Synthetics monitors"
      ],
      "title": "Browser Summary page",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Getting started"
      ],
      "external_id": "a69bb31a3bff73ef8badce5ce435da62e9e7b644",
      "image": "https://docs.newrelic.com/static/e61bbb246d462250e94c99bf637b9cca/c1b63/browser_summary_page.png",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/getting-started/browser-summary-page/",
      "published_at": "2021-12-19T15:18:58Z",
      "updated_at": "2021-12-10T02:30:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's Summary page summarizes the real-user browser performance of your app. Use the Summary page to: View trends in an app's browser-side performance Quickly troubleshoot page load timing issues Navigate to other browser UI pages View the Summary page To view a summary of browser performance for an app: Go to one.newrelic.com > Explorer > Browser applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com, click Browser, and select an app from the Browser index. From the app's Summary page, use standard New Relic page functions to drill down into detailed information. one.newrelic.com > Browser > (select an app) > Summary: After you select an application from the browser apps index, the Summary page shows a summary of browser performance for that app. The Summary page includes: Core Web Vitals widgets User time on the site Initial page load and route change chart User-centric page load times chart Throughput chart Front end vs. back end chart First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL Related Entities widget View Synthetics monitors Core Web Vitals widgets The Core Web Vitals widgets show how your browser performs according to Google's Core Web Vitals. The Core Web Vitals widgets include: LCP - Largest Contentful Paint FID - First Input Delay CLS - Cumulative Layout Shift User time on the site The User time on the site widget shows the time a user remains on the site. Initial page load and route change chart The Initial page load and route change chart shows the load time of a traditional URL change stemming from a load or reload of a URL. This chart appears with more detail about the page load timing process on the page load time page. User-centric page load times chart The User-centric page load times chart shows the load time of a page for a user. This chart appears with more detail about the page load timing process on the page load time page. Throughput chart The Throughput chart displays browser throughput as pages per minute (ppm). The value in the upper right of the chart is the average value for the selected time range. If you have enabled SPA monitoring enabled and the Summary page shows the SPA load time chart, the Throughput chart will also use SPA data. Tip App server requests per minute (rpm) may show a different measurement than the browser page load timing's pages per minute (ppm). Front end vs. back end chart The Front end vs. back end chart links to the connect APM service application. For details on APM and tracing, see Language agents and distributed tracing. First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL You'll also see summary versions of these metrics from the page load time page and JavaScript errors page: First interaction by device type First interaction by user agent JavaScript errors Longest first input delay by URL Related Entities widget The Related Entities widget shows all the entities that are related to the browser. To understand more about connections between entities, read about Entity relationships. View Synthetics monitors The button directs you to the Synthetics page. To read more about Synthetics, see Synthetic monitoring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.8283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> Summary page",
        "sections": "<em>Browser</em> Summary page",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s Summary page summarizes the real-user <em>browser</em> performance of your app. Use the Summary page to: View trends in an app&#x27;s <em>browser</em>-side performance Quickly <em>troubleshoot</em> page load timing issues Navigate to other <em>browser</em> UI pages View the Summary page To view a summary of <em>browser</em>"
      },
      "id": "60440d9c196a674ac8960f5b"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/get-browser-side-troubleshooting-details-har-file": [
    {
      "sections": [
        "AJAX call fails with a CORS redirect error message",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "AJAX call fails with a CORS redirect error message",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "a4e478428acefb454ab8969cccb666d03ae458f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/ajax-call-fails-cors-redirect-error-message/",
      "published_at": "2021-12-19T13:56:44Z",
      "updated_at": "2021-11-13T07:04:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem A redirected AJAX call is being rejected with a CORS error message, for example: Access to XMLHttpRequest at 'https://my-domain-2/path' (redirected from 'https://my-domain-1/path') from origin 'https://my-website-domain' has been blocked by CORS policy: Request header field x-newrelic-id is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The browser agent automatically adds custom headers to outgoing same-origin AJAX calls in order to support the Distributed Tracing feature. When the server that receives the AJAX call responds with a redirect status code (such as 302), the browser will automatically make the same AJAX call to the redirected URL. And if this new URL is on a different origin and the call does not pass the CORS preflight, the browser will fail the call with the error message listed above.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The <em>browser</em> agent"
      },
      "id": "603eb41ce7b9d2ce042a07db"
    },
    {
      "sections": [
        "Troubleshoot AJAX data collection",
        "Problem",
        "Solution",
        "1. Verify you use XMLHttpRequest.",
        "2. Verify the object is instrumented.",
        "3. Verify network access.",
        "JSONP requirements"
      ],
      "title": "Troubleshoot AJAX data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "8dc486fa0fbb0a07f5e93c3cf75590e3e03bba2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/troubleshoot-ajax-data-collection/",
      "published_at": "2021-12-19T13:52:53Z",
      "updated_at": "2021-11-13T07:03:46Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are not seeing AJAX data for your browser app. Solution If your application is instrumented with browser monitoring and is correctly collecting data for other Pro features, follow these steps: 1. Verify you use XMLHttpRequest. Check whether your application uses the XMLHttpRequest object to make AJAX calls. Browser monitoring: Other methods (including the newer Fetch API) currently are not supported when using browser Pro. Single-page app monitoring: Fetch is supported for AJAX requests within a browser interaction with SPA monitoring. If you are making requests using JSONP, see JSONP requirements. 2. Verify the object is instrumented. If you are using XMLHttpRequest, use your browser's dev console to verify that the object has been instrumented by New Relic. Enter the object name at your console. If instrumentation has succeeded, the console should return something like: function (t){var e=new p(t);try{u.emit(\"new-xhr\"... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see Troubleshooting browser monitoring installation. If you see a different response, you may be using another script or library that is conflicting with New Relic instrumentation. Contact support at support.newrelic.com. 3. Verify network access. If the object is properly instrumented, try triggering an AJAX call in your application while monitoring network traffic in the browser's developer tools. Wait up to one minute, and look for a call to bam.nr-data.net/jserrors with an xhr parameter. If the call fails, check for network issues. If you don't see this call, if it fails with an error not related to network access, or if it succeeds but you still aren't seeing data, get support at support.newrelic.com. If your requests use JSONP, see requirements and notes on functionality below: JSONP requirements If your requests use JSONP, these requests will not appear on the AJAX UI page. However, you can view them as assets within session traces. If using SPA monitoring, you can view them on the Breakdown tab of the Page views page. Requirements for JSONP to be recognized: Each JSONP request must use a unique callback function. Most popular libraries (like jQuery) generate a unique callback function dynamically for each request. The query string callback must be named \"callback\" or \"cb\" in order to be recognized by New Relic. This is the default behavior in most popular libraries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> AJAX data collection",
        "sections": "<em>Troubleshoot</em> AJAX data collection",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ": function (t){var e=new p(t);try{u.emit(&quot;new-xhr&quot;... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see <em>Troubleshooting</em> <em>browser</em> <em>monitoring</em> installation. If you see a different response, you may"
      },
      "id": "603e902d196a6762dea83d8a"
    },
    {
      "sections": [
        "Browser Summary page",
        "View the Summary page",
        "Core Web Vitals widgets",
        "User time on the site",
        "Initial page load and route change chart",
        "User-centric page load times chart",
        "Throughput chart",
        "Tip",
        "Front end vs. back end chart",
        "First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL",
        "Related Entities widget",
        "View Synthetics monitors"
      ],
      "title": "Browser Summary page",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Getting started"
      ],
      "external_id": "a69bb31a3bff73ef8badce5ce435da62e9e7b644",
      "image": "https://docs.newrelic.com/static/e61bbb246d462250e94c99bf637b9cca/c1b63/browser_summary_page.png",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/getting-started/browser-summary-page/",
      "published_at": "2021-12-19T15:18:58Z",
      "updated_at": "2021-12-10T02:30:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's Summary page summarizes the real-user browser performance of your app. Use the Summary page to: View trends in an app's browser-side performance Quickly troubleshoot page load timing issues Navigate to other browser UI pages View the Summary page To view a summary of browser performance for an app: Go to one.newrelic.com > Explorer > Browser applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com, click Browser, and select an app from the Browser index. From the app's Summary page, use standard New Relic page functions to drill down into detailed information. one.newrelic.com > Browser > (select an app) > Summary: After you select an application from the browser apps index, the Summary page shows a summary of browser performance for that app. The Summary page includes: Core Web Vitals widgets User time on the site Initial page load and route change chart User-centric page load times chart Throughput chart Front end vs. back end chart First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL Related Entities widget View Synthetics monitors Core Web Vitals widgets The Core Web Vitals widgets show how your browser performs according to Google's Core Web Vitals. The Core Web Vitals widgets include: LCP - Largest Contentful Paint FID - First Input Delay CLS - Cumulative Layout Shift User time on the site The User time on the site widget shows the time a user remains on the site. Initial page load and route change chart The Initial page load and route change chart shows the load time of a traditional URL change stemming from a load or reload of a URL. This chart appears with more detail about the page load timing process on the page load time page. User-centric page load times chart The User-centric page load times chart shows the load time of a page for a user. This chart appears with more detail about the page load timing process on the page load time page. Throughput chart The Throughput chart displays browser throughput as pages per minute (ppm). The value in the upper right of the chart is the average value for the selected time range. If you have enabled SPA monitoring enabled and the Summary page shows the SPA load time chart, the Throughput chart will also use SPA data. Tip App server requests per minute (rpm) may show a different measurement than the browser page load timing's pages per minute (ppm). Front end vs. back end chart The Front end vs. back end chart links to the connect APM service application. For details on APM and tracing, see Language agents and distributed tracing. First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL You'll also see summary versions of these metrics from the page load time page and JavaScript errors page: First interaction by device type First interaction by user agent JavaScript errors Longest first input delay by URL Related Entities widget The Related Entities widget shows all the entities that are related to the browser. To understand more about connections between entities, read about Entity relationships. View Synthetics monitors The button directs you to the Synthetics page. To read more about Synthetics, see Synthetic monitoring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.8283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> Summary page",
        "sections": "<em>Browser</em> Summary page",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s Summary page summarizes the real-user <em>browser</em> performance of your app. Use the Summary page to: View trends in an app&#x27;s <em>browser</em>-side performance Quickly <em>troubleshoot</em> page load timing issues Navigate to other <em>browser</em> UI pages View the Summary page To view a summary of <em>browser</em>"
      },
      "id": "60440d9c196a674ac8960f5b"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/not-seeing-specific-page-or-endpoint-names-browser-data": [
    {
      "sections": [
        "AJAX call fails with a CORS redirect error message",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "AJAX call fails with a CORS redirect error message",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "a4e478428acefb454ab8969cccb666d03ae458f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/ajax-call-fails-cors-redirect-error-message/",
      "published_at": "2021-12-19T13:56:44Z",
      "updated_at": "2021-11-13T07:04:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem A redirected AJAX call is being rejected with a CORS error message, for example: Access to XMLHttpRequest at 'https://my-domain-2/path' (redirected from 'https://my-domain-1/path') from origin 'https://my-website-domain' has been blocked by CORS policy: Request header field x-newrelic-id is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The browser agent automatically adds custom headers to outgoing same-origin AJAX calls in order to support the Distributed Tracing feature. When the server that receives the AJAX call responds with a redirect status code (such as 302), the browser will automatically make the same AJAX call to the redirected URL. And if this new URL is on a different origin and the call does not pass the CORS preflight, the browser will fail the call with the error message listed above.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The <em>browser</em> agent"
      },
      "id": "603eb41ce7b9d2ce042a07db"
    },
    {
      "sections": [
        "Troubleshoot AJAX data collection",
        "Problem",
        "Solution",
        "1. Verify you use XMLHttpRequest.",
        "2. Verify the object is instrumented.",
        "3. Verify network access.",
        "JSONP requirements"
      ],
      "title": "Troubleshoot AJAX data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "8dc486fa0fbb0a07f5e93c3cf75590e3e03bba2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/troubleshoot-ajax-data-collection/",
      "published_at": "2021-12-19T13:52:53Z",
      "updated_at": "2021-11-13T07:03:46Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are not seeing AJAX data for your browser app. Solution If your application is instrumented with browser monitoring and is correctly collecting data for other Pro features, follow these steps: 1. Verify you use XMLHttpRequest. Check whether your application uses the XMLHttpRequest object to make AJAX calls. Browser monitoring: Other methods (including the newer Fetch API) currently are not supported when using browser Pro. Single-page app monitoring: Fetch is supported for AJAX requests within a browser interaction with SPA monitoring. If you are making requests using JSONP, see JSONP requirements. 2. Verify the object is instrumented. If you are using XMLHttpRequest, use your browser's dev console to verify that the object has been instrumented by New Relic. Enter the object name at your console. If instrumentation has succeeded, the console should return something like: function (t){var e=new p(t);try{u.emit(\"new-xhr\"... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see Troubleshooting browser monitoring installation. If you see a different response, you may be using another script or library that is conflicting with New Relic instrumentation. Contact support at support.newrelic.com. 3. Verify network access. If the object is properly instrumented, try triggering an AJAX call in your application while monitoring network traffic in the browser's developer tools. Wait up to one minute, and look for a call to bam.nr-data.net/jserrors with an xhr parameter. If the call fails, check for network issues. If you don't see this call, if it fails with an error not related to network access, or if it succeeds but you still aren't seeing data, get support at support.newrelic.com. If your requests use JSONP, see requirements and notes on functionality below: JSONP requirements If your requests use JSONP, these requests will not appear on the AJAX UI page. However, you can view them as assets within session traces. If using SPA monitoring, you can view them on the Breakdown tab of the Page views page. Requirements for JSONP to be recognized: Each JSONP request must use a unique callback function. Most popular libraries (like jQuery) generate a unique callback function dynamically for each request. The query string callback must be named \"callback\" or \"cb\" in order to be recognized by New Relic. This is the default behavior in most popular libraries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> AJAX data collection",
        "sections": "<em>Troubleshoot</em> AJAX data collection",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ": function (t){var e=new p(t);try{u.emit(&quot;new-xhr&quot;... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see <em>Troubleshooting</em> <em>browser</em> <em>monitoring</em> installation. If you see a different response, you may"
      },
      "id": "603e902d196a6762dea83d8a"
    },
    {
      "sections": [
        "Browser Summary page",
        "View the Summary page",
        "Core Web Vitals widgets",
        "User time on the site",
        "Initial page load and route change chart",
        "User-centric page load times chart",
        "Throughput chart",
        "Tip",
        "Front end vs. back end chart",
        "First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL",
        "Related Entities widget",
        "View Synthetics monitors"
      ],
      "title": "Browser Summary page",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Getting started"
      ],
      "external_id": "a69bb31a3bff73ef8badce5ce435da62e9e7b644",
      "image": "https://docs.newrelic.com/static/e61bbb246d462250e94c99bf637b9cca/c1b63/browser_summary_page.png",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/getting-started/browser-summary-page/",
      "published_at": "2021-12-19T15:18:58Z",
      "updated_at": "2021-12-10T02:30:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's Summary page summarizes the real-user browser performance of your app. Use the Summary page to: View trends in an app's browser-side performance Quickly troubleshoot page load timing issues Navigate to other browser UI pages View the Summary page To view a summary of browser performance for an app: Go to one.newrelic.com > Explorer > Browser applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com, click Browser, and select an app from the Browser index. From the app's Summary page, use standard New Relic page functions to drill down into detailed information. one.newrelic.com > Browser > (select an app) > Summary: After you select an application from the browser apps index, the Summary page shows a summary of browser performance for that app. The Summary page includes: Core Web Vitals widgets User time on the site Initial page load and route change chart User-centric page load times chart Throughput chart Front end vs. back end chart First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL Related Entities widget View Synthetics monitors Core Web Vitals widgets The Core Web Vitals widgets show how your browser performs according to Google's Core Web Vitals. The Core Web Vitals widgets include: LCP - Largest Contentful Paint FID - First Input Delay CLS - Cumulative Layout Shift User time on the site The User time on the site widget shows the time a user remains on the site. Initial page load and route change chart The Initial page load and route change chart shows the load time of a traditional URL change stemming from a load or reload of a URL. This chart appears with more detail about the page load timing process on the page load time page. User-centric page load times chart The User-centric page load times chart shows the load time of a page for a user. This chart appears with more detail about the page load timing process on the page load time page. Throughput chart The Throughput chart displays browser throughput as pages per minute (ppm). The value in the upper right of the chart is the average value for the selected time range. If you have enabled SPA monitoring enabled and the Summary page shows the SPA load time chart, the Throughput chart will also use SPA data. Tip App server requests per minute (rpm) may show a different measurement than the browser page load timing's pages per minute (ppm). Front end vs. back end chart The Front end vs. back end chart links to the connect APM service application. For details on APM and tracing, see Language agents and distributed tracing. First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL You'll also see summary versions of these metrics from the page load time page and JavaScript errors page: First interaction by device type First interaction by user agent JavaScript errors Longest first input delay by URL Related Entities widget The Related Entities widget shows all the entities that are related to the browser. To understand more about connections between entities, read about Entity relationships. View Synthetics monitors The button directs you to the Synthetics page. To read more about Synthetics, see Synthetic monitoring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.82826,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> Summary page",
        "sections": "<em>Browser</em> Summary page",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s Summary page summarizes the real-user <em>browser</em> performance of your app. Use the Summary page to: View trends in an app&#x27;s <em>browser</em>-side performance Quickly <em>troubleshoot</em> page load timing issues Navigate to other <em>browser</em> UI pages View the Summary page To view a summary of <em>browser</em>"
      },
      "id": "60440d9c196a674ac8960f5b"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/third-party-js-errors-missing-stack-traces": [
    {
      "sections": [
        "AJAX call fails with a CORS redirect error message",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "AJAX call fails with a CORS redirect error message",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "a4e478428acefb454ab8969cccb666d03ae458f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/ajax-call-fails-cors-redirect-error-message/",
      "published_at": "2021-12-19T13:56:44Z",
      "updated_at": "2021-11-13T07:04:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem A redirected AJAX call is being rejected with a CORS error message, for example: Access to XMLHttpRequest at 'https://my-domain-2/path' (redirected from 'https://my-domain-1/path') from origin 'https://my-website-domain' has been blocked by CORS policy: Request header field x-newrelic-id is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The browser agent automatically adds custom headers to outgoing same-origin AJAX calls in order to support the Distributed Tracing feature. When the server that receives the AJAX call responds with a redirect status code (such as 302), the browser will automatically make the same AJAX call to the redirected URL. And if this new URL is on a different origin and the call does not pass the CORS preflight, the browser will fail the call with the error message listed above.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The <em>browser</em> agent"
      },
      "id": "603eb41ce7b9d2ce042a07db"
    },
    {
      "sections": [
        "Troubleshoot AJAX data collection",
        "Problem",
        "Solution",
        "1. Verify you use XMLHttpRequest.",
        "2. Verify the object is instrumented.",
        "3. Verify network access.",
        "JSONP requirements"
      ],
      "title": "Troubleshoot AJAX data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "8dc486fa0fbb0a07f5e93c3cf75590e3e03bba2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/troubleshoot-ajax-data-collection/",
      "published_at": "2021-12-19T13:52:53Z",
      "updated_at": "2021-11-13T07:03:46Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are not seeing AJAX data for your browser app. Solution If your application is instrumented with browser monitoring and is correctly collecting data for other Pro features, follow these steps: 1. Verify you use XMLHttpRequest. Check whether your application uses the XMLHttpRequest object to make AJAX calls. Browser monitoring: Other methods (including the newer Fetch API) currently are not supported when using browser Pro. Single-page app monitoring: Fetch is supported for AJAX requests within a browser interaction with SPA monitoring. If you are making requests using JSONP, see JSONP requirements. 2. Verify the object is instrumented. If you are using XMLHttpRequest, use your browser's dev console to verify that the object has been instrumented by New Relic. Enter the object name at your console. If instrumentation has succeeded, the console should return something like: function (t){var e=new p(t);try{u.emit(\"new-xhr\"... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see Troubleshooting browser monitoring installation. If you see a different response, you may be using another script or library that is conflicting with New Relic instrumentation. Contact support at support.newrelic.com. 3. Verify network access. If the object is properly instrumented, try triggering an AJAX call in your application while monitoring network traffic in the browser's developer tools. Wait up to one minute, and look for a call to bam.nr-data.net/jserrors with an xhr parameter. If the call fails, check for network issues. If you don't see this call, if it fails with an error not related to network access, or if it succeeds but you still aren't seeing data, get support at support.newrelic.com. If your requests use JSONP, see requirements and notes on functionality below: JSONP requirements If your requests use JSONP, these requests will not appear on the AJAX UI page. However, you can view them as assets within session traces. If using SPA monitoring, you can view them on the Breakdown tab of the Page views page. Requirements for JSONP to be recognized: Each JSONP request must use a unique callback function. Most popular libraries (like jQuery) generate a unique callback function dynamically for each request. The query string callback must be named \"callback\" or \"cb\" in order to be recognized by New Relic. This is the default behavior in most popular libraries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> AJAX data collection",
        "sections": "<em>Troubleshoot</em> AJAX data collection",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ": function (t){var e=new p(t);try{u.emit(&quot;new-xhr&quot;... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see <em>Troubleshooting</em> <em>browser</em> <em>monitoring</em> installation. If you see a different response, you may"
      },
      "id": "603e902d196a6762dea83d8a"
    },
    {
      "sections": [
        "Browser Summary page",
        "View the Summary page",
        "Core Web Vitals widgets",
        "User time on the site",
        "Initial page load and route change chart",
        "User-centric page load times chart",
        "Throughput chart",
        "Tip",
        "Front end vs. back end chart",
        "First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL",
        "Related Entities widget",
        "View Synthetics monitors"
      ],
      "title": "Browser Summary page",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Getting started"
      ],
      "external_id": "a69bb31a3bff73ef8badce5ce435da62e9e7b644",
      "image": "https://docs.newrelic.com/static/e61bbb246d462250e94c99bf637b9cca/c1b63/browser_summary_page.png",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/getting-started/browser-summary-page/",
      "published_at": "2021-12-19T15:18:58Z",
      "updated_at": "2021-12-10T02:30:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's Summary page summarizes the real-user browser performance of your app. Use the Summary page to: View trends in an app's browser-side performance Quickly troubleshoot page load timing issues Navigate to other browser UI pages View the Summary page To view a summary of browser performance for an app: Go to one.newrelic.com > Explorer > Browser applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com, click Browser, and select an app from the Browser index. From the app's Summary page, use standard New Relic page functions to drill down into detailed information. one.newrelic.com > Browser > (select an app) > Summary: After you select an application from the browser apps index, the Summary page shows a summary of browser performance for that app. The Summary page includes: Core Web Vitals widgets User time on the site Initial page load and route change chart User-centric page load times chart Throughput chart Front end vs. back end chart First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL Related Entities widget View Synthetics monitors Core Web Vitals widgets The Core Web Vitals widgets show how your browser performs according to Google's Core Web Vitals. The Core Web Vitals widgets include: LCP - Largest Contentful Paint FID - First Input Delay CLS - Cumulative Layout Shift User time on the site The User time on the site widget shows the time a user remains on the site. Initial page load and route change chart The Initial page load and route change chart shows the load time of a traditional URL change stemming from a load or reload of a URL. This chart appears with more detail about the page load timing process on the page load time page. User-centric page load times chart The User-centric page load times chart shows the load time of a page for a user. This chart appears with more detail about the page load timing process on the page load time page. Throughput chart The Throughput chart displays browser throughput as pages per minute (ppm). The value in the upper right of the chart is the average value for the selected time range. If you have enabled SPA monitoring enabled and the Summary page shows the SPA load time chart, the Throughput chart will also use SPA data. Tip App server requests per minute (rpm) may show a different measurement than the browser page load timing's pages per minute (ppm). Front end vs. back end chart The Front end vs. back end chart links to the connect APM service application. For details on APM and tracing, see Language agents and distributed tracing. First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL You'll also see summary versions of these metrics from the page load time page and JavaScript errors page: First interaction by device type First interaction by user agent JavaScript errors Longest first input delay by URL Related Entities widget The Related Entities widget shows all the entities that are related to the browser. To understand more about connections between entities, read about Entity relationships. View Synthetics monitors The button directs you to the Synthetics page. To read more about Synthetics, see Synthetic monitoring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.82826,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> Summary page",
        "sections": "<em>Browser</em> Summary page",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s Summary page summarizes the real-user <em>browser</em> performance of your app. Use the Summary page to: View trends in an app&#x27;s <em>browser</em>-side performance Quickly <em>troubleshoot</em> page load timing issues Navigate to other <em>browser</em> UI pages View the Summary page To view a summary of <em>browser</em>"
      },
      "id": "60440d9c196a674ac8960f5b"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/troubleshoot-ajax-data-collection": [
    {
      "sections": [
        "AJAX call fails with a CORS redirect error message",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "AJAX call fails with a CORS redirect error message",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "a4e478428acefb454ab8969cccb666d03ae458f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/ajax-call-fails-cors-redirect-error-message/",
      "published_at": "2021-12-19T13:56:44Z",
      "updated_at": "2021-11-13T07:04:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem A redirected AJAX call is being rejected with a CORS error message, for example: Access to XMLHttpRequest at 'https://my-domain-2/path' (redirected from 'https://my-domain-1/path') from origin 'https://my-website-domain' has been blocked by CORS policy: Request header field x-newrelic-id is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The browser agent automatically adds custom headers to outgoing same-origin AJAX calls in order to support the Distributed Tracing feature. When the server that receives the AJAX call responds with a redirect status code (such as 302), the browser will automatically make the same AJAX call to the redirected URL. And if this new URL is on a different origin and the call does not pass the CORS preflight, the browser will fail the call with the error message listed above.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The <em>browser</em> agent"
      },
      "id": "603eb41ce7b9d2ce042a07db"
    },
    {
      "sections": [
        "Browser Summary page",
        "View the Summary page",
        "Core Web Vitals widgets",
        "User time on the site",
        "Initial page load and route change chart",
        "User-centric page load times chart",
        "Throughput chart",
        "Tip",
        "Front end vs. back end chart",
        "First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL",
        "Related Entities widget",
        "View Synthetics monitors"
      ],
      "title": "Browser Summary page",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Getting started"
      ],
      "external_id": "a69bb31a3bff73ef8badce5ce435da62e9e7b644",
      "image": "https://docs.newrelic.com/static/e61bbb246d462250e94c99bf637b9cca/c1b63/browser_summary_page.png",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/getting-started/browser-summary-page/",
      "published_at": "2021-12-19T15:18:58Z",
      "updated_at": "2021-12-10T02:30:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's Summary page summarizes the real-user browser performance of your app. Use the Summary page to: View trends in an app's browser-side performance Quickly troubleshoot page load timing issues Navigate to other browser UI pages View the Summary page To view a summary of browser performance for an app: Go to one.newrelic.com > Explorer > Browser applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com, click Browser, and select an app from the Browser index. From the app's Summary page, use standard New Relic page functions to drill down into detailed information. one.newrelic.com > Browser > (select an app) > Summary: After you select an application from the browser apps index, the Summary page shows a summary of browser performance for that app. The Summary page includes: Core Web Vitals widgets User time on the site Initial page load and route change chart User-centric page load times chart Throughput chart Front end vs. back end chart First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL Related Entities widget View Synthetics monitors Core Web Vitals widgets The Core Web Vitals widgets show how your browser performs according to Google's Core Web Vitals. The Core Web Vitals widgets include: LCP - Largest Contentful Paint FID - First Input Delay CLS - Cumulative Layout Shift User time on the site The User time on the site widget shows the time a user remains on the site. Initial page load and route change chart The Initial page load and route change chart shows the load time of a traditional URL change stemming from a load or reload of a URL. This chart appears with more detail about the page load timing process on the page load time page. User-centric page load times chart The User-centric page load times chart shows the load time of a page for a user. This chart appears with more detail about the page load timing process on the page load time page. Throughput chart The Throughput chart displays browser throughput as pages per minute (ppm). The value in the upper right of the chart is the average value for the selected time range. If you have enabled SPA monitoring enabled and the Summary page shows the SPA load time chart, the Throughput chart will also use SPA data. Tip App server requests per minute (rpm) may show a different measurement than the browser page load timing's pages per minute (ppm). Front end vs. back end chart The Front end vs. back end chart links to the connect APM service application. For details on APM and tracing, see Language agents and distributed tracing. First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL You'll also see summary versions of these metrics from the page load time page and JavaScript errors page: First interaction by device type First interaction by user agent JavaScript errors Longest first input delay by URL Related Entities widget The Related Entities widget shows all the entities that are related to the browser. To understand more about connections between entities, read about Entity relationships. View Synthetics monitors The button directs you to the Synthetics page. To read more about Synthetics, see Synthetic monitoring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.82826,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> Summary page",
        "sections": "<em>Browser</em> Summary page",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s Summary page summarizes the real-user <em>browser</em> performance of your app. Use the Summary page to: View trends in an app&#x27;s <em>browser</em>-side performance Quickly <em>troubleshoot</em> page load timing issues Navigate to other <em>browser</em> UI pages View the Summary page To view a summary of <em>browser</em>"
      },
      "id": "60440d9c196a674ac8960f5b"
    },
    {
      "sections": [
        "Install the browser monitoring agent",
        "Enable browser monitoring",
        "Deployment options",
        "Enable an APM-monitored app",
        "Enable with copy/paste",
        "Instrument webpages using the APM agent",
        "Use REST API",
        "Browser agent types: Lite, Pro, Pro+SPA"
      ],
      "title": "Install the browser monitoring agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Installation"
      ],
      "external_id": "bc45bbc86cd4d8b81367ad0904907ddc735717f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/installation/install-browser-monitoring-agent/",
      "published_at": "2021-12-19T15:19:26Z",
      "updated_at": "2021-11-13T06:04:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser uses a JavaScript snippet, also referred to as an \"agent,\" to instrument your app's webpages. The JavaScript collects data for browser monitoring. To install the browser agent, you can choose from a number of deployment options. If you don't have one already, create a New Relic account. It's free, forever. Get an account Enable browser monitoring Browser Pro+SPA is the default agent when you enable browser monitoring. This automatically gives you access to all of our browser monitoring features. For more information about the browser monitoring options, see Browser agent types in this document. To enable browser monitoring: Go to one.newrelic.com, select Browser, and then select Add more data. Follow the instructions in the UI to add browser monitoring to your app. Generate some traffic for your app, then wait a few minutes for data to appear in New Relic. Optional: After installation is complete and you are seeing data, go to the App settings page for additional agent configuration, or to change the browser agent type. It may take several minutes after enabling the browser monitoring agent before your webpage data appear in New Relic. If have problems, follow our troubleshooting tips. Deployment options No matter which option you use to deploy browser monitoring, the end result is the same: the browser monitoring JavaScript snippet (also referred to as the \"agent\") is inserted into your app pages. The method you select depends on your preferences and business needs. Enable an APM-monitored app When enabling browser monitoring, you can use an APM agent to automatically inject the browser monitoring JavaScript snippet for you. This is the easiest way to install the agent for an app that's already being monitored by APM. APM-monitored apps are listed on your APM Applications index. Enable with copy/paste When enabling browser monitoring, you can manually insert the JavaScript snippet into your app's webpages. The copy/paste option gives you control over the exact placement of our JavaScript snippet, which is required to monitor the webpage's performance. This is useful for: Standalone apps, static sites, and cached pages delivered by CDN APM apps that are not as closely coupled to the browser app as with a standard server-side app (for example, when your client-side app talks to a REST API back end) Some tips for using the JavaScript snippet: Placement in your webpage: Copy the code snippet, then paste it inline into your pages as close to the top of the <head> element as possible, but after any position-sensitive <meta> tags (for example, X-UA-Compatible or charset information). For more information on the inline head placement, see JavaScript placement requirements. License key and app ID: Near the bottom of the generated JavaScript is your browser license key and application ID. This is useful with the REST API and API Explorer. Instrument webpages using the APM agent This information applies to apps that are also monitored by APM. Our APM agents can instrument webpages with the required JavaScript for page load timing. If you are using an APM agent's API to manually add the JavaScript snippet to your webpages, insert the instrumentation snippet as close to the top as possible. This allows you to take advantage of detailed information about browser's AJAX calls and JavaScript errors. For more information, see the instructions for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby Use REST API This information applies to apps that are also monitored by APM. The REST API lets you manage deployment outside the browser monitoring UI. This is useful for large organizations deploying multiple apps. Browser agent types: Lite, Pro, Pro+SPA We have three types of browser agents: Lite, Pro, and Pro+SPA. The agent type has no impact on your billing. Browser agent type Comparison Pro+SPA This is the default installed agent when you enable browser monitoring. What it includes: Gives you access to all of the Browser Pro features and to Single Page App (SPA) monitoring. Provides detailed page timing data and the most up-to-date New Relic features, including distributed tracing, for all types of applications. Pro+SPA is not limited only to single page applications. After install, you can downgrade anytime to the less advanced agents if you don't want or need SPA monitoring. Pro What it includes: Gives you access to the Browser Pro features. What it doesn't include: Lacks the functionality designed for single page app monitoring. Lite What it includes: Gives you information about some basic page load timing and browser user information. What it doesn't include: Lacks the Browser Pro features and SPA features. Details about how agent types relate to pricing: New Relic One pricing: This pricing model has data ingest as a billing factor. If you want to reduce data ingest, you may want to consider downgrading to lesser agent types after install. Original pricing: Your access to browser monitoring features is gated by your subscription plan, not by the agent type. This means there is no reason not to use the default Pro+SPA agent. After initial agent installation is finished, you can go to the App settings page to edit your configuration or to change your subscription.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.38617,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>browser</em> <em>monitoring</em> agent",
        "sections": "Install the <em>browser</em> <em>monitoring</em> agent",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " <em>troubleshooting</em> tips. Deployment options No matter which option you use to deploy <em>browser</em> <em>monitoring</em>, the end result is the same: the <em>browser</em> <em>monitoring</em> JavaScript snippet (also referred to as the &quot;agent&quot;) is inserted into your app pages. The method you select depends on your preferences and business needs"
      },
      "id": "604429e628ccbcb80b2c60d0"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/troubleshooting-session-trace-collection": [
    {
      "sections": [
        "AJAX call fails with a CORS redirect error message",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "AJAX call fails with a CORS redirect error message",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "a4e478428acefb454ab8969cccb666d03ae458f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/ajax-call-fails-cors-redirect-error-message/",
      "published_at": "2021-12-19T13:56:44Z",
      "updated_at": "2021-11-13T07:04:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem A redirected AJAX call is being rejected with a CORS error message, for example: Access to XMLHttpRequest at 'https://my-domain-2/path' (redirected from 'https://my-domain-1/path') from origin 'https://my-website-domain' has been blocked by CORS policy: Request header field x-newrelic-id is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The browser agent automatically adds custom headers to outgoing same-origin AJAX calls in order to support the Distributed Tracing feature. When the server that receives the AJAX call responds with a redirect status code (such as 302), the browser will automatically make the same AJAX call to the redirected URL. And if this new URL is on a different origin and the call does not pass the CORS preflight, the browser will fail the call with the error message listed above.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The <em>browser</em> agent"
      },
      "id": "603eb41ce7b9d2ce042a07db"
    },
    {
      "sections": [
        "Troubleshoot AJAX data collection",
        "Problem",
        "Solution",
        "1. Verify you use XMLHttpRequest.",
        "2. Verify the object is instrumented.",
        "3. Verify network access.",
        "JSONP requirements"
      ],
      "title": "Troubleshoot AJAX data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "8dc486fa0fbb0a07f5e93c3cf75590e3e03bba2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/troubleshoot-ajax-data-collection/",
      "published_at": "2021-12-19T13:52:53Z",
      "updated_at": "2021-11-13T07:03:46Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are not seeing AJAX data for your browser app. Solution If your application is instrumented with browser monitoring and is correctly collecting data for other Pro features, follow these steps: 1. Verify you use XMLHttpRequest. Check whether your application uses the XMLHttpRequest object to make AJAX calls. Browser monitoring: Other methods (including the newer Fetch API) currently are not supported when using browser Pro. Single-page app monitoring: Fetch is supported for AJAX requests within a browser interaction with SPA monitoring. If you are making requests using JSONP, see JSONP requirements. 2. Verify the object is instrumented. If you are using XMLHttpRequest, use your browser's dev console to verify that the object has been instrumented by New Relic. Enter the object name at your console. If instrumentation has succeeded, the console should return something like: function (t){var e=new p(t);try{u.emit(\"new-xhr\"... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see Troubleshooting browser monitoring installation. If you see a different response, you may be using another script or library that is conflicting with New Relic instrumentation. Contact support at support.newrelic.com. 3. Verify network access. If the object is properly instrumented, try triggering an AJAX call in your application while monitoring network traffic in the browser's developer tools. Wait up to one minute, and look for a call to bam.nr-data.net/jserrors with an xhr parameter. If the call fails, check for network issues. If you don't see this call, if it fails with an error not related to network access, or if it succeeds but you still aren't seeing data, get support at support.newrelic.com. If your requests use JSONP, see requirements and notes on functionality below: JSONP requirements If your requests use JSONP, these requests will not appear on the AJAX UI page. However, you can view them as assets within session traces. If using SPA monitoring, you can view them on the Breakdown tab of the Page views page. Requirements for JSONP to be recognized: Each JSONP request must use a unique callback function. Most popular libraries (like jQuery) generate a unique callback function dynamically for each request. The query string callback must be named \"callback\" or \"cb\" in order to be recognized by New Relic. This is the default behavior in most popular libraries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> AJAX data collection",
        "sections": "<em>Troubleshoot</em> AJAX data collection",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ": function (t){var e=new p(t);try{u.emit(&quot;new-xhr&quot;... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see <em>Troubleshooting</em> <em>browser</em> <em>monitoring</em> installation. If you see a different response, you may"
      },
      "id": "603e902d196a6762dea83d8a"
    },
    {
      "sections": [
        "Browser Summary page",
        "View the Summary page",
        "Core Web Vitals widgets",
        "User time on the site",
        "Initial page load and route change chart",
        "User-centric page load times chart",
        "Throughput chart",
        "Tip",
        "Front end vs. back end chart",
        "First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL",
        "Related Entities widget",
        "View Synthetics monitors"
      ],
      "title": "Browser Summary page",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Getting started"
      ],
      "external_id": "a69bb31a3bff73ef8badce5ce435da62e9e7b644",
      "image": "https://docs.newrelic.com/static/e61bbb246d462250e94c99bf637b9cca/c1b63/browser_summary_page.png",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/getting-started/browser-summary-page/",
      "published_at": "2021-12-19T15:18:58Z",
      "updated_at": "2021-12-10T02:30:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's Summary page summarizes the real-user browser performance of your app. Use the Summary page to: View trends in an app's browser-side performance Quickly troubleshoot page load timing issues Navigate to other browser UI pages View the Summary page To view a summary of browser performance for an app: Go to one.newrelic.com > Explorer > Browser applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com, click Browser, and select an app from the Browser index. From the app's Summary page, use standard New Relic page functions to drill down into detailed information. one.newrelic.com > Browser > (select an app) > Summary: After you select an application from the browser apps index, the Summary page shows a summary of browser performance for that app. The Summary page includes: Core Web Vitals widgets User time on the site Initial page load and route change chart User-centric page load times chart Throughput chart Front end vs. back end chart First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL Related Entities widget View Synthetics monitors Core Web Vitals widgets The Core Web Vitals widgets show how your browser performs according to Google's Core Web Vitals. The Core Web Vitals widgets include: LCP - Largest Contentful Paint FID - First Input Delay CLS - Cumulative Layout Shift User time on the site The User time on the site widget shows the time a user remains on the site. Initial page load and route change chart The Initial page load and route change chart shows the load time of a traditional URL change stemming from a load or reload of a URL. This chart appears with more detail about the page load timing process on the page load time page. User-centric page load times chart The User-centric page load times chart shows the load time of a page for a user. This chart appears with more detail about the page load timing process on the page load time page. Throughput chart The Throughput chart displays browser throughput as pages per minute (ppm). The value in the upper right of the chart is the average value for the selected time range. If you have enabled SPA monitoring enabled and the Summary page shows the SPA load time chart, the Throughput chart will also use SPA data. Tip App server requests per minute (rpm) may show a different measurement than the browser page load timing's pages per minute (ppm). Front end vs. back end chart The Front end vs. back end chart links to the connect APM service application. For details on APM and tracing, see Language agents and distributed tracing. First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL You'll also see summary versions of these metrics from the page load time page and JavaScript errors page: First interaction by device type First interaction by user agent JavaScript errors Longest first input delay by URL Related Entities widget The Related Entities widget shows all the entities that are related to the browser. To understand more about connections between entities, read about Entity relationships. View Synthetics monitors The button directs you to the Synthetics page. To read more about Synthetics, see Synthetic monitoring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.82825,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> Summary page",
        "sections": "<em>Browser</em> Summary page",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s Summary page summarizes the real-user <em>browser</em> performance of your app. Use the Summary page to: View trends in an app&#x27;s <em>browser</em>-side performance Quickly <em>troubleshoot</em> page load timing issues Navigate to other <em>browser</em> UI pages View the Summary page To view a summary of <em>browser</em>"
      },
      "id": "60440d9c196a674ac8960f5b"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/view-detailed-error-logs-browser": [
    {
      "sections": [
        "AJAX call fails with a CORS redirect error message",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "AJAX call fails with a CORS redirect error message",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "a4e478428acefb454ab8969cccb666d03ae458f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/ajax-call-fails-cors-redirect-error-message/",
      "published_at": "2021-12-19T13:56:44Z",
      "updated_at": "2021-11-13T07:04:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem A redirected AJAX call is being rejected with a CORS error message, for example: Access to XMLHttpRequest at 'https://my-domain-2/path' (redirected from 'https://my-domain-1/path') from origin 'https://my-website-domain' has been blocked by CORS policy: Request header field x-newrelic-id is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The browser agent automatically adds custom headers to outgoing same-origin AJAX calls in order to support the Distributed Tracing feature. When the server that receives the AJAX call responds with a redirect status code (such as 302), the browser will automatically make the same AJAX call to the redirected URL. And if this new URL is on a different origin and the call does not pass the CORS preflight, the browser will fail the call with the error message listed above.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The <em>browser</em> agent"
      },
      "id": "603eb41ce7b9d2ce042a07db"
    },
    {
      "sections": [
        "Troubleshoot AJAX data collection",
        "Problem",
        "Solution",
        "1. Verify you use XMLHttpRequest.",
        "2. Verify the object is instrumented.",
        "3. Verify network access.",
        "JSONP requirements"
      ],
      "title": "Troubleshoot AJAX data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "8dc486fa0fbb0a07f5e93c3cf75590e3e03bba2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/troubleshoot-ajax-data-collection/",
      "published_at": "2021-12-19T13:52:53Z",
      "updated_at": "2021-11-13T07:03:46Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are not seeing AJAX data for your browser app. Solution If your application is instrumented with browser monitoring and is correctly collecting data for other Pro features, follow these steps: 1. Verify you use XMLHttpRequest. Check whether your application uses the XMLHttpRequest object to make AJAX calls. Browser monitoring: Other methods (including the newer Fetch API) currently are not supported when using browser Pro. Single-page app monitoring: Fetch is supported for AJAX requests within a browser interaction with SPA monitoring. If you are making requests using JSONP, see JSONP requirements. 2. Verify the object is instrumented. If you are using XMLHttpRequest, use your browser's dev console to verify that the object has been instrumented by New Relic. Enter the object name at your console. If instrumentation has succeeded, the console should return something like: function (t){var e=new p(t);try{u.emit(\"new-xhr\"... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see Troubleshooting browser monitoring installation. If you see a different response, you may be using another script or library that is conflicting with New Relic instrumentation. Contact support at support.newrelic.com. 3. Verify network access. If the object is properly instrumented, try triggering an AJAX call in your application while monitoring network traffic in the browser's developer tools. Wait up to one minute, and look for a call to bam.nr-data.net/jserrors with an xhr parameter. If the call fails, check for network issues. If you don't see this call, if it fails with an error not related to network access, or if it succeeds but you still aren't seeing data, get support at support.newrelic.com. If your requests use JSONP, see requirements and notes on functionality below: JSONP requirements If your requests use JSONP, these requests will not appear on the AJAX UI page. However, you can view them as assets within session traces. If using SPA monitoring, you can view them on the Breakdown tab of the Page views page. Requirements for JSONP to be recognized: Each JSONP request must use a unique callback function. Most popular libraries (like jQuery) generate a unique callback function dynamically for each request. The query string callback must be named \"callback\" or \"cb\" in order to be recognized by New Relic. This is the default behavior in most popular libraries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.02434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> AJAX data collection",
        "sections": "<em>Troubleshoot</em> AJAX data collection",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ": function (t){var e=new p(t);try{u.emit(&quot;new-xhr&quot;... Copy If instrumentation failed, you will see something like: function XMLHttpRequest() { [native_code] } Copy If you see this type of failure response, see <em>Troubleshooting</em> <em>browser</em> <em>monitoring</em> installation. If you see a different response, you may"
      },
      "id": "603e902d196a6762dea83d8a"
    },
    {
      "sections": [
        "Browser Summary page",
        "View the Summary page",
        "Core Web Vitals widgets",
        "User time on the site",
        "Initial page load and route change chart",
        "User-centric page load times chart",
        "Throughput chart",
        "Tip",
        "Front end vs. back end chart",
        "First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL",
        "Related Entities widget",
        "View Synthetics monitors"
      ],
      "title": "Browser Summary page",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Getting started"
      ],
      "external_id": "a69bb31a3bff73ef8badce5ce435da62e9e7b644",
      "image": "https://docs.newrelic.com/static/e61bbb246d462250e94c99bf637b9cca/c1b63/browser_summary_page.png",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/getting-started/browser-summary-page/",
      "published_at": "2021-12-19T15:18:58Z",
      "updated_at": "2021-12-10T02:30:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's Summary page summarizes the real-user browser performance of your app. Use the Summary page to: View trends in an app's browser-side performance Quickly troubleshoot page load timing issues Navigate to other browser UI pages View the Summary page To view a summary of browser performance for an app: Go to one.newrelic.com > Explorer > Browser applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com, click Browser, and select an app from the Browser index. From the app's Summary page, use standard New Relic page functions to drill down into detailed information. one.newrelic.com > Browser > (select an app) > Summary: After you select an application from the browser apps index, the Summary page shows a summary of browser performance for that app. The Summary page includes: Core Web Vitals widgets User time on the site Initial page load and route change chart User-centric page load times chart Throughput chart Front end vs. back end chart First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL Related Entities widget View Synthetics monitors Core Web Vitals widgets The Core Web Vitals widgets show how your browser performs according to Google's Core Web Vitals. The Core Web Vitals widgets include: LCP - Largest Contentful Paint FID - First Input Delay CLS - Cumulative Layout Shift User time on the site The User time on the site widget shows the time a user remains on the site. Initial page load and route change chart The Initial page load and route change chart shows the load time of a traditional URL change stemming from a load or reload of a URL. This chart appears with more detail about the page load timing process on the page load time page. User-centric page load times chart The User-centric page load times chart shows the load time of a page for a user. This chart appears with more detail about the page load timing process on the page load time page. Throughput chart The Throughput chart displays browser throughput as pages per minute (ppm). The value in the upper right of the chart is the average value for the selected time range. If you have enabled SPA monitoring enabled and the Summary page shows the SPA load time chart, the Throughput chart will also use SPA data. Tip App server requests per minute (rpm) may show a different measurement than the browser page load timing's pages per minute (ppm). Front end vs. back end chart The Front end vs. back end chart links to the connect APM service application. For details on APM and tracing, see Language agents and distributed tracing. First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL You'll also see summary versions of these metrics from the page load time page and JavaScript errors page: First interaction by device type First interaction by user agent JavaScript errors Longest first input delay by URL Related Entities widget The Related Entities widget shows all the entities that are related to the browser. To understand more about connections between entities, read about Entity relationships. View Synthetics monitors The button directs you to the Synthetics page. To read more about Synthetics, see Synthetic monitoring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.82825,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> Summary page",
        "sections": "<em>Browser</em> Summary page",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s Summary page summarizes the real-user <em>browser</em> performance of your app. Use the Summary page to: View trends in an app&#x27;s <em>browser</em>-side performance Quickly <em>troubleshoot</em> page load timing issues Navigate to other <em>browser</em> UI pages View the Summary page To view a summary of <em>browser</em>"
      },
      "id": "60440d9c196a674ac8960f5b"
    }
  ],
  "/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring": [
    {
      "sections": [
        "Introduction to Single Page App monitoring",
        "Enable SPA monitoring",
        "Analyze throughput and performance data",
        "Browser SPA features"
      ],
      "title": "Introduction to Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "6dedda52851e1ca1f180c8d88bdcb7038c4d1b5d",
      "image": "https://docs.newrelic.com/static/98d434a02c314f2bd2ce9828aa7b755d/c1b63/browser_SPA.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring/",
      "published_at": "2021-12-19T13:52:52Z",
      "updated_at": "2021-07-21T20:07:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic browser monitoring has a single-page application (SPA) monitoring feature that provides deeper visibility and actionable insights into real user interactions with single-page apps, and for any app that uses AJAX requests. In addition to monitoring route changes automatically, our SPA API allows you to monitor virtually anything that executes inside the browser. This allows developers and their team to: Create faster, more responsive, highly interactive apps. Monitor the throughput and performance that real users are experiencing. Troubleshoot and resolve problems within the context of the page load. Query your data to assist with business decisions. Bring better apps to the marketplace more quickly. Enable SPA monitoring SPA monitoring is enabled by default for new browser agent installations. The SPA-enabled version of the agent gives access to other powerful New Relic features, like distributed tracing. For more information, see Enable browser monitoring. For compatability information for SPA-related features, see SPA requirements. Analyze throughput and performance data Improving on traditional industry standards for measuring page load timing, we give you a complete picture of the activity, both synchronous and asynchronous, associated with page loads and route changes. one.newrelic.com > Browser > (select an app) > Page views: Use browser monitoring's SPA monitoring to examine the throughput and performance of your SPA-architecture app. SPA data monitored by browser monitoring includes: Performance data and throughput for page loads and route changes AJAX request data JavaScript activity, both synchronous and asynchronous Dynamic page updates, monitored using the SPA API With this data, you will gain a clear understanding of how your users experience your app's page loads and route changes, and be able to solve bottlenecks and troubleshoot errors. For more about how New Relic handles SPA data, see Understand SPA data collection. Browser SPA features Here is a summary of SPA monitoring features: Single-page app monitoring Take advantage of these features Robust views in browser's UI When a user initiates a page load or route change, New Relic begins to monitor all subsequent JavaScript, and ends the timing once all AJAX events are complete. This provides a more accurate view of when a page is actually ready for a user compared to the traditional method of ending the timing when the window load event is fired. When SPA monitoring is enabled, the Page views page in browser shows event-driven data about application usage levels (throughput) and user experience (performance), including: Charts with drill-down details about initial page load performance, route changes, and historical performance Sort, search, and filter options, including custom attributes Additional AJAX breakdown data for all initial page loads and route changes For an explanation of how SPA monitoring will impact your existing browser account's data usage, see SPA and browser data usage. Data analysis with data explorer The data explorer supports three SPA-specific event types: BrowserInteraction, AjaxRequest, and BrowserTiming. You can query these events in the query builder to analyze your app's performance and make business decisions. Customized data from API Use SPA API to obtain the specific data you need, such as custom naming, custom timing, finishline API, or other custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.16724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "New Relic <em>browser</em> <em>monitoring</em> has a <em>single</em>-<em>page</em> application (SPA) <em>monitoring</em> feature that provides deeper visibility and actionable insights into real user interactions with <em>single</em>-<em>page</em> apps, and for any <em>app</em> that uses AJAX requests. In addition to <em>monitoring</em> route changes automatically, our SPA API"
      },
      "id": "604408d328ccbcf69e2c6064"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-12-19T14:01:08Z",
      "updated_at": "2021-07-09T07:41:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the browser snippet, available for browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow browser's guidelines for security with data collection and reporting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.29572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Browser</em> agent version",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (SPA) <em>monitoring</em> for <em>browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these SPA <em>monitoring</em> requirements. <em>Browser</em> agent version SPA <em>monitoring</em> requires an SPA-specific version of the <em>browser</em> snippet, available for <em>browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-12-19T14:03:57Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own applications framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.53886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " are captured, either as a <em>Browser</em>Interaction event or as a <em>Page</em>Action event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring": [
    {
      "sections": [
        "Install Single Page App monitoring",
        "Requirements",
        "Enable or disable SPA monitoring"
      ],
      "title": "Install Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "04501b8d90b2c9b3bf3fa29f1662596a1379e2b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring/",
      "published_at": "2021-12-19T13:53:32Z",
      "updated_at": "2021-07-27T14:14:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Single page app (SPA) monitoring comes with the default install of the browser agent. Requirements You can review compability and requirements for SPA monitoring here. When you set up your first monitored app in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms, you authorize New Relic to collect hash fragments from URLs. You only need to select the checkbox option once for an account. Enable or disable SPA monitoring When you enable browser monitoring, SPA monitoring is included by default because it gives access to a range of our most recent features, including distributed tracing. Some older agent installations may need to be upgraded. Read more about browser agent types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.61494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Single</em> <em>page</em> <em>app</em> (SPA) <em>monitoring</em> comes with the default install of the <em>browser</em> agent. Requirements You can review compability and requirements for SPA <em>monitoring</em> here. When you set up your first monitored <em>app</em> in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms"
      },
      "id": "6043f16664441f56fa378eec"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-12-19T14:01:08Z",
      "updated_at": "2021-07-09T07:41:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the browser snippet, available for browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow browser's guidelines for security with data collection and reporting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.29572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Browser</em> agent version",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (SPA) <em>monitoring</em> for <em>browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these SPA <em>monitoring</em> requirements. <em>Browser</em> agent version SPA <em>monitoring</em> requires an SPA-specific version of the <em>browser</em> snippet, available for <em>browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-12-19T14:03:57Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own applications framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.53886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " are captured, either as a <em>Browser</em>Interaction event or as a <em>Page</em>Action event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements": [
    {
      "sections": [
        "Install Single Page App monitoring",
        "Requirements",
        "Enable or disable SPA monitoring"
      ],
      "title": "Install Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "04501b8d90b2c9b3bf3fa29f1662596a1379e2b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring/",
      "published_at": "2021-12-19T13:53:32Z",
      "updated_at": "2021-07-27T14:14:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Single page app (SPA) monitoring comes with the default install of the browser agent. Requirements You can review compability and requirements for SPA monitoring here. When you set up your first monitored app in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms, you authorize New Relic to collect hash fragments from URLs. You only need to select the checkbox option once for an account. Enable or disable SPA monitoring When you enable browser monitoring, SPA monitoring is included by default because it gives access to a range of our most recent features, including distributed tracing. Some older agent installations may need to be upgraded. Read more about browser agent types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.61494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Single</em> <em>page</em> <em>app</em> (SPA) <em>monitoring</em> comes with the default install of the <em>browser</em> agent. Requirements You can review compability and requirements for SPA <em>monitoring</em> here. When you set up your first monitored <em>app</em> in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms"
      },
      "id": "6043f16664441f56fa378eec"
    },
    {
      "sections": [
        "Introduction to Single Page App monitoring",
        "Enable SPA monitoring",
        "Analyze throughput and performance data",
        "Browser SPA features"
      ],
      "title": "Introduction to Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "6dedda52851e1ca1f180c8d88bdcb7038c4d1b5d",
      "image": "https://docs.newrelic.com/static/98d434a02c314f2bd2ce9828aa7b755d/c1b63/browser_SPA.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring/",
      "published_at": "2021-12-19T13:52:52Z",
      "updated_at": "2021-07-21T20:07:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic browser monitoring has a single-page application (SPA) monitoring feature that provides deeper visibility and actionable insights into real user interactions with single-page apps, and for any app that uses AJAX requests. In addition to monitoring route changes automatically, our SPA API allows you to monitor virtually anything that executes inside the browser. This allows developers and their team to: Create faster, more responsive, highly interactive apps. Monitor the throughput and performance that real users are experiencing. Troubleshoot and resolve problems within the context of the page load. Query your data to assist with business decisions. Bring better apps to the marketplace more quickly. Enable SPA monitoring SPA monitoring is enabled by default for new browser agent installations. The SPA-enabled version of the agent gives access to other powerful New Relic features, like distributed tracing. For more information, see Enable browser monitoring. For compatability information for SPA-related features, see SPA requirements. Analyze throughput and performance data Improving on traditional industry standards for measuring page load timing, we give you a complete picture of the activity, both synchronous and asynchronous, associated with page loads and route changes. one.newrelic.com > Browser > (select an app) > Page views: Use browser monitoring's SPA monitoring to examine the throughput and performance of your SPA-architecture app. SPA data monitored by browser monitoring includes: Performance data and throughput for page loads and route changes AJAX request data JavaScript activity, both synchronous and asynchronous Dynamic page updates, monitored using the SPA API With this data, you will gain a clear understanding of how your users experience your app's page loads and route changes, and be able to solve bottlenecks and troubleshoot errors. For more about how New Relic handles SPA data, see Understand SPA data collection. Browser SPA features Here is a summary of SPA monitoring features: Single-page app monitoring Take advantage of these features Robust views in browser's UI When a user initiates a page load or route change, New Relic begins to monitor all subsequent JavaScript, and ends the timing once all AJAX events are complete. This provides a more accurate view of when a page is actually ready for a user compared to the traditional method of ending the timing when the window load event is fired. When SPA monitoring is enabled, the Page views page in browser shows event-driven data about application usage levels (throughput) and user experience (performance), including: Charts with drill-down details about initial page load performance, route changes, and historical performance Sort, search, and filter options, including custom attributes Additional AJAX breakdown data for all initial page loads and route changes For an explanation of how SPA monitoring will impact your existing browser account's data usage, see SPA and browser data usage. Data analysis with data explorer The data explorer supports three SPA-specific event types: BrowserInteraction, AjaxRequest, and BrowserTiming. You can query these events in the query builder to analyze your app's performance and make business decisions. Customized data from API Use SPA API to obtain the specific data you need, such as custom naming, custom timing, finishline API, or other custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.16724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "New Relic <em>browser</em> <em>monitoring</em> has a <em>single</em>-<em>page</em> application (SPA) <em>monitoring</em> feature that provides deeper visibility and actionable insights into real user interactions with <em>single</em>-<em>page</em> apps, and for any <em>app</em> that uses AJAX requests. In addition to <em>monitoring</em> route changes automatically, our SPA API"
      },
      "id": "604408d328ccbcf69e2c6064"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-12-19T14:03:57Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own applications framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.53886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " are captured, either as a <em>Browser</em>Interaction event or as a <em>Page</em>Action event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent": [
    {
      "sections": [
        "Install Single Page App monitoring",
        "Requirements",
        "Enable or disable SPA monitoring"
      ],
      "title": "Install Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "04501b8d90b2c9b3bf3fa29f1662596a1379e2b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring/",
      "published_at": "2021-12-19T13:53:32Z",
      "updated_at": "2021-07-27T14:14:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Single page app (SPA) monitoring comes with the default install of the browser agent. Requirements You can review compability and requirements for SPA monitoring here. When you set up your first monitored app in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms, you authorize New Relic to collect hash fragments from URLs. You only need to select the checkbox option once for an account. Enable or disable SPA monitoring When you enable browser monitoring, SPA monitoring is included by default because it gives access to a range of our most recent features, including distributed tracing. Some older agent installations may need to be upgraded. Read more about browser agent types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.79471,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Single</em> <em>page</em> <em>app</em> (SPA) <em>monitoring</em> comes with the default install of the <em>browser</em> agent. Requirements You can review compability and requirements for SPA <em>monitoring</em> here. When you set up your first monitored <em>app</em> in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms"
      },
      "id": "6043f16664441f56fa378eec"
    },
    {
      "sections": [
        "Introduction to Single Page App monitoring",
        "Enable SPA monitoring",
        "Analyze throughput and performance data",
        "Browser SPA features"
      ],
      "title": "Introduction to Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "6dedda52851e1ca1f180c8d88bdcb7038c4d1b5d",
      "image": "https://docs.newrelic.com/static/98d434a02c314f2bd2ce9828aa7b755d/c1b63/browser_SPA.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring/",
      "published_at": "2021-12-19T13:52:52Z",
      "updated_at": "2021-07-21T20:07:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic browser monitoring has a single-page application (SPA) monitoring feature that provides deeper visibility and actionable insights into real user interactions with single-page apps, and for any app that uses AJAX requests. In addition to monitoring route changes automatically, our SPA API allows you to monitor virtually anything that executes inside the browser. This allows developers and their team to: Create faster, more responsive, highly interactive apps. Monitor the throughput and performance that real users are experiencing. Troubleshoot and resolve problems within the context of the page load. Query your data to assist with business decisions. Bring better apps to the marketplace more quickly. Enable SPA monitoring SPA monitoring is enabled by default for new browser agent installations. The SPA-enabled version of the agent gives access to other powerful New Relic features, like distributed tracing. For more information, see Enable browser monitoring. For compatability information for SPA-related features, see SPA requirements. Analyze throughput and performance data Improving on traditional industry standards for measuring page load timing, we give you a complete picture of the activity, both synchronous and asynchronous, associated with page loads and route changes. one.newrelic.com > Browser > (select an app) > Page views: Use browser monitoring's SPA monitoring to examine the throughput and performance of your SPA-architecture app. SPA data monitored by browser monitoring includes: Performance data and throughput for page loads and route changes AJAX request data JavaScript activity, both synchronous and asynchronous Dynamic page updates, monitored using the SPA API With this data, you will gain a clear understanding of how your users experience your app's page loads and route changes, and be able to solve bottlenecks and troubleshoot errors. For more about how New Relic handles SPA data, see Understand SPA data collection. Browser SPA features Here is a summary of SPA monitoring features: Single-page app monitoring Take advantage of these features Robust views in browser's UI When a user initiates a page load or route change, New Relic begins to monitor all subsequent JavaScript, and ends the timing once all AJAX events are complete. This provides a more accurate view of when a page is actually ready for a user compared to the traditional method of ending the timing when the window load event is fired. When SPA monitoring is enabled, the Page views page in browser shows event-driven data about application usage levels (throughput) and user experience (performance), including: Charts with drill-down details about initial page load performance, route changes, and historical performance Sort, search, and filter options, including custom attributes Additional AJAX breakdown data for all initial page loads and route changes For an explanation of how SPA monitoring will impact your existing browser account's data usage, see SPA and browser data usage. Data analysis with data explorer The data explorer supports three SPA-specific event types: BrowserInteraction, AjaxRequest, and BrowserTiming. You can query these events in the query builder to analyze your app's performance and make business decisions. Customized data from API Use SPA API to obtain the specific data you need, such as custom naming, custom timing, finishline API, or other custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.43349,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " your <em>app</em>&#x27;s <em>page</em> loads and route changes, and be able to solve bottlenecks and <em>troubleshoot</em> errors. For more about how New Relic handles SPA data, see Understand SPA data collection. <em>Browser</em> SPA features Here is a summary of SPA <em>monitoring</em> features: <em>Single</em>-<em>page</em> <em>app</em> <em>monitoring</em> Take advantage"
      },
      "id": "604408d328ccbcf69e2c6064"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-12-19T14:01:08Z",
      "updated_at": "2021-07-09T07:41:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the browser snippet, available for browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow browser's guidelines for security with data collection and reporting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.73032,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Browser</em> agent version",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (SPA) <em>monitoring</em> for <em>browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these SPA <em>monitoring</em> requirements. <em>Browser</em> agent version SPA <em>monitoring</em> requires an SPA-specific version of the <em>browser</em> snippet, available for <em>browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection": [
    {
      "sections": [
        "View SPA data in Browser UI",
        "Single-page app (SPA) data",
        "Filter SPA views",
        "Group SPA views",
        "SPA view details",
        "Initial page load performance details",
        "Route change performance details"
      ],
      "title": "View SPA data in Browser UI",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "0ab30db71f34da6376ff5e71734292b247754ca4",
      "image": "https://docs.newrelic.com/static/04bcea9186a93fc786a6db3469765824/c1b63/spa_overview.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui/",
      "published_at": "2021-12-20T04:34:42Z",
      "updated_at": "2021-07-09T10:04:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have opted in to SPA (single-page app) monitoring, the browser Page views page will include data on SPA route changes and initial page loads. one.newrelic.com > Browser > (select an app) > Page views: When you opt in to SPA monitoring, the browser Page views page will display SPA data like route changes and associated asynchronous browser activity. Single-page app (SPA) data To view SPA data: Go to one.newrelic.com > Browser > (select an app) > Page views. Initial page loads and route changes are automatically grouped by browser interaction name. You can adjust this with your allow list settings for segments. If you set custom route names with the SPA API, the custom route names will be displayed. You can change how the page loads and route changes are grouped by using the Group page by dropdown. By default, the list of page loads and route changes displays the most time consuming views at the top of the list. You can also sort by average response time, median response time, and throughput per minute by using the Sort by dropdown. To search for specific views by grouped URL, type in the search bar below the Sort by dropdown. For example, to find URLs that represent your checkout page, search for checkout. The charts on the initial Page view page display: The five views with the slowest average response times The five views with the highest throughput To change the range of time being examined, use the time picker near the top of the page. (If you choose a time range more than eight days in the past, some filtering and grouping functionality won't be available.) Filter SPA views one.newrelic.com > Browser > (select an app) > Page views > Filter: Use the Filter to filter for route changes, initial page loads, and other attributes like location and browser type. To view only initial page loads or only route changes, use the Filter dropdown. For example, to view only route changes, select Filter > Route change. The filter also gives you the ability to filter by other attributes of page loads and route changes, such as app name, geographical location of the browser, and browser type. For example, to see only page loads and route changes that occurred on browsers in the city of Portland, Oregon, select Filter > City > Portland. Group SPA views You can use the Group page by dropdown to group the list of page views by any attribute. For example, if you want to compare the average response times by browser type, select Group page by > userAgent. The combination of filtering and grouping lets you quickly find very specific data. For example, to compare how a specific URL is loading on different browsers: From the Filter dropdown, select targetURL, then select the URL you want to study. From the Group page by dropdown, select userAgent. SPA view details one.newrelic.com > Browser > (select an app) > Page views > (select a view): Select a view from the list to see assorted details and breakdowns. Select an individual page load or route change to see details. Selecting either will provide a breakdown of where time was spent for a browser interaction, and display that data over a time series matching the window selected in the time picker. Every route change view can theoretically also be an initial page load. (For example, when a route change URL is sent to someone else and they load it, that will now be considered an initial page load to New Relic.) This is why the SPA view details page has charts for both initial page loads and route changes. This allows you to compare how a view performs as an initial page load to how its performance as a route change. There are three chart display options, selectable with the icons to the right of the Avg initial page load time chart title. The default display is the color-coded stacked area chart. You can also switch to a Histogram display or a percentile line graph. Also on the details page is a Throughput chart that combines initial page loads and route changes. The chart displays the 5 pages with the highest throughput, which are listed beneath the chart, and consolidates all other pages into Other. Here are details on the specific performance data displayed for both page loads and route changes: Initial page load performance details For initial page loads, the performance details include the average back end time, front end time, and the window onload event: Back end time includes network, web app time, and request queuing. Front end time includes DOM processing, page rendering, and the time to complete all XHRs. A horizontal red line shows when the window load event is fired. This corresponds to the traditional page load timing measured by the browser agent without SPA monitoring enabled. With SPA monitoring it is common to have a window load event before the front end time is complete. (For more about how SPA page load timing differs from traditional page load timing, see Understand SPA data collection.) Route change performance details For route changes, the performance chart displays JS duration and waiting time. JS Duration is the sum of all JavaScript execution time during the interaction, which is synchronous by definition. The remaining time is called Waiting time and is derived by subtracting JS duration from the total duration. The Historical performance and Breakdown details are similar for both page loads and route changes: Detail tab Comments Historical data The Historical performance tab displays throughput (views per minute) and response time charted against the same time period yesterday and last week. Breakdowns The Breakdowns tab lists the various components individually timed as part of an interaction. By default, all XHRs are captured and timed. You can also use the SPA API to include additional elements for a route change or page load.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.55914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>SPA</em> <em>data</em> in <em>Browser</em> UI",
        "sections": "<em>Single</em>-<em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "If you have opted in to <em>SPA</em> (<em>single</em>-<em>page</em> <em>app</em>) <em>monitoring</em>, the <em>browser</em> <em>Page</em> views <em>page</em> will include <em>data</em> on <em>SPA</em> route changes and initial <em>page</em> loads. one.newrelic.com &gt; <em>Browser</em> &gt; (select an <em>app</em>) &gt; <em>Page</em> views: When you opt in to <em>SPA</em> <em>monitoring</em>, the <em>browser</em> <em>Page</em> views <em>page</em> will display <em>SPA</em> <em>data</em> like"
      },
      "id": "60440de328ccbc26592c60be"
    },
    {
      "sections": [
        "Use SPA API"
      ],
      "title": "Use SPA API",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "85ba9b61e8ba08112a3a276d186fbe7af894251d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api/",
      "published_at": "2021-12-20T09:46:29Z",
      "updated_at": "2021-03-11T07:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser's single-page application (SPA) monitoring includes an API to add custom monitoring of specific browser interactions. This is useful for monitoring interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget. The SPA API also allows you to turn off default monitoring for interactions that you do not consider important enough to monitor. For more information about the SPA API, including specific API calls, see the Browser agent and SPA API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.49622,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>SPA</em> API",
        "sections": "<em>Use</em> <em>SPA</em> API",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Browser</em>&#x27;s <em>single</em>-<em>page</em> application (<em>SPA</em>) <em>monitoring</em> includes an API to add custom <em>monitoring</em> of specific <em>browser</em> interactions. This is useful for <em>monitoring</em> interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget"
      },
      "id": "60440de328ccbc04a23025de"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-12-19T14:03:57Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own applications framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.66925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing route changes with <em>SPA</em> agent",
        "sections": "Missing route changes with <em>SPA</em> agent",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " Short term solutions To make sure all route changes are captured, you can <em>use</em> our <em>SPA</em> interaction() API. Using the interaction API will categorize the <em>Browser</em>Interaction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api": [
    {
      "sections": [
        "View SPA data in Browser UI",
        "Single-page app (SPA) data",
        "Filter SPA views",
        "Group SPA views",
        "SPA view details",
        "Initial page load performance details",
        "Route change performance details"
      ],
      "title": "View SPA data in Browser UI",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "0ab30db71f34da6376ff5e71734292b247754ca4",
      "image": "https://docs.newrelic.com/static/04bcea9186a93fc786a6db3469765824/c1b63/spa_overview.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui/",
      "published_at": "2021-12-20T04:34:42Z",
      "updated_at": "2021-07-09T10:04:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have opted in to SPA (single-page app) monitoring, the browser Page views page will include data on SPA route changes and initial page loads. one.newrelic.com > Browser > (select an app) > Page views: When you opt in to SPA monitoring, the browser Page views page will display SPA data like route changes and associated asynchronous browser activity. Single-page app (SPA) data To view SPA data: Go to one.newrelic.com > Browser > (select an app) > Page views. Initial page loads and route changes are automatically grouped by browser interaction name. You can adjust this with your allow list settings for segments. If you set custom route names with the SPA API, the custom route names will be displayed. You can change how the page loads and route changes are grouped by using the Group page by dropdown. By default, the list of page loads and route changes displays the most time consuming views at the top of the list. You can also sort by average response time, median response time, and throughput per minute by using the Sort by dropdown. To search for specific views by grouped URL, type in the search bar below the Sort by dropdown. For example, to find URLs that represent your checkout page, search for checkout. The charts on the initial Page view page display: The five views with the slowest average response times The five views with the highest throughput To change the range of time being examined, use the time picker near the top of the page. (If you choose a time range more than eight days in the past, some filtering and grouping functionality won't be available.) Filter SPA views one.newrelic.com > Browser > (select an app) > Page views > Filter: Use the Filter to filter for route changes, initial page loads, and other attributes like location and browser type. To view only initial page loads or only route changes, use the Filter dropdown. For example, to view only route changes, select Filter > Route change. The filter also gives you the ability to filter by other attributes of page loads and route changes, such as app name, geographical location of the browser, and browser type. For example, to see only page loads and route changes that occurred on browsers in the city of Portland, Oregon, select Filter > City > Portland. Group SPA views You can use the Group page by dropdown to group the list of page views by any attribute. For example, if you want to compare the average response times by browser type, select Group page by > userAgent. The combination of filtering and grouping lets you quickly find very specific data. For example, to compare how a specific URL is loading on different browsers: From the Filter dropdown, select targetURL, then select the URL you want to study. From the Group page by dropdown, select userAgent. SPA view details one.newrelic.com > Browser > (select an app) > Page views > (select a view): Select a view from the list to see assorted details and breakdowns. Select an individual page load or route change to see details. Selecting either will provide a breakdown of where time was spent for a browser interaction, and display that data over a time series matching the window selected in the time picker. Every route change view can theoretically also be an initial page load. (For example, when a route change URL is sent to someone else and they load it, that will now be considered an initial page load to New Relic.) This is why the SPA view details page has charts for both initial page loads and route changes. This allows you to compare how a view performs as an initial page load to how its performance as a route change. There are three chart display options, selectable with the icons to the right of the Avg initial page load time chart title. The default display is the color-coded stacked area chart. You can also switch to a Histogram display or a percentile line graph. Also on the details page is a Throughput chart that combines initial page loads and route changes. The chart displays the 5 pages with the highest throughput, which are listed beneath the chart, and consolidates all other pages into Other. Here are details on the specific performance data displayed for both page loads and route changes: Initial page load performance details For initial page loads, the performance details include the average back end time, front end time, and the window onload event: Back end time includes network, web app time, and request queuing. Front end time includes DOM processing, page rendering, and the time to complete all XHRs. A horizontal red line shows when the window load event is fired. This corresponds to the traditional page load timing measured by the browser agent without SPA monitoring enabled. With SPA monitoring it is common to have a window load event before the front end time is complete. (For more about how SPA page load timing differs from traditional page load timing, see Understand SPA data collection.) Route change performance details For route changes, the performance chart displays JS duration and waiting time. JS Duration is the sum of all JavaScript execution time during the interaction, which is synchronous by definition. The remaining time is called Waiting time and is derived by subtracting JS duration from the total duration. The Historical performance and Breakdown details are similar for both page loads and route changes: Detail tab Comments Historical data The Historical performance tab displays throughput (views per minute) and response time charted against the same time period yesterday and last week. Breakdowns The Breakdowns tab lists the various components individually timed as part of an interaction. By default, all XHRs are captured and timed. You can also use the SPA API to include additional elements for a route change or page load.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.55914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>SPA</em> <em>data</em> in <em>Browser</em> UI",
        "sections": "<em>Single</em>-<em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "If you have opted in to <em>SPA</em> (<em>single</em>-<em>page</em> <em>app</em>) <em>monitoring</em>, the <em>browser</em> <em>Page</em> views <em>page</em> will include <em>data</em> on <em>SPA</em> route changes and initial <em>page</em> loads. one.newrelic.com &gt; <em>Browser</em> &gt; (select an <em>app</em>) &gt; <em>Page</em> views: When you opt in to <em>SPA</em> <em>monitoring</em>, the <em>browser</em> <em>Page</em> views <em>page</em> will display <em>SPA</em> <em>data</em> like"
      },
      "id": "60440de328ccbc26592c60be"
    },
    {
      "sections": [
        "SPA data collection",
        "Browser interactions",
        "Types of SPA data reporting",
        "Initial page loads",
        "Route changes",
        "Custom monitoring",
        "Difference from traditional page load timing",
        "Tip",
        "Timers",
        "Events and attributes"
      ],
      "title": "SPA data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "d42d239aca2ea13a37fd926dca3672fcf83d73dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection/",
      "published_at": "2021-12-20T05:21:36Z",
      "updated_at": "2021-07-09T08:08:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how browser collects and stores your asynchronous single page app (SPA) data. This will give you a better understanding of the SPA data you see in the browser UI. This will also help you more easily add custom monitoring with the SPA API. Browser interactions At the heart of SPA monitoring is the concept of the browser interaction. New Relic defines a browser interaction as anything that occurs in the app user's browser; for example: A user interaction that leads to a page load or route change A scheduled, dynamic update to an app's widget A browser interaction includes not just the initial triggering event, but also the activity caused by that event, such as AJAX requests and both synchronous and asynchronous JavaScript. By tracking not just the cause but also the effects of a browser interaction, we help you understand how users experience your application's views and route changes. All apps are different and have different monitoring needs. That's why we include default monitoring as well as the ability to set up custom monitoring for any browser interactions you choose. Types of SPA data reporting Three major categories of single page app data can be reported to New Relic: Initial page loads Route changes Custom browser interactions created via the SPA API Each of these creates a BrowserInteraction event. If one or more AJAX requests are part of an interaction, then associated AjaxRequest events are also created. These events and their attributes can be queried in the query builder. Initial page loads An initial page load is a traditional URL change, stemming from a complete load or reload of a URL. This is indicated in the browser when a page load event fires (the window.onload event). Initial page loads appear along with route changes in the browser UI. Route changes SPA users experience dynamic route changes in a similar way to page loads. Visitors to a site or app generally do not care how a new view was delivered; they simply know that when they perform an action, a new view appears. For this reason, we treat route changes in a similar way to page loads in the UI. In order to optimally monitor single page applications, we start monitoring many browser interactions that could theoretically lead to route changes. If these interactions do not lead to route changes, browser initiates monitoring but then discards them. If these interactions do lead to a route change, browser saves the interaction sequence as a BrowserInteraction event, including information about both synchronous and asynchronous activity. An interaction is considered a route change and saved as a BrowserInteraction event when one of the following occurs: The URL hash changes (usually using window.location.hash). A popstate event fires during a callback associated with an interaction. A pushState or replaceState API is called. Route changes appear along with initial page loads in the browser UI. We receive and save hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. For more information about data collection and reporting, see Security for browser. Custom monitoring You can use the SPA API to set up custom monitoring of browser interactions that are not monitored by default. You can also use the API to disable default monitoring. Custom events are saved as BrowserInteraction events and have the following attributes: The category attribute will have the value Custom. The trigger attribute will have the value api. (This is the default value but can be changed with the API.) Difference from traditional page load timing To provide optimized data for single page app monitoring, we measure page load timing in a new way: by wrapping low level browser functions, both synchronous and asynchronous. This gives a fuller depiction of how long it takes to complete the changes required for a new view. This is different from the traditional method for page load timing. Traditional page load timing uses the firing of the window.onload event to determine when a page is loaded. This is not an optimal way to measure view change timing because web apps often have asynchronous code that runs for a significant amount of time after the window.onload event occurs. Tip Browser's standard, non-SPA Page views page displays different page load times than when SPA monitoring is enabled. Because SPA monitoring is measuring all asynchronous activity, the SPA load times will generally be longer than standard page load times. The traditional window.onload page load timing still appears on the SPA Page views page. When you select a specific page load event, Window onload appears as a red line in the page load time chart. You can also select Switch to standard page views to return to traditional load timing displays. Timers The agent monitors all asynchronous calls, including timers. Timers with durations shorter than one second are wrapped. Timers longer than one second are not wrapped because usually they are meant for non-web transactions, such as background work or polling that is unrelated to a user interaction. Events and attributes We save browser interactions that lead to route changes and page loads as BrowserInteraction events, and AJAX requests as AjaxRequest events. You can query these events in the query builder.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.5534,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> <em>data</em> collection",
        "sections": "<em>SPA</em> <em>data</em> collection",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "This document explains how <em>browser</em> collects and stores your asynchronous <em>single</em> <em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>. This will give you a better understanding of the <em>SPA</em> <em>data</em> you see in the <em>browser</em> UI. This will also help you more easily add custom <em>monitoring</em> with the <em>SPA</em> API. <em>Browser</em> interactions At the heart"
      },
      "id": "60440d9b196a672eb1960f6d"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-12-19T14:03:57Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own applications framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.66925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing route changes with <em>SPA</em> agent",
        "sections": "Missing route changes with <em>SPA</em> agent",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " Short term solutions To make sure all route changes are captured, you can <em>use</em> our <em>SPA</em> interaction() API. Using the interaction API will categorize the <em>Browser</em>Interaction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui": [
    {
      "sections": [
        "SPA data collection",
        "Browser interactions",
        "Types of SPA data reporting",
        "Initial page loads",
        "Route changes",
        "Custom monitoring",
        "Difference from traditional page load timing",
        "Tip",
        "Timers",
        "Events and attributes"
      ],
      "title": "SPA data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "d42d239aca2ea13a37fd926dca3672fcf83d73dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection/",
      "published_at": "2021-12-20T05:21:36Z",
      "updated_at": "2021-07-09T08:08:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how browser collects and stores your asynchronous single page app (SPA) data. This will give you a better understanding of the SPA data you see in the browser UI. This will also help you more easily add custom monitoring with the SPA API. Browser interactions At the heart of SPA monitoring is the concept of the browser interaction. New Relic defines a browser interaction as anything that occurs in the app user's browser; for example: A user interaction that leads to a page load or route change A scheduled, dynamic update to an app's widget A browser interaction includes not just the initial triggering event, but also the activity caused by that event, such as AJAX requests and both synchronous and asynchronous JavaScript. By tracking not just the cause but also the effects of a browser interaction, we help you understand how users experience your application's views and route changes. All apps are different and have different monitoring needs. That's why we include default monitoring as well as the ability to set up custom monitoring for any browser interactions you choose. Types of SPA data reporting Three major categories of single page app data can be reported to New Relic: Initial page loads Route changes Custom browser interactions created via the SPA API Each of these creates a BrowserInteraction event. If one or more AJAX requests are part of an interaction, then associated AjaxRequest events are also created. These events and their attributes can be queried in the query builder. Initial page loads An initial page load is a traditional URL change, stemming from a complete load or reload of a URL. This is indicated in the browser when a page load event fires (the window.onload event). Initial page loads appear along with route changes in the browser UI. Route changes SPA users experience dynamic route changes in a similar way to page loads. Visitors to a site or app generally do not care how a new view was delivered; they simply know that when they perform an action, a new view appears. For this reason, we treat route changes in a similar way to page loads in the UI. In order to optimally monitor single page applications, we start monitoring many browser interactions that could theoretically lead to route changes. If these interactions do not lead to route changes, browser initiates monitoring but then discards them. If these interactions do lead to a route change, browser saves the interaction sequence as a BrowserInteraction event, including information about both synchronous and asynchronous activity. An interaction is considered a route change and saved as a BrowserInteraction event when one of the following occurs: The URL hash changes (usually using window.location.hash). A popstate event fires during a callback associated with an interaction. A pushState or replaceState API is called. Route changes appear along with initial page loads in the browser UI. We receive and save hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. For more information about data collection and reporting, see Security for browser. Custom monitoring You can use the SPA API to set up custom monitoring of browser interactions that are not monitored by default. You can also use the API to disable default monitoring. Custom events are saved as BrowserInteraction events and have the following attributes: The category attribute will have the value Custom. The trigger attribute will have the value api. (This is the default value but can be changed with the API.) Difference from traditional page load timing To provide optimized data for single page app monitoring, we measure page load timing in a new way: by wrapping low level browser functions, both synchronous and asynchronous. This gives a fuller depiction of how long it takes to complete the changes required for a new view. This is different from the traditional method for page load timing. Traditional page load timing uses the firing of the window.onload event to determine when a page is loaded. This is not an optimal way to measure view change timing because web apps often have asynchronous code that runs for a significant amount of time after the window.onload event occurs. Tip Browser's standard, non-SPA Page views page displays different page load times than when SPA monitoring is enabled. Because SPA monitoring is measuring all asynchronous activity, the SPA load times will generally be longer than standard page load times. The traditional window.onload page load timing still appears on the SPA Page views page. When you select a specific page load event, Window onload appears as a red line in the page load time chart. You can also select Switch to standard page views to return to traditional load timing displays. Timers The agent monitors all asynchronous calls, including timers. Timers with durations shorter than one second are wrapped. Timers longer than one second are not wrapped because usually they are meant for non-web transactions, such as background work or polling that is unrelated to a user interaction. Events and attributes We save browser interactions that lead to route changes and page loads as BrowserInteraction events, and AJAX requests as AjaxRequest events. You can query these events in the query builder.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.5534,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> <em>data</em> collection",
        "sections": "<em>SPA</em> <em>data</em> collection",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "This document explains how <em>browser</em> collects and stores your asynchronous <em>single</em> <em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>. This will give you a better understanding of the <em>SPA</em> <em>data</em> you see in the <em>browser</em> UI. This will also help you more easily add custom <em>monitoring</em> with the <em>SPA</em> API. <em>Browser</em> interactions At the heart"
      },
      "id": "60440d9b196a672eb1960f6d"
    },
    {
      "sections": [
        "Use SPA API"
      ],
      "title": "Use SPA API",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "85ba9b61e8ba08112a3a276d186fbe7af894251d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api/",
      "published_at": "2021-12-20T09:46:29Z",
      "updated_at": "2021-03-11T07:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser's single-page application (SPA) monitoring includes an API to add custom monitoring of specific browser interactions. This is useful for monitoring interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget. The SPA API also allows you to turn off default monitoring for interactions that you do not consider important enough to monitor. For more information about the SPA API, including specific API calls, see the Browser agent and SPA API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.4962,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>SPA</em> API",
        "sections": "<em>Use</em> <em>SPA</em> API",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Browser</em>&#x27;s <em>single</em>-<em>page</em> application (<em>SPA</em>) <em>monitoring</em> includes an API to add custom <em>monitoring</em> of specific <em>browser</em> interactions. This is useful for <em>monitoring</em> interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget"
      },
      "id": "60440de328ccbc04a23025de"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-12-19T14:03:57Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own applications framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.66925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing route changes with <em>SPA</em> agent",
        "sections": "Missing route changes with <em>SPA</em> agent",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " Short term solutions To make sure all route changes are captured, you can <em>use</em> our <em>SPA</em> interaction() API. Using the interaction API will categorize the <em>Browser</em>Interaction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/codestream/codestream-integrations/msteams-integration": [
    {
      "image": "https://docs.newrelic.com/static/8945e0a9c512b8638ebf8165d47aee04/69902/QS-SignUp3.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-user-guide/",
      "sections": [
        "New Relic CodeStream user guide",
        "Jump to a topic",
        "1. Install the CodeStream extension in your IDE and sign up.",
        "2. Connect your tools",
        "3. Discuss any block of code, at any time",
        "4. Get feedback on your work in progress",
        "5. Create or review a pull request",
        "Help and feedback"
      ],
      "published_at": "2021-12-19T15:16:39Z",
      "title": "New Relic CodeStream user guide",
      "updated_at": "2021-11-24T04:44:31Z",
      "type": "docs",
      "external_id": "fa9af0118a8872fea89fda91482c44fb69913ea2",
      "document_type": "page",
      "popularity": 1,
      "body": "Jump to a topic Use the navigation on the left to jump straight to any topic. Otherwise, read on to get started with New Relic CodeStream. If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. 1. Install the CodeStream extension in your IDE and sign up. Install CodeStream for VS Code, Visual Studio or JetBrains. The CodeStream pane automatically appears in the sidebar for VS Code or in a tool window at the right side for JetBrains or Visual Studio. Click Sign Up and Create a team if you're the first person from your team to join CodeStream or paste in your invitation code if you were invited to a team already on CodeStream. Learn more about how to use CodeStream. 2. Connect your tools Create and review pull requests on GitHub, GitLab or Bitbucket. Create issues on Jira, Trello, and other issue trackers. Share code discussions on Slack or Microsoft Teams. CodeStream brings the tools you use every day together in your IDE. Click on your headshot at the top of the CodeStream pane and go to the Integrations page to get all of your tools connected. 3. Discuss any block of code, at any time Whether you're trying to understand someone else's code or getting help with some code you just wrote, just select the code and ask your question. Learn more about discussing code. 4. Get feedback on your work in progress Select Request Feedback from the + menu at any time in the development cycle, whether its a quick look over some work in progress (even uncommitted code!) or a formal review of a completed effort. Teammates can review your changes right in their IDE, with no need to switch branches or set aside their own work. Learn more about feedback requests. 5. Create or review a pull request Look for the Pull Requests section of the CodeStream sidebar to review an open pull request. Just click on a pull request (or load one from URL) to get a complete GitHub experience right in your IDE! Note that you can create a pull request in GitHub, GitLab or Bitbucket, but support for reviewing pull requests is currently only available for GitHub (cloud or Enterprise). Learn more about pull requests. Help and feedback Report a bug or suggest an improvement in GitHub issues. Contact us directly at support@codestream.com. Follow @teamcodestream for product updates and to share feedback and questions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1187.6934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>CodeStream</em> user guide",
        "sections": "1. Install the <em>CodeStream</em> extension in your IDE <em>and</em> sign up.",
        "body": " discussions on Slack or <em>Microsoft</em> <em>Teams</em>. <em>CodeStream</em> brings the tools you use every day together in your IDE. Click on your headshot at the top of the <em>CodeStream</em> pane and go to the Integrations page to get all of your tools connected. 3. Discuss any block of <em>code</em>, at any time Whether you&#x27;re trying"
      },
      "id": "61744137e7b9d2428b13c6a0"
    },
    {
      "image": "https://docs.newrelic.com/static/5c1d085b14abf961ca66b96285f0c0fa/69902/QS-Integrations.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/install-codestream/",
      "sections": [
        "Install New Relic CodeStream",
        "Install CodeStream",
        "Instant Observability (I/O) quickstart",
        "Visual Studio Code",
        "Visual Studio",
        "JetBrains",
        "Connect your tools",
        "Tip",
        "Discuss any block of code, at any time",
        "Get feedback on your work in progress",
        "Create or review a pull request",
        "Help and feedback"
      ],
      "published_at": "2021-12-19T14:27:50Z",
      "title": "Install New Relic CodeStream",
      "updated_at": "2021-11-24T09:39:10Z",
      "type": "docs",
      "external_id": "5d431c8f9a2690b64d26ac9fc173b18085153aac",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that makes it easy to discuss and review code in a more natural and contextual way. Once connected to New Relic, collaborate on your application errors directly in your IDE. If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Install CodeStream You can install CodeStream for your specific IDE or install it through our Instant Observability (I/O) quickstart. Instant Observability (I/O) quickstart Install CodeStream with its Instant Observability (I/O) quickstart to connect CodeStream to your New Relic account via your user key. Visual Studio Code Download and install CodeStream for Visual Studio Code. You can also install it directly in Visual Studio Code via the extensions marketplace. Visual Studio Download and install CodeStream for Visual Studio. You can also install it directly in Visual Studio via the extensions marketplace. JetBrains Download and install CodeStream for JetBrains. You can also install it from the JetBrains plugins menu. Connect your tools Create and review pull requests on GitHub, GitLab, or Bitbucket. Create issues on Jira, Trello, and other issue trackers. Investigate errors reported to New Relic One. Share code discussions on Slack or Microsoft Teams. CodeStream brings the tools you use every day together in your IDE. Click your headshot at the top of the CodeStream pane, then click Integrations to connect all of your tools to CodeStream. Tip Once you've installed CodeStream, to connect to New Relic, you'll need your New Relic user key. Go here to learn more about finding or creating your user key. Discuss any block of code, at any time Whether you're trying to understand someone else's code or getting help with some code you just wrote, select the code and click the comment button to ask your question. Learn more about discussing code. Get feedback on your work in progress Click the + menu then click Request Feedback at any time in the development cycle, whether its a quick look over some work in progress (even uncommitted code) or a formal review of a completed effort. Teammates can review your changes right in their IDE, with no need to switch branches or set aside their own work. Learn more about feedback requests. Create or review a pull request In the CodeStream sidebar, look for the Pull Requests section to review an open pull request. Select a pull request (or load one from URL) to get a complete GitHub experience right in your IDE. You can create a pull request in GitHub, GitLab, or Bitbucket, but support for reviewing pull requests is currently only available for GitHub. Learn more about pull requests. Help and feedback Report a bug or suggest an improvement in GitHub issues. Contact us directly at support@codestream.com. Follow @teamcodestream for product updates and to share feedback and questions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1083.6969,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install New Relic <em>CodeStream</em>",
        "sections": "Install New Relic <em>CodeStream</em>",
        "body": ", and other issue trackers. Investigate errors reported to New Relic One. Share <em>code</em> discussions on Slack or <em>Microsoft</em> <em>Teams</em>. <em>CodeStream</em> brings the tools you use every day together in your IDE. Click your headshot at the top of the <em>CodeStream</em> pane, then click Integrations to connect all of your tools"
      },
      "id": "6174400564441ff1025fd832"
    },
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.51132,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    }
  ],
  "/docs/codestream/codestream-integrations/notifications": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.1947,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://developer.newrelic.com/static/5177711f1b2afa281eb4b16b448a95c4/0086b/errors-inbox.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/triage-errors/",
      "sections": [
        "Triage your errors",
        "lab",
        "View error details",
        "Tip",
        "Set an error's status",
        "Assign an error"
      ],
      "published_at": "2021-12-19T13:43:05Z",
      "title": "Triage your errors",
      "updated_at": "2021-12-19T13:43:05Z",
      "type": "developer",
      "external_id": "7e24d04a7ffa408fee136170d2bf7467ab6c48cd",
      "document_type": "page",
      "popularity": 1,
      "info": "Track and triage errors across your stack with Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've set up Errors Inbox before starting this one. Geek's Movie Shop is running in your development environment, and you're able to see its errors in Errors Inbox. Because you want to ensure a smooth experience for your customers, you need to analyze and triage these errors. By triaging your errors, you reduce the noise in your inbox. This helps you focus on the errors that impact your application the most. View error details In Errors Inbox, you see all unresolved errors across your application by default. Sometimes you need to learn more about an error before you can decide what to do with it. Step 1 of 2 Click the pika.exceptions:ChannelWrongStateError. This takes you to its details page. Here, you see the error's full context, including its stack trace and the number of times it occurred. The stack trace is especially important since it helps you narrow down the cause of the problem. Step 2 of 2 In the bottom right corner of Stack Trace, click Show all. The full trace tells you that something is wrong in your payment service. If this were a real-world application, you could use this stack trace and other details from this view to fix the issue. However, in this lab you're focused on using Errors Inbox, so skip this step. Tip You can also integrate CodeStream with your Errors Inbox. This allows you to jump to the relevant code in your IDE with the click of a button. Once you've configured CodeStream, click Open in IDE. Set an error's status Each error in Errors Inbox is Unresolved by default. But if you fix a bug or decide it isn't worth fixing, you can change its status to reflect that. Another developer on your team said they fixed this pika.exceptions:ChannelWrongStateError, so update its status to Resolved. Step 1 of 3 In New Relic, navigate to Errors Inbox. Step 2 of 3 On the error's row, click the status dropdown. You see two options in the dropdown: Resolve Ignore Step 3 of 3 Select Resolve. When you resolve an error, it no longer appears on the main screen. However, if the error occurs again, Errors Inbox automatically unresolves it. Tip If you want to ignore an error instead of resolving it, you can do that here as well. When you ignore an error, it no longer appears on the main screen. To see it again, either change the filter to include ignored error groups or stop ignoring the error. Assign an error Refresh the page. Oops! You resolved pika.exceptions:ChannelWrongStateError, but it's back in your Unresolved error groups. Apparently the bug wasn't fixed after all. You've decided to fix the error yourself. Step 1 of 2 On the far right side of the error group, click the user icon. Step 2 of 2 Enter and submit your email address. This tells your team that you're responsible for resolving the error. Tip Currently, when you assign an error group to a user, they don't receive a notification. Notifications are coming soon. You've triaged the pika.exceptions:ChannelWrongStateError. You can do the same for a few others as well. After ignoring, resolving, and assigning errors, your inbox is looking a lot cleaner than when you first saw it. Next, you filter your inbox and integrate it with other services so you can find, prioritize, and fix the errors that need fixing before you release your new app version to the world. lab This procedure is part of a lab that teaches you how to track full stack errors using Errors Inbox. Now that you've triaged your errors, it's time to manage them.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.67426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " service. If this were a real-world application, you could use this stack trace and other details from this view to fix the issue. However, in this lab you&#x27;re focused on using Errors Inbox, so skip this step. Tip You can also integrate <em>CodeStream</em> with your Errors Inbox. This allows you to jump"
      },
      "id": "61bf36e9196a67049def096d"
    },
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-20T01:42:42Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.03543,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>",
        "body": " pika.exceptions:ChannelWrongStateError, you don&#x27;t see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>"
      },
      "id": "61be8f01196a67e048eef29c"
    }
  ],
  "/docs/codestream/codestream-integrations/slack-integration": [
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-20T01:42:42Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1243.7249,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Optional: Integrate Errors Inbox with <em>Slack</em>, Jira, <em>and</em> <em>CodeStream</em>",
        "body": " pika.exceptions:ChannelWrongStateError, you don&#x27;t see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with <em>Slack</em>, Jira, and <em>CodeStream</em>"
      },
      "id": "61be8f01196a67e048eef29c"
    },
    {
      "image": "https://docs.newrelic.com/static/79d35d62b4c952d3f8b6131bbcfce9e7/f96db/Sidebar3.png",
      "url": "https://docs.newrelic.com/docs/codestream/codestream-ui-overview/codestream-sidebar/",
      "sections": [
        "CodeStream sidebar overview",
        "Sidebar overview",
        "The username menu",
        "Header menu items"
      ],
      "published_at": "2021-12-19T14:13:21Z",
      "title": "CodeStream sidebar overview",
      "updated_at": "2021-11-13T21:09:54Z",
      "type": "docs",
      "external_id": "d3bb6106b4e568060453b597ac08e4a51471f3a3",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic CodeStream sidebar surfaces all the items you need to see, and do, in a customizable tree-based view that is always available. The main sidebar sections are: pull requests, feedback requests, codemarks, observability, and issues. Sidebar overview Here's a quick overview of the sidebar sections: Pull requests: If your team uses GitHub or GitHub Enterprise to host your code, you'll see all of your open pull requests listed here. Click a specific pull request to start reviewing or editing it. Feedback requests: If you've been assigned a feedback request or you've requested feedback from someone else, find those listed here. Codemarks: Codemarks are the discussions that annotate your codebase. Codemarks are created pull requests, feedback requests, or through ad hoc code comments/issues. All of the codemarks in your current repository are listed for reference. Observability: Track errors assigned to you in New Relic One and discover recent errors in the repositories you have open in your IDE. Issues: See all of your open issues, across multiple services, in one place. Click a specific issue to update its status, create a feature branch to do your work, and update your status on Slack. The CodeStream sidebar is completely customizable: Drag and drop the sections to reorder them. Click and drag a section divider to resize the sections on either side. Expand or collapse each section as needed. Click the maximize button in each section to fill the whole screen. This is useful when you're looking at a longer list. Click it again to return to your previous view. The username menu The username menu gives you options for managing your account, your organization, how you receive notifications, and what sections are visible. Here are descriptions of each menu item: Account: View your profile. Includes various options for customizing the profile photo, email, username, and full name for your account. View: Uncheck sections you're not interested in seeing. Notifications: Manage how and what notifications you receive. Organization admin: Manage your organization settings. Also, export your data and delete your organization. Switch organization: Use this if you're a member of more than one organization. Integrations: Connect CodeStream to the code host, issue, and messaging providers you use. New Relic setup: Connect your New Relic account to CodeStream to get the most out of New Relic CodeStream's observability tools. Feedback: Got feedback for us? Write a GitHub issue. Help: Links to documentation, our video library, keybindings, the CodeStream workflow, what's new, and reporting an issue. Header menu items The header menu items provide different options for creating and discovering content in your organization. From left to right: Create, Activity feed, My organization, and Filter & search. + (Compose): Click to create a code comment/issue, request feedback on changes, or to create a pull request. Activity feed: The activity feed will let you know about new code comments/issues and feedback requests, as well as replies to existing ones. My organization: See who is in your CodeStream organization, invite new members, and create blame maps. Filter & search: The filter a search tools enable you to slice and dice your teams collection of code comments, issues, and feature requests however you see fit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 606.2236,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> sidebar overview",
        "sections": "<em>CodeStream</em> sidebar overview",
        "body": " status on <em>Slack</em>. The <em>CodeStream</em> sidebar is completely customizable: Drag and drop the sections to reorder them. Click and drag a section divider to resize the sections on either side. Expand or collapse each section as needed. Click the maximize button in each section to fill the whole screen"
      },
      "id": "617cbd1b28ccbc18bf7fef35"
    },
    {
      "image": "https://docs.newrelic.com/static/8945e0a9c512b8638ebf8165d47aee04/69902/QS-SignUp3.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-user-guide/",
      "sections": [
        "New Relic CodeStream user guide",
        "Jump to a topic",
        "1. Install the CodeStream extension in your IDE and sign up.",
        "2. Connect your tools",
        "3. Discuss any block of code, at any time",
        "4. Get feedback on your work in progress",
        "5. Create or review a pull request",
        "Help and feedback"
      ],
      "published_at": "2021-12-19T15:16:39Z",
      "title": "New Relic CodeStream user guide",
      "updated_at": "2021-11-24T04:44:31Z",
      "type": "docs",
      "external_id": "fa9af0118a8872fea89fda91482c44fb69913ea2",
      "document_type": "page",
      "popularity": 1,
      "body": "Jump to a topic Use the navigation on the left to jump straight to any topic. Otherwise, read on to get started with New Relic CodeStream. If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. 1. Install the CodeStream extension in your IDE and sign up. Install CodeStream for VS Code, Visual Studio or JetBrains. The CodeStream pane automatically appears in the sidebar for VS Code or in a tool window at the right side for JetBrains or Visual Studio. Click Sign Up and Create a team if you're the first person from your team to join CodeStream or paste in your invitation code if you were invited to a team already on CodeStream. Learn more about how to use CodeStream. 2. Connect your tools Create and review pull requests on GitHub, GitLab or Bitbucket. Create issues on Jira, Trello, and other issue trackers. Share code discussions on Slack or Microsoft Teams. CodeStream brings the tools you use every day together in your IDE. Click on your headshot at the top of the CodeStream pane and go to the Integrations page to get all of your tools connected. 3. Discuss any block of code, at any time Whether you're trying to understand someone else's code or getting help with some code you just wrote, just select the code and ask your question. Learn more about discussing code. 4. Get feedback on your work in progress Select Request Feedback from the + menu at any time in the development cycle, whether its a quick look over some work in progress (even uncommitted code!) or a formal review of a completed effort. Teammates can review your changes right in their IDE, with no need to switch branches or set aside their own work. Learn more about feedback requests. 5. Create or review a pull request Look for the Pull Requests section of the CodeStream sidebar to review an open pull request. Just click on a pull request (or load one from URL) to get a complete GitHub experience right in your IDE! Note that you can create a pull request in GitHub, GitLab or Bitbucket, but support for reviewing pull requests is currently only available for GitHub (cloud or Enterprise). Learn more about pull requests. Help and feedback Report a bug or suggest an improvement in GitHub issues. Contact us directly at support@codestream.com. Follow @teamcodestream for product updates and to share feedback and questions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 509.24948,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>CodeStream</em> user guide",
        "sections": "1. Install the <em>CodeStream</em> extension in your IDE <em>and</em> sign up.",
        "body": " discussions on <em>Slack</em> or Microsoft Teams. <em>CodeStream</em> brings the tools you use every day together in your IDE. Click on your headshot at the top of the <em>CodeStream</em> pane and go to the Integrations page to get all of your tools connected. 3. Discuss any block of <em>code</em>, at any time Whether you&#x27;re trying"
      },
      "id": "61744137e7b9d2428b13c6a0"
    }
  ],
  "/docs/codestream/codestream-settings/account-settings": [
    {
      "image": "https://docs.newrelic.com/static/89fc796cef01d95170eace2254590fbe/1efb2/connect-repo1.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-new-relic/",
      "sections": [
        "CodeStream and New Relic One",
        "Preview release",
        "Connect CodeStream and New Relic",
        "Caution",
        "See your errors and what's causing them",
        "Tip",
        "How to go from errors inbox to your IDE",
        "APM errors and CodeStream",
        "Associate repositories with errors",
        "Use environment variable with APM (recommended)",
        "Use the UI",
        "Use the NerdGraph API",
        "Associate build SHAs or release tags with errors",
        "Install APM agents with CodeStream",
        "Dynamic logging with Go and Pixie"
      ],
      "published_at": "2021-12-19T14:37:10Z",
      "title": "CodeStream and New Relic One",
      "updated_at": "2021-12-14T23:24:49Z",
      "type": "docs",
      "external_id": "a6c04d95011d9150cb0798580c15695bb9f3bbda",
      "document_type": "page",
      "popularity": 1,
      "body": "CodeStream and New Relic One work together to give you insight into your code's errors, as well as making it easier to get started instrumenting your code with our APM agents. With CodeStream connected to New Relic One, you can jump from a stack trace error directly to the offending line of code in your IDE. Once in your IDE, you can navigate the stack trace and collaborate with your teammates to resolve the issue. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Connect CodeStream and New Relic Before you can take advantage of New Relic's observability features in CodeStream, you'll need to connect them. Requirements for connecting CodeStream and New Relic: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key If you don't have a user key or want to learn more about how you can use and manage them, see our doc on the New Relic user key. Once you have your New Relic user key, in CodeStream's Observability section click Connect to New Relic One, then paste your API key and click Connect to New Relic One. Caution New Relic users can share stacktrace errors on CodeStream. Once you've connected CodeStream to New Relic, any new users you add to your CodeStream organization can see those errors. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Requirements for opening stack trace errors in your IDE: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key CodeStream and New Relic connection Data being reported to New Relic via APM monitoring A workload for errors inbox An error For APM errors, your repository's commit hash and release tag New Relic errors inbox is a single place to proactively detect, prioritize, and take action on your errors before they impact customers. With CodeStream, you can jump from an error directly to the offending code in your IDE. Tip Limited to APM errors. How to go from errors inbox to your IDE From one.newrelic.com/, go to Errors Inbox, click a stack trace error, then click Open in IDE. APM errors and CodeStream In order to view stack trace errors in your IDE, CodeStream needs to know what repository the error is associated with and, ideally, which version of the code generated the error. Associate repositories with errors Once you've started monitoring for APM, mobile, browser, or Lambda, you should create repository entities and associate them with entities for all of your services. In order to create a repository entity you'll need to provide the repository's remote URL. For example, the remote URL can be in either the SSH or HTTPS format: git@github.com:newrelic/beta-docs-site.git https://github.com/newrelic/beta-docs-site.git Caution It's possible to add the same GitHub repository more than once, if you're using different protocols to do so. The UI warns you about this, but won't prevent you from doing so. For example, https://github.com/tuna/repo and git@github.com:tuna/repo are the same repo, with different protocols. If you try to open an error in your IDE and there isn't an associated repository, CodeStream will prompt you to make an association and save that association for all errors from the given entity on New Relic. However, it would be preferably to use one of the following methods since they require less ongoing manual effort and eliminate the possibility of end-user mistakes, such as misconfigured remote URLs. Use environment variable with APM (recommended) Set the environment variable NEW_RELIC_METADATA_REPOSITORY_URL. New Relic APM agents create the repository entity and associate it to your application entity automatically. This requires the SSH or HTTPS URL format. We recommend that these be set as part of your build pipeline. Use the UI Once you've started sending data to New Relic, use the UI to connect your related repository. Go to the APM Summary page via one.newrelic.com > Explorer > Services - APM > (select an app), then look for the Repositories section at the bottom-right. Click Connect repository to find an existing repository or add a new one. Use the NerdGraph API Use New Relic's NerdGraph APIsto create a repository and associate it with your application entities. Step 1: Create a repository entity To create a repository entity, use the referenceEntityCreateOrUpdateRepository API and make sure to save the GUID that's produced. The API takes the following parameters: accountId - the integer account ID for the account you want to add the repository to url - example https://github.com/newrelic/beta-docs-site.git name - example: newrelic/beta-docs-site mutation { referenceEntityCreateOrUpdateRepository(repositories: [{accountId: [YOUR_ACCOUNT_ID], name: \"[REPO_NAME]\", url: \"[REPO_URL]\"}]) { created failures { guid message type } } } Copy In order to find the entity you create, you can use a query like the following. Note that the URL you provided to referenceEntityCreateOrUpdateRepository gets saved as an entity tag. { actor { entitySearch(query: \"name = 'a name' OR tags.url = 'a url'\") { count query results { entities { guid name tags { key values } } } } } } Copy Step 2: Associate the repository entity to your application entity First, find the GUID for the application you want to associate your repository to. Parameters: sourceEntityGuid - the entity GUID of the application targetEntityGuid - the entity GUID of your repository type - always BUILT_FROM mutation { entityRelationshipUserDefinedCreateOrReplace(sourceEntityGuid: \"\", targetEntityGuid: \"\", type: BUILT_FROM) { errors { message type } } } Copy To see all entities related to your repository you can do a query like this: { actor { entity(guid: \"[YOUR_REPOSITORY_GUID]]\") { relatedEntities(filter: {direction: BOTH, relationshipTypes: {include: BUILT_FROM}}) { results { target { entity { name guid type } } type } } name type tags { values key } } } } Copy Step 3: Cleanup (if needed) Delete a repository with the following query: mutation DeleteRepository { entityDelete(guids: \"[ENTITY_GUID_HERE]]\") { deletedEntities failures { message guid } } } Copy Associate build SHAs or release tags with errors To use CodeStream's Open in IDE with your APM stack trace errors, use environment variables to configure your APM agent with your application's commit sha and/or your release tag associated with the running version of your software. CodeStream only needs the first seven characters of your commit sha (for example, 734713b) to make this connection, but you can include the entire sha. Alternately, you can use a release tag (such as v0.1.209 or release-209) for CodeStream to find the correct version of your code. For New Relic APM, the commit and/or release tag (tags.commit and tags.releaseTag) are added as attributes on Transaction and TransactionError events. You can use APM environment variables to set these attributes. We recommend setting one or both of these variables as part of your build pipeline. NEW_RELIC_METADATA_COMMIT - The commit sha. You can include the whole thing or only the first seven characters. NEW_RELIC_METADATA_RELEASE_TAG - A release tag (such as v0.1.209 or release-209). This has the advantage of being human readable. For more on how to set these variables, here are specific configuration details for each language: Go Java .NET Node.js PHP Python Install APM agents with CodeStream Requirements for installing New Relic APM agents via CodeStream: New Relic account New Relic user key CodeStream and New Relic connection A supported language application codebase .NET Core Java Node.JS When you first connect CodeStream to New Relic, if you're working on an application's codebase that's not being monitored by New Relic, CodeStream will offer to instrument that application for you. Like New Relic's guided install, CodeStream will walk you through and automate all of the steps to installing the APM agent to start sending data to New Relic. This check only happens automatically when the initial connection is made. To do so later, in the CodeStream extension, click your username, then click New Relic Setup. Dynamic logging with Go and Pixie New Relic account New Relic user API key CodeStream and New Relic connection A Kubernetes cluster monitored by Pixie An application written in Go You can use CodeStream to enable dynamic logging for your Pixie-monitored Go applications. Just right-click on any method name and select Dynamic Logging Using Pixie.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.81235,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> <em>and</em> New Relic One",
        "sections": "<em>CodeStream</em> <em>and</em> New Relic One",
        "body": " the advantage of being human readable. For more on how to <em>set</em> these variables, here are specific configuration details for each language: Go Java .NET Node.js PHP Python Install APM agents with <em>CodeStream</em> Requirements for installing New Relic APM agents via <em>CodeStream</em>: New Relic <em>account</em> New Relic user"
      },
      "id": "6171e652196a67e9c92f0156"
    },
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.99004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to New Relic <em>CodeStream</em>",
        "sections": "Intro to New Relic <em>CodeStream</em>",
        "body": ") If you haven&#x27;t already, sign up for a free New Relic <em>account</em> so that you can get the most out of New Relic <em>CodeStream</em>. Preview release <em>CodeStream</em>&#x27;s integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release"
      },
      "id": "617440e3e7b9d2836c13c43c"
    },
    {
      "image": "https://docs.newrelic.com/static/79d35d62b4c952d3f8b6131bbcfce9e7/f96db/Sidebar3.png",
      "url": "https://docs.newrelic.com/docs/codestream/codestream-ui-overview/codestream-sidebar/",
      "sections": [
        "CodeStream sidebar overview",
        "Sidebar overview",
        "The username menu",
        "Header menu items"
      ],
      "published_at": "2021-12-19T14:13:21Z",
      "title": "CodeStream sidebar overview",
      "updated_at": "2021-11-13T21:09:54Z",
      "type": "docs",
      "external_id": "d3bb6106b4e568060453b597ac08e4a51471f3a3",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic CodeStream sidebar surfaces all the items you need to see, and do, in a customizable tree-based view that is always available. The main sidebar sections are: pull requests, feedback requests, codemarks, observability, and issues. Sidebar overview Here's a quick overview of the sidebar sections: Pull requests: If your team uses GitHub or GitHub Enterprise to host your code, you'll see all of your open pull requests listed here. Click a specific pull request to start reviewing or editing it. Feedback requests: If you've been assigned a feedback request or you've requested feedback from someone else, find those listed here. Codemarks: Codemarks are the discussions that annotate your codebase. Codemarks are created pull requests, feedback requests, or through ad hoc code comments/issues. All of the codemarks in your current repository are listed for reference. Observability: Track errors assigned to you in New Relic One and discover recent errors in the repositories you have open in your IDE. Issues: See all of your open issues, across multiple services, in one place. Click a specific issue to update its status, create a feature branch to do your work, and update your status on Slack. The CodeStream sidebar is completely customizable: Drag and drop the sections to reorder them. Click and drag a section divider to resize the sections on either side. Expand or collapse each section as needed. Click the maximize button in each section to fill the whole screen. This is useful when you're looking at a longer list. Click it again to return to your previous view. The username menu The username menu gives you options for managing your account, your organization, how you receive notifications, and what sections are visible. Here are descriptions of each menu item: Account: View your profile. Includes various options for customizing the profile photo, email, username, and full name for your account. View: Uncheck sections you're not interested in seeing. Notifications: Manage how and what notifications you receive. Organization admin: Manage your organization settings. Also, export your data and delete your organization. Switch organization: Use this if you're a member of more than one organization. Integrations: Connect CodeStream to the code host, issue, and messaging providers you use. New Relic setup: Connect your New Relic account to CodeStream to get the most out of New Relic CodeStream's observability tools. Feedback: Got feedback for us? Write a GitHub issue. Help: Links to documentation, our video library, keybindings, the CodeStream workflow, what's new, and reporting an issue. Header menu items The header menu items provide different options for creating and discovering content in your organization. From left to right: Create, Activity feed, My organization, and Filter & search. + (Compose): Click to create a code comment/issue, request feedback on changes, or to create a pull request. Activity feed: The activity feed will let you know about new code comments/issues and feedback requests, as well as replies to existing ones. My organization: See who is in your CodeStream organization, invite new members, and create blame maps. Filter & search: The filter a search tools enable you to slice and dice your teams collection of code comments, issues, and feature requests however you see fit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.40637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> sidebar overview",
        "sections": "<em>CodeStream</em> sidebar overview",
        "body": " <em>settings</em>. Also, export your data and delete your organization. Switch organization: Use this if you&#x27;re a member of more than one organization. Integrations: Connect <em>CodeStream</em> to the <em>code</em> host, issue, and messaging providers you use. New Relic setup: Connect your New Relic <em>account</em> to <em>CodeStream</em> to get"
      },
      "id": "617cbd1b28ccbc18bf7fef35"
    }
  ],
  "/docs/codestream/codestream-settings/team-administration": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.19467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://docs.newrelic.com/static/89fc796cef01d95170eace2254590fbe/1efb2/connect-repo1.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-new-relic/",
      "sections": [
        "CodeStream and New Relic One",
        "Preview release",
        "Connect CodeStream and New Relic",
        "Caution",
        "See your errors and what's causing them",
        "Tip",
        "How to go from errors inbox to your IDE",
        "APM errors and CodeStream",
        "Associate repositories with errors",
        "Use environment variable with APM (recommended)",
        "Use the UI",
        "Use the NerdGraph API",
        "Associate build SHAs or release tags with errors",
        "Install APM agents with CodeStream",
        "Dynamic logging with Go and Pixie"
      ],
      "published_at": "2021-12-19T14:37:10Z",
      "title": "CodeStream and New Relic One",
      "updated_at": "2021-12-14T23:24:49Z",
      "type": "docs",
      "external_id": "a6c04d95011d9150cb0798580c15695bb9f3bbda",
      "document_type": "page",
      "popularity": 1,
      "body": "CodeStream and New Relic One work together to give you insight into your code's errors, as well as making it easier to get started instrumenting your code with our APM agents. With CodeStream connected to New Relic One, you can jump from a stack trace error directly to the offending line of code in your IDE. Once in your IDE, you can navigate the stack trace and collaborate with your teammates to resolve the issue. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Connect CodeStream and New Relic Before you can take advantage of New Relic's observability features in CodeStream, you'll need to connect them. Requirements for connecting CodeStream and New Relic: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key If you don't have a user key or want to learn more about how you can use and manage them, see our doc on the New Relic user key. Once you have your New Relic user key, in CodeStream's Observability section click Connect to New Relic One, then paste your API key and click Connect to New Relic One. Caution New Relic users can share stacktrace errors on CodeStream. Once you've connected CodeStream to New Relic, any new users you add to your CodeStream organization can see those errors. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Requirements for opening stack trace errors in your IDE: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key CodeStream and New Relic connection Data being reported to New Relic via APM monitoring A workload for errors inbox An error For APM errors, your repository's commit hash and release tag New Relic errors inbox is a single place to proactively detect, prioritize, and take action on your errors before they impact customers. With CodeStream, you can jump from an error directly to the offending code in your IDE. Tip Limited to APM errors. How to go from errors inbox to your IDE From one.newrelic.com/, go to Errors Inbox, click a stack trace error, then click Open in IDE. APM errors and CodeStream In order to view stack trace errors in your IDE, CodeStream needs to know what repository the error is associated with and, ideally, which version of the code generated the error. Associate repositories with errors Once you've started monitoring for APM, mobile, browser, or Lambda, you should create repository entities and associate them with entities for all of your services. In order to create a repository entity you'll need to provide the repository's remote URL. For example, the remote URL can be in either the SSH or HTTPS format: git@github.com:newrelic/beta-docs-site.git https://github.com/newrelic/beta-docs-site.git Caution It's possible to add the same GitHub repository more than once, if you're using different protocols to do so. The UI warns you about this, but won't prevent you from doing so. For example, https://github.com/tuna/repo and git@github.com:tuna/repo are the same repo, with different protocols. If you try to open an error in your IDE and there isn't an associated repository, CodeStream will prompt you to make an association and save that association for all errors from the given entity on New Relic. However, it would be preferably to use one of the following methods since they require less ongoing manual effort and eliminate the possibility of end-user mistakes, such as misconfigured remote URLs. Use environment variable with APM (recommended) Set the environment variable NEW_RELIC_METADATA_REPOSITORY_URL. New Relic APM agents create the repository entity and associate it to your application entity automatically. This requires the SSH or HTTPS URL format. We recommend that these be set as part of your build pipeline. Use the UI Once you've started sending data to New Relic, use the UI to connect your related repository. Go to the APM Summary page via one.newrelic.com > Explorer > Services - APM > (select an app), then look for the Repositories section at the bottom-right. Click Connect repository to find an existing repository or add a new one. Use the NerdGraph API Use New Relic's NerdGraph APIsto create a repository and associate it with your application entities. Step 1: Create a repository entity To create a repository entity, use the referenceEntityCreateOrUpdateRepository API and make sure to save the GUID that's produced. The API takes the following parameters: accountId - the integer account ID for the account you want to add the repository to url - example https://github.com/newrelic/beta-docs-site.git name - example: newrelic/beta-docs-site mutation { referenceEntityCreateOrUpdateRepository(repositories: [{accountId: [YOUR_ACCOUNT_ID], name: \"[REPO_NAME]\", url: \"[REPO_URL]\"}]) { created failures { guid message type } } } Copy In order to find the entity you create, you can use a query like the following. Note that the URL you provided to referenceEntityCreateOrUpdateRepository gets saved as an entity tag. { actor { entitySearch(query: \"name = 'a name' OR tags.url = 'a url'\") { count query results { entities { guid name tags { key values } } } } } } Copy Step 2: Associate the repository entity to your application entity First, find the GUID for the application you want to associate your repository to. Parameters: sourceEntityGuid - the entity GUID of the application targetEntityGuid - the entity GUID of your repository type - always BUILT_FROM mutation { entityRelationshipUserDefinedCreateOrReplace(sourceEntityGuid: \"\", targetEntityGuid: \"\", type: BUILT_FROM) { errors { message type } } } Copy To see all entities related to your repository you can do a query like this: { actor { entity(guid: \"[YOUR_REPOSITORY_GUID]]\") { relatedEntities(filter: {direction: BOTH, relationshipTypes: {include: BUILT_FROM}}) { results { target { entity { name guid type } } type } } name type tags { values key } } } } Copy Step 3: Cleanup (if needed) Delete a repository with the following query: mutation DeleteRepository { entityDelete(guids: \"[ENTITY_GUID_HERE]]\") { deletedEntities failures { message guid } } } Copy Associate build SHAs or release tags with errors To use CodeStream's Open in IDE with your APM stack trace errors, use environment variables to configure your APM agent with your application's commit sha and/or your release tag associated with the running version of your software. CodeStream only needs the first seven characters of your commit sha (for example, 734713b) to make this connection, but you can include the entire sha. Alternately, you can use a release tag (such as v0.1.209 or release-209) for CodeStream to find the correct version of your code. For New Relic APM, the commit and/or release tag (tags.commit and tags.releaseTag) are added as attributes on Transaction and TransactionError events. You can use APM environment variables to set these attributes. We recommend setting one or both of these variables as part of your build pipeline. NEW_RELIC_METADATA_COMMIT - The commit sha. You can include the whole thing or only the first seven characters. NEW_RELIC_METADATA_RELEASE_TAG - A release tag (such as v0.1.209 or release-209). This has the advantage of being human readable. For more on how to set these variables, here are specific configuration details for each language: Go Java .NET Node.js PHP Python Install APM agents with CodeStream Requirements for installing New Relic APM agents via CodeStream: New Relic account New Relic user key CodeStream and New Relic connection A supported language application codebase .NET Core Java Node.JS When you first connect CodeStream to New Relic, if you're working on an application's codebase that's not being monitored by New Relic, CodeStream will offer to instrument that application for you. Like New Relic's guided install, CodeStream will walk you through and automate all of the steps to installing the APM agent to start sending data to New Relic. This check only happens automatically when the initial connection is made. To do so later, in the CodeStream extension, click your username, then click New Relic Setup. Dynamic logging with Go and Pixie New Relic account New Relic user API key CodeStream and New Relic connection A Kubernetes cluster monitored by Pixie An application written in Go You can use CodeStream to enable dynamic logging for your Pixie-monitored Go applications. Just right-click on any method name and select Dynamic Logging Using Pixie.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.84076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> <em>and</em> New Relic One",
        "sections": "<em>CodeStream</em> <em>and</em> New Relic One",
        "body": " section click Connect to New Relic One, then paste your API key and click Connect to New Relic One. Caution New Relic users can share stacktrace errors on <em>CodeStream</em>. Once you&#x27;ve connected <em>CodeStream</em> to New Relic, any new users you add to your <em>CodeStream</em> <em>organization</em> can see those errors. See your"
      },
      "id": "6171e652196a67e9c92f0156"
    },
    {
      "image": "https://docs.newrelic.com/static/30e00c292c5aa1c5d702d67be5021a45/f96db/CreateAnAccount6.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/sign-up-codestream/",
      "sections": [
        "Sign up for CodeStream",
        "Create an account",
        "CodeStream organizations",
        "Create or join an organization",
        "Invite your team"
      ],
      "published_at": "2021-12-19T15:29:26Z",
      "title": "Sign up for CodeStream",
      "updated_at": "2021-11-24T09:42:56Z",
      "type": "docs",
      "external_id": "2f8eda03703523f62844512a3b8ef005b624ebc2",
      "document_type": "page",
      "popularity": 1,
      "body": "To get the most out of New Relic CodeStream's collaboration tools, create an organization and then invite your team members to it. If you haven't already, sign up for a free New Relic account to jump from your application's stack trace errors in New Relic One directly to the line of code responsible in your IDE. Create an account If you already have the CodeStream extension installed in your IDE, you can start the sign up process from the CodeStream pane. There are two ways to sign up for CodeStream. You can sign up with a set of CodeStream credentials (such as, email address and password). Alternatively, you can sign up using your GitHub, GitLab, or Bitbucket (cloud versions only) account. Signing up via your code host also connects your repositories to CodeStream. If the email address you're using with your code host isn't your work email, you should create CodeStream-specific credentials instead. If you sign up via CodeStream, your next step will be to confirm your email address by entering a code sent to you via email. You can paste the code into any of the boxes rather than typing each number individually. CodeStream organizations A CodeStream organization is where you and your teammates will discuss code. Similar to a Slack workspace, all of the developers in your company are in the same CodeStream organization. CodeStream's activity feed keeps things relevant for you by showing activity related to the code you have open in your IDE. The discussions about code build up a knowledge base that is a company-wide resource, so the only reason to have multiple organizations on CodeStream is if you truly need separation. For example, you might have an organization for your day job and another for an open-source project you work on. Or maybe you're a consultant that's a member of different CodeStream organizations for each of your clients. Create or join an organization If you're invited to join an organization on CodeStream, sign up with the same email address the invitation was sent to. You'll automatically be added to that organization. If you're the first person from your company to sign up for CodeStream you can go ahead and create a new organization. Otherwise, there may be existing CodeStream organizations available for you to join based on your email domain. If you think your company is already on CodeStream, but don't see an organization to join, make sure that you've signed up with your work email. If you decide to create an organization you'll be asked to give it a name and, if you signed up with your work email address, anyone else with that email domain can join the organization. Invite your team Collaboration is a team sport so invite your teammates to join you on CodeStream. CodeStream will offer up some suggestions based on the commit history of the repositories you have open in your IDE. Now you're ready to start using CodeStream.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.96841,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sign up for <em>CodeStream</em>",
        "sections": "<em>CodeStream</em> <em>organizations</em>",
        "body": "To get the most out of New Relic <em>CodeStream</em>&#x27;s collaboration tools, create an <em>organization</em> and then invite your team members to it. If you haven&#x27;t already, sign up for a free New Relic account to jump from your application&#x27;s stack trace errors in New Relic One directly to the line of <em>code</em>"
      },
      "id": "617440e3196a6782592f011c"
    }
  ],
  "/docs/codestream/codestream-ui-overview/activity-feed": [
    {
      "image": "https://docs.newrelic.com/static/30e00c292c5aa1c5d702d67be5021a45/f96db/CreateAnAccount6.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/sign-up-codestream/",
      "sections": [
        "Sign up for CodeStream",
        "Create an account",
        "CodeStream organizations",
        "Create or join an organization",
        "Invite your team"
      ],
      "published_at": "2021-12-19T15:29:26Z",
      "title": "Sign up for CodeStream",
      "updated_at": "2021-11-24T09:42:56Z",
      "type": "docs",
      "external_id": "2f8eda03703523f62844512a3b8ef005b624ebc2",
      "document_type": "page",
      "popularity": 1,
      "body": "To get the most out of New Relic CodeStream's collaboration tools, create an organization and then invite your team members to it. If you haven't already, sign up for a free New Relic account to jump from your application's stack trace errors in New Relic One directly to the line of code responsible in your IDE. Create an account If you already have the CodeStream extension installed in your IDE, you can start the sign up process from the CodeStream pane. There are two ways to sign up for CodeStream. You can sign up with a set of CodeStream credentials (such as, email address and password). Alternatively, you can sign up using your GitHub, GitLab, or Bitbucket (cloud versions only) account. Signing up via your code host also connects your repositories to CodeStream. If the email address you're using with your code host isn't your work email, you should create CodeStream-specific credentials instead. If you sign up via CodeStream, your next step will be to confirm your email address by entering a code sent to you via email. You can paste the code into any of the boxes rather than typing each number individually. CodeStream organizations A CodeStream organization is where you and your teammates will discuss code. Similar to a Slack workspace, all of the developers in your company are in the same CodeStream organization. CodeStream's activity feed keeps things relevant for you by showing activity related to the code you have open in your IDE. The discussions about code build up a knowledge base that is a company-wide resource, so the only reason to have multiple organizations on CodeStream is if you truly need separation. For example, you might have an organization for your day job and another for an open-source project you work on. Or maybe you're a consultant that's a member of different CodeStream organizations for each of your clients. Create or join an organization If you're invited to join an organization on CodeStream, sign up with the same email address the invitation was sent to. You'll automatically be added to that organization. If you're the first person from your company to sign up for CodeStream you can go ahead and create a new organization. Otherwise, there may be existing CodeStream organizations available for you to join based on your email domain. If you think your company is already on CodeStream, but don't see an organization to join, make sure that you've signed up with your work email. If you decide to create an organization you'll be asked to give it a name and, if you signed up with your work email address, anyone else with that email domain can join the organization. Invite your team Collaboration is a team sport so invite your teammates to join you on CodeStream. CodeStream will offer up some suggestions based on the commit history of the repositories you have open in your IDE. Now you're ready to start using CodeStream.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1731.3553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sign up for <em>CodeStream</em>",
        "sections": "Sign up for <em>CodeStream</em>",
        "body": " and your teammates will discuss <em>code</em>. Similar to a Slack workspace, all of the developers in your company are in the same <em>CodeStream</em> organization. <em>CodeStream</em>&#x27;s <em>activity</em> <em>feed</em> keeps things relevant for you by showing <em>activity</em> related to the <em>code</em> you have open in your IDE. The discussions about <em>code</em> build up"
      },
      "id": "617440e3196a6782592f011c"
    },
    {
      "image": "https://docs.newrelic.com/static/eeb160b7c86583a706f3b8b4cc3d5f41/f96db/AccountSettings2.png",
      "url": "https://docs.newrelic.com/docs/codestream/codestream-settings/account-settings/",
      "sections": [
        "CodeStream account settings and profile pages",
        "Account overview",
        "Account profile"
      ],
      "published_at": "2021-12-19T14:28:31Z",
      "title": "CodeStream account settings and profile pages",
      "updated_at": "2021-11-13T21:05:57Z",
      "type": "docs",
      "external_id": "83e4ba3ea989b1f2a0bce57b59bf3a7ca92ad2cc",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream account settings let you make changes to your personal account. Account overview The Account menu is located under the ellipses menu at the top of the CodeStream pane. The account menu includes options for viewing your profile and changing your profile photo, username, full name, and email address. When you change your email address, the old one will remain in effect until you click the link in the confirmation email that's sent to you. If you'd like to cancel your CodeStream account, find that option under Other Actions. Account profile If you click a headshot from anywhere in CodeStream (such as, the activity feed or a discussion thread) you're taken to that person's profile page. When viewing your own profile page, hover over entries for username, email address, phone number, works on, or the profile photo to see a pencil icon that enables you to make changes to those fields.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1457.4229,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> account settings and profile pages",
        "sections": "<em>CodeStream</em> account settings and profile pages",
        "body": " anywhere in <em>CodeStream</em> (such as, the <em>activity</em> <em>feed</em> or a discussion thread) you&#x27;re taken to that person&#x27;s profile page. When viewing your own profile page, hover over entries for username, email address, phone number, works on, or the profile photo to see a pencil icon that enables you to make changes to those fields."
      },
      "id": "61743fc5e7b9d2b9e813cf20"
    },
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.5113,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    }
  ],
  "/docs/codestream/codestream-ui-overview/codemarks-section": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.5113,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://docs.newrelic.com/static/74c274508fc745275751f72d3e01ea33/f96db/CodemarkAddRange1.png",
      "url": "https://docs.newrelic.com/docs/codestream/how-use-codestream/discuss-code/",
      "sections": [
        "Discuss code on CodeStream",
        "What is a codemark?",
        "Create a codemark",
        "Comment codemarks",
        "Issue codemarks",
        "Bring the right people into the discussion",
        "Work with different versions of the code",
        "Resolve codemarks",
        "Advanced features",
        "Multiple ranges",
        "File attachments",
        "Add tags",
        "Related codemarks",
        "Manage codemarks"
      ],
      "published_at": "2021-12-21T01:40:40Z",
      "title": "Discuss code on CodeStream",
      "updated_at": "2021-11-13T21:16:02Z",
      "type": "docs",
      "external_id": "9169c03142311fe838566856d0ff154df0e6d555",
      "document_type": "page",
      "popularity": 1,
      "body": "What is a codemark? Quite simply, a codemark is a discussion connected to the code. It could be a question, a suggestion, a bug report, or documentation. All of these discussions are saved, anchored to the blocks of code they refer to, so that they can be leveraged in the future. It could be a new developer joining the team, a developer trying to fix a bug in someone elses code, or even just you trying to remember why you made that change six months ago. Whatever the case, CodeStream helps you understand the code by surfacing the discussions in a contextual way. Even as a file changes over time, the codemarks remain connected to the code. Add some new lines of code above the code block, make edits to the code, or even cut-and-paste the entire block to a different section of the file, and youll see the codemark move along with your changes. Create a codemark To create a codemark, select a block of code in your editor and then click one of the icons that appears in the CodeStream pane next to your selection. If you're using a JetBrains IDE, such as IntelliJ, you can also create a codemark via the + button that appears in the editor's gutter when you select a block of code. When you're viewing a diff, for either a feedback request or a pull request, the button will also appear when you hover over the gutter to make it easy to comment on a single line. Even when the CodeStream pane is closed or not in view, you can create a codemark via the CodeStream options in either the lightbulb or context menus. You can also look for the + menu at the top of the CodeStream pane. Need to reach teammates that dont spend a lot of time in the IDE? Or maybe some teammates that arent yet on CodeStream? You can optionally share a codemark out to Slack or Microsoft Teams. The Slack integration even allows your teammates to reply directly from Slack. Comment codemarks Comment codemarks are the all-purpose codemark for linking any type of discussion to a block of code. Ask a question. Make a suggestion. Document some code. Make note of key sections of the codebase. The possibilities are endless. Issue codemarks When something needs to get done theres a better chance of it happening if its captured as an issue with someones name attached. Assign issues as a way of reporting bugs or manage your tech debt by capturing items as tracked issues instead of inline FIXMEs. If your team uses Asana, Azure DevOps, Bitbucket (cloud), Clubhouse, GitHub (cloud or Enterprise), GitLab (cloud or Self-Managed), Jira (cloud or Server), Linear, Trello, or YouTrack (cloud) for tracking issues, you can create an issue on one of those services directly from CodeStream. Select the service you use from the dropdown at the top of the codemark form. After going through the authentication process with the selected service, you can select a destination for your issue. For example, with Jira you'll be able to select the appropriate issue type and project. Once the issue has been created on CodeStream, it includes a link to the issue that was created on the external service. In the example, you'll see the URL for the issue on Jira. The issue on Jira includes a link to open the relevant code in your IDE. Bring the right people into the discussion When you create a codemark, CodeStream automatically mentions the people that most recently touched the code you're commenting on. They may be the best people to answer your question, but you can, of course, remove those mentions and manually mention someone else if appropriate. It may be the case that the people that have touched the code aren't yet on CodeStream, in which case CodeStream will provide checkboxes to have them notified via email. They can reply to the email to have their comment posted to CodeStream and, of course, they can install CodeStream to participate from their IDE. Work with different versions of the code Maybe youre on a feature branch, have local changes, or simply havent pulled in a while. There are countless reasons why the code youre looking at might be different than what a teammate is looking at. As a result, there will be plenty of times when the code referenced in a codemark doesnt match what you have locally. CodeStream recognizes these situations and includes the original version of the code block (such as, at the time the codemark was created), the current version, and a diff. Keep in mind that with CodeStream you can discuss any line of code, in any source file, at any time, even if its code that you just typed into your editor and havent yet committed. CodeStream empowers you to discuss code at the very earliest stages of the development process. Resolve codemarks Although not required, both comment and issue codemarks can be resolved. The codemarks section of the CodeStream pane breaks out codemarks into open, resolved and archived sections. Green, purple, and gray icons are used to represent those different states. If you see a lot of open/green codemarks in the CodeStream pane, that means that your teammates are being blocked by discussions and issues that haven't been resolved. You can add a comment at the same time you resolve the codemark and you can also archive the codemark at the same time. Advanced features Advanced features include multiple range codemarks, file attachments, tags, and related codemarks. Multiple ranges Many discussions about code involve more than just one block of code and concepts are often best presented when you can refer to multiple code locations at once. Here are a few examples of multi-range codemark at work: A change to a function is being contemplated that will impact its name. Each instance of the function call can now be referenced in one discussion. A React component and its CSS styling arent interacting well and you want to ask the team for input. You might select the div and the CSS rules you think should apply, so your teammates know exactly what youre talking about. Clients which make API calls to the server might get an unexpected result. Select the code where youre making the API call, and the handler in the API server, to connect the two actions together. To create a multi-range codemark, click + Add Code Block. Then select another block of code from the same file, a different file, or even a different repo. You can intersperse the difference code blocks in your post by referring to each one as [#N] (or click the pin icon from one of the code blocks to insert the markdown for you), as in the following example. Here's how that example is rendered. Once you've created the codemark, you can jump between the different locations by clicking the jump icon at the bottom right of each code block. When you edit a codemark, you can add and remove code blocks and you can change the location of any of the code blocks by clicking the dashed square icon. File attachments Enrich your discussions about code by attaching files directly to code blocks. Think about how much more compelling your comments and documentation become when you attach: A spec to guide the development of a new feature A log file to help debug an issue in the code A mockup to help clarify some UI work A screenshot to highlight a problem When creating a code comment or issue, you can attach a file by dragging-and-dropping onto the description field, pasting from your clipboard, or by clicking the paperclip icon. Images can even be displayed inline using markdown. Click the pin icon to the right of the attachment and CodeStream will insert the markdown for you. Now your teammate knows exactly what youre looking for. You can click on files in the attachments section to either download it or open it in the appropriate application. Add tags Look for the tag icon inside the codemark compose box to either select a tag or create a tag using any combination of color and text label. Tags are a great way to broadly organize and group your organization's codemarks and the possibilities here are endless. You can also filter by tag on the Filter & Search page. Related codemarks Click the CodeStream icon in the codemark compose form to select other related codemarks to attach them to the current codemark. This establishes a connection between different parts of a codebase. For example, when a change to one part of the codebase would require a change to another part, identify the dependency by creating two related codemarks. Once youve added the related codemarks theyll be displayed in a related section and you can click on any one to jump to that codemark and the corresponding section of the code. Manage codemarks Click the ellipses menu for any codemark and you'll see options to manage the codemark. Share: In addition to sharing to Slack or Teams at the time you create a codemark, you can also share it anytime later. Follow/Unfollow: Follow a codemark to be notified when its updated. Unfollow to stop receiving notifications. Copy link: Get a permalink for the codemark to share it anywhere. Archive: If theres a codemark that you dont think is important enough to be on permanent display in a given file, but you dont want to completely delete it, you can archive it instead. Settings in the codemarks section allow you to easily see all archived codemarks. Edit: Only the codemark's author can edit it. Delete: Only the codemark's author can delete it, but we encourage you to archive instead of deleting unless you're positive the codemark won't have any future value. Inject as Inline Comment: If you'd like a specific codemark to become part of the repo use this option to have it added as an inline comment. You can select the appropriate format, and then indicate if you want to include timestamps, replies, or to have the comment wrapped at 80 characters. You can also elect to have the codemark archived once it's been added as an inline comment. Reposition codemark: In most cases, a codemark will automatically remain linked to the block of code it refers to as the file changes over time. For example, if you cut the block of code and paste it at a different location in the file, the codemark will move right along with it. There are some scenarios, however, that CodeStream isn't able to handle automatically. For example, if you pasted the block of code into a different file. In these cases, the Reposition codemark allows you to select the new location of the block of code so that the codemark is displayed properly.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.31512,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discuss <em>code</em> on <em>CodeStream</em>",
        "sections": "Discuss <em>code</em> on <em>CodeStream</em>",
        "body": " if its <em>code</em> that you just typed into your editor and havent yet committed. <em>CodeStream</em> empowers you to discuss <em>code</em> at the very earliest stages of the development process. Resolve <em>codemarks</em> Although not required, both comment and issue <em>codemarks</em> can be resolved. The <em>codemarks</em> <em>section</em> of the <em>CodeStream</em>"
      },
      "id": "6174400564441fe8685fd746"
    },
    {
      "image": "https://docs.newrelic.com/static/79d35d62b4c952d3f8b6131bbcfce9e7/f96db/Sidebar3.png",
      "url": "https://docs.newrelic.com/docs/codestream/codestream-ui-overview/codestream-sidebar/",
      "sections": [
        "CodeStream sidebar overview",
        "Sidebar overview",
        "The username menu",
        "Header menu items"
      ],
      "published_at": "2021-12-19T14:13:21Z",
      "title": "CodeStream sidebar overview",
      "updated_at": "2021-11-13T21:09:54Z",
      "type": "docs",
      "external_id": "d3bb6106b4e568060453b597ac08e4a51471f3a3",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic CodeStream sidebar surfaces all the items you need to see, and do, in a customizable tree-based view that is always available. The main sidebar sections are: pull requests, feedback requests, codemarks, observability, and issues. Sidebar overview Here's a quick overview of the sidebar sections: Pull requests: If your team uses GitHub or GitHub Enterprise to host your code, you'll see all of your open pull requests listed here. Click a specific pull request to start reviewing or editing it. Feedback requests: If you've been assigned a feedback request or you've requested feedback from someone else, find those listed here. Codemarks: Codemarks are the discussions that annotate your codebase. Codemarks are created pull requests, feedback requests, or through ad hoc code comments/issues. All of the codemarks in your current repository are listed for reference. Observability: Track errors assigned to you in New Relic One and discover recent errors in the repositories you have open in your IDE. Issues: See all of your open issues, across multiple services, in one place. Click a specific issue to update its status, create a feature branch to do your work, and update your status on Slack. The CodeStream sidebar is completely customizable: Drag and drop the sections to reorder them. Click and drag a section divider to resize the sections on either side. Expand or collapse each section as needed. Click the maximize button in each section to fill the whole screen. This is useful when you're looking at a longer list. Click it again to return to your previous view. The username menu The username menu gives you options for managing your account, your organization, how you receive notifications, and what sections are visible. Here are descriptions of each menu item: Account: View your profile. Includes various options for customizing the profile photo, email, username, and full name for your account. View: Uncheck sections you're not interested in seeing. Notifications: Manage how and what notifications you receive. Organization admin: Manage your organization settings. Also, export your data and delete your organization. Switch organization: Use this if you're a member of more than one organization. Integrations: Connect CodeStream to the code host, issue, and messaging providers you use. New Relic setup: Connect your New Relic account to CodeStream to get the most out of New Relic CodeStream's observability tools. Feedback: Got feedback for us? Write a GitHub issue. Help: Links to documentation, our video library, keybindings, the CodeStream workflow, what's new, and reporting an issue. Header menu items The header menu items provide different options for creating and discovering content in your organization. From left to right: Create, Activity feed, My organization, and Filter & search. + (Compose): Click to create a code comment/issue, request feedback on changes, or to create a pull request. Activity feed: The activity feed will let you know about new code comments/issues and feedback requests, as well as replies to existing ones. My organization: See who is in your CodeStream organization, invite new members, and create blame maps. Filter & search: The filter a search tools enable you to slice and dice your teams collection of code comments, issues, and feature requests however you see fit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.07663,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> sidebar overview",
        "sections": "<em>CodeStream</em> sidebar overview",
        "body": "The New Relic <em>CodeStream</em> sidebar surfaces all the items you need to see, and do, in a customizable tree-based view that is always available. The main sidebar sections are: pull requests, feedback requests, <em>codemarks</em>, observability, and issues. Sidebar overview Here&#x27;s a quick overview of the sidebar"
      },
      "id": "617cbd1b28ccbc18bf7fef35"
    }
  ],
  "/docs/codestream/codestream-ui-overview/codestream-keyboard-shortcuts": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.5113,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-20T01:42:42Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.71191,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>",
        "body": " pika.exceptions:ChannelWrongStateError, you don&#x27;t see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>"
      },
      "id": "61be8f01196a67e048eef29c"
    },
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.5653,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to New Relic <em>CodeStream</em>",
        "sections": "Intro to New Relic <em>CodeStream</em>",
        "body": "New Relic <em>CodeStream</em> is a developer collaboration platform that enables your development team to discuss and review <em>code</em> in a natural and contextual way. <em>CodeStream</em> not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional"
      },
      "id": "617440e3e7b9d2836c13c43c"
    }
  ],
  "/docs/codestream/codestream-ui-overview/codestream-sidebar": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.19467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://docs.newrelic.com/static/8945e0a9c512b8638ebf8165d47aee04/69902/QS-SignUp3.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-user-guide/",
      "sections": [
        "New Relic CodeStream user guide",
        "Jump to a topic",
        "1. Install the CodeStream extension in your IDE and sign up.",
        "2. Connect your tools",
        "3. Discuss any block of code, at any time",
        "4. Get feedback on your work in progress",
        "5. Create or review a pull request",
        "Help and feedback"
      ],
      "published_at": "2021-12-19T15:16:39Z",
      "title": "New Relic CodeStream user guide",
      "updated_at": "2021-11-24T04:44:31Z",
      "type": "docs",
      "external_id": "fa9af0118a8872fea89fda91482c44fb69913ea2",
      "document_type": "page",
      "popularity": 1,
      "body": "Jump to a topic Use the navigation on the left to jump straight to any topic. Otherwise, read on to get started with New Relic CodeStream. If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. 1. Install the CodeStream extension in your IDE and sign up. Install CodeStream for VS Code, Visual Studio or JetBrains. The CodeStream pane automatically appears in the sidebar for VS Code or in a tool window at the right side for JetBrains or Visual Studio. Click Sign Up and Create a team if you're the first person from your team to join CodeStream or paste in your invitation code if you were invited to a team already on CodeStream. Learn more about how to use CodeStream. 2. Connect your tools Create and review pull requests on GitHub, GitLab or Bitbucket. Create issues on Jira, Trello, and other issue trackers. Share code discussions on Slack or Microsoft Teams. CodeStream brings the tools you use every day together in your IDE. Click on your headshot at the top of the CodeStream pane and go to the Integrations page to get all of your tools connected. 3. Discuss any block of code, at any time Whether you're trying to understand someone else's code or getting help with some code you just wrote, just select the code and ask your question. Learn more about discussing code. 4. Get feedback on your work in progress Select Request Feedback from the + menu at any time in the development cycle, whether its a quick look over some work in progress (even uncommitted code!) or a formal review of a completed effort. Teammates can review your changes right in their IDE, with no need to switch branches or set aside their own work. Learn more about feedback requests. 5. Create or review a pull request Look for the Pull Requests section of the CodeStream sidebar to review an open pull request. Just click on a pull request (or load one from URL) to get a complete GitHub experience right in your IDE! Note that you can create a pull request in GitHub, GitLab or Bitbucket, but support for reviewing pull requests is currently only available for GitHub (cloud or Enterprise). Learn more about pull requests. Help and feedback Report a bug or suggest an improvement in GitHub issues. Contact us directly at support@codestream.com. Follow @teamcodestream for product updates and to share feedback and questions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.224,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>CodeStream</em> user guide",
        "sections": "New Relic <em>CodeStream</em> user guide",
        "body": " in your IDE and sign up. Install <em>CodeStream</em> for VS <em>Code</em>, Visual Studio or JetBrains. The <em>CodeStream</em> pane automatically appears in the <em>sidebar</em> for VS <em>Code</em> or in a tool window at the right side for JetBrains or Visual Studio. Click Sign Up and Create a team if you&#x27;re the first person from your team to join"
      },
      "id": "61744137e7b9d2428b13c6a0"
    },
    {
      "image": "https://docs.newrelic.com/static/c1b964985880261f094399e10af5773a/1efb2/MSTCSSigninPage.png",
      "url": "https://docs.newrelic.com/docs/codestream/codestream-integrations/msteams-integration/",
      "sections": [
        "Microsoft Teams and CodeStream",
        "Connect to Microsoft Teams",
        "Participate in CodeStream from Microsoft Teams",
        "Open in IDE",
        "Open on GitHub (or Bitbucket or GitLab)"
      ],
      "published_at": "2021-12-19T15:29:05Z",
      "title": "Microsoft Teams and CodeStream",
      "updated_at": "2021-11-13T21:03:15Z",
      "type": "docs",
      "external_id": "6aa93f89e0a2de618a36e82930fcb23d72eb1321",
      "document_type": "page",
      "popularity": 1,
      "body": "Connect New Relic CodeStream to your Microsoft Teams channel. When you post a codemark your teammates will get notified via the activity feed, and potentially via email. Sometimes, though, you might want to share to Microsoft Teams as well. This would allow you to reach people who havent yet joined CodeStream, or maybe dont spend a lot of time in their IDE. Connect to Microsoft Teams Click here to install the CodeStream app or go to apps in your Microsoft Teams sidebar and search for CodeStream. Once installed you should see the following popup for the CodeStream app, click the Add button. Note, do not expand it and select the options to add to team or chat. Simply click Add. This will take you to your private chat with the CodeStream bot, and youll see the CodeStream logo appear in the Teams sidebar. Type signin in this chat and submit. A post from the bot will appear in the stream, along with a Sign in button. Click the button and youre taken to the web and prompted to sign into CodeStream. After signing in, you're given a token that youll need to copy and paste into your chat with the CodeStream bot back in MS Teams. Paste the token into the chat and submit. Go to a channel in which youd like to share, type @, and then select Get bots in the popup. Select the CodeStream bot from the list (you can search for it if you need to), and then click Add. Return to the channel and @mention the CodeStream bot with the connect command. Repeat this in any channel that you'd like to share to. Once you get the following confirmation, youre ready to share to Teams from CodeStream. When you return to CodeStream you'll now be able to share to the channels that you just connected. Participate in CodeStream from Microsoft Teams When you share to Microsoft Teams, not only does it notify your teammates about the codemark, but they can use it to jump directly into their IDEs to participate in the conversation on CodeStream. Open in IDE Click Open in IDE to view both the code and the discussion right inside your IDE. Youre taken through a CodeStream web page where you can choose which IDE to open. CodeStream remembers your selection the next time you view a discussion from the same repository. Youre then taken to the appropriate source file in your IDE, scrolled to the relevant block of code, with the discussion displayed in the CodeStream pane. If you dont happen to have that repository open in your IDE, CodeStream will automatically open the source file for you (assuming youve opened that repository previously, with CodeStream installed, so that we know where to find it). If youre using a JetBrains IDE, install the Toolbox app so that CodeStream can deep link into the IDE. Open on GitHub (or Bitbucket or GitLab) If the code block is from a repository hosted on GitHub, Bitbucket, or GitLab, this button will take you to the corresponding block of code on that hosting service.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.57004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Microsoft Teams and <em>CodeStream</em>",
        "sections": "Microsoft Teams and <em>CodeStream</em>",
        "body": " joined <em>CodeStream</em>, or maybe dont spend a lot of time in their IDE. Connect to Microsoft Teams Click here to install the <em>CodeStream</em> app or go to apps in your Microsoft Teams <em>sidebar</em> and search for <em>CodeStream</em>. Once installed you should see the following popup for the <em>CodeStream</em> app, click the Add button"
      },
      "id": "6174403d196a678e4e2f271d"
    }
  ],
  "/docs/codestream/codestream-ui-overview/feedback-requests-section": [
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1959.6194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to New Relic <em>CodeStream</em>",
        "sections": "Get <em>feedback</em> on work-in-progress with pre-PR <em>code</em> review",
        "body": " For most development teams, the final step in the development process is a pull <em>request</em>. Even if your team has decided to use <em>CodeStream</em>&#x27;s <em>feedback</em> <em>requests</em> as a replacement for, and not just a precursor to, your end-of-cycle PR-based <em>code</em> reviews, you can create and review pull <em>requests</em> right inside"
      },
      "id": "617440e3e7b9d2836c13c43c"
    },
    {
      "image": "https://docs.newrelic.com/static/595e873b1bfe20aa5d39a66adf18d0c9/f96db/RequestFeedback.png",
      "url": "https://docs.newrelic.com/docs/codestream/how-use-codestream/request-feedback/",
      "sections": [
        "Request feedback on CodeStream",
        "Request feedback",
        "Tip",
        "Provide feedback",
        "Comments and change requests",
        "Add more code changes"
      ],
      "published_at": "2021-12-19T15:43:19Z",
      "title": "Request feedback on CodeStream",
      "updated_at": "2021-11-13T21:19:49Z",
      "type": "docs",
      "external_id": "752fa4dd9516d616b763d1552836fc30a93ccc7b",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream's feedback requests are powerful enough to use for traditional end-of-cycle code reviews, but at the same time they're so easy and flexible that you can use them throughout the development process to get quick feedback on work-in-progress. You can even use feedback requests for uncommitted your changes. Traditional code review happens at the end of the development cycle, when youre looking to get the changes merged. Not only are end-of-cycle code reviews much more burdensome on your teammates, but you run the risk of identifying issues so late in the game that you end up having to decide between blowing up your schedule or taking on technical debt. Whether youre at the beginning of a project, with just some stubbed out functions, are mid-way through a work in progress, or are ready for a final review of a finished project, CodeStream enables feedback at any point during the development cycle. CodeStream handles the complexity of sharing your current status, including pushed commits, local commits, and staged and saved changes. Your teammates can provide feedback from their IDE, with no need to switch applications, and no need to switch branches or pull changes. By the time you get to the formal code review/pull request at the end of the development cycle, its far less painful and more of a formality because issues have been raised, discussed, and resolved all along the way. Request feedback To request feedback at any time, regardless of the current state of your work, click the + Create button at the top of the CodeStream pane, or the + Request Feedback button in the header of the Feedback Requests section. You can also use a keyboard shortcut (ctlr+shift+/ r or ctrl+/ r on a Mac). With a single click you can name the feedback request based on the last commit message, the branch name, or, if you started work by selecting a ticket, the ticket title. CodeStream assumes that you are requesting feedback on changes in the repository/branch of the file you've currently selected in your editor. If you have multiple repositories open in your IDE, you can change this via the repository dropdown at the very top of the feedback request form. Depending on your organization's settings, CodeStream may suggest specific reviewers. Based on the commit history of the code being changed, the suggestions may even include someone that isn't yet on your CodeStream team. In that case, they'd be notified by email. Hover over a reviewers name to see more details or to remove them. If multiple reviewers are assigned you may also have the option to determine whether any of them can approve the review or if each one has to approve it individually. The Changed Files section lists all of the files that have been added, removed, or modified. Click any file to view a diff if you want to review your changes before submitting the feedback request. If you have a file thats not suitable for review, such as a checked-in binary file, you can hover over any file and click the x to exclude that file from the feedback request. That file will be moved to a list below the form. New files are, by default, excluded from the feedback request, but you can hover over their entry in the list and click + to add them. Hover over an excluded file and click the trashcan to permanently exclude it from all future feedback requests. Permanently excluding files creates a .codestreamignore file in the repository. If you think your teammates will also want to exclude these files (for example, a package-lock.json or other system-generated file), you can commit and push the file so that they can make use of it as well. The changes represented across the selected files are broken out into four different categories, allowing you to select exactly what you would like to include in the feedback request. This includes changes that haven't been pushed, or even committed. The four categories are: Saved changes Staged changes Local commits Pushed commits Commits are listed in descending order across the Local Commits and Pushed Commits sections. If you uncheck the box for a commit, it will automatically uncheck the boxes for all of its preceding commits. In other words, the commits included in the feedback request must be consecutive. Only your commits are checked by default, but you can include any of them in your review. Tip Make sure the email address in your git configuration matches your CodeStream email address. Or set up a blame map to map your git email address to you CodeStream email address. Optionally, you can share your feedback request out to either Slack or Microsoft Teams. When you submit your feedback request, your teammates will be notified via the activity feed, with anyone assigned as a reviewer being @mentioned so that theyll also receive an email notification. Provide feedback The best part of CodeStream's feedback requests is that having your teammates look over your code doesn't put any extra burden on them. There's no need for them to set aside their own work to switch branches or pull changes and no need to for them to leave their IDE. As long as they have the appropriate repository, they can open the feedback request and start reviewing your changes. Click any file in the Changed Files section to review the changes. The changes are presented with a diff in your editor. You can step through the changes in the file using your IDE's native navigation or click the up/down arrows at the top of your IDE. For JetBrains IDEs, CodeStream only supports the side-by-side diff viewer. Typically, the diff will represent the changes in the branch associated with the feedback request (such as, a feature/topic branch) against the base branch, at the point at which the feature branch was created. With CodeStream diffs this may not always be the case, because the developer may not have included all of their changes in the feedback request. As a result, the version of the files that the changes are being diffed against may, in fact, also include changes that arent in the base branch. This is important in order to provide continuity. Comments and change requests If you have a general comment about the changes, add a reply to the feedback request's thread. If you want to comment on the actual changes, select some code from the right side of the diff and then click the comment button that appears in the CodeStream pane next to your selection. You can also use a keyboard shortcut (ctlr+shift+/ c or ctrl+/ c on a Mac) after selecting some code. Since you have the full file context, you arent limited to commenting on just the lines of code that were changed. For example, you might notice another part of the file that needs work as well or that you simply want to reference. Whether its a general comment or a comment on code, you can mark it as a change request to let the developer know that its required before youll approve the changes. While you're providing feedback, you can even comment on files that aren't part of the changeset and they'll get added as a reply to the review. This is helpful to be able to point your teammate to another location in the codebase that might need improving. All of the change requests associated with the the feedback request are summarized in a section at the top, in addition to being part of the discussion thread. This is where they'll get marked complete when the work is done. Look for the green and red buttons at the top to either approve the changes or request additional changes. If there are any open change requests, the approve button will be replaced by a blue button that shows the number. You can still approve the changes, but we wanted to make sure you were aware of the outstanding work. When there are multiple reviewers, and an approval is required from each, CodeStream makes it very clear when there are still outstanding approvals. The blue button at the top right shows how many approvals are outstanding. The green thumbs up on the headshots of reviewers indicates that they've already approved your changes. Add more code changes A typical workflow involves the reviewer leaving some comments or suggesting some changes and then the developer responding to that feedback with more changes to the code. To continue the process, click the blue Amend button to add your changes. Similar to when you originally submitted the feedback request, you can choose from your saved and staged changes and your local and pushed commits. Any open change requests are also listed so you can mark off any that are addressed by your update. By default, when the reviewer goes back into the feedback request, theyll be looking at the complete changeset (such as, changes across all updates) as they go through the diffs for each file. They can also view the diffs for any individual update. The feedback review process can continue across as many updates as needed to get to the final approval of your changes. Once the feedback request has been approved, you can create a pull request from within CodeStream to get your code merged. Tip The feedback request can't be amended or reopened once a pull request has been created.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1211.4012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Request</em> <em>feedback</em> on <em>CodeStream</em>",
        "sections": "<em>Request</em> <em>feedback</em> on <em>CodeStream</em>",
        "body": " state of your work, click the + Create button at the top of the <em>CodeStream</em> pane, or the + <em>Request</em> <em>Feedback</em> button in the header of the <em>Feedback</em> <em>Requests</em> section. You can also use a keyboard shortcut (ctlr+shift+&#x2F; r or ctrl+&#x2F; r on a Mac). With a single click you can name the <em>feedback</em> <em>request</em> based"
      },
      "id": "6174403d28ccbc9b20c6cca0"
    },
    {
      "image": "https://docs.newrelic.com/static/dd18b67123e9d4b7d40b56a8653a1f6b/f96db/OpenPullRequest1.png",
      "url": "https://docs.newrelic.com/docs/codestream/how-use-codestream/pull-requests/",
      "sections": [
        "Manage pull requests in CodeStream",
        "Pull request workflow",
        "Create a pull request",
        "Review a pull request",
        "Caution",
        "Leverage pull request comments"
      ],
      "published_at": "2021-12-21T01:41:29Z",
      "title": "Manage pull requests in CodeStream",
      "updated_at": "2021-11-13T21:14:26Z",
      "type": "docs",
      "external_id": "7e35f2ff4f06799fe492ffb6b2fedbb52e898b69",
      "document_type": "page",
      "popularity": 1,
      "body": "For most development teams, the final step in the development process is a pull request. Even if your team has decided to use New Relic CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, CodeStream allows you to keep all of that workflow inside your IDE. Pull request workflow There are four elements of CodeStream's pull request workflow. The following table outlines which code-hosting services are supported for each element. Feature Supported Services Create a pull request GitHub, GitHub Enterprise, GitLab, GitLab Self-Managed, Bitbucket, Bitbucket Server Create a pull request across forks GitHub, GitHub Enterprise, GitLab, GitLab Self-Managed Review and edit a pull request GitHub, GitHub Enterprise, GitLab, GitLab Self-Managed Display pull request comments as code annotations GitHub, GitLab, Bitbucket Create a pull request To open a pull request at any time, click the + button at the top of the CodeStream pane or the + button in the header of the Pull Requests section. You can also use a keyboard shortcut (ctlr+shift+/ p, ctrl+/ p on a Mac, and m if you're a GitLab user). CodeStream provides you with tree view, list view, and diff view options for reviewing your changes before opening the pull request. With a single click you can name the pull request based on the last commit message, the branch name, or, if you started work by selecting a ticket, the ticket title. If you have a ticket selected, you can also explicitly tie the ticket to the pull request and CodeStream will include a link to the ticket in the pull request's description. Before submitting the pull request, you can review your changes by clicking on any of the files listed below the form. To create a pull request across forks, click the compare across forks link at the top of the page and the form will update to allow you to select both the base and head repositories. You can also create a pull request from within a CodeStream feedback request. Once the feedback request has been approved, youll see an option to open a pull request at the top. Before you can create a pull request, make sure that any changes included in the feedback request have been committed and pushed. Also, if the feature branch youre working on doesnt have a remote tracking branch youll be given the option to set that as part of creating the pull request. When you create a pull request from a feedback request, CodeStream connects the dots between the two by adding a link to the pull request in the feedback request. Add a link to the feedback request, along with information about who did the review and when, in the description of the pull request. Review a pull request Caution The ability to review pull requests is currently not available for Bitbucket. Regardless of where the pull request was created, you can edit, review, and even merge it from within CodeStream. CodeStream brings GitHub and GitLab into your IDE, so there's zero learning curve. If you know how to work with pull requests on GitHub or GitLab, you'll know how to do it in CodeStream as well. You can edit a GitHub pull request's details, such as reviewers, assignees and labels. For a GitLab merge request, you can use edit mode (via the dropdown at the top of the page) or use the sidebar. By default, you can only add a single reviewer and a single assignee to a GitLab merge request. If your organization supports multiple reviewers and assignees, click the gear menu in the heading of the Merge Requests section of the CodeStream pane to enable this. Review the conversation and add comments with the ability to @mention your collaborators. View the changes, add comments, and submit a review. CodeStream does improve upon the GitHub/GitLab experience in a couple of important ways. On GitHub and GitLab you can only view the changes as a series of diff hunks. CodeStream provides that view as well, but if you'd prefer to see the changes in the context of the full file you can use either list view or tree view. Select the code you want to comment on and then click the Comment button (or select Comment from the context menu). When commenting, you can either add a single comment or start a review. With CodeStream, you can comment on lines of code that haven't changed. You can select any lines of code in the diff and not just those that are part of the changeset. These comments are added as a single comment to the pull request and aren't part of any review you may have in progress. All the power of GitHub pull requests and GitLab merge requests, and then some, right in your IDE. Leverage pull request comments Once the pull request has been approved and the code has been merged, that's usually the end of life for any comments in that pull request. Although there's often useful information in those comments that may have long-term value, they're rarely seen again. CodeStream gives those comments a second life by displaying them alongside the blocks of code that they refer to. To have pull request comments displayed as annotations in your codemarks, as well as in the Codemarks section of the CodeStream pane, click the gear icon in that section and check Show comments from pull requests. When you first check that box, if you havent already authenticated with your code-hosting service, youll be prompted to do so. Comments from merged PRs will appear next to the blocks of code they refer to. Comments from open PRs will also be included if you are on a relevant branch. For example, if the open PR is a request to merge the feature/some-name branch into main, youll see comments from that PR if you've checked out either feature/some-name or main, but not when youre on any other branch. As the code evolves, the location of each comment is automatically updated so that it remains linked to the block of code it refers to. PR comments for a given file are updated roughly every 30 minutes, so new comments may not appear right away. You can force an update by restarting your IDE.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1017.7266,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage pull <em>requests</em> in <em>CodeStream</em>",
        "sections": "Manage pull <em>requests</em> in <em>CodeStream</em>",
        "body": "For most development teams, the final step in the development process is a pull <em>request</em>. Even if your team has decided to use New Relic <em>CodeStream</em>&#x27;s <em>feedback</em> <em>requests</em> as a replacement for, and not just a precursor to, your end-of-cycle PR-based <em>code</em> reviews, <em>CodeStream</em> allows you to keep all"
      },
      "id": "61744006196a67ee542f0555"
    }
  ],
  "/docs/codestream/codestream-ui-overview/filter-search": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.5113,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-20T01:42:42Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.54759,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Optional: Integrate Errors Inbox with Slack, Jira, <em>and</em> <em>CodeStream</em>",
        "body": " pika.exceptions:ChannelWrongStateError, you don&#x27;t see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, <em>filter</em> by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>"
      },
      "id": "61be8f01196a67e048eef29c"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/",
      "sections": [
        "Resolve Errors Faster with Full Stack Error Tracking",
        "Important",
        "Learning Objectives",
        "Requirements",
        "Procedures",
        "1. Spin up your application",
        "2. Set up Errors Inbox",
        "3. Triage your errors",
        "4. Manage your triaged errors"
      ],
      "published_at": "2021-12-20T01:49:34Z",
      "title": "Resolve Errors Faster with Full Stack Error Tracking",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "a96d1a5e8ac7b53af9924ab519c673f316780d13",
      "document_type": "page",
      "popularity": 1,
      "info": "Use New Relic to qucikly track errors in your application with the help of Errors Inbox.",
      "body": "You're one of the developers of an eCommerce website called Geek's Movie Shop, and recently, you introduced some new features. Before you push your changes to production where all your users will have access to them, you want to discover as many errors as you can in your development environment. Then you can decide which ones to fix and which ones to ignore. Errors Inbox is the perfect tool to help you do this. Important Errors Inbox is not available in the EU region. Learning Objectives In this lab, you: Spin up Geek's Movie Shop in your development environment Set up a workload for Errors Inbox Resolve and ignore errors in your inbox Assign unresolved errors Filter errors in your inbox by status Integrate Errors Inbox with Jira, CodeStream, or Slack Requirements Create a free New Relic account in the US region Install Docker Procedures 1. Spin up your application Set up your your environment to deploy Geek's Movie Shop. 5 min 2. Set up Errors Inbox Set up Errors Inbox in New Relic 5 min 3. Triage your errors Track and triage errors across your stack with Errors Inbox 5 min 4. Manage your triaged errors Managed your triaged errors in Errors Inbox 5 min",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 225.76088,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " Inbox Resolve and ignore errors in your inbox Assign unresolved errors <em>Filter</em> errors in your inbox by status Integrate Errors Inbox with Jira, <em>CodeStream</em>, or Slack Requirements Create a free New Relic account in the US region Install Docker Procedures 1. Spin up your application Set up your your"
      },
      "id": "61be8f0128ccbce013e53496"
    }
  ],
  "/docs/codestream/codestream-ui-overview/issues-section": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.5113,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://docs.newrelic.com/static/48721d72a10a277b2ef615b62a07f0fe/f96db/GitHubAuth.png",
      "url": "https://docs.newrelic.com/docs/codestream/troubleshooting/github-org-repos/",
      "sections": [
        "Why aren't PRs and issues from all of my GitHub organizations listed in CodeStream?"
      ],
      "published_at": "2021-12-19T17:24:03Z",
      "title": "Why aren't PRs and issues from all of my GitHub organizations listed in CodeStream?",
      "updated_at": "2021-11-13T20:01:28Z",
      "type": "docs",
      "external_id": "aa4cd2a3acc746bc90aa1cf6663335e36084c002",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect to GitHub you should see all of your open pull requests in the Pull Requests section of the CodeStream pane, as well as all issues assigned to you in the Issues section. If pull requests or issues from any of your GitHub organizations are missing, it's probably because at the time you authenticated with GitHub and you didn't grant access to all of your organizations. If you didn't click the Grant button at authentication time, on GitHub go to Settings > Applications and click the Authorized OAuth Apps tab. From there, click the CodeStream application. On the following page, click the Grant button next to any organizations that you'd like to be able to access from CodeStream. In some instances, you'll see a Request button instead of Grant, which means that the owner of your GitHub organization will need to grant you access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 361.00467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Why aren&#x27;t PRs and <em>issues</em> from all of my GitHub organizations listed in <em>CodeStream</em>?",
        "sections": "Why aren&#x27;t PRs and <em>issues</em> from all of my GitHub organizations listed in <em>CodeStream</em>?",
        "body": "When you connect to GitHub you should see all of your open pull requests in the Pull Requests section of the <em>CodeStream</em> pane, as well as all <em>issues</em> assigned to you in the <em>Issues</em> section. If pull requests or <em>issues</em> from any of your GitHub organizations are missing, it&#x27;s probably because at the time"
      },
      "id": "617441c3e7b9d2478513cf8c"
    },
    {
      "image": "https://docs.newrelic.com/static/ec73595e0bcde8b47ae3040cc556ddd1/f96db/NotificationSettings4.png",
      "url": "https://docs.newrelic.com/docs/codestream/codestream-integrations/notifications/",
      "sections": [
        "CodeStream notifications",
        "Notification settings",
        "Follow or unfollow",
        "Desktop notifications",
        "Other notifications"
      ],
      "published_at": "2021-12-19T17:22:46Z",
      "title": "CodeStream notifications",
      "updated_at": "2021-11-13T21:01:16Z",
      "type": "docs",
      "external_id": "0af3b7458032e1b89f8e3cc7225d7c7b0272354a",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream will notify you about comments, issues, and feedback requests that you follow, and you can choose whether you want to be notified via email, desktop (for the VS Code and JetBrains extensions only), or both. Look for the notifications option under your user profile menu at the top of the CodeStream pane. Notification settings By default, you're set to automatically follow any comment, issue, or feedback request that you created, where youve been mentioned (either in the original post or in a subsequent reply), or to which youve replied. You can always choose to follow or unfollow any individual comment, issue, or feedback request via its ellipses menu. Follow or unfollow Email notifications are sent immediately. You can participate in the discussion by replying to the email. Your reply will get added to CodeStream as a reply to the appropriate comment, issue, or feedback request. Be sure that when you reply you're doing so from the same email address where the notification was sent (that is, your email address listed in My Organization on CodeStream). You can unfollow a codemark or code review by clicking the link at the bottom of the email. Desktop notifications If youre using CodeStream in VS Code or a JetBrains IDE you can also receive desktop notifications in the IDE for comment, issue, or feedback requests that you follow. Click the Open button to open the discussion so that you can participate. Other notifications CodeStream offers the following notifications that can be turned on and off via the checkboxes at the bottom of the page. Notify me about outstanding feedback requests: Get an email reminder about open feedback requests assigned to you that you haven't responded to in the last 24 hours. Notify me about new unreviewed commits from teammates when I pull: Any time you pull, if there are new commits from a teammate on the current branch you'll get a toast notification. Click the Review button to start reviewing your teammate's changes and provide feedback. Send me weekly emails summarizing my activity: Sent every Monday with information about you and your organization's activity for the previous week. If you've connected to GitHub or GitHub Enterprise to leverage CodeStream's pull request integration, you'll also be notified when a pull request is assigned to you or you are added as a reviewer. Click the Open button to open the pull request right in your IDE where you can review the changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 279.3895,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> notifications",
        "sections": "<em>CodeStream</em> notifications",
        "body": "New Relic <em>CodeStream</em> will notify you about comments, <em>issues</em>, and feedback requests that you follow, and you can choose whether you want to be notified via email, desktop (for the VS <em>Code</em> and JetBrains extensions only), or both. Look for the notifications option under your user profile menu"
      },
      "id": "6174407564441f5c515fcf66"
    }
  ],
  "/docs/codestream/codestream-ui-overview/my-organization": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.19464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-20T01:42:42Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.4878,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>your</em> triaged errors",
        "sections": "<em>Manage</em> <em>your</em> triaged errors",
        "info": "<em>Managed</em> <em>your</em> triaged errors in Errors Inbox",
        "body": " Being able to view resolved and ignored errors is useful, but you&#x27;re trying to squash the bugs in <em>your</em> application before you deploy it to production. To help you <em>manage</em> this, connect <em>your</em> inbox to Slack, Jira, and <em>CodeStream</em>. Summary In this lab, you set up Errors Inbox to proactively observe"
      },
      "id": "61be8f01196a67e048eef29c"
    },
    {
      "image": "https://docs.newrelic.com/static/89fc796cef01d95170eace2254590fbe/1efb2/connect-repo1.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-new-relic/",
      "sections": [
        "CodeStream and New Relic One",
        "Preview release",
        "Connect CodeStream and New Relic",
        "Caution",
        "See your errors and what's causing them",
        "Tip",
        "How to go from errors inbox to your IDE",
        "APM errors and CodeStream",
        "Associate repositories with errors",
        "Use environment variable with APM (recommended)",
        "Use the UI",
        "Use the NerdGraph API",
        "Associate build SHAs or release tags with errors",
        "Install APM agents with CodeStream",
        "Dynamic logging with Go and Pixie"
      ],
      "published_at": "2021-12-19T14:37:10Z",
      "title": "CodeStream and New Relic One",
      "updated_at": "2021-12-14T23:24:49Z",
      "type": "docs",
      "external_id": "a6c04d95011d9150cb0798580c15695bb9f3bbda",
      "document_type": "page",
      "popularity": 1,
      "body": "CodeStream and New Relic One work together to give you insight into your code's errors, as well as making it easier to get started instrumenting your code with our APM agents. With CodeStream connected to New Relic One, you can jump from a stack trace error directly to the offending line of code in your IDE. Once in your IDE, you can navigate the stack trace and collaborate with your teammates to resolve the issue. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Connect CodeStream and New Relic Before you can take advantage of New Relic's observability features in CodeStream, you'll need to connect them. Requirements for connecting CodeStream and New Relic: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key If you don't have a user key or want to learn more about how you can use and manage them, see our doc on the New Relic user key. Once you have your New Relic user key, in CodeStream's Observability section click Connect to New Relic One, then paste your API key and click Connect to New Relic One. Caution New Relic users can share stacktrace errors on CodeStream. Once you've connected CodeStream to New Relic, any new users you add to your CodeStream organization can see those errors. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Requirements for opening stack trace errors in your IDE: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key CodeStream and New Relic connection Data being reported to New Relic via APM monitoring A workload for errors inbox An error For APM errors, your repository's commit hash and release tag New Relic errors inbox is a single place to proactively detect, prioritize, and take action on your errors before they impact customers. With CodeStream, you can jump from an error directly to the offending code in your IDE. Tip Limited to APM errors. How to go from errors inbox to your IDE From one.newrelic.com/, go to Errors Inbox, click a stack trace error, then click Open in IDE. APM errors and CodeStream In order to view stack trace errors in your IDE, CodeStream needs to know what repository the error is associated with and, ideally, which version of the code generated the error. Associate repositories with errors Once you've started monitoring for APM, mobile, browser, or Lambda, you should create repository entities and associate them with entities for all of your services. In order to create a repository entity you'll need to provide the repository's remote URL. For example, the remote URL can be in either the SSH or HTTPS format: git@github.com:newrelic/beta-docs-site.git https://github.com/newrelic/beta-docs-site.git Caution It's possible to add the same GitHub repository more than once, if you're using different protocols to do so. The UI warns you about this, but won't prevent you from doing so. For example, https://github.com/tuna/repo and git@github.com:tuna/repo are the same repo, with different protocols. If you try to open an error in your IDE and there isn't an associated repository, CodeStream will prompt you to make an association and save that association for all errors from the given entity on New Relic. However, it would be preferably to use one of the following methods since they require less ongoing manual effort and eliminate the possibility of end-user mistakes, such as misconfigured remote URLs. Use environment variable with APM (recommended) Set the environment variable NEW_RELIC_METADATA_REPOSITORY_URL. New Relic APM agents create the repository entity and associate it to your application entity automatically. This requires the SSH or HTTPS URL format. We recommend that these be set as part of your build pipeline. Use the UI Once you've started sending data to New Relic, use the UI to connect your related repository. Go to the APM Summary page via one.newrelic.com > Explorer > Services - APM > (select an app), then look for the Repositories section at the bottom-right. Click Connect repository to find an existing repository or add a new one. Use the NerdGraph API Use New Relic's NerdGraph APIsto create a repository and associate it with your application entities. Step 1: Create a repository entity To create a repository entity, use the referenceEntityCreateOrUpdateRepository API and make sure to save the GUID that's produced. The API takes the following parameters: accountId - the integer account ID for the account you want to add the repository to url - example https://github.com/newrelic/beta-docs-site.git name - example: newrelic/beta-docs-site mutation { referenceEntityCreateOrUpdateRepository(repositories: [{accountId: [YOUR_ACCOUNT_ID], name: \"[REPO_NAME]\", url: \"[REPO_URL]\"}]) { created failures { guid message type } } } Copy In order to find the entity you create, you can use a query like the following. Note that the URL you provided to referenceEntityCreateOrUpdateRepository gets saved as an entity tag. { actor { entitySearch(query: \"name = 'a name' OR tags.url = 'a url'\") { count query results { entities { guid name tags { key values } } } } } } Copy Step 2: Associate the repository entity to your application entity First, find the GUID for the application you want to associate your repository to. Parameters: sourceEntityGuid - the entity GUID of the application targetEntityGuid - the entity GUID of your repository type - always BUILT_FROM mutation { entityRelationshipUserDefinedCreateOrReplace(sourceEntityGuid: \"\", targetEntityGuid: \"\", type: BUILT_FROM) { errors { message type } } } Copy To see all entities related to your repository you can do a query like this: { actor { entity(guid: \"[YOUR_REPOSITORY_GUID]]\") { relatedEntities(filter: {direction: BOTH, relationshipTypes: {include: BUILT_FROM}}) { results { target { entity { name guid type } } type } } name type tags { values key } } } } Copy Step 3: Cleanup (if needed) Delete a repository with the following query: mutation DeleteRepository { entityDelete(guids: \"[ENTITY_GUID_HERE]]\") { deletedEntities failures { message guid } } } Copy Associate build SHAs or release tags with errors To use CodeStream's Open in IDE with your APM stack trace errors, use environment variables to configure your APM agent with your application's commit sha and/or your release tag associated with the running version of your software. CodeStream only needs the first seven characters of your commit sha (for example, 734713b) to make this connection, but you can include the entire sha. Alternately, you can use a release tag (such as v0.1.209 or release-209) for CodeStream to find the correct version of your code. For New Relic APM, the commit and/or release tag (tags.commit and tags.releaseTag) are added as attributes on Transaction and TransactionError events. You can use APM environment variables to set these attributes. We recommend setting one or both of these variables as part of your build pipeline. NEW_RELIC_METADATA_COMMIT - The commit sha. You can include the whole thing or only the first seven characters. NEW_RELIC_METADATA_RELEASE_TAG - A release tag (such as v0.1.209 or release-209). This has the advantage of being human readable. For more on how to set these variables, here are specific configuration details for each language: Go Java .NET Node.js PHP Python Install APM agents with CodeStream Requirements for installing New Relic APM agents via CodeStream: New Relic account New Relic user key CodeStream and New Relic connection A supported language application codebase .NET Core Java Node.JS When you first connect CodeStream to New Relic, if you're working on an application's codebase that's not being monitored by New Relic, CodeStream will offer to instrument that application for you. Like New Relic's guided install, CodeStream will walk you through and automate all of the steps to installing the APM agent to start sending data to New Relic. This check only happens automatically when the initial connection is made. To do so later, in the CodeStream extension, click your username, then click New Relic Setup. Dynamic logging with Go and Pixie New Relic account New Relic user API key CodeStream and New Relic connection A Kubernetes cluster monitored by Pixie An application written in Go You can use CodeStream to enable dynamic logging for your Pixie-monitored Go applications. Just right-click on any method name and select Dynamic Logging Using Pixie.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.90353,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> and New Relic <em>One</em>",
        "sections": "<em>CodeStream</em> and New Relic <em>One</em>",
        "body": " have a New Relic account, sign up at newrelic.com&#x2F;signup. It&#x27;s free, forever!) New Relic user key If you don&#x27;t have a user key or want to learn more about how you can use and <em>manage</em> them, see our doc on the New Relic user key. Once you have <em>your</em> New Relic user key, in <em>CodeStream</em>&#x27;s Observability"
      },
      "id": "6171e652196a67e9c92f0156"
    }
  ],
  "/docs/codestream/codestream-ui-overview/observability-section": [
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 702.2488,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to New Relic <em>CodeStream</em>",
        "sections": "Intro to New Relic <em>CodeStream</em>",
        "body": " knowledge that is currently being lost in Slack channels and emails. Not only that, our <em>observability</em> solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic <em>CodeStream</em> to discover, troubleshoot, and triage errors in your IDE. (2:27"
      },
      "id": "617440e3e7b9d2836c13c43c"
    },
    {
      "image": "https://docs.newrelic.com/static/8ab59b1cd343193c20dbdb5f35420fcb/432e7/ErrorOnNR1.png",
      "url": "https://docs.newrelic.com/docs/codestream/how-use-codestream/performance-monitoring/",
      "sections": [
        "Performance monitoring with CodeStream",
        "Discover errors on New Relic One",
        "Discover errors via CodeStream",
        "Error details",
        "Collaborate with CodeStream",
        "Use build SHAs with CodeStream",
        "Other collaboration tools",
        "Associate your repository"
      ],
      "published_at": "2021-12-21T01:41:28Z",
      "title": "Performance monitoring with CodeStream",
      "updated_at": "2021-10-30T03:34:44Z",
      "type": "docs",
      "external_id": "378ad1d91c35b3c33347ee3cf91afb28620b45f7",
      "document_type": "page",
      "popularity": 1,
      "body": "Its important to know how your code is performing in production and whether or not its generating errors. To help you with this, New Relic CodeStream brings performance monitoring right into your IDE. Discover errors on New Relic One Once youve connected CodeStream to your New Relic One account, and you've created one or more workloads with errors inbox on New Relic One, use Open in IDE to see APM errors with stack traces directly in your IDE. When you've connected CodeStream to your New Relic One account, in errors inbox click Open in IDE to see the code that caused the error. Once connected, all of your collaboration work in CodeStream (such as the discussion, assignee, and error status) syncs with New Relic One, where you can continue to collaborate. A typical collaboration session could include developers commenting on code in their IDEs, a DevOps engineer assigning errors in errors inbox, and a development manager following along in Slack. By meeting people in the tools they're already using, New Relic CodeStream shortens the amount of time between error discovery and error resolution. Discover errors via CodeStream In addition to errors inbox, discover errors in your IDE in the CodeStream observability section. In addition to recent errors in your repos, see any specific errors assigned to you. Use CodeStream's observability section to keep up to date with recent and assigned stack trace errors. Error details No matter how you've arrived at an error in your IDE, CodeStream presents all of the errors details, including the stack trace, and you can collaborate with your teammates to resolve the error. Navigate the stack trace to investigate the issue. Click any frame in the stack trace to jump straight to the corresponding file and line number in your IDE. As you navigate the stack trace, if you come across code that seems like the source of your problem, select it and click the comment icon to start collaborating. Collaborate with CodeStream With CodeStream open, once you've identified the problematic code, select it in your editor and click the comment icon that appears next to it in the CodeStream pane. CodeStream automatically mentions the most recent person to touch the code related to the error, making it easy for you to bring the right people into the discussion. Select code in your editor to add a comment. Assign the error and update its status for better tracking an accountability. Once youve identified the problem you can assign the error, either to an existing teammate on CodeStream or to a person suggested based on the repositorys Git commit history. You can update the errors status from unresolved to resolved or ignored. Use build SHAs with CodeStream You may see this warning if there's no build SHA associated with a specific error. CodeStream uses the build SHA to match the specific stack trace error with the version of the code running in the environment that triggered the error. The build SHA not configured warning message reads: No build SHA associated with this error. Your version of the code may not match the environment that triggered the error. To resolve this warning, set the environment variables for your APM agent. Even without the build SHA configured, you can still investigate the error, but you may not be looking at the version of the code that caused it. The build SHA not found warning message reads: Your version of the code doesn't match production. Fetch the following commit to better investigate the error. If you do have build SHAs configured, but the version of the code you're on locally doesn't contain that commit, CodeStream will let you know so that you can more effectively investigate and resolve the error. CodeStream will also let you know if the error doesnt have a stack trace associated with it. This happens with older errors when the stack trace has aged out on New Relic One. Other collaboration tools In an error discussion, use the ... More actions dropdown to share the discussion on Slack or Microsoft Teams. Associate your repository If there's no repository associated with CodeStream when you click Open in IDE on an error, CodeStream prompts you to do so. All of the repositories you currently have open in your IDE are listed in the select a repo dropdown. If you dont see the repository you want listed, open it in your IDE and it will automatically get added to the list. If youre working with a fork, make sure you select the upstream remote. To avoid having to do this manual association every time you open an error, you can make these associations via your APM agent's environment variables.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 601.8254,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Performance monitoring with <em>CodeStream</em>",
        "sections": "Performance monitoring with <em>CodeStream</em>",
        "body": " in the <em>CodeStream</em> <em>observability</em> section. In addition to recent errors in your repos, see any specific errors assigned to you. Use <em>CodeStream</em>&#x27;s <em>observability</em> section to keep up to date with recent and assigned stack trace errors. Error details No matter how you&#x27;ve arrived at an error in your IDE"
      },
      "id": "617cbd54e7b9d28f12c0535e"
    },
    {
      "image": "https://docs.newrelic.com/static/89fc796cef01d95170eace2254590fbe/1efb2/connect-repo1.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-new-relic/",
      "sections": [
        "CodeStream and New Relic One",
        "Preview release",
        "Connect CodeStream and New Relic",
        "Caution",
        "See your errors and what's causing them",
        "Tip",
        "How to go from errors inbox to your IDE",
        "APM errors and CodeStream",
        "Associate repositories with errors",
        "Use environment variable with APM (recommended)",
        "Use the UI",
        "Use the NerdGraph API",
        "Associate build SHAs or release tags with errors",
        "Install APM agents with CodeStream",
        "Dynamic logging with Go and Pixie"
      ],
      "published_at": "2021-12-19T14:37:10Z",
      "title": "CodeStream and New Relic One",
      "updated_at": "2021-12-14T23:24:49Z",
      "type": "docs",
      "external_id": "a6c04d95011d9150cb0798580c15695bb9f3bbda",
      "document_type": "page",
      "popularity": 1,
      "body": "CodeStream and New Relic One work together to give you insight into your code's errors, as well as making it easier to get started instrumenting your code with our APM agents. With CodeStream connected to New Relic One, you can jump from a stack trace error directly to the offending line of code in your IDE. Once in your IDE, you can navigate the stack trace and collaborate with your teammates to resolve the issue. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Connect CodeStream and New Relic Before you can take advantage of New Relic's observability features in CodeStream, you'll need to connect them. Requirements for connecting CodeStream and New Relic: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key If you don't have a user key or want to learn more about how you can use and manage them, see our doc on the New Relic user key. Once you have your New Relic user key, in CodeStream's Observability section click Connect to New Relic One, then paste your API key and click Connect to New Relic One. Caution New Relic users can share stacktrace errors on CodeStream. Once you've connected CodeStream to New Relic, any new users you add to your CodeStream organization can see those errors. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Requirements for opening stack trace errors in your IDE: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key CodeStream and New Relic connection Data being reported to New Relic via APM monitoring A workload for errors inbox An error For APM errors, your repository's commit hash and release tag New Relic errors inbox is a single place to proactively detect, prioritize, and take action on your errors before they impact customers. With CodeStream, you can jump from an error directly to the offending code in your IDE. Tip Limited to APM errors. How to go from errors inbox to your IDE From one.newrelic.com/, go to Errors Inbox, click a stack trace error, then click Open in IDE. APM errors and CodeStream In order to view stack trace errors in your IDE, CodeStream needs to know what repository the error is associated with and, ideally, which version of the code generated the error. Associate repositories with errors Once you've started monitoring for APM, mobile, browser, or Lambda, you should create repository entities and associate them with entities for all of your services. In order to create a repository entity you'll need to provide the repository's remote URL. For example, the remote URL can be in either the SSH or HTTPS format: git@github.com:newrelic/beta-docs-site.git https://github.com/newrelic/beta-docs-site.git Caution It's possible to add the same GitHub repository more than once, if you're using different protocols to do so. The UI warns you about this, but won't prevent you from doing so. For example, https://github.com/tuna/repo and git@github.com:tuna/repo are the same repo, with different protocols. If you try to open an error in your IDE and there isn't an associated repository, CodeStream will prompt you to make an association and save that association for all errors from the given entity on New Relic. However, it would be preferably to use one of the following methods since they require less ongoing manual effort and eliminate the possibility of end-user mistakes, such as misconfigured remote URLs. Use environment variable with APM (recommended) Set the environment variable NEW_RELIC_METADATA_REPOSITORY_URL. New Relic APM agents create the repository entity and associate it to your application entity automatically. This requires the SSH or HTTPS URL format. We recommend that these be set as part of your build pipeline. Use the UI Once you've started sending data to New Relic, use the UI to connect your related repository. Go to the APM Summary page via one.newrelic.com > Explorer > Services - APM > (select an app), then look for the Repositories section at the bottom-right. Click Connect repository to find an existing repository or add a new one. Use the NerdGraph API Use New Relic's NerdGraph APIsto create a repository and associate it with your application entities. Step 1: Create a repository entity To create a repository entity, use the referenceEntityCreateOrUpdateRepository API and make sure to save the GUID that's produced. The API takes the following parameters: accountId - the integer account ID for the account you want to add the repository to url - example https://github.com/newrelic/beta-docs-site.git name - example: newrelic/beta-docs-site mutation { referenceEntityCreateOrUpdateRepository(repositories: [{accountId: [YOUR_ACCOUNT_ID], name: \"[REPO_NAME]\", url: \"[REPO_URL]\"}]) { created failures { guid message type } } } Copy In order to find the entity you create, you can use a query like the following. Note that the URL you provided to referenceEntityCreateOrUpdateRepository gets saved as an entity tag. { actor { entitySearch(query: \"name = 'a name' OR tags.url = 'a url'\") { count query results { entities { guid name tags { key values } } } } } } Copy Step 2: Associate the repository entity to your application entity First, find the GUID for the application you want to associate your repository to. Parameters: sourceEntityGuid - the entity GUID of the application targetEntityGuid - the entity GUID of your repository type - always BUILT_FROM mutation { entityRelationshipUserDefinedCreateOrReplace(sourceEntityGuid: \"\", targetEntityGuid: \"\", type: BUILT_FROM) { errors { message type } } } Copy To see all entities related to your repository you can do a query like this: { actor { entity(guid: \"[YOUR_REPOSITORY_GUID]]\") { relatedEntities(filter: {direction: BOTH, relationshipTypes: {include: BUILT_FROM}}) { results { target { entity { name guid type } } type } } name type tags { values key } } } } Copy Step 3: Cleanup (if needed) Delete a repository with the following query: mutation DeleteRepository { entityDelete(guids: \"[ENTITY_GUID_HERE]]\") { deletedEntities failures { message guid } } } Copy Associate build SHAs or release tags with errors To use CodeStream's Open in IDE with your APM stack trace errors, use environment variables to configure your APM agent with your application's commit sha and/or your release tag associated with the running version of your software. CodeStream only needs the first seven characters of your commit sha (for example, 734713b) to make this connection, but you can include the entire sha. Alternately, you can use a release tag (such as v0.1.209 or release-209) for CodeStream to find the correct version of your code. For New Relic APM, the commit and/or release tag (tags.commit and tags.releaseTag) are added as attributes on Transaction and TransactionError events. You can use APM environment variables to set these attributes. We recommend setting one or both of these variables as part of your build pipeline. NEW_RELIC_METADATA_COMMIT - The commit sha. You can include the whole thing or only the first seven characters. NEW_RELIC_METADATA_RELEASE_TAG - A release tag (such as v0.1.209 or release-209). This has the advantage of being human readable. For more on how to set these variables, here are specific configuration details for each language: Go Java .NET Node.js PHP Python Install APM agents with CodeStream Requirements for installing New Relic APM agents via CodeStream: New Relic account New Relic user key CodeStream and New Relic connection A supported language application codebase .NET Core Java Node.JS When you first connect CodeStream to New Relic, if you're working on an application's codebase that's not being monitored by New Relic, CodeStream will offer to instrument that application for you. Like New Relic's guided install, CodeStream will walk you through and automate all of the steps to installing the APM agent to start sending data to New Relic. This check only happens automatically when the initial connection is made. To do so later, in the CodeStream extension, click your username, then click New Relic Setup. Dynamic logging with Go and Pixie New Relic account New Relic user API key CodeStream and New Relic connection A Kubernetes cluster monitored by Pixie An application written in Go You can use CodeStream to enable dynamic logging for your Pixie-monitored Go applications. Just right-click on any method name and select Dynamic Logging Using Pixie.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 568.36707,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> and New Relic One",
        "sections": "<em>CodeStream</em> and New Relic One",
        "body": " policy. (This does not apply to all other <em>CodeStream</em> functionality.) Connect <em>CodeStream</em> and New Relic Before you can take advantage of New Relic&#x27;s <em>observability</em> features in <em>CodeStream</em>, you&#x27;ll need to connect them. Requirements for connecting <em>CodeStream</em> and New Relic: New Relic account (If you don&#x27;t"
      },
      "id": "6171e652196a67e9c92f0156"
    }
  ],
  "/docs/codestream/codestream-ui-overview/permalinks": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.19464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-20T01:42:42Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.03494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>",
        "body": " pika.exceptions:ChannelWrongStateError, you don&#x27;t see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>"
      },
      "id": "61be8f01196a67e048eef29c"
    },
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.92108,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to New Relic <em>CodeStream</em>",
        "sections": "Intro to New Relic <em>CodeStream</em>",
        "body": "New Relic <em>CodeStream</em> is a developer collaboration platform that enables your development team to discuss and review <em>code</em> in a natural and contextual way. <em>CodeStream</em> not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional"
      },
      "id": "617440e3e7b9d2836c13c43c"
    }
  ],
  "/docs/codestream/codestream-ui-overview/pull-requests-section": [
    {
      "image": "https://docs.newrelic.com/static/5c1d085b14abf961ca66b96285f0c0fa/69902/QS-Integrations.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/install-codestream/",
      "sections": [
        "Install New Relic CodeStream",
        "Install CodeStream",
        "Instant Observability (I/O) quickstart",
        "Visual Studio Code",
        "Visual Studio",
        "JetBrains",
        "Connect your tools",
        "Tip",
        "Discuss any block of code, at any time",
        "Get feedback on your work in progress",
        "Create or review a pull request",
        "Help and feedback"
      ],
      "published_at": "2021-12-19T14:27:50Z",
      "title": "Install New Relic CodeStream",
      "updated_at": "2021-11-24T09:39:10Z",
      "type": "docs",
      "external_id": "5d431c8f9a2690b64d26ac9fc173b18085153aac",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that makes it easy to discuss and review code in a more natural and contextual way. Once connected to New Relic, collaborate on your application errors directly in your IDE. If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Install CodeStream You can install CodeStream for your specific IDE or install it through our Instant Observability (I/O) quickstart. Instant Observability (I/O) quickstart Install CodeStream with its Instant Observability (I/O) quickstart to connect CodeStream to your New Relic account via your user key. Visual Studio Code Download and install CodeStream for Visual Studio Code. You can also install it directly in Visual Studio Code via the extensions marketplace. Visual Studio Download and install CodeStream for Visual Studio. You can also install it directly in Visual Studio via the extensions marketplace. JetBrains Download and install CodeStream for JetBrains. You can also install it from the JetBrains plugins menu. Connect your tools Create and review pull requests on GitHub, GitLab, or Bitbucket. Create issues on Jira, Trello, and other issue trackers. Investigate errors reported to New Relic One. Share code discussions on Slack or Microsoft Teams. CodeStream brings the tools you use every day together in your IDE. Click your headshot at the top of the CodeStream pane, then click Integrations to connect all of your tools to CodeStream. Tip Once you've installed CodeStream, to connect to New Relic, you'll need your New Relic user key. Go here to learn more about finding or creating your user key. Discuss any block of code, at any time Whether you're trying to understand someone else's code or getting help with some code you just wrote, select the code and click the comment button to ask your question. Learn more about discussing code. Get feedback on your work in progress Click the + menu then click Request Feedback at any time in the development cycle, whether its a quick look over some work in progress (even uncommitted code) or a formal review of a completed effort. Teammates can review your changes right in their IDE, with no need to switch branches or set aside their own work. Learn more about feedback requests. Create or review a pull request In the CodeStream sidebar, look for the Pull Requests section to review an open pull request. Select a pull request (or load one from URL) to get a complete GitHub experience right in your IDE. You can create a pull request in GitHub, GitLab, or Bitbucket, but support for reviewing pull requests is currently only available for GitHub. Learn more about pull requests. Help and feedback Report a bug or suggest an improvement in GitHub issues. Contact us directly at support@codestream.com. Follow @teamcodestream for product updates and to share feedback and questions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1554.1273,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install New Relic <em>CodeStream</em>",
        "sections": "Create or review a <em>pull</em> <em>request</em>",
        "body": " uncommitted <em>code</em>) or a formal review of a completed effort. Teammates can review your changes right in their IDE, with no need to switch branches or set aside their own work. Learn more about feedback <em>requests</em>. Create or review a <em>pull</em> <em>request</em> In the <em>CodeStream</em> sidebar, look for the <em>Pull</em> <em>Requests</em>"
      },
      "id": "6174400564441ff1025fd832"
    },
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.19464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 326.00696,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to New Relic <em>CodeStream</em>",
        "sections": "Create and review <em>pull</em> <em>requests</em>",
        "body": " For most development teams, the final step in the development process is a <em>pull</em> <em>request</em>. Even if your team has decided to use <em>CodeStream</em>&#x27;s feedback <em>requests</em> as a replacement for, and not just a precursor to, your end-of-cycle PR-based <em>code</em> reviews, you can create and review <em>pull</em> <em>requests</em> right inside"
      },
      "id": "617440e3e7b9d2836c13c43c"
    }
  ],
  "/docs/codestream/how-use-codestream/discuss-code": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 453.21967,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.76852,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to New Relic <em>CodeStream</em>",
        "sections": "<em>Discuss</em> <em>code</em> just like commenting <em>on</em> a Google Doc",
        "body": "New Relic <em>CodeStream</em> is a developer collaboration platform that enables your development team to <em>discuss</em> and review <em>code</em> in a natural and contextual way. <em>CodeStream</em> not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional"
      },
      "id": "617440e3e7b9d2836c13c43c"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/whats-new/2021/10/wn-codestream-1021/",
      "sections": [
        "Simplify code collaboration and review with New Relic CodeStream"
      ],
      "published_at": "2021-12-20T14:32:28Z",
      "title": "Simplify code collaboration and review with New Relic CodeStream",
      "updated_at": "2021-12-10T12:55:48Z",
      "type": "docs",
      "external_id": "f9d13af696d67a12cebebfc6698e916f3a5a11c9",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "Now you can resolve production errors faster and improve software performance with New Relic CodeStream. CodeStream is an exciting new IDE extension that helps developers discuss, review, and understand their code by integrating with popular dev tools and providing advanced in-IDE commenting. With the latest integration to New Relic One, CodeStream surfaces production errors inside your development environment for faster debugging. A free preview of the New Relic integration for CodeStream is available for everyone until February 28, 2022!",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.46118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Simplify <em>code</em> collaboration and review with New Relic <em>CodeStream</em>",
        "sections": "Simplify <em>code</em> collaboration and review with New Relic <em>CodeStream</em>",
        "body": "Now you can resolve production errors faster and improve software performance with New Relic <em>CodeStream</em>. <em>CodeStream</em> is an exciting new IDE extension that helps developers <em>discuss</em>, review, and understand their <em>code</em> by integrating with popular dev tools and providing advanced in-IDE commenting"
      },
      "id": "617434da196a67c6212f0dde"
    }
  ],
  "/docs/codestream/how-use-codestream/performance-monitoring": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.51126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.29712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to New Relic <em>CodeStream</em>",
        "sections": "<em>Monitor</em> your <em>codes</em> <em>performance</em> in production",
        "body": " your IDE. <em>CodeStream</em> shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. <em>Monitor</em> your <em>code</em>s <em>performance</em> in production Your pursuit of software quality doesnt end once the <em>code</em> has been merged. Connect <em>CodeStream</em> to your New Relic One account"
      },
      "id": "617440e3e7b9d2836c13c43c"
    },
    {
      "image": "https://docs.newrelic.com/static/89fc796cef01d95170eace2254590fbe/1efb2/connect-repo1.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-new-relic/",
      "sections": [
        "CodeStream and New Relic One",
        "Preview release",
        "Connect CodeStream and New Relic",
        "Caution",
        "See your errors and what's causing them",
        "Tip",
        "How to go from errors inbox to your IDE",
        "APM errors and CodeStream",
        "Associate repositories with errors",
        "Use environment variable with APM (recommended)",
        "Use the UI",
        "Use the NerdGraph API",
        "Associate build SHAs or release tags with errors",
        "Install APM agents with CodeStream",
        "Dynamic logging with Go and Pixie"
      ],
      "published_at": "2021-12-19T14:37:10Z",
      "title": "CodeStream and New Relic One",
      "updated_at": "2021-12-14T23:24:49Z",
      "type": "docs",
      "external_id": "a6c04d95011d9150cb0798580c15695bb9f3bbda",
      "document_type": "page",
      "popularity": 1,
      "body": "CodeStream and New Relic One work together to give you insight into your code's errors, as well as making it easier to get started instrumenting your code with our APM agents. With CodeStream connected to New Relic One, you can jump from a stack trace error directly to the offending line of code in your IDE. Once in your IDE, you can navigate the stack trace and collaborate with your teammates to resolve the issue. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Connect CodeStream and New Relic Before you can take advantage of New Relic's observability features in CodeStream, you'll need to connect them. Requirements for connecting CodeStream and New Relic: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key If you don't have a user key or want to learn more about how you can use and manage them, see our doc on the New Relic user key. Once you have your New Relic user key, in CodeStream's Observability section click Connect to New Relic One, then paste your API key and click Connect to New Relic One. Caution New Relic users can share stacktrace errors on CodeStream. Once you've connected CodeStream to New Relic, any new users you add to your CodeStream organization can see those errors. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Requirements for opening stack trace errors in your IDE: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key CodeStream and New Relic connection Data being reported to New Relic via APM monitoring A workload for errors inbox An error For APM errors, your repository's commit hash and release tag New Relic errors inbox is a single place to proactively detect, prioritize, and take action on your errors before they impact customers. With CodeStream, you can jump from an error directly to the offending code in your IDE. Tip Limited to APM errors. How to go from errors inbox to your IDE From one.newrelic.com/, go to Errors Inbox, click a stack trace error, then click Open in IDE. APM errors and CodeStream In order to view stack trace errors in your IDE, CodeStream needs to know what repository the error is associated with and, ideally, which version of the code generated the error. Associate repositories with errors Once you've started monitoring for APM, mobile, browser, or Lambda, you should create repository entities and associate them with entities for all of your services. In order to create a repository entity you'll need to provide the repository's remote URL. For example, the remote URL can be in either the SSH or HTTPS format: git@github.com:newrelic/beta-docs-site.git https://github.com/newrelic/beta-docs-site.git Caution It's possible to add the same GitHub repository more than once, if you're using different protocols to do so. The UI warns you about this, but won't prevent you from doing so. For example, https://github.com/tuna/repo and git@github.com:tuna/repo are the same repo, with different protocols. If you try to open an error in your IDE and there isn't an associated repository, CodeStream will prompt you to make an association and save that association for all errors from the given entity on New Relic. However, it would be preferably to use one of the following methods since they require less ongoing manual effort and eliminate the possibility of end-user mistakes, such as misconfigured remote URLs. Use environment variable with APM (recommended) Set the environment variable NEW_RELIC_METADATA_REPOSITORY_URL. New Relic APM agents create the repository entity and associate it to your application entity automatically. This requires the SSH or HTTPS URL format. We recommend that these be set as part of your build pipeline. Use the UI Once you've started sending data to New Relic, use the UI to connect your related repository. Go to the APM Summary page via one.newrelic.com > Explorer > Services - APM > (select an app), then look for the Repositories section at the bottom-right. Click Connect repository to find an existing repository or add a new one. Use the NerdGraph API Use New Relic's NerdGraph APIsto create a repository and associate it with your application entities. Step 1: Create a repository entity To create a repository entity, use the referenceEntityCreateOrUpdateRepository API and make sure to save the GUID that's produced. The API takes the following parameters: accountId - the integer account ID for the account you want to add the repository to url - example https://github.com/newrelic/beta-docs-site.git name - example: newrelic/beta-docs-site mutation { referenceEntityCreateOrUpdateRepository(repositories: [{accountId: [YOUR_ACCOUNT_ID], name: \"[REPO_NAME]\", url: \"[REPO_URL]\"}]) { created failures { guid message type } } } Copy In order to find the entity you create, you can use a query like the following. Note that the URL you provided to referenceEntityCreateOrUpdateRepository gets saved as an entity tag. { actor { entitySearch(query: \"name = 'a name' OR tags.url = 'a url'\") { count query results { entities { guid name tags { key values } } } } } } Copy Step 2: Associate the repository entity to your application entity First, find the GUID for the application you want to associate your repository to. Parameters: sourceEntityGuid - the entity GUID of the application targetEntityGuid - the entity GUID of your repository type - always BUILT_FROM mutation { entityRelationshipUserDefinedCreateOrReplace(sourceEntityGuid: \"\", targetEntityGuid: \"\", type: BUILT_FROM) { errors { message type } } } Copy To see all entities related to your repository you can do a query like this: { actor { entity(guid: \"[YOUR_REPOSITORY_GUID]]\") { relatedEntities(filter: {direction: BOTH, relationshipTypes: {include: BUILT_FROM}}) { results { target { entity { name guid type } } type } } name type tags { values key } } } } Copy Step 3: Cleanup (if needed) Delete a repository with the following query: mutation DeleteRepository { entityDelete(guids: \"[ENTITY_GUID_HERE]]\") { deletedEntities failures { message guid } } } Copy Associate build SHAs or release tags with errors To use CodeStream's Open in IDE with your APM stack trace errors, use environment variables to configure your APM agent with your application's commit sha and/or your release tag associated with the running version of your software. CodeStream only needs the first seven characters of your commit sha (for example, 734713b) to make this connection, but you can include the entire sha. Alternately, you can use a release tag (such as v0.1.209 or release-209) for CodeStream to find the correct version of your code. For New Relic APM, the commit and/or release tag (tags.commit and tags.releaseTag) are added as attributes on Transaction and TransactionError events. You can use APM environment variables to set these attributes. We recommend setting one or both of these variables as part of your build pipeline. NEW_RELIC_METADATA_COMMIT - The commit sha. You can include the whole thing or only the first seven characters. NEW_RELIC_METADATA_RELEASE_TAG - A release tag (such as v0.1.209 or release-209). This has the advantage of being human readable. For more on how to set these variables, here are specific configuration details for each language: Go Java .NET Node.js PHP Python Install APM agents with CodeStream Requirements for installing New Relic APM agents via CodeStream: New Relic account New Relic user key CodeStream and New Relic connection A supported language application codebase .NET Core Java Node.JS When you first connect CodeStream to New Relic, if you're working on an application's codebase that's not being monitored by New Relic, CodeStream will offer to instrument that application for you. Like New Relic's guided install, CodeStream will walk you through and automate all of the steps to installing the APM agent to start sending data to New Relic. This check only happens automatically when the initial connection is made. To do so later, in the CodeStream extension, click your username, then click New Relic Setup. Dynamic logging with Go and Pixie New Relic account New Relic user API key CodeStream and New Relic connection A Kubernetes cluster monitored by Pixie An application written in Go You can use CodeStream to enable dynamic logging for your Pixie-monitored Go applications. Just right-click on any method name and select Dynamic Logging Using Pixie.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.08163,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> and New Relic One",
        "sections": "Install APM agents <em>with</em> <em>CodeStream</em>",
        "body": " free, forever!) New Relic user key <em>CodeStream</em> and New Relic connection Data being reported to New Relic via APM <em>monitoring</em> A workload for errors inbox An error For APM errors, your repository&#x27;s commit hash and release tag New Relic errors inbox is a single place to proactively detect, prioritize"
      },
      "id": "6171e652196a67e9c92f0156"
    }
  ],
  "/docs/codestream/how-use-codestream/pull-requests": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.19464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.55176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Intro</em> to New Relic <em>CodeStream</em>",
        "sections": "<em>Intro</em> to New Relic <em>CodeStream</em>",
        "body": " For most development teams, the final step in the development process is a <em>pull</em> <em>request</em>. Even if your team has decided to use <em>CodeStream</em>&#x27;s feedback <em>requests</em> as a replacement for, and not just a precursor to, your end-of-cycle PR-based <em>code</em> reviews, you can create and review <em>pull</em> <em>requests</em> right inside"
      },
      "id": "617440e3e7b9d2836c13c43c"
    },
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-20T01:42:42Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.57767,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your triaged errors",
        "sections": "Optional: <em>Integrate</em> Errors <em>Inbox</em> with Slack, Jira, and <em>CodeStream</em>",
        "info": "<em>Managed</em> your triaged errors <em>in</em> Errors <em>Inbox</em>",
        "body": " Being able to view resolved and ignored errors is useful, but you&#x27;re trying to squash the bugs in your application before you deploy it to production. To help you <em>manage</em> this, connect your inbox to Slack, Jira, and <em>CodeStream</em>. Summary In this lab, you set up Errors Inbox to proactively observe"
      },
      "id": "61be8f01196a67e048eef29c"
    }
  ],
  "/docs/codestream/how-use-codestream/request-feedback": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.19464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://docs.newrelic.com/static/dd18b67123e9d4b7d40b56a8653a1f6b/f96db/OpenPullRequest1.png",
      "url": "https://docs.newrelic.com/docs/codestream/how-use-codestream/pull-requests/",
      "sections": [
        "Manage pull requests in CodeStream",
        "Pull request workflow",
        "Create a pull request",
        "Review a pull request",
        "Caution",
        "Leverage pull request comments"
      ],
      "published_at": "2021-12-21T01:41:29Z",
      "title": "Manage pull requests in CodeStream",
      "updated_at": "2021-11-13T21:14:26Z",
      "type": "docs",
      "external_id": "7e35f2ff4f06799fe492ffb6b2fedbb52e898b69",
      "document_type": "page",
      "popularity": 1,
      "body": "For most development teams, the final step in the development process is a pull request. Even if your team has decided to use New Relic CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, CodeStream allows you to keep all of that workflow inside your IDE. Pull request workflow There are four elements of CodeStream's pull request workflow. The following table outlines which code-hosting services are supported for each element. Feature Supported Services Create a pull request GitHub, GitHub Enterprise, GitLab, GitLab Self-Managed, Bitbucket, Bitbucket Server Create a pull request across forks GitHub, GitHub Enterprise, GitLab, GitLab Self-Managed Review and edit a pull request GitHub, GitHub Enterprise, GitLab, GitLab Self-Managed Display pull request comments as code annotations GitHub, GitLab, Bitbucket Create a pull request To open a pull request at any time, click the + button at the top of the CodeStream pane or the + button in the header of the Pull Requests section. You can also use a keyboard shortcut (ctlr+shift+/ p, ctrl+/ p on a Mac, and m if you're a GitLab user). CodeStream provides you with tree view, list view, and diff view options for reviewing your changes before opening the pull request. With a single click you can name the pull request based on the last commit message, the branch name, or, if you started work by selecting a ticket, the ticket title. If you have a ticket selected, you can also explicitly tie the ticket to the pull request and CodeStream will include a link to the ticket in the pull request's description. Before submitting the pull request, you can review your changes by clicking on any of the files listed below the form. To create a pull request across forks, click the compare across forks link at the top of the page and the form will update to allow you to select both the base and head repositories. You can also create a pull request from within a CodeStream feedback request. Once the feedback request has been approved, youll see an option to open a pull request at the top. Before you can create a pull request, make sure that any changes included in the feedback request have been committed and pushed. Also, if the feature branch youre working on doesnt have a remote tracking branch youll be given the option to set that as part of creating the pull request. When you create a pull request from a feedback request, CodeStream connects the dots between the two by adding a link to the pull request in the feedback request. Add a link to the feedback request, along with information about who did the review and when, in the description of the pull request. Review a pull request Caution The ability to review pull requests is currently not available for Bitbucket. Regardless of where the pull request was created, you can edit, review, and even merge it from within CodeStream. CodeStream brings GitHub and GitLab into your IDE, so there's zero learning curve. If you know how to work with pull requests on GitHub or GitLab, you'll know how to do it in CodeStream as well. You can edit a GitHub pull request's details, such as reviewers, assignees and labels. For a GitLab merge request, you can use edit mode (via the dropdown at the top of the page) or use the sidebar. By default, you can only add a single reviewer and a single assignee to a GitLab merge request. If your organization supports multiple reviewers and assignees, click the gear menu in the heading of the Merge Requests section of the CodeStream pane to enable this. Review the conversation and add comments with the ability to @mention your collaborators. View the changes, add comments, and submit a review. CodeStream does improve upon the GitHub/GitLab experience in a couple of important ways. On GitHub and GitLab you can only view the changes as a series of diff hunks. CodeStream provides that view as well, but if you'd prefer to see the changes in the context of the full file you can use either list view or tree view. Select the code you want to comment on and then click the Comment button (or select Comment from the context menu). When commenting, you can either add a single comment or start a review. With CodeStream, you can comment on lines of code that haven't changed. You can select any lines of code in the diff and not just those that are part of the changeset. These comments are added as a single comment to the pull request and aren't part of any review you may have in progress. All the power of GitHub pull requests and GitLab merge requests, and then some, right in your IDE. Leverage pull request comments Once the pull request has been approved and the code has been merged, that's usually the end of life for any comments in that pull request. Although there's often useful information in those comments that may have long-term value, they're rarely seen again. CodeStream gives those comments a second life by displaying them alongside the blocks of code that they refer to. To have pull request comments displayed as annotations in your codemarks, as well as in the Codemarks section of the CodeStream pane, click the gear icon in that section and check Show comments from pull requests. When you first check that box, if you havent already authenticated with your code-hosting service, youll be prompted to do so. Comments from merged PRs will appear next to the blocks of code they refer to. Comments from open PRs will also be included if you are on a relevant branch. For example, if the open PR is a request to merge the feature/some-name branch into main, youll see comments from that PR if you've checked out either feature/some-name or main, but not when youre on any other branch. As the code evolves, the location of each comment is automatically updated so that it remains linked to the block of code it refers to. PR comments for a given file are updated roughly every 30 minutes, so new comments may not appear right away. You can force an update by restarting your IDE.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.60092,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage pull <em>requests</em> in <em>CodeStream</em>",
        "sections": "Manage pull <em>requests</em> in <em>CodeStream</em>",
        "body": "For most development teams, the final step in the development process is a pull <em>request</em>. Even if your team has decided to use New Relic <em>CodeStream</em>&#x27;s <em>feedback</em> requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based <em>code</em> reviews, <em>CodeStream</em> allows you to keep all"
      },
      "id": "61744006196a67ee542f0555"
    },
    {
      "image": "https://docs.newrelic.com/static/a6aec54accbdc1434b605775cb1bb6a6/f96db/FRSection1.png",
      "url": "https://docs.newrelic.com/docs/codestream/codestream-ui-overview/feedback-requests-section/",
      "sections": [
        "CodeStream feedback requests"
      ],
      "published_at": "2021-12-19T14:05:26Z",
      "title": "CodeStream feedback requests",
      "updated_at": "2021-11-13T21:09:08Z",
      "type": "docs",
      "external_id": "def1d9cba862bb96307f99a80da7c7a634355582",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream's feedback requests section lists all of the open feedback requests that have been assigned to you or that you've requested, as well as any of your recent feedback requests that have been approved or where changes have been requested. Click a feedback request to jump in and start reviewing or to see your teammates comments on your work. When you hover over the Feedback Requests section heading, you'll see a + icon to create a new feedback request. If you're an admin you'll also see a gear icon to control how both feedback request assignments and approvals work for your organization. By default, the person requesting feedback can decide how approvals work, but you can also set a default behavior for all feedback requests for your organization. Any reviewer can approve: Anyone can approve the feedback request, regardless of how many reviewers have been assigned. All reviewers must approve individually: Each assigned reviewer must individually approve the feedback request before its considered approved. You can also decide if and how CodeStream suggests reviewers. Round-robin will cycle through all developers in the organization. Random will randomly assign the feedback request to any developer in the organization. The Authorship options suggest up to three reviewers based on the developers who wrote the lines of code impacted by the changes, as well as other developers who may have committed to the branch.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 279.25143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> <em>feedback</em> <em>requests</em>",
        "sections": "<em>CodeStream</em> <em>feedback</em> <em>requests</em>",
        "body": "New Relic <em>CodeStream</em>&#x27;s <em>feedback</em> requests section lists all of the open <em>feedback</em> requests that have been assigned to you or that you&#x27;ve requested, as well as any of your recent <em>feedback</em> requests that have been approved or where changes have been requested. Click a <em>feedback</em> <em>request</em> to jump"
      },
      "id": "61743f4ae7b9d2636813d144"
    }
  ],
  "/docs/codestream/how-use-codestream/start-work": [
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.57883,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>New</em> Relic <em>CodeStream</em>",
        "sections": "Intro to <em>New</em> Relic <em>CodeStream</em>",
        "body": "<em>New</em> Relic <em>CodeStream</em> is a developer collaboration platform that enables <em>your</em> development team to discuss and review <em>code</em> in a natural and contextual way. <em>CodeStream</em> not only makes <em>your</em> discussions easier, by allowing them to happen in context in <em>your</em> IDE, but it also preserves the institutional"
      },
      "id": "617440e3e7b9d2836c13c43c"
    },
    {
      "image": "https://docs.newrelic.com/static/89fc796cef01d95170eace2254590fbe/1efb2/connect-repo1.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-new-relic/",
      "sections": [
        "CodeStream and New Relic One",
        "Preview release",
        "Connect CodeStream and New Relic",
        "Caution",
        "See your errors and what's causing them",
        "Tip",
        "How to go from errors inbox to your IDE",
        "APM errors and CodeStream",
        "Associate repositories with errors",
        "Use environment variable with APM (recommended)",
        "Use the UI",
        "Use the NerdGraph API",
        "Associate build SHAs or release tags with errors",
        "Install APM agents with CodeStream",
        "Dynamic logging with Go and Pixie"
      ],
      "published_at": "2021-12-19T14:37:10Z",
      "title": "CodeStream and New Relic One",
      "updated_at": "2021-12-14T23:24:49Z",
      "type": "docs",
      "external_id": "a6c04d95011d9150cb0798580c15695bb9f3bbda",
      "document_type": "page",
      "popularity": 1,
      "body": "CodeStream and New Relic One work together to give you insight into your code's errors, as well as making it easier to get started instrumenting your code with our APM agents. With CodeStream connected to New Relic One, you can jump from a stack trace error directly to the offending line of code in your IDE. Once in your IDE, you can navigate the stack trace and collaborate with your teammates to resolve the issue. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Connect CodeStream and New Relic Before you can take advantage of New Relic's observability features in CodeStream, you'll need to connect them. Requirements for connecting CodeStream and New Relic: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key If you don't have a user key or want to learn more about how you can use and manage them, see our doc on the New Relic user key. Once you have your New Relic user key, in CodeStream's Observability section click Connect to New Relic One, then paste your API key and click Connect to New Relic One. Caution New Relic users can share stacktrace errors on CodeStream. Once you've connected CodeStream to New Relic, any new users you add to your CodeStream organization can see those errors. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Requirements for opening stack trace errors in your IDE: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key CodeStream and New Relic connection Data being reported to New Relic via APM monitoring A workload for errors inbox An error For APM errors, your repository's commit hash and release tag New Relic errors inbox is a single place to proactively detect, prioritize, and take action on your errors before they impact customers. With CodeStream, you can jump from an error directly to the offending code in your IDE. Tip Limited to APM errors. How to go from errors inbox to your IDE From one.newrelic.com/, go to Errors Inbox, click a stack trace error, then click Open in IDE. APM errors and CodeStream In order to view stack trace errors in your IDE, CodeStream needs to know what repository the error is associated with and, ideally, which version of the code generated the error. Associate repositories with errors Once you've started monitoring for APM, mobile, browser, or Lambda, you should create repository entities and associate them with entities for all of your services. In order to create a repository entity you'll need to provide the repository's remote URL. For example, the remote URL can be in either the SSH or HTTPS format: git@github.com:newrelic/beta-docs-site.git https://github.com/newrelic/beta-docs-site.git Caution It's possible to add the same GitHub repository more than once, if you're using different protocols to do so. The UI warns you about this, but won't prevent you from doing so. For example, https://github.com/tuna/repo and git@github.com:tuna/repo are the same repo, with different protocols. If you try to open an error in your IDE and there isn't an associated repository, CodeStream will prompt you to make an association and save that association for all errors from the given entity on New Relic. However, it would be preferably to use one of the following methods since they require less ongoing manual effort and eliminate the possibility of end-user mistakes, such as misconfigured remote URLs. Use environment variable with APM (recommended) Set the environment variable NEW_RELIC_METADATA_REPOSITORY_URL. New Relic APM agents create the repository entity and associate it to your application entity automatically. This requires the SSH or HTTPS URL format. We recommend that these be set as part of your build pipeline. Use the UI Once you've started sending data to New Relic, use the UI to connect your related repository. Go to the APM Summary page via one.newrelic.com > Explorer > Services - APM > (select an app), then look for the Repositories section at the bottom-right. Click Connect repository to find an existing repository or add a new one. Use the NerdGraph API Use New Relic's NerdGraph APIsto create a repository and associate it with your application entities. Step 1: Create a repository entity To create a repository entity, use the referenceEntityCreateOrUpdateRepository API and make sure to save the GUID that's produced. The API takes the following parameters: accountId - the integer account ID for the account you want to add the repository to url - example https://github.com/newrelic/beta-docs-site.git name - example: newrelic/beta-docs-site mutation { referenceEntityCreateOrUpdateRepository(repositories: [{accountId: [YOUR_ACCOUNT_ID], name: \"[REPO_NAME]\", url: \"[REPO_URL]\"}]) { created failures { guid message type } } } Copy In order to find the entity you create, you can use a query like the following. Note that the URL you provided to referenceEntityCreateOrUpdateRepository gets saved as an entity tag. { actor { entitySearch(query: \"name = 'a name' OR tags.url = 'a url'\") { count query results { entities { guid name tags { key values } } } } } } Copy Step 2: Associate the repository entity to your application entity First, find the GUID for the application you want to associate your repository to. Parameters: sourceEntityGuid - the entity GUID of the application targetEntityGuid - the entity GUID of your repository type - always BUILT_FROM mutation { entityRelationshipUserDefinedCreateOrReplace(sourceEntityGuid: \"\", targetEntityGuid: \"\", type: BUILT_FROM) { errors { message type } } } Copy To see all entities related to your repository you can do a query like this: { actor { entity(guid: \"[YOUR_REPOSITORY_GUID]]\") { relatedEntities(filter: {direction: BOTH, relationshipTypes: {include: BUILT_FROM}}) { results { target { entity { name guid type } } type } } name type tags { values key } } } } Copy Step 3: Cleanup (if needed) Delete a repository with the following query: mutation DeleteRepository { entityDelete(guids: \"[ENTITY_GUID_HERE]]\") { deletedEntities failures { message guid } } } Copy Associate build SHAs or release tags with errors To use CodeStream's Open in IDE with your APM stack trace errors, use environment variables to configure your APM agent with your application's commit sha and/or your release tag associated with the running version of your software. CodeStream only needs the first seven characters of your commit sha (for example, 734713b) to make this connection, but you can include the entire sha. Alternately, you can use a release tag (such as v0.1.209 or release-209) for CodeStream to find the correct version of your code. For New Relic APM, the commit and/or release tag (tags.commit and tags.releaseTag) are added as attributes on Transaction and TransactionError events. You can use APM environment variables to set these attributes. We recommend setting one or both of these variables as part of your build pipeline. NEW_RELIC_METADATA_COMMIT - The commit sha. You can include the whole thing or only the first seven characters. NEW_RELIC_METADATA_RELEASE_TAG - A release tag (such as v0.1.209 or release-209). This has the advantage of being human readable. For more on how to set these variables, here are specific configuration details for each language: Go Java .NET Node.js PHP Python Install APM agents with CodeStream Requirements for installing New Relic APM agents via CodeStream: New Relic account New Relic user key CodeStream and New Relic connection A supported language application codebase .NET Core Java Node.JS When you first connect CodeStream to New Relic, if you're working on an application's codebase that's not being monitored by New Relic, CodeStream will offer to instrument that application for you. Like New Relic's guided install, CodeStream will walk you through and automate all of the steps to installing the APM agent to start sending data to New Relic. This check only happens automatically when the initial connection is made. To do so later, in the CodeStream extension, click your username, then click New Relic Setup. Dynamic logging with Go and Pixie New Relic account New Relic user API key CodeStream and New Relic connection A Kubernetes cluster monitored by Pixie An application written in Go You can use CodeStream to enable dynamic logging for your Pixie-monitored Go applications. Just right-click on any method name and select Dynamic Logging Using Pixie.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.67307,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> and <em>New</em> Relic One",
        "sections": "<em>CodeStream</em> and <em>New</em> Relic One",
        "body": "<em>CodeStream</em> and <em>New</em> Relic One <em>work</em> together to give you insight into <em>your</em> <em>code</em>&#x27;s errors, as well as making it easier to get started instrumenting <em>your</em> <em>code</em> with our APM agents. With <em>CodeStream</em> connected to <em>New</em> Relic One, you can jump from a stack trace error directly to the offending line of <em>code</em>"
      },
      "id": "6171e652196a67e9c92f0156"
    },
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-20T01:42:42Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.9128,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> triaged errors",
        "sections": "Optional: Integrate Errors Inbox <em>with</em> Slack, Jira, and <em>CodeStream</em>",
        "info": "Managed <em>your</em> triaged errors in Errors Inbox",
        "body": " pika.exceptions:ChannelWrongStateError, you don&#x27;t see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe <em>your</em> ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>"
      },
      "id": "61be8f01196a67e048eef29c"
    }
  ],
  "/docs/codestream/start-here/codestream-new-relic": [
    {
      "image": "https://docs.newrelic.com/static/bda6e10caadb978a13dfcbb98b4f79bb/f96db/ObservabilitySection-connect1.png",
      "url": "https://docs.newrelic.com/docs/codestream/codestream-ui-overview/observability-section/",
      "sections": [
        "CodeStream observability",
        "Connect CodeStream and New Relic One",
        "See your errors in CodeStream",
        "Tip"
      ],
      "published_at": "2021-12-19T14:12:37Z",
      "title": "CodeStream observability",
      "updated_at": "2021-11-13T21:12:48Z",
      "type": "docs",
      "external_id": "15085b32c3ff3c5e4a469b6ef9151cdb8624b25a",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to get the most out of New Relic CodeStream, connect CodeStream to New Relic One via your New Relic user key. Once that's done, for entities you're monitoring with New Relic One, you'll see your errors directly in CodeStream. Connect CodeStream and New Relic One Before you can start seeing errors in your IDE and take advantage of other New Relic and CodeStream features, you'll need to enter your New Relic user key. Go here to get or create your New Relic user key. Once you have your user key, in Observability click Connect to New Relic One, then paste your user key and click Connect. See your errors in CodeStream Once you've connected New Relic to CodeStream, you'll see observed errors directly in CodeStream. These sections help you and your team manage and see your errors in different ways: Errors assigned to me: If an error has been assigned to you, you'll see it here. Recent errors in: Each repository you have open in your IDE will have its own grouping of errors. If your repository URL is mapped to more than one entity you're observing in New Relic, a dropdown lets you filter by entity. Select entity from New Relic: Use this to connect a repository in your IDE with an entity you're observing with New Relic. Tip If your project isn't monitored by New Relic, you can use CodeStream to get that started. In the CodeStream extension, in the Observability section, click the gear icon, and then click Instrument my App. Follow the instructions to instrument your code.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1543.289,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> observability",
        "sections": "Connect <em>CodeStream</em> <em>and</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": "In order to get the most out of <em>New</em> <em>Relic</em> <em>CodeStream</em>, connect <em>CodeStream</em> to <em>New</em> <em>Relic</em> <em>One</em> via your <em>New</em> <em>Relic</em> user key. Once that&#x27;s done, for entities you&#x27;re monitoring with <em>New</em> <em>Relic</em> <em>One</em>, you&#x27;ll see your errors directly in <em>CodeStream</em>. Connect <em>CodeStream</em> and <em>New</em> <em>Relic</em> <em>One</em> Before you can start seeing"
      },
      "id": "61743f8be7b9d2b9d113c7cc"
    },
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1523.0813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>New</em> <em>Relic</em> <em>CodeStream</em>",
        "sections": "Intro to <em>New</em> <em>Relic</em> <em>CodeStream</em>",
        "body": ") If you haven&#x27;t already, sign up for a free <em>New</em> <em>Relic</em> account so that you can get the most out of <em>New</em> <em>Relic</em> <em>CodeStream</em>. Preview release <em>CodeStream</em>&#x27;s integration with <em>New</em> <em>Relic</em> <em>One</em> is a preview release limited to <em>New</em> <em>Relic</em> <em>One</em> accounts on our US data center, and your use is subject to the pre-release"
      },
      "id": "617440e3e7b9d2836c13c43c"
    },
    {
      "image": "https://docs.newrelic.com/static/8ab59b1cd343193c20dbdb5f35420fcb/432e7/ErrorOnNR1.png",
      "url": "https://docs.newrelic.com/docs/codestream/how-use-codestream/performance-monitoring/",
      "sections": [
        "Performance monitoring with CodeStream",
        "Discover errors on New Relic One",
        "Discover errors via CodeStream",
        "Error details",
        "Collaborate with CodeStream",
        "Use build SHAs with CodeStream",
        "Other collaboration tools",
        "Associate your repository"
      ],
      "published_at": "2021-12-21T01:41:28Z",
      "title": "Performance monitoring with CodeStream",
      "updated_at": "2021-10-30T03:34:44Z",
      "type": "docs",
      "external_id": "378ad1d91c35b3c33347ee3cf91afb28620b45f7",
      "document_type": "page",
      "popularity": 1,
      "body": "Its important to know how your code is performing in production and whether or not its generating errors. To help you with this, New Relic CodeStream brings performance monitoring right into your IDE. Discover errors on New Relic One Once youve connected CodeStream to your New Relic One account, and you've created one or more workloads with errors inbox on New Relic One, use Open in IDE to see APM errors with stack traces directly in your IDE. When you've connected CodeStream to your New Relic One account, in errors inbox click Open in IDE to see the code that caused the error. Once connected, all of your collaboration work in CodeStream (such as the discussion, assignee, and error status) syncs with New Relic One, where you can continue to collaborate. A typical collaboration session could include developers commenting on code in their IDEs, a DevOps engineer assigning errors in errors inbox, and a development manager following along in Slack. By meeting people in the tools they're already using, New Relic CodeStream shortens the amount of time between error discovery and error resolution. Discover errors via CodeStream In addition to errors inbox, discover errors in your IDE in the CodeStream observability section. In addition to recent errors in your repos, see any specific errors assigned to you. Use CodeStream's observability section to keep up to date with recent and assigned stack trace errors. Error details No matter how you've arrived at an error in your IDE, CodeStream presents all of the errors details, including the stack trace, and you can collaborate with your teammates to resolve the error. Navigate the stack trace to investigate the issue. Click any frame in the stack trace to jump straight to the corresponding file and line number in your IDE. As you navigate the stack trace, if you come across code that seems like the source of your problem, select it and click the comment icon to start collaborating. Collaborate with CodeStream With CodeStream open, once you've identified the problematic code, select it in your editor and click the comment icon that appears next to it in the CodeStream pane. CodeStream automatically mentions the most recent person to touch the code related to the error, making it easy for you to bring the right people into the discussion. Select code in your editor to add a comment. Assign the error and update its status for better tracking an accountability. Once youve identified the problem you can assign the error, either to an existing teammate on CodeStream or to a person suggested based on the repositorys Git commit history. You can update the errors status from unresolved to resolved or ignored. Use build SHAs with CodeStream You may see this warning if there's no build SHA associated with a specific error. CodeStream uses the build SHA to match the specific stack trace error with the version of the code running in the environment that triggered the error. The build SHA not configured warning message reads: No build SHA associated with this error. Your version of the code may not match the environment that triggered the error. To resolve this warning, set the environment variables for your APM agent. Even without the build SHA configured, you can still investigate the error, but you may not be looking at the version of the code that caused it. The build SHA not found warning message reads: Your version of the code doesn't match production. Fetch the following commit to better investigate the error. If you do have build SHAs configured, but the version of the code you're on locally doesn't contain that commit, CodeStream will let you know so that you can more effectively investigate and resolve the error. CodeStream will also let you know if the error doesnt have a stack trace associated with it. This happens with older errors when the stack trace has aged out on New Relic One. Other collaboration tools In an error discussion, use the ... More actions dropdown to share the discussion on Slack or Microsoft Teams. Associate your repository If there's no repository associated with CodeStream when you click Open in IDE on an error, CodeStream prompts you to do so. All of the repositories you currently have open in your IDE are listed in the select a repo dropdown. If you dont see the repository you want listed, open it in your IDE and it will automatically get added to the list. If youre working with a fork, make sure you select the upstream remote. To avoid having to do this manual association every time you open an error, you can make these associations via your APM agent's environment variables.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1120.7212,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Performance monitoring with <em>CodeStream</em>",
        "sections": "Discover errors on <em>New</em> <em>Relic</em> <em>One</em>",
        "body": "Its important to know how your <em>code</em> is performing in production and whether or not its generating errors. To help you with this, <em>New</em> <em>Relic</em> <em>CodeStream</em> brings performance monitoring right into your IDE. Discover errors on <em>New</em> <em>Relic</em> <em>One</em> Once youve connected <em>CodeStream</em> to your <em>New</em> <em>Relic</em> <em>One</em> account"
      },
      "id": "617cbd54e7b9d28f12c0535e"
    }
  ],
  "/docs/codestream/start-here/codestream-user-guide": [
    {
      "image": "https://docs.newrelic.com/static/89fc796cef01d95170eace2254590fbe/1efb2/connect-repo1.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-new-relic/",
      "sections": [
        "CodeStream and New Relic One",
        "Preview release",
        "Connect CodeStream and New Relic",
        "Caution",
        "See your errors and what's causing them",
        "Tip",
        "How to go from errors inbox to your IDE",
        "APM errors and CodeStream",
        "Associate repositories with errors",
        "Use environment variable with APM (recommended)",
        "Use the UI",
        "Use the NerdGraph API",
        "Associate build SHAs or release tags with errors",
        "Install APM agents with CodeStream",
        "Dynamic logging with Go and Pixie"
      ],
      "published_at": "2021-12-19T14:37:10Z",
      "title": "CodeStream and New Relic One",
      "updated_at": "2021-12-14T23:24:49Z",
      "type": "docs",
      "external_id": "a6c04d95011d9150cb0798580c15695bb9f3bbda",
      "document_type": "page",
      "popularity": 1,
      "body": "CodeStream and New Relic One work together to give you insight into your code's errors, as well as making it easier to get started instrumenting your code with our APM agents. With CodeStream connected to New Relic One, you can jump from a stack trace error directly to the offending line of code in your IDE. Once in your IDE, you can navigate the stack trace and collaborate with your teammates to resolve the issue. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Connect CodeStream and New Relic Before you can take advantage of New Relic's observability features in CodeStream, you'll need to connect them. Requirements for connecting CodeStream and New Relic: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key If you don't have a user key or want to learn more about how you can use and manage them, see our doc on the New Relic user key. Once you have your New Relic user key, in CodeStream's Observability section click Connect to New Relic One, then paste your API key and click Connect to New Relic One. Caution New Relic users can share stacktrace errors on CodeStream. Once you've connected CodeStream to New Relic, any new users you add to your CodeStream organization can see those errors. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Requirements for opening stack trace errors in your IDE: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key CodeStream and New Relic connection Data being reported to New Relic via APM monitoring A workload for errors inbox An error For APM errors, your repository's commit hash and release tag New Relic errors inbox is a single place to proactively detect, prioritize, and take action on your errors before they impact customers. With CodeStream, you can jump from an error directly to the offending code in your IDE. Tip Limited to APM errors. How to go from errors inbox to your IDE From one.newrelic.com/, go to Errors Inbox, click a stack trace error, then click Open in IDE. APM errors and CodeStream In order to view stack trace errors in your IDE, CodeStream needs to know what repository the error is associated with and, ideally, which version of the code generated the error. Associate repositories with errors Once you've started monitoring for APM, mobile, browser, or Lambda, you should create repository entities and associate them with entities for all of your services. In order to create a repository entity you'll need to provide the repository's remote URL. For example, the remote URL can be in either the SSH or HTTPS format: git@github.com:newrelic/beta-docs-site.git https://github.com/newrelic/beta-docs-site.git Caution It's possible to add the same GitHub repository more than once, if you're using different protocols to do so. The UI warns you about this, but won't prevent you from doing so. For example, https://github.com/tuna/repo and git@github.com:tuna/repo are the same repo, with different protocols. If you try to open an error in your IDE and there isn't an associated repository, CodeStream will prompt you to make an association and save that association for all errors from the given entity on New Relic. However, it would be preferably to use one of the following methods since they require less ongoing manual effort and eliminate the possibility of end-user mistakes, such as misconfigured remote URLs. Use environment variable with APM (recommended) Set the environment variable NEW_RELIC_METADATA_REPOSITORY_URL. New Relic APM agents create the repository entity and associate it to your application entity automatically. This requires the SSH or HTTPS URL format. We recommend that these be set as part of your build pipeline. Use the UI Once you've started sending data to New Relic, use the UI to connect your related repository. Go to the APM Summary page via one.newrelic.com > Explorer > Services - APM > (select an app), then look for the Repositories section at the bottom-right. Click Connect repository to find an existing repository or add a new one. Use the NerdGraph API Use New Relic's NerdGraph APIsto create a repository and associate it with your application entities. Step 1: Create a repository entity To create a repository entity, use the referenceEntityCreateOrUpdateRepository API and make sure to save the GUID that's produced. The API takes the following parameters: accountId - the integer account ID for the account you want to add the repository to url - example https://github.com/newrelic/beta-docs-site.git name - example: newrelic/beta-docs-site mutation { referenceEntityCreateOrUpdateRepository(repositories: [{accountId: [YOUR_ACCOUNT_ID], name: \"[REPO_NAME]\", url: \"[REPO_URL]\"}]) { created failures { guid message type } } } Copy In order to find the entity you create, you can use a query like the following. Note that the URL you provided to referenceEntityCreateOrUpdateRepository gets saved as an entity tag. { actor { entitySearch(query: \"name = 'a name' OR tags.url = 'a url'\") { count query results { entities { guid name tags { key values } } } } } } Copy Step 2: Associate the repository entity to your application entity First, find the GUID for the application you want to associate your repository to. Parameters: sourceEntityGuid - the entity GUID of the application targetEntityGuid - the entity GUID of your repository type - always BUILT_FROM mutation { entityRelationshipUserDefinedCreateOrReplace(sourceEntityGuid: \"\", targetEntityGuid: \"\", type: BUILT_FROM) { errors { message type } } } Copy To see all entities related to your repository you can do a query like this: { actor { entity(guid: \"[YOUR_REPOSITORY_GUID]]\") { relatedEntities(filter: {direction: BOTH, relationshipTypes: {include: BUILT_FROM}}) { results { target { entity { name guid type } } type } } name type tags { values key } } } } Copy Step 3: Cleanup (if needed) Delete a repository with the following query: mutation DeleteRepository { entityDelete(guids: \"[ENTITY_GUID_HERE]]\") { deletedEntities failures { message guid } } } Copy Associate build SHAs or release tags with errors To use CodeStream's Open in IDE with your APM stack trace errors, use environment variables to configure your APM agent with your application's commit sha and/or your release tag associated with the running version of your software. CodeStream only needs the first seven characters of your commit sha (for example, 734713b) to make this connection, but you can include the entire sha. Alternately, you can use a release tag (such as v0.1.209 or release-209) for CodeStream to find the correct version of your code. For New Relic APM, the commit and/or release tag (tags.commit and tags.releaseTag) are added as attributes on Transaction and TransactionError events. You can use APM environment variables to set these attributes. We recommend setting one or both of these variables as part of your build pipeline. NEW_RELIC_METADATA_COMMIT - The commit sha. You can include the whole thing or only the first seven characters. NEW_RELIC_METADATA_RELEASE_TAG - A release tag (such as v0.1.209 or release-209). This has the advantage of being human readable. For more on how to set these variables, here are specific configuration details for each language: Go Java .NET Node.js PHP Python Install APM agents with CodeStream Requirements for installing New Relic APM agents via CodeStream: New Relic account New Relic user key CodeStream and New Relic connection A supported language application codebase .NET Core Java Node.JS When you first connect CodeStream to New Relic, if you're working on an application's codebase that's not being monitored by New Relic, CodeStream will offer to instrument that application for you. Like New Relic's guided install, CodeStream will walk you through and automate all of the steps to installing the APM agent to start sending data to New Relic. This check only happens automatically when the initial connection is made. To do so later, in the CodeStream extension, click your username, then click New Relic Setup. Dynamic logging with Go and Pixie New Relic account New Relic user API key CodeStream and New Relic connection A Kubernetes cluster monitored by Pixie An application written in Go You can use CodeStream to enable dynamic logging for your Pixie-monitored Go applications. Just right-click on any method name and select Dynamic Logging Using Pixie.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.12474,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> and <em>New</em> <em>Relic</em> One",
        "sections": "<em>CodeStream</em> and <em>New</em> <em>Relic</em> One",
        "body": " have a <em>New</em> <em>Relic</em> account, sign up at newrelic.com&#x2F;signup. It&#x27;s free, forever!) <em>New</em> <em>Relic</em> <em>user</em> key If you don&#x27;t have a <em>user</em> key or want to learn more about how you can use and manage them, see our doc on the <em>New</em> <em>Relic</em> <em>user</em> key. Once you have your <em>New</em> <em>Relic</em> <em>user</em> key, in <em>CodeStream</em>&#x27;s Observability"
      },
      "id": "6171e652196a67e9c92f0156"
    },
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-20T01:42:42Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.84906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>",
        "body": " pika.exceptions:ChannelWrongStateError, you don&#x27;t see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>"
      },
      "id": "61be8f01196a67e048eef29c"
    },
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.10446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>New</em> <em>Relic</em> <em>CodeStream</em>",
        "sections": "Intro to <em>New</em> <em>Relic</em> <em>CodeStream</em>",
        "body": "<em>New</em> <em>Relic</em> <em>CodeStream</em> is a developer collaboration platform that enables your development team to discuss and review <em>code</em> in a natural and contextual way. <em>CodeStream</em> not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional"
      },
      "id": "617440e3e7b9d2836c13c43c"
    }
  ],
  "/docs/codestream/start-here/install-codestream": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/new-relic-codestream-quick-start/",
      "sections": [
        "New Relic and CodeStream quick start",
        "Preview release",
        "Start with a New Relic account",
        "Install CodeStream via New Relic",
        "Install CodeStream in your IDE",
        "Install New Relic"
      ],
      "published_at": "2021-12-19T14:04:40Z",
      "title": "New Relic and CodeStream quick start",
      "updated_at": "2021-10-23T17:07:51Z",
      "type": "docs",
      "external_id": "a033944a31b2a9b7c5c5dba553e592a856c41890",
      "document_type": "page",
      "popularity": 1,
      "body": "Follow these quick steps to get started with New Relic and CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Start with a New Relic account If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever! Install CodeStream via New Relic Use our CodeStream quickstart to install it for your IDE. Install CodeStream in your IDE You can also install CodeStream via your Visual Studio Code and Visual Studio extensions menu or JetBrains plugins menu. Install New Relic Follow the steps in our Add your data UI page to get data flowing in. For your first install, we recommend using Guided install option, which will set up many integrations with a single command. (Go here for EU Guided install.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 550.846,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> and <em>CodeStream</em> quick start",
        "sections": "<em>Install</em> <em>CodeStream</em> via <em>New</em> <em>Relic</em>",
        "body": " <em>CodeStream</em> functionality.) Start with a <em>New</em> <em>Relic</em> account If you don&#x27;t have a <em>New</em> <em>Relic</em> account, sign up at newrelic.com&#x2F;signup. It&#x27;s free, forever! <em>Install</em> <em>CodeStream</em> via <em>New</em> <em>Relic</em> Use our <em>CodeStream</em> quickstart to <em>install</em> it for your IDE. <em>Install</em> <em>CodeStream</em> in your IDE You can also <em>install</em> <em>CodeStream</em>"
      },
      "id": "6174416728ccbc350fc6a7be"
    },
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.51123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://docs.newrelic.com/static/89fc796cef01d95170eace2254590fbe/1efb2/connect-repo1.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-new-relic/",
      "sections": [
        "CodeStream and New Relic One",
        "Preview release",
        "Connect CodeStream and New Relic",
        "Caution",
        "See your errors and what's causing them",
        "Tip",
        "How to go from errors inbox to your IDE",
        "APM errors and CodeStream",
        "Associate repositories with errors",
        "Use environment variable with APM (recommended)",
        "Use the UI",
        "Use the NerdGraph API",
        "Associate build SHAs or release tags with errors",
        "Install APM agents with CodeStream",
        "Dynamic logging with Go and Pixie"
      ],
      "published_at": "2021-12-19T14:37:10Z",
      "title": "CodeStream and New Relic One",
      "updated_at": "2021-12-14T23:24:49Z",
      "type": "docs",
      "external_id": "a6c04d95011d9150cb0798580c15695bb9f3bbda",
      "document_type": "page",
      "popularity": 1,
      "body": "CodeStream and New Relic One work together to give you insight into your code's errors, as well as making it easier to get started instrumenting your code with our APM agents. With CodeStream connected to New Relic One, you can jump from a stack trace error directly to the offending line of code in your IDE. Once in your IDE, you can navigate the stack trace and collaborate with your teammates to resolve the issue. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Connect CodeStream and New Relic Before you can take advantage of New Relic's observability features in CodeStream, you'll need to connect them. Requirements for connecting CodeStream and New Relic: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key If you don't have a user key or want to learn more about how you can use and manage them, see our doc on the New Relic user key. Once you have your New Relic user key, in CodeStream's Observability section click Connect to New Relic One, then paste your API key and click Connect to New Relic One. Caution New Relic users can share stacktrace errors on CodeStream. Once you've connected CodeStream to New Relic, any new users you add to your CodeStream organization can see those errors. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Requirements for opening stack trace errors in your IDE: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key CodeStream and New Relic connection Data being reported to New Relic via APM monitoring A workload for errors inbox An error For APM errors, your repository's commit hash and release tag New Relic errors inbox is a single place to proactively detect, prioritize, and take action on your errors before they impact customers. With CodeStream, you can jump from an error directly to the offending code in your IDE. Tip Limited to APM errors. How to go from errors inbox to your IDE From one.newrelic.com/, go to Errors Inbox, click a stack trace error, then click Open in IDE. APM errors and CodeStream In order to view stack trace errors in your IDE, CodeStream needs to know what repository the error is associated with and, ideally, which version of the code generated the error. Associate repositories with errors Once you've started monitoring for APM, mobile, browser, or Lambda, you should create repository entities and associate them with entities for all of your services. In order to create a repository entity you'll need to provide the repository's remote URL. For example, the remote URL can be in either the SSH or HTTPS format: git@github.com:newrelic/beta-docs-site.git https://github.com/newrelic/beta-docs-site.git Caution It's possible to add the same GitHub repository more than once, if you're using different protocols to do so. The UI warns you about this, but won't prevent you from doing so. For example, https://github.com/tuna/repo and git@github.com:tuna/repo are the same repo, with different protocols. If you try to open an error in your IDE and there isn't an associated repository, CodeStream will prompt you to make an association and save that association for all errors from the given entity on New Relic. However, it would be preferably to use one of the following methods since they require less ongoing manual effort and eliminate the possibility of end-user mistakes, such as misconfigured remote URLs. Use environment variable with APM (recommended) Set the environment variable NEW_RELIC_METADATA_REPOSITORY_URL. New Relic APM agents create the repository entity and associate it to your application entity automatically. This requires the SSH or HTTPS URL format. We recommend that these be set as part of your build pipeline. Use the UI Once you've started sending data to New Relic, use the UI to connect your related repository. Go to the APM Summary page via one.newrelic.com > Explorer > Services - APM > (select an app), then look for the Repositories section at the bottom-right. Click Connect repository to find an existing repository or add a new one. Use the NerdGraph API Use New Relic's NerdGraph APIsto create a repository and associate it with your application entities. Step 1: Create a repository entity To create a repository entity, use the referenceEntityCreateOrUpdateRepository API and make sure to save the GUID that's produced. The API takes the following parameters: accountId - the integer account ID for the account you want to add the repository to url - example https://github.com/newrelic/beta-docs-site.git name - example: newrelic/beta-docs-site mutation { referenceEntityCreateOrUpdateRepository(repositories: [{accountId: [YOUR_ACCOUNT_ID], name: \"[REPO_NAME]\", url: \"[REPO_URL]\"}]) { created failures { guid message type } } } Copy In order to find the entity you create, you can use a query like the following. Note that the URL you provided to referenceEntityCreateOrUpdateRepository gets saved as an entity tag. { actor { entitySearch(query: \"name = 'a name' OR tags.url = 'a url'\") { count query results { entities { guid name tags { key values } } } } } } Copy Step 2: Associate the repository entity to your application entity First, find the GUID for the application you want to associate your repository to. Parameters: sourceEntityGuid - the entity GUID of the application targetEntityGuid - the entity GUID of your repository type - always BUILT_FROM mutation { entityRelationshipUserDefinedCreateOrReplace(sourceEntityGuid: \"\", targetEntityGuid: \"\", type: BUILT_FROM) { errors { message type } } } Copy To see all entities related to your repository you can do a query like this: { actor { entity(guid: \"[YOUR_REPOSITORY_GUID]]\") { relatedEntities(filter: {direction: BOTH, relationshipTypes: {include: BUILT_FROM}}) { results { target { entity { name guid type } } type } } name type tags { values key } } } } Copy Step 3: Cleanup (if needed) Delete a repository with the following query: mutation DeleteRepository { entityDelete(guids: \"[ENTITY_GUID_HERE]]\") { deletedEntities failures { message guid } } } Copy Associate build SHAs or release tags with errors To use CodeStream's Open in IDE with your APM stack trace errors, use environment variables to configure your APM agent with your application's commit sha and/or your release tag associated with the running version of your software. CodeStream only needs the first seven characters of your commit sha (for example, 734713b) to make this connection, but you can include the entire sha. Alternately, you can use a release tag (such as v0.1.209 or release-209) for CodeStream to find the correct version of your code. For New Relic APM, the commit and/or release tag (tags.commit and tags.releaseTag) are added as attributes on Transaction and TransactionError events. You can use APM environment variables to set these attributes. We recommend setting one or both of these variables as part of your build pipeline. NEW_RELIC_METADATA_COMMIT - The commit sha. You can include the whole thing or only the first seven characters. NEW_RELIC_METADATA_RELEASE_TAG - A release tag (such as v0.1.209 or release-209). This has the advantage of being human readable. For more on how to set these variables, here are specific configuration details for each language: Go Java .NET Node.js PHP Python Install APM agents with CodeStream Requirements for installing New Relic APM agents via CodeStream: New Relic account New Relic user key CodeStream and New Relic connection A supported language application codebase .NET Core Java Node.JS When you first connect CodeStream to New Relic, if you're working on an application's codebase that's not being monitored by New Relic, CodeStream will offer to instrument that application for you. Like New Relic's guided install, CodeStream will walk you through and automate all of the steps to installing the APM agent to start sending data to New Relic. This check only happens automatically when the initial connection is made. To do so later, in the CodeStream extension, click your username, then click New Relic Setup. Dynamic logging with Go and Pixie New Relic account New Relic user API key CodeStream and New Relic connection A Kubernetes cluster monitored by Pixie An application written in Go You can use CodeStream to enable dynamic logging for your Pixie-monitored Go applications. Just right-click on any method name and select Dynamic Logging Using Pixie.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.27704,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> and <em>New</em> <em>Relic</em> One",
        "sections": "<em>CodeStream</em> and <em>New</em> <em>Relic</em> One",
        "body": " the advantage of being human readable. For more on how to set these variables, here are specific configuration details for each language: Go Java .NET Node.js PHP Python <em>Install</em> APM agents with <em>CodeStream</em> Requirements for installing <em>New</em> <em>Relic</em> APM agents via <em>CodeStream</em>: <em>New</em> <em>Relic</em> account <em>New</em> <em>Relic</em> user"
      },
      "id": "6171e652196a67e9c92f0156"
    }
  ],
  "/docs/codestream/start-here/new-relic-codestream-quick-start": [
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.39737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>New</em> <em>Relic</em> <em>CodeStream</em>",
        "sections": "Intro to <em>New</em> <em>Relic</em> <em>CodeStream</em>",
        "body": " knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A <em>quick</em> overview of how you can use <em>New</em> <em>Relic</em> <em>CodeStream</em> to discover, troubleshoot, and triage errors in your IDE. (2:27"
      },
      "id": "617440e3e7b9d2836c13c43c"
    },
    {
      "image": "https://docs.newrelic.com/static/89fc796cef01d95170eace2254590fbe/1efb2/connect-repo1.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-new-relic/",
      "sections": [
        "CodeStream and New Relic One",
        "Preview release",
        "Connect CodeStream and New Relic",
        "Caution",
        "See your errors and what's causing them",
        "Tip",
        "How to go from errors inbox to your IDE",
        "APM errors and CodeStream",
        "Associate repositories with errors",
        "Use environment variable with APM (recommended)",
        "Use the UI",
        "Use the NerdGraph API",
        "Associate build SHAs or release tags with errors",
        "Install APM agents with CodeStream",
        "Dynamic logging with Go and Pixie"
      ],
      "published_at": "2021-12-19T14:37:10Z",
      "title": "CodeStream and New Relic One",
      "updated_at": "2021-12-14T23:24:49Z",
      "type": "docs",
      "external_id": "a6c04d95011d9150cb0798580c15695bb9f3bbda",
      "document_type": "page",
      "popularity": 1,
      "body": "CodeStream and New Relic One work together to give you insight into your code's errors, as well as making it easier to get started instrumenting your code with our APM agents. With CodeStream connected to New Relic One, you can jump from a stack trace error directly to the offending line of code in your IDE. Once in your IDE, you can navigate the stack trace and collaborate with your teammates to resolve the issue. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Connect CodeStream and New Relic Before you can take advantage of New Relic's observability features in CodeStream, you'll need to connect them. Requirements for connecting CodeStream and New Relic: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key If you don't have a user key or want to learn more about how you can use and manage them, see our doc on the New Relic user key. Once you have your New Relic user key, in CodeStream's Observability section click Connect to New Relic One, then paste your API key and click Connect to New Relic One. Caution New Relic users can share stacktrace errors on CodeStream. Once you've connected CodeStream to New Relic, any new users you add to your CodeStream organization can see those errors. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Requirements for opening stack trace errors in your IDE: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key CodeStream and New Relic connection Data being reported to New Relic via APM monitoring A workload for errors inbox An error For APM errors, your repository's commit hash and release tag New Relic errors inbox is a single place to proactively detect, prioritize, and take action on your errors before they impact customers. With CodeStream, you can jump from an error directly to the offending code in your IDE. Tip Limited to APM errors. How to go from errors inbox to your IDE From one.newrelic.com/, go to Errors Inbox, click a stack trace error, then click Open in IDE. APM errors and CodeStream In order to view stack trace errors in your IDE, CodeStream needs to know what repository the error is associated with and, ideally, which version of the code generated the error. Associate repositories with errors Once you've started monitoring for APM, mobile, browser, or Lambda, you should create repository entities and associate them with entities for all of your services. In order to create a repository entity you'll need to provide the repository's remote URL. For example, the remote URL can be in either the SSH or HTTPS format: git@github.com:newrelic/beta-docs-site.git https://github.com/newrelic/beta-docs-site.git Caution It's possible to add the same GitHub repository more than once, if you're using different protocols to do so. The UI warns you about this, but won't prevent you from doing so. For example, https://github.com/tuna/repo and git@github.com:tuna/repo are the same repo, with different protocols. If you try to open an error in your IDE and there isn't an associated repository, CodeStream will prompt you to make an association and save that association for all errors from the given entity on New Relic. However, it would be preferably to use one of the following methods since they require less ongoing manual effort and eliminate the possibility of end-user mistakes, such as misconfigured remote URLs. Use environment variable with APM (recommended) Set the environment variable NEW_RELIC_METADATA_REPOSITORY_URL. New Relic APM agents create the repository entity and associate it to your application entity automatically. This requires the SSH or HTTPS URL format. We recommend that these be set as part of your build pipeline. Use the UI Once you've started sending data to New Relic, use the UI to connect your related repository. Go to the APM Summary page via one.newrelic.com > Explorer > Services - APM > (select an app), then look for the Repositories section at the bottom-right. Click Connect repository to find an existing repository or add a new one. Use the NerdGraph API Use New Relic's NerdGraph APIsto create a repository and associate it with your application entities. Step 1: Create a repository entity To create a repository entity, use the referenceEntityCreateOrUpdateRepository API and make sure to save the GUID that's produced. The API takes the following parameters: accountId - the integer account ID for the account you want to add the repository to url - example https://github.com/newrelic/beta-docs-site.git name - example: newrelic/beta-docs-site mutation { referenceEntityCreateOrUpdateRepository(repositories: [{accountId: [YOUR_ACCOUNT_ID], name: \"[REPO_NAME]\", url: \"[REPO_URL]\"}]) { created failures { guid message type } } } Copy In order to find the entity you create, you can use a query like the following. Note that the URL you provided to referenceEntityCreateOrUpdateRepository gets saved as an entity tag. { actor { entitySearch(query: \"name = 'a name' OR tags.url = 'a url'\") { count query results { entities { guid name tags { key values } } } } } } Copy Step 2: Associate the repository entity to your application entity First, find the GUID for the application you want to associate your repository to. Parameters: sourceEntityGuid - the entity GUID of the application targetEntityGuid - the entity GUID of your repository type - always BUILT_FROM mutation { entityRelationshipUserDefinedCreateOrReplace(sourceEntityGuid: \"\", targetEntityGuid: \"\", type: BUILT_FROM) { errors { message type } } } Copy To see all entities related to your repository you can do a query like this: { actor { entity(guid: \"[YOUR_REPOSITORY_GUID]]\") { relatedEntities(filter: {direction: BOTH, relationshipTypes: {include: BUILT_FROM}}) { results { target { entity { name guid type } } type } } name type tags { values key } } } } Copy Step 3: Cleanup (if needed) Delete a repository with the following query: mutation DeleteRepository { entityDelete(guids: \"[ENTITY_GUID_HERE]]\") { deletedEntities failures { message guid } } } Copy Associate build SHAs or release tags with errors To use CodeStream's Open in IDE with your APM stack trace errors, use environment variables to configure your APM agent with your application's commit sha and/or your release tag associated with the running version of your software. CodeStream only needs the first seven characters of your commit sha (for example, 734713b) to make this connection, but you can include the entire sha. Alternately, you can use a release tag (such as v0.1.209 or release-209) for CodeStream to find the correct version of your code. For New Relic APM, the commit and/or release tag (tags.commit and tags.releaseTag) are added as attributes on Transaction and TransactionError events. You can use APM environment variables to set these attributes. We recommend setting one or both of these variables as part of your build pipeline. NEW_RELIC_METADATA_COMMIT - The commit sha. You can include the whole thing or only the first seven characters. NEW_RELIC_METADATA_RELEASE_TAG - A release tag (such as v0.1.209 or release-209). This has the advantage of being human readable. For more on how to set these variables, here are specific configuration details for each language: Go Java .NET Node.js PHP Python Install APM agents with CodeStream Requirements for installing New Relic APM agents via CodeStream: New Relic account New Relic user key CodeStream and New Relic connection A supported language application codebase .NET Core Java Node.JS When you first connect CodeStream to New Relic, if you're working on an application's codebase that's not being monitored by New Relic, CodeStream will offer to instrument that application for you. Like New Relic's guided install, CodeStream will walk you through and automate all of the steps to installing the APM agent to start sending data to New Relic. This check only happens automatically when the initial connection is made. To do so later, in the CodeStream extension, click your username, then click New Relic Setup. Dynamic logging with Go and Pixie New Relic account New Relic user API key CodeStream and New Relic connection A Kubernetes cluster monitored by Pixie An application written in Go You can use CodeStream to enable dynamic logging for your Pixie-monitored Go applications. Just right-click on any method name and select Dynamic Logging Using Pixie.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.51346,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> <em>and</em> <em>New</em> <em>Relic</em> One",
        "sections": "<em>CodeStream</em> <em>and</em> <em>New</em> <em>Relic</em> One",
        "body": " for you. Like <em>New</em> <em>Relic</em>&#x27;s guided install, <em>CodeStream</em> will walk you through and automate all of the steps to installing the APM agent to <em>start</em> sending data to <em>New</em> <em>Relic</em>. This check only happens automatically when the initial connection is made. To do so later, in the <em>CodeStream</em> extension, click your"
      },
      "id": "6171e652196a67e9c92f0156"
    },
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-20T01:42:42Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.53232,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Optional: Integrate Errors Inbox with Slack, Jira, <em>and</em> <em>CodeStream</em>",
        "body": " pika.exceptions:ChannelWrongStateError, you don&#x27;t see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>"
      },
      "id": "61be8f01196a67e048eef29c"
    }
  ],
  "/docs/codestream/start-here/sign-up-codestream": [
    {
      "image": "https://docs.newrelic.com/static/490255cdad35ea9f73a5ec0877f086e6/f0991/MyOrgMenu.png",
      "url": "https://docs.newrelic.com/docs/codestream/codestream-ui-overview/my-organization/",
      "sections": [
        "Manage your organization on CodeStream",
        "The organization menu",
        "Invite your teammates",
        "Blame map"
      ],
      "published_at": "2021-12-19T14:12:38Z",
      "title": "Manage your organization on CodeStream",
      "updated_at": "2021-11-13T21:12:13Z",
      "type": "docs",
      "external_id": "c781fd39a475318eb539553700ed1f1fe3bdf18c",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream provides a number of tools for managing your organization. The organization menu In the header, click the My Organization menu button to see who's in your New Relic CodeStream organization, invite new members, and create blame maps. Admins are identified in the teammates list. If you're an admin, there's a dropdown to assign or remove admin privileges to any member. Invite your teammates Click Invite Teammates to invite new members to your organization. The outstanding invitations section lists all open invitations. The right side of each row has links to remove the invitation or to resend the invite. Click reinvite to send another invitation via email. You can also hover over the reinvite link for the option to generate an email yourself. The suggested teammates section, only available for admins, is a list of possible teammates derived from the commit history of your open repositories. At the right side of each row are links to remove the suggestion from the list or to invite the person. Blame map Click Blame Map to add email addresses that you use for committing code that may be different from the email address you used to sign up for CodeStream. For example, your CodeStream email address might be dave@acme.com, but you might also commit code as dave@webmail.com. Click Add mapping, enter your Git email address, and then select your entry from the list of organization members. That way, when someone comments on code committed by dave@webmail.com, CodeStream will know to at-mention you (such as, dave@acme.com). While non-admins can only create blame maps for themselves, admins can create blame maps for any member of the organization. This is useful for reassigning code ownership when people leave the organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 953.0941,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage your organization on <em>CodeStream</em>",
        "sections": "Manage your organization on <em>CodeStream</em>",
        "body": " of your open repositories. At the right side of each row are links to remove the suggestion from the list or to invite the person. Blame map Click Blame Map to add email addresses that you use for committing <em>code</em> that may be different from the email address you used to <em>sign</em> <em>up</em> for <em>CodeStream</em>"
      },
      "id": "617f403c28ccbcd75f8003ea"
    },
    {
      "image": "https://docs.newrelic.com/static/8945e0a9c512b8638ebf8165d47aee04/69902/QS-SignUp3.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-user-guide/",
      "sections": [
        "New Relic CodeStream user guide",
        "Jump to a topic",
        "1. Install the CodeStream extension in your IDE and sign up.",
        "2. Connect your tools",
        "3. Discuss any block of code, at any time",
        "4. Get feedback on your work in progress",
        "5. Create or review a pull request",
        "Help and feedback"
      ],
      "published_at": "2021-12-19T15:16:39Z",
      "title": "New Relic CodeStream user guide",
      "updated_at": "2021-11-24T04:44:31Z",
      "type": "docs",
      "external_id": "fa9af0118a8872fea89fda91482c44fb69913ea2",
      "document_type": "page",
      "popularity": 1,
      "body": "Jump to a topic Use the navigation on the left to jump straight to any topic. Otherwise, read on to get started with New Relic CodeStream. If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. 1. Install the CodeStream extension in your IDE and sign up. Install CodeStream for VS Code, Visual Studio or JetBrains. The CodeStream pane automatically appears in the sidebar for VS Code or in a tool window at the right side for JetBrains or Visual Studio. Click Sign Up and Create a team if you're the first person from your team to join CodeStream or paste in your invitation code if you were invited to a team already on CodeStream. Learn more about how to use CodeStream. 2. Connect your tools Create and review pull requests on GitHub, GitLab or Bitbucket. Create issues on Jira, Trello, and other issue trackers. Share code discussions on Slack or Microsoft Teams. CodeStream brings the tools you use every day together in your IDE. Click on your headshot at the top of the CodeStream pane and go to the Integrations page to get all of your tools connected. 3. Discuss any block of code, at any time Whether you're trying to understand someone else's code or getting help with some code you just wrote, just select the code and ask your question. Learn more about discussing code. 4. Get feedback on your work in progress Select Request Feedback from the + menu at any time in the development cycle, whether its a quick look over some work in progress (even uncommitted code!) or a formal review of a completed effort. Teammates can review your changes right in their IDE, with no need to switch branches or set aside their own work. Learn more about feedback requests. 5. Create or review a pull request Look for the Pull Requests section of the CodeStream sidebar to review an open pull request. Just click on a pull request (or load one from URL) to get a complete GitHub experience right in your IDE! Note that you can create a pull request in GitHub, GitLab or Bitbucket, but support for reviewing pull requests is currently only available for GitHub (cloud or Enterprise). Learn more about pull requests. Help and feedback Report a bug or suggest an improvement in GitHub issues. Contact us directly at support@codestream.com. Follow @teamcodestream for product updates and to share feedback and questions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 941.34235,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>CodeStream</em> user guide",
        "sections": "1. Install the <em>CodeStream</em> extension in your IDE and <em>sign</em> <em>up</em>.",
        "body": "Jump to a topic Use the navigation on the left to jump straight to any topic. Otherwise, read on to get started with New Relic <em>CodeStream</em>. If you haven&#x27;t already, <em>sign</em> <em>up</em> for a free New Relic account so that you can get the most out of New Relic <em>CodeStream</em>. 1. Install the <em>CodeStream</em> extension"
      },
      "id": "61744137e7b9d2428b13c6a0"
    },
    {
      "image": "https://docs.newrelic.com/static/0d940de4d107acece21b6e518f1a2c53/d10fb/OrganizationSettings.png",
      "url": "https://docs.newrelic.com/docs/codestream/codestream-settings/team-administration/",
      "sections": [
        "CodeStream organization settings and administration",
        "Manage people and roles",
        "Use blame map to reassign code",
        "Organization settings",
        "Onboarding settings",
        "Feedback request assignment and approval",
        "Change your organization's name",
        "Export your data"
      ],
      "published_at": "2021-12-19T15:09:06Z",
      "title": "CodeStream organization settings and administration",
      "updated_at": "2021-11-13T21:06:47Z",
      "type": "docs",
      "external_id": "643e62ff1fc920ca94e3bcd2e27e3a9be4317515",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream provides several tools for managing the teammates in your organization, whether they have accounts with New Relic One or not. Manage people and roles Click My Organization menu at the top of the CodeStream pane to invite people to your organization and assign or remove admin privileges. Use blame map to reassign code Click Blame Map to define code ownership with your organization. By default, when you comment on code, CodeStream mentions (or offers to email) the author or authors of the code you're commenting on. If that person has left the company it might not be the right thing to do. Non-admins are able to set up blame maps for themselves to handle situations where the email address they use to commit code is different than the one they used to sign up for CodeStream. Organization settings If you're an organization admin, look for the Organization Admin menu under the headshot menu at the top of the CodeStream pane. Onboarding settings Domain-based joining allows anyone with email addresses on the specified domains to join your CodeStream organization without being first invited. Not only does this make it very easy to get your teammates on board, but it ensures that they'll be part of your organization (as opposed to accidentally creating their own). Feedback request assignment and approval Admins can control how both feedback request assignments and approvals work for your organization. By default, the person requesting feedback can decide how approvals work, but you can, instead, set a default behavior for all feedback requests for the organization. Any reviewer can approve: Anyone can approve the feedback request, regardless of how many reviewers are assigned. All reviewers must approve individually: Each assigned reviewer must individually approve the feedback request before its considered approved. You can also decide if and how CodeStream suggests reviewers. Round-robin will cycle through all developers in the organization. Random will randomly assign the feedback request to any developer in the organization. The Authorship options will suggest up to three reviewers based on the developers who wrote the lines of code impacted by the changes, as well as other developers who may have committed to the branch. Change your organization's name Update the name of your CodeStream organization at any time. Export your data There's a lightweight export tool for getting your organization's discussions out of CodeStream. Click the icon to copy all of your data to the clipboard so that you can paste it elsewhere.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 880.63245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> organization settings and administration",
        "sections": "<em>CodeStream</em> organization settings and administration",
        "body": " not be the right thing to do. Non-admins are able to set <em>up</em> blame maps for themselves to handle situations where the email address they use to commit <em>code</em> is different than the one they used to <em>sign</em> <em>up</em> for <em>CodeStream</em>. Organization settings If you&#x27;re an organization admin, look for the Organization Admin menu"
      },
      "id": "61743ee264441ff1025fd5b5"
    }
  ],
  "/docs/codestream/start-here/what-is-codestream": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.19458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-20T01:42:42Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.84888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>",
        "body": " pika.exceptions:ChannelWrongStateError, you don&#x27;t see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>"
      },
      "id": "61be8f01196a67e048eef29c"
    },
    {
      "image": "https://docs.newrelic.com/static/89fc796cef01d95170eace2254590fbe/1efb2/connect-repo1.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-new-relic/",
      "sections": [
        "CodeStream and New Relic One",
        "Preview release",
        "Connect CodeStream and New Relic",
        "Caution",
        "See your errors and what's causing them",
        "Tip",
        "How to go from errors inbox to your IDE",
        "APM errors and CodeStream",
        "Associate repositories with errors",
        "Use environment variable with APM (recommended)",
        "Use the UI",
        "Use the NerdGraph API",
        "Associate build SHAs or release tags with errors",
        "Install APM agents with CodeStream",
        "Dynamic logging with Go and Pixie"
      ],
      "published_at": "2021-12-19T14:37:10Z",
      "title": "CodeStream and New Relic One",
      "updated_at": "2021-12-14T23:24:49Z",
      "type": "docs",
      "external_id": "a6c04d95011d9150cb0798580c15695bb9f3bbda",
      "document_type": "page",
      "popularity": 1,
      "body": "CodeStream and New Relic One work together to give you insight into your code's errors, as well as making it easier to get started instrumenting your code with our APM agents. With CodeStream connected to New Relic One, you can jump from a stack trace error directly to the offending line of code in your IDE. Once in your IDE, you can navigate the stack trace and collaborate with your teammates to resolve the issue. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Connect CodeStream and New Relic Before you can take advantage of New Relic's observability features in CodeStream, you'll need to connect them. Requirements for connecting CodeStream and New Relic: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key If you don't have a user key or want to learn more about how you can use and manage them, see our doc on the New Relic user key. Once you have your New Relic user key, in CodeStream's Observability section click Connect to New Relic One, then paste your API key and click Connect to New Relic One. Caution New Relic users can share stacktrace errors on CodeStream. Once you've connected CodeStream to New Relic, any new users you add to your CodeStream organization can see those errors. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Requirements for opening stack trace errors in your IDE: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key CodeStream and New Relic connection Data being reported to New Relic via APM monitoring A workload for errors inbox An error For APM errors, your repository's commit hash and release tag New Relic errors inbox is a single place to proactively detect, prioritize, and take action on your errors before they impact customers. With CodeStream, you can jump from an error directly to the offending code in your IDE. Tip Limited to APM errors. How to go from errors inbox to your IDE From one.newrelic.com/, go to Errors Inbox, click a stack trace error, then click Open in IDE. APM errors and CodeStream In order to view stack trace errors in your IDE, CodeStream needs to know what repository the error is associated with and, ideally, which version of the code generated the error. Associate repositories with errors Once you've started monitoring for APM, mobile, browser, or Lambda, you should create repository entities and associate them with entities for all of your services. In order to create a repository entity you'll need to provide the repository's remote URL. For example, the remote URL can be in either the SSH or HTTPS format: git@github.com:newrelic/beta-docs-site.git https://github.com/newrelic/beta-docs-site.git Caution It's possible to add the same GitHub repository more than once, if you're using different protocols to do so. The UI warns you about this, but won't prevent you from doing so. For example, https://github.com/tuna/repo and git@github.com:tuna/repo are the same repo, with different protocols. If you try to open an error in your IDE and there isn't an associated repository, CodeStream will prompt you to make an association and save that association for all errors from the given entity on New Relic. However, it would be preferably to use one of the following methods since they require less ongoing manual effort and eliminate the possibility of end-user mistakes, such as misconfigured remote URLs. Use environment variable with APM (recommended) Set the environment variable NEW_RELIC_METADATA_REPOSITORY_URL. New Relic APM agents create the repository entity and associate it to your application entity automatically. This requires the SSH or HTTPS URL format. We recommend that these be set as part of your build pipeline. Use the UI Once you've started sending data to New Relic, use the UI to connect your related repository. Go to the APM Summary page via one.newrelic.com > Explorer > Services - APM > (select an app), then look for the Repositories section at the bottom-right. Click Connect repository to find an existing repository or add a new one. Use the NerdGraph API Use New Relic's NerdGraph APIsto create a repository and associate it with your application entities. Step 1: Create a repository entity To create a repository entity, use the referenceEntityCreateOrUpdateRepository API and make sure to save the GUID that's produced. The API takes the following parameters: accountId - the integer account ID for the account you want to add the repository to url - example https://github.com/newrelic/beta-docs-site.git name - example: newrelic/beta-docs-site mutation { referenceEntityCreateOrUpdateRepository(repositories: [{accountId: [YOUR_ACCOUNT_ID], name: \"[REPO_NAME]\", url: \"[REPO_URL]\"}]) { created failures { guid message type } } } Copy In order to find the entity you create, you can use a query like the following. Note that the URL you provided to referenceEntityCreateOrUpdateRepository gets saved as an entity tag. { actor { entitySearch(query: \"name = 'a name' OR tags.url = 'a url'\") { count query results { entities { guid name tags { key values } } } } } } Copy Step 2: Associate the repository entity to your application entity First, find the GUID for the application you want to associate your repository to. Parameters: sourceEntityGuid - the entity GUID of the application targetEntityGuid - the entity GUID of your repository type - always BUILT_FROM mutation { entityRelationshipUserDefinedCreateOrReplace(sourceEntityGuid: \"\", targetEntityGuid: \"\", type: BUILT_FROM) { errors { message type } } } Copy To see all entities related to your repository you can do a query like this: { actor { entity(guid: \"[YOUR_REPOSITORY_GUID]]\") { relatedEntities(filter: {direction: BOTH, relationshipTypes: {include: BUILT_FROM}}) { results { target { entity { name guid type } } type } } name type tags { values key } } } } Copy Step 3: Cleanup (if needed) Delete a repository with the following query: mutation DeleteRepository { entityDelete(guids: \"[ENTITY_GUID_HERE]]\") { deletedEntities failures { message guid } } } Copy Associate build SHAs or release tags with errors To use CodeStream's Open in IDE with your APM stack trace errors, use environment variables to configure your APM agent with your application's commit sha and/or your release tag associated with the running version of your software. CodeStream only needs the first seven characters of your commit sha (for example, 734713b) to make this connection, but you can include the entire sha. Alternately, you can use a release tag (such as v0.1.209 or release-209) for CodeStream to find the correct version of your code. For New Relic APM, the commit and/or release tag (tags.commit and tags.releaseTag) are added as attributes on Transaction and TransactionError events. You can use APM environment variables to set these attributes. We recommend setting one or both of these variables as part of your build pipeline. NEW_RELIC_METADATA_COMMIT - The commit sha. You can include the whole thing or only the first seven characters. NEW_RELIC_METADATA_RELEASE_TAG - A release tag (such as v0.1.209 or release-209). This has the advantage of being human readable. For more on how to set these variables, here are specific configuration details for each language: Go Java .NET Node.js PHP Python Install APM agents with CodeStream Requirements for installing New Relic APM agents via CodeStream: New Relic account New Relic user key CodeStream and New Relic connection A supported language application codebase .NET Core Java Node.JS When you first connect CodeStream to New Relic, if you're working on an application's codebase that's not being monitored by New Relic, CodeStream will offer to instrument that application for you. Like New Relic's guided install, CodeStream will walk you through and automate all of the steps to installing the APM agent to start sending data to New Relic. This check only happens automatically when the initial connection is made. To do so later, in the CodeStream extension, click your username, then click New Relic Setup. Dynamic logging with Go and Pixie New Relic account New Relic user API key CodeStream and New Relic connection A Kubernetes cluster monitored by Pixie An application written in Go You can use CodeStream to enable dynamic logging for your Pixie-monitored Go applications. Just right-click on any method name and select Dynamic Logging Using Pixie.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.59749,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> and <em>New</em> <em>Relic</em> One",
        "sections": "<em>CodeStream</em> and <em>New</em> <em>Relic</em> One",
        "body": "<em>CodeStream</em> and <em>New</em> <em>Relic</em> One work together to give you insight into your <em>code</em>&#x27;s errors, as well as making it easier to get started instrumenting your <em>code</em> with our APM agents. With <em>CodeStream</em> connected to <em>New</em> <em>Relic</em> One, you can jump from a stack trace error directly to the offending line of <em>code</em>"
      },
      "id": "6171e652196a67e9c92f0156"
    }
  ],
  "/docs/codestream/troubleshooting/client-logs": [
    {
      "image": "https://developer.newrelic.com/static/5177711f1b2afa281eb4b16b448a95c4/0086b/errors-inbox.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/triage-errors/",
      "sections": [
        "Triage your errors",
        "lab",
        "View error details",
        "Tip",
        "Set an error's status",
        "Assign an error"
      ],
      "published_at": "2021-12-19T13:43:05Z",
      "title": "Triage your errors",
      "updated_at": "2021-12-19T13:43:05Z",
      "type": "developer",
      "external_id": "7e24d04a7ffa408fee136170d2bf7467ab6c48cd",
      "document_type": "page",
      "popularity": 1,
      "info": "Track and triage errors across your stack with Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've set up Errors Inbox before starting this one. Geek's Movie Shop is running in your development environment, and you're able to see its errors in Errors Inbox. Because you want to ensure a smooth experience for your customers, you need to analyze and triage these errors. By triaging your errors, you reduce the noise in your inbox. This helps you focus on the errors that impact your application the most. View error details In Errors Inbox, you see all unresolved errors across your application by default. Sometimes you need to learn more about an error before you can decide what to do with it. Step 1 of 2 Click the pika.exceptions:ChannelWrongStateError. This takes you to its details page. Here, you see the error's full context, including its stack trace and the number of times it occurred. The stack trace is especially important since it helps you narrow down the cause of the problem. Step 2 of 2 In the bottom right corner of Stack Trace, click Show all. The full trace tells you that something is wrong in your payment service. If this were a real-world application, you could use this stack trace and other details from this view to fix the issue. However, in this lab you're focused on using Errors Inbox, so skip this step. Tip You can also integrate CodeStream with your Errors Inbox. This allows you to jump to the relevant code in your IDE with the click of a button. Once you've configured CodeStream, click Open in IDE. Set an error's status Each error in Errors Inbox is Unresolved by default. But if you fix a bug or decide it isn't worth fixing, you can change its status to reflect that. Another developer on your team said they fixed this pika.exceptions:ChannelWrongStateError, so update its status to Resolved. Step 1 of 3 In New Relic, navigate to Errors Inbox. Step 2 of 3 On the error's row, click the status dropdown. You see two options in the dropdown: Resolve Ignore Step 3 of 3 Select Resolve. When you resolve an error, it no longer appears on the main screen. However, if the error occurs again, Errors Inbox automatically unresolves it. Tip If you want to ignore an error instead of resolving it, you can do that here as well. When you ignore an error, it no longer appears on the main screen. To see it again, either change the filter to include ignored error groups or stop ignoring the error. Assign an error Refresh the page. Oops! You resolved pika.exceptions:ChannelWrongStateError, but it's back in your Unresolved error groups. Apparently the bug wasn't fixed after all. You've decided to fix the error yourself. Step 1 of 2 On the far right side of the error group, click the user icon. Step 2 of 2 Enter and submit your email address. This tells your team that you're responsible for resolving the error. Tip Currently, when you assign an error group to a user, they don't receive a notification. Notifications are coming soon. You've triaged the pika.exceptions:ChannelWrongStateError. You can do the same for a few others as well. After ignoring, resolving, and assigning errors, your inbox is looking a lot cleaner than when you first saw it. Next, you filter your inbox and integrate it with other services so you can find, prioritize, and fix the errors that need fixing before you release your new app version to the world. lab This procedure is part of a lab that teaches you how to track full stack errors using Errors Inbox. Now that you've triaged your errors, it's time to manage them.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.90298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "info": "Track and triage errors across your stack with Errors <em>Inbox</em>",
        "body": " service. If this were a real-world application, you could use this stack trace and other details from this view to fix the issue. However, in this lab you&#x27;re focused on using Errors Inbox, so skip this step. Tip You <em>can</em> also integrate <em>CodeStream</em> with your Errors Inbox. This allows you to jump"
      },
      "id": "61bf36e9196a67049def096d"
    },
    {
      "image": "https://docs.newrelic.com/static/490255cdad35ea9f73a5ec0877f086e6/f0991/MyOrgMenu.png",
      "url": "https://docs.newrelic.com/docs/codestream/codestream-ui-overview/my-organization/",
      "sections": [
        "Manage your organization on CodeStream",
        "The organization menu",
        "Invite your teammates",
        "Blame map"
      ],
      "published_at": "2021-12-19T14:12:38Z",
      "title": "Manage your organization on CodeStream",
      "updated_at": "2021-11-13T21:12:13Z",
      "type": "docs",
      "external_id": "c781fd39a475318eb539553700ed1f1fe3bdf18c",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream provides a number of tools for managing your organization. The organization menu In the header, click the My Organization menu button to see who's in your New Relic CodeStream organization, invite new members, and create blame maps. Admins are identified in the teammates list. If you're an admin, there's a dropdown to assign or remove admin privileges to any member. Invite your teammates Click Invite Teammates to invite new members to your organization. The outstanding invitations section lists all open invitations. The right side of each row has links to remove the invitation or to resend the invite. Click reinvite to send another invitation via email. You can also hover over the reinvite link for the option to generate an email yourself. The suggested teammates section, only available for admins, is a list of possible teammates derived from the commit history of your open repositories. At the right side of each row are links to remove the suggestion from the list or to invite the person. Blame map Click Blame Map to add email addresses that you use for committing code that may be different from the email address you used to sign up for CodeStream. For example, your CodeStream email address might be dave@acme.com, but you might also commit code as dave@webmail.com. Click Add mapping, enter your Git email address, and then select your entry from the list of organization members. That way, when someone comments on code committed by dave@webmail.com, CodeStream will know to at-mention you (such as, dave@acme.com). While non-admins can only create blame maps for themselves, admins can create blame maps for any member of the organization. This is useful for reassigning code ownership when people leave the organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.75043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage your organization on <em>CodeStream</em>",
        "sections": "Manage your organization on <em>CodeStream</em>",
        "body": "New Relic <em>CodeStream</em> provides a number of tools for managing your organization. The organization menu In the header, click the <em>My</em> Organization menu button to see who&#x27;s in your New Relic <em>CodeStream</em> organization, invite new members, and create blame maps. Admins are identified in the teammates list"
      },
      "id": "617f403c28ccbcd75f8003ea"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-pro-features/upload-source-maps-api/",
      "sections": [
        "Upload source maps via API",
        "Prepare for using the source map API",
        "What is the JavaScript URL?",
        "Is a release name and ID required?",
        "Is a repo URL or a build commit hash required?",
        "Are there limits to source map uploads?",
        "Push source maps to New Relic",
        "Use npm module via command line or client-side script",
        "Important",
        "npm command line: Publish",
        "npm command line: List published maps",
        "npm command line: Delete",
        "npm via Node.js script: Publish",
        "npm via Node.js script: List published maps",
        "npm via Node.js script: Delete",
        "Use API via curl",
        "curl: Upload maps",
        "curl: List existing maps",
        "curl: Delete map",
        "Troubleshoot source maps"
      ],
      "published_at": "2021-12-19T16:35:03Z",
      "title": "Upload source maps via API",
      "updated_at": "2021-12-10T01:54:18Z",
      "type": "docs",
      "external_id": "3c5a8467aa0c47e12cbe83080e701e3c7cee090c",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring supports the uploading of source maps, which are used to un-minify error stack traces on the JS errors page. This document explains how to use the API to publish (upload) source maps to browser. Prepare for using the source map API In order to upload source maps to browser via the API, you'll need this information: A user API key (before November 20, 2020, the Admin API key was required; that will still work if already in place) The New Relic application ID for the deployed app The full JavaScript file URL Optionally, if the JavaScript URL doesn't automatically have release info appended to it, the release name and ID What is the JavaScript URL? Every time the agent captures an error in your code, it's associated with the URL of the JavaScript in which it occurred. This is the src attribute of the script tag in your HTML. This full JavaScript URL is required when sending source maps to browser. You can find the URL for an error's JavaScript file in browser, on the JS errors page. See Browser monitoring source maps for more on finding these errors in the UI. Is a release name and ID required? Many organizations include a version number or hash in the JavaScript URL. This is generally added to \"bust\" caches to ensure your users get the most recent version of your code. This type of URL might look something like: https://example.com/assets/application-59.min.js https://example.com/assets/bundle-d6d031.min.js https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.js If your app's URLs automatically have the version info appended to it, the browser agent has everything it needs in order to match errors with your code. You can move ahead to generating source maps. If this doesn't apply to you, and JS URLs do not have version info appended, youll have to assist the agent by specifying a release name and ID with the API. Is a repo URL or a build commit hash required? If you're interested in connecting New Relic to your CodeStream organization when this feature is available, your repository URL or build commit hash are required. Otherwise, this is optional. If you're interested in learning more about this, you can read about how CodeStream and New Relic work together to make it easier to identify errors and collaborate on fixing them. Are there limits to source map uploads? There is no limit to the overall number of source maps you can upload. However, the API is rate-limited per account: You can upload a maximum of 1000 source maps per minute. You can upload a maximum of 15,000 source maps per day. Source map files can be a maximum of 50Mb in size. Push source maps to New Relic Now that you have one or more source maps, you are ready to publish it to browser. You can use any of these methods to send source maps to browser: Use the New Relic npm module with the API via the command line or via a client-side JavaScript build/deploy script like Gulp or Grunt. Use API curl commands. Use the browser UI. Use npm module via command line or client-side script The easiest and recommended way to upload source maps to browser is to use the our new @newrelic/publish-sourcemap npm module. It provides a command line tool and Javascript API to accomplish this task. More documentation is available in the npm repo. Here are some examples of using the npm module via the command line. Important The following examples are for US accounts. For EU accounts, the endpoint is https://sourcemaps.service.eu.newrelic.com. For more information, see Introduction to the EU region data center. npm command line: Publish Here's an example of uploading source maps using the npm module via the command line. Note that the source map can come from a local file or a remote URL. npm install -g @newrelic/publish-sourcemap publish-sourcemap PATH_TO_SOURCE_MAP_FILE (local or remote) PATH_TO_ORIGINAL_FILE --apiKey=YOUR_NEW_RELIC_USER_KEY --applicationId=YOUR_NEW_RELIC_APP_ID --repoUrl=GITHUB_REPOSITORY_URL --buildCommit=GIT_BUILD_COMMIT_HASH Copy npm command line: List published maps Here's an example of listing published source maps: list-sourcemaps --applicationId=YOUR_APP_ID --apiKey=YOUR_NEW_RELIC_USER_KEY Options: --applicationId Browser application id --apiKey New Relic user API key Copy npm command line: Delete Here's an example of deleting a source map: delete-sourcemap --applicationId=YOUR_APP_ID --apiKey=YOUR_NEW_RELIC_USER_API_KEY --sourcemapId=YOUR_SOURCE_MAP_ID Options: --applicationId Browser application id --apiKey New Relic user API key --sourcemapId Unique id generated for a source map Copy Here are some examples of using the npm module to publish from client-side JavaScript: npm via Node.js script: Publish Here's an example of publishing a source map via a Node.js script: var publishSourcemap = require('@newrelic/publish-sourcemap').publishSourcemap publishSourcemap({ sourcemapPath: 'SOURCE_MAP_FULL_PATH', javascriptUrl: 'JS_URL', applicationId: YOUR_NEW_RELIC_APP_ID, apiKey: 'YOUR_NEW_RELIC_USER_API_KEY', repoUrl: 'GITHUB_REPOSITORY_URL', buildCommit: 'GIT_BUILD_COMMIT_HASH' }, function (err) { console.log(err || 'Sourcemap upload done')}) Copy npm via Node.js script: List published maps Here's an example of listing all published source maps: var listSourcemaps = require(@newrelic/publish-sourcemap).listSourcemaps listSourcemaps({ applicationId: YOUR_NEW_RELIC_APP_ID, apiKey: 'YOUR_NEW_RELIC_USER_API_KEY', limit: [Max number of results to return || 20]: , offset: [Number of results to skip before returning || 0]: , }, function (err, res) { console.log(err || res.sourcemaps)}) Copy npm via Node.js script: Delete Here's an example of deleting a source map file via a Node.js script: var deleteSourcemap = require(@newrelic/publish-sourcemap).deleteSourcemap deleteSourcemap({ sourcemapId: 'SOURCE_MAP_ID', applicationId: YOUR_NEW_RELIC_APP_ID, apiKey: 'YOUR_NEW_RELIC_USER_API_KEY', }, function (err) { console.log(err || 'Deleted source map')}) Copy When you're done, go to the JS errors page in browser, select an error grouping, and see if your error stack traces have been un-minified. Use API via curl Below are some examples of using curl to publish, list, and delete source maps: curl: Upload maps An example of using API via curl to publish maps to browser: curl -H \"Api-Key: YOUR_NEW_RELIC_USER_API_KEY\" \\ -F \"sourcemap=@SOURCE_MAP_PATH\" \\ -F \"javascriptUrl=JS_URL\" \\ -F \"releaseId=YOUR_RELEASE_ID\" \\ -F \"releaseName=YOUR_UI_PAGE\" \\ https://sourcemaps.service.newrelic.com/v2/applications/YOUR_NEW_RELIC_APP_ID/sourcemaps Copy curl -H \"Api-Key: YOUR_NEW_RELIC_USER_API_KEY\" \\ -F \"sourcemap=@SOURCE_MAP_PATH\" \\ -F \"javascriptUrl=JS_URL\" \\ -F \"releaseId=YOUR_RELEASE_ID\" \\ -F \"releaseName=YOUR_UI_PAGE\" \\ -F \"repoUrl=GITHUB_REPOSITORY_URL\" \\ -F \"buildCommit=GIT_BUILD_COMMIT_HASH\" \\ https://sourcemaps.service.newrelic.com/v2/applications/YOUR_NEW_RELIC_APP_ID/sourcemaps Copy curl: List existing maps Below is an example of how to get a list of source maps previously uploaded to New Relic via curl. New Relic returns the source map's unique SOURCEMAP_ID and its components: curl \\ -H \"Api-Key: YOUR_NEW_RELIC_USER_API_KEY\" \\ https://sourcemaps.service.newrelic.com/v2/applications/YOUR_NEW_RELIC_APP_ID/sourcemaps Copy curl: Delete map To delete a source map: Use the GET endpoint to list existing source maps and locate the SOURCEMAP_ID. Run the following command via curl: curl -X DELETE \\ -H \"Api-Key: YOUR_NEW_RELIC_USER_API_KEY\" \\ https://sourcemaps.service.newrelic.com/v2/applications/YOUR_NEW_RELIC_APP_ID/sourcemaps/SOURCEMAP_ID Copy When you're done, go to the JS errors page in browser, select an error grouping, and see if your error stack traces have been un-minified. Troubleshoot source maps If you are having trouble generating source maps from your build system, or if your errors in browser are remaining minified, see the source maps troubleshooting documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.12207,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Use npm module via command line or <em>client</em>-<em>side</em> script",
        "body": ", this is optional. If you&#x27;re interested in learning more about this, you <em>can</em> read about how <em>CodeStream</em> and New Relic work together to make it easier to identify errors and collaborate on fixing them. Are there limits to source map uploads? There is no limit to the overall number of source maps you <em>can</em> upload"
      },
      "id": "6043fea6196a672dec960f78"
    }
  ],
  "/docs/codestream/troubleshooting/git-issues": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.51123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on <em>Git</em>Hub <em>CodeStream</em>&#x27;s third-party software notices on <em>Git</em>Hub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.47961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to New Relic <em>CodeStream</em>",
        "sections": "Intro to New Relic <em>CodeStream</em>",
        "body": " your IDE. <em>CodeStream</em> shows a diff view of all the files changed in a PR. Review and approve the PR as you would on <em>Git</em>Hub. Monitor your <em>code</em>s performance in production Your pursuit of software quality doesnt end once the <em>code</em> has been merged. Connect <em>CodeStream</em> to your New Relic One account"
      },
      "id": "617440e3e7b9d2836c13c43c"
    },
    {
      "image": "https://docs.newrelic.com/static/89fc796cef01d95170eace2254590fbe/1efb2/connect-repo1.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-new-relic/",
      "sections": [
        "CodeStream and New Relic One",
        "Preview release",
        "Connect CodeStream and New Relic",
        "Caution",
        "See your errors and what's causing them",
        "Tip",
        "How to go from errors inbox to your IDE",
        "APM errors and CodeStream",
        "Associate repositories with errors",
        "Use environment variable with APM (recommended)",
        "Use the UI",
        "Use the NerdGraph API",
        "Associate build SHAs or release tags with errors",
        "Install APM agents with CodeStream",
        "Dynamic logging with Go and Pixie"
      ],
      "published_at": "2021-12-19T14:37:10Z",
      "title": "CodeStream and New Relic One",
      "updated_at": "2021-12-14T23:24:49Z",
      "type": "docs",
      "external_id": "a6c04d95011d9150cb0798580c15695bb9f3bbda",
      "document_type": "page",
      "popularity": 1,
      "body": "CodeStream and New Relic One work together to give you insight into your code's errors, as well as making it easier to get started instrumenting your code with our APM agents. With CodeStream connected to New Relic One, you can jump from a stack trace error directly to the offending line of code in your IDE. Once in your IDE, you can navigate the stack trace and collaborate with your teammates to resolve the issue. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Connect CodeStream and New Relic Before you can take advantage of New Relic's observability features in CodeStream, you'll need to connect them. Requirements for connecting CodeStream and New Relic: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key If you don't have a user key or want to learn more about how you can use and manage them, see our doc on the New Relic user key. Once you have your New Relic user key, in CodeStream's Observability section click Connect to New Relic One, then paste your API key and click Connect to New Relic One. Caution New Relic users can share stacktrace errors on CodeStream. Once you've connected CodeStream to New Relic, any new users you add to your CodeStream organization can see those errors. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Requirements for opening stack trace errors in your IDE: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key CodeStream and New Relic connection Data being reported to New Relic via APM monitoring A workload for errors inbox An error For APM errors, your repository's commit hash and release tag New Relic errors inbox is a single place to proactively detect, prioritize, and take action on your errors before they impact customers. With CodeStream, you can jump from an error directly to the offending code in your IDE. Tip Limited to APM errors. How to go from errors inbox to your IDE From one.newrelic.com/, go to Errors Inbox, click a stack trace error, then click Open in IDE. APM errors and CodeStream In order to view stack trace errors in your IDE, CodeStream needs to know what repository the error is associated with and, ideally, which version of the code generated the error. Associate repositories with errors Once you've started monitoring for APM, mobile, browser, or Lambda, you should create repository entities and associate them with entities for all of your services. In order to create a repository entity you'll need to provide the repository's remote URL. For example, the remote URL can be in either the SSH or HTTPS format: git@github.com:newrelic/beta-docs-site.git https://github.com/newrelic/beta-docs-site.git Caution It's possible to add the same GitHub repository more than once, if you're using different protocols to do so. The UI warns you about this, but won't prevent you from doing so. For example, https://github.com/tuna/repo and git@github.com:tuna/repo are the same repo, with different protocols. If you try to open an error in your IDE and there isn't an associated repository, CodeStream will prompt you to make an association and save that association for all errors from the given entity on New Relic. However, it would be preferably to use one of the following methods since they require less ongoing manual effort and eliminate the possibility of end-user mistakes, such as misconfigured remote URLs. Use environment variable with APM (recommended) Set the environment variable NEW_RELIC_METADATA_REPOSITORY_URL. New Relic APM agents create the repository entity and associate it to your application entity automatically. This requires the SSH or HTTPS URL format. We recommend that these be set as part of your build pipeline. Use the UI Once you've started sending data to New Relic, use the UI to connect your related repository. Go to the APM Summary page via one.newrelic.com > Explorer > Services - APM > (select an app), then look for the Repositories section at the bottom-right. Click Connect repository to find an existing repository or add a new one. Use the NerdGraph API Use New Relic's NerdGraph APIsto create a repository and associate it with your application entities. Step 1: Create a repository entity To create a repository entity, use the referenceEntityCreateOrUpdateRepository API and make sure to save the GUID that's produced. The API takes the following parameters: accountId - the integer account ID for the account you want to add the repository to url - example https://github.com/newrelic/beta-docs-site.git name - example: newrelic/beta-docs-site mutation { referenceEntityCreateOrUpdateRepository(repositories: [{accountId: [YOUR_ACCOUNT_ID], name: \"[REPO_NAME]\", url: \"[REPO_URL]\"}]) { created failures { guid message type } } } Copy In order to find the entity you create, you can use a query like the following. Note that the URL you provided to referenceEntityCreateOrUpdateRepository gets saved as an entity tag. { actor { entitySearch(query: \"name = 'a name' OR tags.url = 'a url'\") { count query results { entities { guid name tags { key values } } } } } } Copy Step 2: Associate the repository entity to your application entity First, find the GUID for the application you want to associate your repository to. Parameters: sourceEntityGuid - the entity GUID of the application targetEntityGuid - the entity GUID of your repository type - always BUILT_FROM mutation { entityRelationshipUserDefinedCreateOrReplace(sourceEntityGuid: \"\", targetEntityGuid: \"\", type: BUILT_FROM) { errors { message type } } } Copy To see all entities related to your repository you can do a query like this: { actor { entity(guid: \"[YOUR_REPOSITORY_GUID]]\") { relatedEntities(filter: {direction: BOTH, relationshipTypes: {include: BUILT_FROM}}) { results { target { entity { name guid type } } type } } name type tags { values key } } } } Copy Step 3: Cleanup (if needed) Delete a repository with the following query: mutation DeleteRepository { entityDelete(guids: \"[ENTITY_GUID_HERE]]\") { deletedEntities failures { message guid } } } Copy Associate build SHAs or release tags with errors To use CodeStream's Open in IDE with your APM stack trace errors, use environment variables to configure your APM agent with your application's commit sha and/or your release tag associated with the running version of your software. CodeStream only needs the first seven characters of your commit sha (for example, 734713b) to make this connection, but you can include the entire sha. Alternately, you can use a release tag (such as v0.1.209 or release-209) for CodeStream to find the correct version of your code. For New Relic APM, the commit and/or release tag (tags.commit and tags.releaseTag) are added as attributes on Transaction and TransactionError events. You can use APM environment variables to set these attributes. We recommend setting one or both of these variables as part of your build pipeline. NEW_RELIC_METADATA_COMMIT - The commit sha. You can include the whole thing or only the first seven characters. NEW_RELIC_METADATA_RELEASE_TAG - A release tag (such as v0.1.209 or release-209). This has the advantage of being human readable. For more on how to set these variables, here are specific configuration details for each language: Go Java .NET Node.js PHP Python Install APM agents with CodeStream Requirements for installing New Relic APM agents via CodeStream: New Relic account New Relic user key CodeStream and New Relic connection A supported language application codebase .NET Core Java Node.JS When you first connect CodeStream to New Relic, if you're working on an application's codebase that's not being monitored by New Relic, CodeStream will offer to instrument that application for you. Like New Relic's guided install, CodeStream will walk you through and automate all of the steps to installing the APM agent to start sending data to New Relic. This check only happens automatically when the initial connection is made. To do so later, in the CodeStream extension, click your username, then click New Relic Setup. Dynamic logging with Go and Pixie New Relic account New Relic user API key CodeStream and New Relic connection A Kubernetes cluster monitored by Pixie An application written in Go You can use CodeStream to enable dynamic logging for your Pixie-monitored Go applications. Just right-click on any method name and select Dynamic Logging Using Pixie.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 225.609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> <em>and</em> New Relic One",
        "sections": "<em>CodeStream</em> <em>and</em> New Relic One",
        "body": "<em>CodeStream</em> and New Relic One work together to give you insight into your <em>code</em>&#x27;s errors, as well as making it easier to get started instrumenting your <em>code</em> with our APM agents. With <em>CodeStream</em> connected to New Relic One, you can jump from a stack trace error directly to the offending line of <em>code</em>"
      },
      "id": "6171e652196a67e9c92f0156"
    }
  ],
  "/docs/codestream/troubleshooting/github-org-repos": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/writer-workflow/github-intro/",
      "sections": [
        "Get around GitHub",
        "Who is who in an issue/PR?",
        "Track issues in the board",
        "Deal with references in GitHub (and the style guide)",
        "Merge releases into main work (or, when do we publish?)",
        "GitHub labels"
      ],
      "published_at": "2021-12-20T04:59:44Z",
      "title": "Get around GitHub",
      "updated_at": "2021-12-20T04:59:44Z",
      "type": "docs",
      "external_id": "539ae5620ae9be8f8c3752fd3eda664186fbb5c4",
      "document_type": "page",
      "popularity": 1,
      "body": "As tech doc writers (TW) we edit docs, do peer edits, or use the Docs Team GitHub board to track the status of issues and pull requests (PR). Who is who in an issue/PR? GitHub keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR is filed, check on the filers username and see if they're listed as a member of the New Relic organization. If they aren't, try to find them on Slack based on their username. If you're not sure about someone's affiliation, treat them as external until you know otherwise. People in an issue/PR include: Creator: The person who opened the issue or PR. This could be a writer, a Relic, or an external user. We'll label the issue or PR differently depending on who created it. If you're not sure if a user is a Relic, a good trick is to click on their profile and see if they're a member of the New Relic GitHub org. Assignee: The person taking responsibility for a PR or issue. This will usually be used by the Hero or Sidekick to assign non-TW PRs and issues to themselves. It can also be used to take a TWs PR or issue over from them. Reviewer: The person who reviews or peer edits the code/document and approves the changes. Not necessarily the person responsible for that area or responsible for merging the commit. You can pre-assign up to 100 reviewers to a given issue. Track issues in the board The docs board has the following columns: Column Description Needs triage The Hero or Sidekick review and label issues and PRs in this column, then drag them to the appropriate column. If a PR or issue is labeled eng, the Hero/Sidekick can go ahead and click its ellipses icon to archive it. Hero: to do PRs that the Hero needs to review, publish, and follow up with SMEs as needed. Hero: Assign yourself as Assignee. In review (Hero or any TW) Drag PRs to this column when they are being reviewed. This shows who is reviewing and what is being reviewed, so two writers dont mistakenly work on the same PR. Any TW: Writer needs PR review PRs from Tech Docs team members that need a light edit pass to make sure everything in GitHub is correct. This should be checked by other writers every few hours so PRs dont get stale. If you have a PR thats been lingering here too long, ask for a reviewer in #doc_sprint_talk. Whoever takes it: assign yourself as Reviewer. Any TW: needs peer edit Like our Needs Peer Edit column in Jira: A writer has requested a review of their PR. Review their PR in GitHub and leave comments. Whoever takes it: assign yourself as Reviewer. Waiting on SME/Blocked For PRs that are blocked by need for SME info or confirmation (for example, as Hero you are waiting on an answer from the person who sent in a Hero pull request). Waiting on TW to merge All reviews are complete. The TW who created the PR (or who is assigned the issue) needs to merge this work into develop. Drafts A draft is a way to open a PR while indicating that the work is still in progress and not necessarily ready to merge immediately. You can't merge a Draft PR directly. Instead, you must move it out of draft status first. When you see a draft PR (especially from outside the team!), treat it as though it's a working draft, and reach out to the creator to discuss. Read more on GitHub's drafts. As a Hero, make sure you attend to the following throughout your day: Check in with the previous Hero at the start of your day (especially on Monday at the start of the week). Dont forget to sync with the BCN Hero if necessary. Watch for incoming PRs in #docs_deploys, and review everything in the Needs triage column. Drag cards from that column to the appropriate column. Work through the cards in the Hero: to do column. Everyone on the team helps keep things moving: All writers should keep an eye on both Any TW columns. There's one column for PRs that need a simpler review before merging (typo fixes, drive-by edits, etc), and another column for PRs that need a peer edit. There are also two blocked columns: One for PRs blocked on a SME, and another column where we're waiting on the TW who created the PR to review feedback and/or merge. After merging, remove your ticket from the board. Deal with references in GitHub (and the style guide) Don't link to anything non-public from a public place. You can reference Jira tickets, but reference tickets by issue key (DOC-1234 is ok) rather than a link (https://newrelic.atlassian.net/browse/DOC-1234 is not). Don't mention traffic or usage numbers publicly. Don't reference internal people by name. If they have a GH account, @mention their GH handle. If they don't, talk instead about teams (\"talk to a browser team engineer\" or \"Support Engineer\") rather than people. You can mention the #documentation channel and hero. Merge releases into main work (or, when do we publish?) The Hero currently merges three times a day: At 9 AM (morning), 12 PM (noon), and 3 PM (evening) Pacific. We merge release branches into main to avoid interuptions when someone merges into develop during a release. To learn more about this workflow, see the gitflow documentation in Atlassian. To start a release: Create a branch based off develop Github Desktop by clicking Current Branch in the top header, clicking New Branch in the dropdown, and then selecting Develop. Name the branch following this pattern: daily-release/mm-dd-yy-morning/noon/evening. Here's an example: daily-release/10-27-21-morning. Push your changes by clicking Push Origin in GitHub Desktop. Create a pull request into main from your new daily release branch by clicking Create Pull Request. This will open a pull request screen on github.com. Pull requests default to merging into develop, so select main as the base branch in the left side of the page and then click Submit Pull Request. Wait until all the checks complete, and then merge the pull request. All branches that follow the daily-release/mm-dd-yy-morning pattern are protected branches. This means the branches can't be deleted or pushed to by non-admins. GitHub labels Every issue needs labels to help us triage and track the health of our backlog: content: Always add, this indicates the issue is content-related rather than a design or engineering issue. pg_*: Always add to indicate the product group. For full definitions, see the \"Doc Jira and GitHub fields\" doc in the internal team Google Drive. Indicate who created the issue: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). Optionally: docs-issues-migrate: Issues that are too large in scope for the docs team to handle without product team expertise. This label alerts the docs issues team to migrate these issues into the customer feedback channel where they will be triaged and sent to product teams. Jirad: Issues that have a corresponding Jira ticket. Make sure you leave the Jira number in the comments of the issue (for example, DOC-1234). Every pull request needs these labels so we can see where our contributions come from: content: Always add, this indicates the PR is content-related rather than design or engineering. Indicate who created the pull request: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). If the PR fixes an external issue, label it as from_tw since the work was done by a tech writer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 512.96704,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get around <em>GitHub</em>",
        "sections": "Deal with references <em>in</em> <em>GitHub</em> (<em>and</em> <em>the</em> style guide)",
        "body": " <em>GitHub</em> org. Assignee: The person taking responsibility for a PR or issue. This will usually be used by the Hero or Sidekick to assign non-TW <em>PRs</em> and <em>issues</em> to themselves. It can also be used to take a TWs PR or issue over <em>from</em> them. Reviewer: The person who reviews or peer edits the <em>code</em>&#x2F;document"
      },
      "id": "61ab4782196a672667d0efa1"
    },
    {
      "image": "https://docs.newrelic.com/static/dd18b67123e9d4b7d40b56a8653a1f6b/f96db/OpenPullRequest1.png",
      "url": "https://docs.newrelic.com/docs/codestream/how-use-codestream/pull-requests/",
      "sections": [
        "Manage pull requests in CodeStream",
        "Pull request workflow",
        "Create a pull request",
        "Review a pull request",
        "Caution",
        "Leverage pull request comments"
      ],
      "published_at": "2021-12-21T01:41:29Z",
      "title": "Manage pull requests in CodeStream",
      "updated_at": "2021-11-13T21:14:26Z",
      "type": "docs",
      "external_id": "7e35f2ff4f06799fe492ffb6b2fedbb52e898b69",
      "document_type": "page",
      "popularity": 1,
      "body": "For most development teams, the final step in the development process is a pull request. Even if your team has decided to use New Relic CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, CodeStream allows you to keep all of that workflow inside your IDE. Pull request workflow There are four elements of CodeStream's pull request workflow. The following table outlines which code-hosting services are supported for each element. Feature Supported Services Create a pull request GitHub, GitHub Enterprise, GitLab, GitLab Self-Managed, Bitbucket, Bitbucket Server Create a pull request across forks GitHub, GitHub Enterprise, GitLab, GitLab Self-Managed Review and edit a pull request GitHub, GitHub Enterprise, GitLab, GitLab Self-Managed Display pull request comments as code annotations GitHub, GitLab, Bitbucket Create a pull request To open a pull request at any time, click the + button at the top of the CodeStream pane or the + button in the header of the Pull Requests section. You can also use a keyboard shortcut (ctlr+shift+/ p, ctrl+/ p on a Mac, and m if you're a GitLab user). CodeStream provides you with tree view, list view, and diff view options for reviewing your changes before opening the pull request. With a single click you can name the pull request based on the last commit message, the branch name, or, if you started work by selecting a ticket, the ticket title. If you have a ticket selected, you can also explicitly tie the ticket to the pull request and CodeStream will include a link to the ticket in the pull request's description. Before submitting the pull request, you can review your changes by clicking on any of the files listed below the form. To create a pull request across forks, click the compare across forks link at the top of the page and the form will update to allow you to select both the base and head repositories. You can also create a pull request from within a CodeStream feedback request. Once the feedback request has been approved, youll see an option to open a pull request at the top. Before you can create a pull request, make sure that any changes included in the feedback request have been committed and pushed. Also, if the feature branch youre working on doesnt have a remote tracking branch youll be given the option to set that as part of creating the pull request. When you create a pull request from a feedback request, CodeStream connects the dots between the two by adding a link to the pull request in the feedback request. Add a link to the feedback request, along with information about who did the review and when, in the description of the pull request. Review a pull request Caution The ability to review pull requests is currently not available for Bitbucket. Regardless of where the pull request was created, you can edit, review, and even merge it from within CodeStream. CodeStream brings GitHub and GitLab into your IDE, so there's zero learning curve. If you know how to work with pull requests on GitHub or GitLab, you'll know how to do it in CodeStream as well. You can edit a GitHub pull request's details, such as reviewers, assignees and labels. For a GitLab merge request, you can use edit mode (via the dropdown at the top of the page) or use the sidebar. By default, you can only add a single reviewer and a single assignee to a GitLab merge request. If your organization supports multiple reviewers and assignees, click the gear menu in the heading of the Merge Requests section of the CodeStream pane to enable this. Review the conversation and add comments with the ability to @mention your collaborators. View the changes, add comments, and submit a review. CodeStream does improve upon the GitHub/GitLab experience in a couple of important ways. On GitHub and GitLab you can only view the changes as a series of diff hunks. CodeStream provides that view as well, but if you'd prefer to see the changes in the context of the full file you can use either list view or tree view. Select the code you want to comment on and then click the Comment button (or select Comment from the context menu). When commenting, you can either add a single comment or start a review. With CodeStream, you can comment on lines of code that haven't changed. You can select any lines of code in the diff and not just those that are part of the changeset. These comments are added as a single comment to the pull request and aren't part of any review you may have in progress. All the power of GitHub pull requests and GitLab merge requests, and then some, right in your IDE. Leverage pull request comments Once the pull request has been approved and the code has been merged, that's usually the end of life for any comments in that pull request. Although there's often useful information in those comments that may have long-term value, they're rarely seen again. CodeStream gives those comments a second life by displaying them alongside the blocks of code that they refer to. To have pull request comments displayed as annotations in your codemarks, as well as in the Codemarks section of the CodeStream pane, click the gear icon in that section and check Show comments from pull requests. When you first check that box, if you havent already authenticated with your code-hosting service, youll be prompted to do so. Comments from merged PRs will appear next to the blocks of code they refer to. Comments from open PRs will also be included if you are on a relevant branch. For example, if the open PR is a request to merge the feature/some-name branch into main, youll see comments from that PR if you've checked out either feature/some-name or main, but not when youre on any other branch. As the code evolves, the location of each comment is automatically updated so that it remains linked to the block of code it refers to. PR comments for a given file are updated roughly every 30 minutes, so new comments may not appear right away. You can force an update by restarting your IDE.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 381.33978,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage pull requests <em>in</em> <em>CodeStream</em>",
        "sections": "Manage pull requests <em>in</em> <em>CodeStream</em>",
        "body": " request. Review a pull request Caution The ability to review pull requests is currently not available for Bitbucket. Regardless of where the pull request was created, you can edit, review, and even merge it <em>from</em> within <em>CodeStream</em>. <em>CodeStream</em> brings <em>GitHub</em> and <em>Git</em>Lab into your IDE, so there&#x27;s zero"
      },
      "id": "61744006196a67ee542f0555"
    },
    {
      "image": "https://docs.newrelic.com/static/74c274508fc745275751f72d3e01ea33/f96db/CodemarkAddRange1.png",
      "url": "https://docs.newrelic.com/docs/codestream/how-use-codestream/discuss-code/",
      "sections": [
        "Discuss code on CodeStream",
        "What is a codemark?",
        "Create a codemark",
        "Comment codemarks",
        "Issue codemarks",
        "Bring the right people into the discussion",
        "Work with different versions of the code",
        "Resolve codemarks",
        "Advanced features",
        "Multiple ranges",
        "File attachments",
        "Add tags",
        "Related codemarks",
        "Manage codemarks"
      ],
      "published_at": "2021-12-21T01:40:40Z",
      "title": "Discuss code on CodeStream",
      "updated_at": "2021-11-13T21:16:02Z",
      "type": "docs",
      "external_id": "9169c03142311fe838566856d0ff154df0e6d555",
      "document_type": "page",
      "popularity": 1,
      "body": "What is a codemark? Quite simply, a codemark is a discussion connected to the code. It could be a question, a suggestion, a bug report, or documentation. All of these discussions are saved, anchored to the blocks of code they refer to, so that they can be leveraged in the future. It could be a new developer joining the team, a developer trying to fix a bug in someone elses code, or even just you trying to remember why you made that change six months ago. Whatever the case, CodeStream helps you understand the code by surfacing the discussions in a contextual way. Even as a file changes over time, the codemarks remain connected to the code. Add some new lines of code above the code block, make edits to the code, or even cut-and-paste the entire block to a different section of the file, and youll see the codemark move along with your changes. Create a codemark To create a codemark, select a block of code in your editor and then click one of the icons that appears in the CodeStream pane next to your selection. If you're using a JetBrains IDE, such as IntelliJ, you can also create a codemark via the + button that appears in the editor's gutter when you select a block of code. When you're viewing a diff, for either a feedback request or a pull request, the button will also appear when you hover over the gutter to make it easy to comment on a single line. Even when the CodeStream pane is closed or not in view, you can create a codemark via the CodeStream options in either the lightbulb or context menus. You can also look for the + menu at the top of the CodeStream pane. Need to reach teammates that dont spend a lot of time in the IDE? Or maybe some teammates that arent yet on CodeStream? You can optionally share a codemark out to Slack or Microsoft Teams. The Slack integration even allows your teammates to reply directly from Slack. Comment codemarks Comment codemarks are the all-purpose codemark for linking any type of discussion to a block of code. Ask a question. Make a suggestion. Document some code. Make note of key sections of the codebase. The possibilities are endless. Issue codemarks When something needs to get done theres a better chance of it happening if its captured as an issue with someones name attached. Assign issues as a way of reporting bugs or manage your tech debt by capturing items as tracked issues instead of inline FIXMEs. If your team uses Asana, Azure DevOps, Bitbucket (cloud), Clubhouse, GitHub (cloud or Enterprise), GitLab (cloud or Self-Managed), Jira (cloud or Server), Linear, Trello, or YouTrack (cloud) for tracking issues, you can create an issue on one of those services directly from CodeStream. Select the service you use from the dropdown at the top of the codemark form. After going through the authentication process with the selected service, you can select a destination for your issue. For example, with Jira you'll be able to select the appropriate issue type and project. Once the issue has been created on CodeStream, it includes a link to the issue that was created on the external service. In the example, you'll see the URL for the issue on Jira. The issue on Jira includes a link to open the relevant code in your IDE. Bring the right people into the discussion When you create a codemark, CodeStream automatically mentions the people that most recently touched the code you're commenting on. They may be the best people to answer your question, but you can, of course, remove those mentions and manually mention someone else if appropriate. It may be the case that the people that have touched the code aren't yet on CodeStream, in which case CodeStream will provide checkboxes to have them notified via email. They can reply to the email to have their comment posted to CodeStream and, of course, they can install CodeStream to participate from their IDE. Work with different versions of the code Maybe youre on a feature branch, have local changes, or simply havent pulled in a while. There are countless reasons why the code youre looking at might be different than what a teammate is looking at. As a result, there will be plenty of times when the code referenced in a codemark doesnt match what you have locally. CodeStream recognizes these situations and includes the original version of the code block (such as, at the time the codemark was created), the current version, and a diff. Keep in mind that with CodeStream you can discuss any line of code, in any source file, at any time, even if its code that you just typed into your editor and havent yet committed. CodeStream empowers you to discuss code at the very earliest stages of the development process. Resolve codemarks Although not required, both comment and issue codemarks can be resolved. The codemarks section of the CodeStream pane breaks out codemarks into open, resolved and archived sections. Green, purple, and gray icons are used to represent those different states. If you see a lot of open/green codemarks in the CodeStream pane, that means that your teammates are being blocked by discussions and issues that haven't been resolved. You can add a comment at the same time you resolve the codemark and you can also archive the codemark at the same time. Advanced features Advanced features include multiple range codemarks, file attachments, tags, and related codemarks. Multiple ranges Many discussions about code involve more than just one block of code and concepts are often best presented when you can refer to multiple code locations at once. Here are a few examples of multi-range codemark at work: A change to a function is being contemplated that will impact its name. Each instance of the function call can now be referenced in one discussion. A React component and its CSS styling arent interacting well and you want to ask the team for input. You might select the div and the CSS rules you think should apply, so your teammates know exactly what youre talking about. Clients which make API calls to the server might get an unexpected result. Select the code where youre making the API call, and the handler in the API server, to connect the two actions together. To create a multi-range codemark, click + Add Code Block. Then select another block of code from the same file, a different file, or even a different repo. You can intersperse the difference code blocks in your post by referring to each one as [#N] (or click the pin icon from one of the code blocks to insert the markdown for you), as in the following example. Here's how that example is rendered. Once you've created the codemark, you can jump between the different locations by clicking the jump icon at the bottom right of each code block. When you edit a codemark, you can add and remove code blocks and you can change the location of any of the code blocks by clicking the dashed square icon. File attachments Enrich your discussions about code by attaching files directly to code blocks. Think about how much more compelling your comments and documentation become when you attach: A spec to guide the development of a new feature A log file to help debug an issue in the code A mockup to help clarify some UI work A screenshot to highlight a problem When creating a code comment or issue, you can attach a file by dragging-and-dropping onto the description field, pasting from your clipboard, or by clicking the paperclip icon. Images can even be displayed inline using markdown. Click the pin icon to the right of the attachment and CodeStream will insert the markdown for you. Now your teammate knows exactly what youre looking for. You can click on files in the attachments section to either download it or open it in the appropriate application. Add tags Look for the tag icon inside the codemark compose box to either select a tag or create a tag using any combination of color and text label. Tags are a great way to broadly organize and group your organization's codemarks and the possibilities here are endless. You can also filter by tag on the Filter & Search page. Related codemarks Click the CodeStream icon in the codemark compose form to select other related codemarks to attach them to the current codemark. This establishes a connection between different parts of a codebase. For example, when a change to one part of the codebase would require a change to another part, identify the dependency by creating two related codemarks. Once youve added the related codemarks theyll be displayed in a related section and you can click on any one to jump to that codemark and the corresponding section of the code. Manage codemarks Click the ellipses menu for any codemark and you'll see options to manage the codemark. Share: In addition to sharing to Slack or Teams at the time you create a codemark, you can also share it anytime later. Follow/Unfollow: Follow a codemark to be notified when its updated. Unfollow to stop receiving notifications. Copy link: Get a permalink for the codemark to share it anywhere. Archive: If theres a codemark that you dont think is important enough to be on permanent display in a given file, but you dont want to completely delete it, you can archive it instead. Settings in the codemarks section allow you to easily see all archived codemarks. Edit: Only the codemark's author can edit it. Delete: Only the codemark's author can delete it, but we encourage you to archive instead of deleting unless you're positive the codemark won't have any future value. Inject as Inline Comment: If you'd like a specific codemark to become part of the repo use this option to have it added as an inline comment. You can select the appropriate format, and then indicate if you want to include timestamps, replies, or to have the comment wrapped at 80 characters. You can also elect to have the codemark archived once it's been added as an inline comment. Reposition codemark: In most cases, a codemark will automatically remain linked to the block of code it refers to as the file changes over time. For example, if you cut the block of code and paste it at a different location in the file, the codemark will move right along with it. There are some scenarios, however, that CodeStream isn't able to handle automatically. For example, if you pasted the block of code into a different file. In these cases, the Reposition codemark allows you to select the new location of the block of code so that the codemark is displayed properly.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 315.657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discuss <em>code</em> on <em>CodeStream</em>",
        "sections": "Discuss <em>code</em> on <em>CodeStream</em>",
        "body": " team uses Asana, Azure DevOps, Bitbucket (cloud), Clubhouse, <em>GitHub</em> (cloud or Enterprise), <em>Git</em>Lab (cloud or Self-Managed), Jira (cloud or Server), Linear, Trello, or YouTrack (cloud) for tracking <em>issues</em>, you can create an issue on one of those services directly <em>from</em> <em>CodeStream</em>. Select the service you"
      },
      "id": "6174400564441fe8685fd746"
    }
  ],
  "/docs/codestream/troubleshooting/glsm-version": [
    {
      "image": "https://docs.newrelic.com/static/8fc91276c7cb53b35f896fcac177247d/f96db/IssuesSection.png",
      "url": "https://docs.newrelic.com/docs/codestream/codestream-ui-overview/issues-section/",
      "sections": [
        "CodeStream issues",
        "Connect your service to CodeStream",
        "Manage your issues"
      ],
      "published_at": "2021-12-19T14:05:25Z",
      "title": "CodeStream issues",
      "updated_at": "2021-11-13T21:10:47Z",
      "type": "docs",
      "external_id": "4c463e5a5ce0017a2496b90dd3f410cd711cef62",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream issues are where you'll see the issues from your external code-hosting or issue-tracking service. Connect your service to CodeStream If you're not already connected to an external service, this section lists all of the available, supported services: Asana Azure DevOps Bitbucket (cloud) Clubhouse GitHub (cloud or Enterprise) GitLab (cloud or Self-Managed) Jira (cloud or Server) Linear Trello YouTrack (cloud) Manage your issues Once youve connected to your teams issue-tracking or code-hosting services, all of the issues assigned to you are listed in the issues section. Your organization can use multiple external services at once. Select the one you want to use from the dropdown list. Click an issue to start working on it. You can create a feature branch, update the ticket status, and even update your status on Slack. Hover over an issue's row to see an option to view the issue on your issue-tracking service toward the end of the row. For many services you can also filter the list. For example, if youre connected to Trello, you can filter to see a specific list or set of lists. For Jira, Jira Server, GitHub, GitHub Enterprise, GitLab, and GitLab Self-managed you can even create custom filters. There are some special guidelines when creating a custom query for GitHub and GitHub Enterprise or for GitLab and GitLab Self-Managed. Hover over the section's heading for more options. Click the refresh button to update the list with any recently added tickets. Click New issue (although it may be labelled differently based on the selected service) to create a issue in your issue-tracking service right from CodeStream. You can even associate that ticket with a block of code in your editor. If you need to work on something that doesnt have an associated ticket, you can click Start Ad-hoc Work to get started without a ticket.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 497.34866,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> issues",
        "sections": "Connect <em>your</em> service to <em>CodeStream</em>",
        "body": " (cloud) Clubhouse <em>Git</em>Hub (cloud or Enterprise) <em>GitLab</em> (cloud or <em>Self</em>-<em>Managed</em>) Jira (cloud or Server) Linear Trello YouTrack (cloud) Manage <em>your</em> issues Once youve connected to <em>your</em> teams issue-tracking or <em>code</em>-hosting services, all of the issues assigned to you are listed in the issues section"
      },
      "id": "61743f8b64441f60375fdaf5"
    },
    {
      "image": "https://docs.newrelic.com/static/dd18b67123e9d4b7d40b56a8653a1f6b/f96db/OpenPullRequest1.png",
      "url": "https://docs.newrelic.com/docs/codestream/how-use-codestream/pull-requests/",
      "sections": [
        "Manage pull requests in CodeStream",
        "Pull request workflow",
        "Create a pull request",
        "Review a pull request",
        "Caution",
        "Leverage pull request comments"
      ],
      "published_at": "2021-12-21T01:41:29Z",
      "title": "Manage pull requests in CodeStream",
      "updated_at": "2021-11-13T21:14:26Z",
      "type": "docs",
      "external_id": "7e35f2ff4f06799fe492ffb6b2fedbb52e898b69",
      "document_type": "page",
      "popularity": 1,
      "body": "For most development teams, the final step in the development process is a pull request. Even if your team has decided to use New Relic CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, CodeStream allows you to keep all of that workflow inside your IDE. Pull request workflow There are four elements of CodeStream's pull request workflow. The following table outlines which code-hosting services are supported for each element. Feature Supported Services Create a pull request GitHub, GitHub Enterprise, GitLab, GitLab Self-Managed, Bitbucket, Bitbucket Server Create a pull request across forks GitHub, GitHub Enterprise, GitLab, GitLab Self-Managed Review and edit a pull request GitHub, GitHub Enterprise, GitLab, GitLab Self-Managed Display pull request comments as code annotations GitHub, GitLab, Bitbucket Create a pull request To open a pull request at any time, click the + button at the top of the CodeStream pane or the + button in the header of the Pull Requests section. You can also use a keyboard shortcut (ctlr+shift+/ p, ctrl+/ p on a Mac, and m if you're a GitLab user). CodeStream provides you with tree view, list view, and diff view options for reviewing your changes before opening the pull request. With a single click you can name the pull request based on the last commit message, the branch name, or, if you started work by selecting a ticket, the ticket title. If you have a ticket selected, you can also explicitly tie the ticket to the pull request and CodeStream will include a link to the ticket in the pull request's description. Before submitting the pull request, you can review your changes by clicking on any of the files listed below the form. To create a pull request across forks, click the compare across forks link at the top of the page and the form will update to allow you to select both the base and head repositories. You can also create a pull request from within a CodeStream feedback request. Once the feedback request has been approved, youll see an option to open a pull request at the top. Before you can create a pull request, make sure that any changes included in the feedback request have been committed and pushed. Also, if the feature branch youre working on doesnt have a remote tracking branch youll be given the option to set that as part of creating the pull request. When you create a pull request from a feedback request, CodeStream connects the dots between the two by adding a link to the pull request in the feedback request. Add a link to the feedback request, along with information about who did the review and when, in the description of the pull request. Review a pull request Caution The ability to review pull requests is currently not available for Bitbucket. Regardless of where the pull request was created, you can edit, review, and even merge it from within CodeStream. CodeStream brings GitHub and GitLab into your IDE, so there's zero learning curve. If you know how to work with pull requests on GitHub or GitLab, you'll know how to do it in CodeStream as well. You can edit a GitHub pull request's details, such as reviewers, assignees and labels. For a GitLab merge request, you can use edit mode (via the dropdown at the top of the page) or use the sidebar. By default, you can only add a single reviewer and a single assignee to a GitLab merge request. If your organization supports multiple reviewers and assignees, click the gear menu in the heading of the Merge Requests section of the CodeStream pane to enable this. Review the conversation and add comments with the ability to @mention your collaborators. View the changes, add comments, and submit a review. CodeStream does improve upon the GitHub/GitLab experience in a couple of important ways. On GitHub and GitLab you can only view the changes as a series of diff hunks. CodeStream provides that view as well, but if you'd prefer to see the changes in the context of the full file you can use either list view or tree view. Select the code you want to comment on and then click the Comment button (or select Comment from the context menu). When commenting, you can either add a single comment or start a review. With CodeStream, you can comment on lines of code that haven't changed. You can select any lines of code in the diff and not just those that are part of the changeset. These comments are added as a single comment to the pull request and aren't part of any review you may have in progress. All the power of GitHub pull requests and GitLab merge requests, and then some, right in your IDE. Leverage pull request comments Once the pull request has been approved and the code has been merged, that's usually the end of life for any comments in that pull request. Although there's often useful information in those comments that may have long-term value, they're rarely seen again. CodeStream gives those comments a second life by displaying them alongside the blocks of code that they refer to. To have pull request comments displayed as annotations in your codemarks, as well as in the Codemarks section of the CodeStream pane, click the gear icon in that section and check Show comments from pull requests. When you first check that box, if you havent already authenticated with your code-hosting service, youll be prompted to do so. Comments from merged PRs will appear next to the blocks of code they refer to. Comments from open PRs will also be included if you are on a relevant branch. For example, if the open PR is a request to merge the feature/some-name branch into main, youll see comments from that PR if you've checked out either feature/some-name or main, but not when youre on any other branch. As the code evolves, the location of each comment is automatically updated so that it remains linked to the block of code it refers to. PR comments for a given file are updated roughly every 30 minutes, so new comments may not appear right away. You can force an update by restarting your IDE.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 482.94287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> pull requests in <em>CodeStream</em>",
        "sections": "<em>Manage</em> pull requests in <em>CodeStream</em>",
        "body": " of that workflow inside <em>your</em> IDE. Pull request workflow There are four elements of <em>CodeStream</em>&#x27;s pull request workflow. The following table outlines which <em>code</em>-hosting services are supported for each element. Feature Supported Services Create a pull request <em>Git</em>Hub, <em>Git</em>Hub Enterprise, <em>GitLab</em>, <em>GitLab</em> <em>Self</em>"
      },
      "id": "61744006196a67ee542f0555"
    },
    {
      "image": "https://docs.newrelic.com/static/8945e0a9c512b8638ebf8165d47aee04/69902/QS-SignUp3.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-user-guide/",
      "sections": [
        "New Relic CodeStream user guide",
        "Jump to a topic",
        "1. Install the CodeStream extension in your IDE and sign up.",
        "2. Connect your tools",
        "3. Discuss any block of code, at any time",
        "4. Get feedback on your work in progress",
        "5. Create or review a pull request",
        "Help and feedback"
      ],
      "published_at": "2021-12-19T15:16:39Z",
      "title": "New Relic CodeStream user guide",
      "updated_at": "2021-11-24T04:44:31Z",
      "type": "docs",
      "external_id": "fa9af0118a8872fea89fda91482c44fb69913ea2",
      "document_type": "page",
      "popularity": 1,
      "body": "Jump to a topic Use the navigation on the left to jump straight to any topic. Otherwise, read on to get started with New Relic CodeStream. If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. 1. Install the CodeStream extension in your IDE and sign up. Install CodeStream for VS Code, Visual Studio or JetBrains. The CodeStream pane automatically appears in the sidebar for VS Code or in a tool window at the right side for JetBrains or Visual Studio. Click Sign Up and Create a team if you're the first person from your team to join CodeStream or paste in your invitation code if you were invited to a team already on CodeStream. Learn more about how to use CodeStream. 2. Connect your tools Create and review pull requests on GitHub, GitLab or Bitbucket. Create issues on Jira, Trello, and other issue trackers. Share code discussions on Slack or Microsoft Teams. CodeStream brings the tools you use every day together in your IDE. Click on your headshot at the top of the CodeStream pane and go to the Integrations page to get all of your tools connected. 3. Discuss any block of code, at any time Whether you're trying to understand someone else's code or getting help with some code you just wrote, just select the code and ask your question. Learn more about discussing code. 4. Get feedback on your work in progress Select Request Feedback from the + menu at any time in the development cycle, whether its a quick look over some work in progress (even uncommitted code!) or a formal review of a completed effort. Teammates can review your changes right in their IDE, with no need to switch branches or set aside their own work. Learn more about feedback requests. 5. Create or review a pull request Look for the Pull Requests section of the CodeStream sidebar to review an open pull request. Just click on a pull request (or load one from URL) to get a complete GitHub experience right in your IDE! Note that you can create a pull request in GitHub, GitLab or Bitbucket, but support for reviewing pull requests is currently only available for GitHub (cloud or Enterprise). Learn more about pull requests. Help and feedback Report a bug or suggest an improvement in GitHub issues. Contact us directly at support@codestream.com. Follow @teamcodestream for product updates and to share feedback and questions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 406.0692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>CodeStream</em> user guide",
        "sections": "1. Install <em>the</em> <em>CodeStream</em> extension in <em>your</em> IDE and sign up.",
        "body": " <em>CodeStream</em> or paste in <em>your</em> invitation <em>code</em> if you were invited to a team already on <em>CodeStream</em>. Learn more about how to use <em>CodeStream</em>. 2. Connect <em>your</em> tools Create and review pull requests on <em>Git</em>Hub, <em>GitLab</em> or Bitbucket. Create issues on Jira, Trello, and other issue trackers. Share <em>code</em>"
      },
      "id": "61744137e7b9d2428b13c6a0"
    }
  ],
  "/docs/codestream/troubleshooting/jira-server-integration": [
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-20T01:42:42Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 291.29724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Optional: Integrate Errors Inbox with Slack, <em>Jira</em>, and <em>CodeStream</em>",
        "body": " Being able to view resolved and ignored errors is useful, but you&#x27;re trying to squash the bugs in your application before you deploy it to production. To help you manage this, <em>connect</em> your inbox to Slack, <em>Jira</em>, and <em>CodeStream</em>. Summary In this lab, you set up Errors Inbox to proactively observe"
      },
      "id": "61be8f01196a67e048eef29c"
    },
    {
      "image": "https://docs.newrelic.com/static/89fc796cef01d95170eace2254590fbe/1efb2/connect-repo1.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-new-relic/",
      "sections": [
        "CodeStream and New Relic One",
        "Preview release",
        "Connect CodeStream and New Relic",
        "Caution",
        "See your errors and what's causing them",
        "Tip",
        "How to go from errors inbox to your IDE",
        "APM errors and CodeStream",
        "Associate repositories with errors",
        "Use environment variable with APM (recommended)",
        "Use the UI",
        "Use the NerdGraph API",
        "Associate build SHAs or release tags with errors",
        "Install APM agents with CodeStream",
        "Dynamic logging with Go and Pixie"
      ],
      "published_at": "2021-12-19T14:37:10Z",
      "title": "CodeStream and New Relic One",
      "updated_at": "2021-12-14T23:24:49Z",
      "type": "docs",
      "external_id": "a6c04d95011d9150cb0798580c15695bb9f3bbda",
      "document_type": "page",
      "popularity": 1,
      "body": "CodeStream and New Relic One work together to give you insight into your code's errors, as well as making it easier to get started instrumenting your code with our APM agents. With CodeStream connected to New Relic One, you can jump from a stack trace error directly to the offending line of code in your IDE. Once in your IDE, you can navigate the stack trace and collaborate with your teammates to resolve the issue. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Connect CodeStream and New Relic Before you can take advantage of New Relic's observability features in CodeStream, you'll need to connect them. Requirements for connecting CodeStream and New Relic: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key If you don't have a user key or want to learn more about how you can use and manage them, see our doc on the New Relic user key. Once you have your New Relic user key, in CodeStream's Observability section click Connect to New Relic One, then paste your API key and click Connect to New Relic One. Caution New Relic users can share stacktrace errors on CodeStream. Once you've connected CodeStream to New Relic, any new users you add to your CodeStream organization can see those errors. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Requirements for opening stack trace errors in your IDE: New Relic account (If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever!) New Relic user key CodeStream and New Relic connection Data being reported to New Relic via APM monitoring A workload for errors inbox An error For APM errors, your repository's commit hash and release tag New Relic errors inbox is a single place to proactively detect, prioritize, and take action on your errors before they impact customers. With CodeStream, you can jump from an error directly to the offending code in your IDE. Tip Limited to APM errors. How to go from errors inbox to your IDE From one.newrelic.com/, go to Errors Inbox, click a stack trace error, then click Open in IDE. APM errors and CodeStream In order to view stack trace errors in your IDE, CodeStream needs to know what repository the error is associated with and, ideally, which version of the code generated the error. Associate repositories with errors Once you've started monitoring for APM, mobile, browser, or Lambda, you should create repository entities and associate them with entities for all of your services. In order to create a repository entity you'll need to provide the repository's remote URL. For example, the remote URL can be in either the SSH or HTTPS format: git@github.com:newrelic/beta-docs-site.git https://github.com/newrelic/beta-docs-site.git Caution It's possible to add the same GitHub repository more than once, if you're using different protocols to do so. The UI warns you about this, but won't prevent you from doing so. For example, https://github.com/tuna/repo and git@github.com:tuna/repo are the same repo, with different protocols. If you try to open an error in your IDE and there isn't an associated repository, CodeStream will prompt you to make an association and save that association for all errors from the given entity on New Relic. However, it would be preferably to use one of the following methods since they require less ongoing manual effort and eliminate the possibility of end-user mistakes, such as misconfigured remote URLs. Use environment variable with APM (recommended) Set the environment variable NEW_RELIC_METADATA_REPOSITORY_URL. New Relic APM agents create the repository entity and associate it to your application entity automatically. This requires the SSH or HTTPS URL format. We recommend that these be set as part of your build pipeline. Use the UI Once you've started sending data to New Relic, use the UI to connect your related repository. Go to the APM Summary page via one.newrelic.com > Explorer > Services - APM > (select an app), then look for the Repositories section at the bottom-right. Click Connect repository to find an existing repository or add a new one. Use the NerdGraph API Use New Relic's NerdGraph APIsto create a repository and associate it with your application entities. Step 1: Create a repository entity To create a repository entity, use the referenceEntityCreateOrUpdateRepository API and make sure to save the GUID that's produced. The API takes the following parameters: accountId - the integer account ID for the account you want to add the repository to url - example https://github.com/newrelic/beta-docs-site.git name - example: newrelic/beta-docs-site mutation { referenceEntityCreateOrUpdateRepository(repositories: [{accountId: [YOUR_ACCOUNT_ID], name: \"[REPO_NAME]\", url: \"[REPO_URL]\"}]) { created failures { guid message type } } } Copy In order to find the entity you create, you can use a query like the following. Note that the URL you provided to referenceEntityCreateOrUpdateRepository gets saved as an entity tag. { actor { entitySearch(query: \"name = 'a name' OR tags.url = 'a url'\") { count query results { entities { guid name tags { key values } } } } } } Copy Step 2: Associate the repository entity to your application entity First, find the GUID for the application you want to associate your repository to. Parameters: sourceEntityGuid - the entity GUID of the application targetEntityGuid - the entity GUID of your repository type - always BUILT_FROM mutation { entityRelationshipUserDefinedCreateOrReplace(sourceEntityGuid: \"\", targetEntityGuid: \"\", type: BUILT_FROM) { errors { message type } } } Copy To see all entities related to your repository you can do a query like this: { actor { entity(guid: \"[YOUR_REPOSITORY_GUID]]\") { relatedEntities(filter: {direction: BOTH, relationshipTypes: {include: BUILT_FROM}}) { results { target { entity { name guid type } } type } } name type tags { values key } } } } Copy Step 3: Cleanup (if needed) Delete a repository with the following query: mutation DeleteRepository { entityDelete(guids: \"[ENTITY_GUID_HERE]]\") { deletedEntities failures { message guid } } } Copy Associate build SHAs or release tags with errors To use CodeStream's Open in IDE with your APM stack trace errors, use environment variables to configure your APM agent with your application's commit sha and/or your release tag associated with the running version of your software. CodeStream only needs the first seven characters of your commit sha (for example, 734713b) to make this connection, but you can include the entire sha. Alternately, you can use a release tag (such as v0.1.209 or release-209) for CodeStream to find the correct version of your code. For New Relic APM, the commit and/or release tag (tags.commit and tags.releaseTag) are added as attributes on Transaction and TransactionError events. You can use APM environment variables to set these attributes. We recommend setting one or both of these variables as part of your build pipeline. NEW_RELIC_METADATA_COMMIT - The commit sha. You can include the whole thing or only the first seven characters. NEW_RELIC_METADATA_RELEASE_TAG - A release tag (such as v0.1.209 or release-209). This has the advantage of being human readable. For more on how to set these variables, here are specific configuration details for each language: Go Java .NET Node.js PHP Python Install APM agents with CodeStream Requirements for installing New Relic APM agents via CodeStream: New Relic account New Relic user key CodeStream and New Relic connection A supported language application codebase .NET Core Java Node.JS When you first connect CodeStream to New Relic, if you're working on an application's codebase that's not being monitored by New Relic, CodeStream will offer to instrument that application for you. Like New Relic's guided install, CodeStream will walk you through and automate all of the steps to installing the APM agent to start sending data to New Relic. This check only happens automatically when the initial connection is made. To do so later, in the CodeStream extension, click your username, then click New Relic Setup. Dynamic logging with Go and Pixie New Relic account New Relic user API key CodeStream and New Relic connection A Kubernetes cluster monitored by Pixie An application written in Go You can use CodeStream to enable dynamic logging for your Pixie-monitored Go applications. Just right-click on any method name and select Dynamic Logging Using Pixie.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.44234,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> and New Relic One",
        "sections": "<em>Connect</em> <em>CodeStream</em> and New Relic",
        "body": " key <em>CodeStream</em> and New Relic <em>connection</em> A supported language application codebase .NET Core Java Node.JS When you first <em>connect</em> <em>CodeStream</em> to New Relic, if you&#x27;re working on an application&#x27;s codebase that&#x27;s not being monitored by New Relic, <em>CodeStream</em> will offer to instrument that application"
      },
      "id": "6171e652196a67e9c92f0156"
    },
    {
      "sections": [
        "Alerts and applied intelligence notification integrations",
        "Early access",
        "Integration details",
        "Atlassian Jira",
        "Permissions",
        "Set up a Jira destination",
        "Important",
        "Two-way sync",
        "Configure the message template",
        "Send a test notification",
        "ServiceNow (Incident-Management)",
        "Roles",
        "Set up a destination",
        "Slack",
        "Prerequisites",
        "Set up a Slack destination",
        "Configure the Slack message settings",
        "Webhook",
        "Set up a webhook destination",
        "Configure the webhook event template",
        "Customize the webhook payload",
        "Email",
        "Configure the email settings"
      ],
      "title": "Alerts and applied intelligence notification integrations",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident Intelligence",
        "Destinations"
      ],
      "external_id": "7220c630fc187bb61784ff2cc2213e588b269b00",
      "image": "https://docs.newrelic.com/static/d4e9baecc3a76dd1a5945f8ec0aeca66/c1b63/webhook-notification-template.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/notification-integrations/",
      "published_at": "2021-12-19T15:28:40Z",
      "updated_at": "2021-12-19T15:28:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Alerts and Applied Intelligence notification integrations are specific services and platforms you can use to send notifications from New Relic. Integration details Read more about each of our specific notification integrations. Atlassian Jira Integrate New Relic with Atlassian Jira(Cloud) and automatically create and update Jira issues. Permissions The required permissions from the Jira API-Token are create, edit, and close tickets. To enable the two-way sync toggle, the provided Jira API-Key should have an Admin role. Set up a Jira destination Create Jira issues, then enable Jira and New Relic to share updates and stay synced. To create a Jira destination, enter the following information: Destination name: Custom name to identify the destination Jira account endpoint: the URL of the destination User-name: this will be the email address of the user making the connection API token: generated from your Atlassian account Important New Relic currently supports Atlassian-Jira Classic (company-managed) projects. Before saving the destination, we recommend you test the connection via the test connection button. Jira destination configuration. We recommand to test the connection before saving. Two-way sync You can enable a two-way integration with Jira to keep the issues' state synced with the corresponding state in New Relic. To enable two-way sync, turn on the two-way integration toggle. When turned on, a Jira Webhook would be created in your Jira account at a later stage, for the selected project (see customize a message template). The webhook would contain access details to Newrelic (URL and Newrelic-API-KEY) Configure the message template To configure a template for a Jira issue, you first need to choose a destination. You will be able to create a new destination at this stage. Upon successful connection to the destination, you will need to choose a project, and then select the Jira issue type you would like to be used. Once the issue-type is selected, the configured project's fields are fetched from your account and automatically mapped to your Jira instance. To help you get started, we automatically present the required and recommended fields and values. Required fields must be set with a value. You can add or remove optional fields(use the X mark on their right side) Jira message template. Send a test notification You can see how the JIRA issue will appear by clicking a test notification with default field values. If successful, a JIRA issue will be created and a link will appear. ServiceNow (Incident-Management) Integrate New Relic with ServiceNow Incident-Management and automatically create and update incidents. Roles As part of the integrations, we fetch fields from the your serviceNow incident table and optional values. For this, the provided ServiceNow user details required read permissions for the tables: sys_dictionary, sys_choice, sys_user and task. A read/write permission to incident To be able to fetch users for the caller column, we required read permissions for the sys_users table. The above permissions can be achieved with the roles personalize_choices, personalize_dictionary, rest_service, itil. Read/Write permissions to the api_key_credentials table is required to enable two-way integration. This can be covered with the roles credentials_admin and discovery_admin. Set up a destination To create a ServiceNow destination, enter the following information: Destination Name: custom name to identify the destination Domain: the URL of the destination User-name: the name of the user Password: the user names password Before saving the destination, we recommend testing the connection by clicking the test connection button. Two-way sync You can configure a two-way integration with ServiceNow Incidents Management to keep the incidents' state synced with the corresponding state in New Relic. Here are some required steps to remember when configuring the two-way integration: Turn on the two-way integration toggle. Open and download this XML file, which includes the business rule triggering events back to New Relic One. In the ServiceNow sidebar menu, go to System Definition > Business Rules. Click the menu icon in one of the column headers, select Import XML and upload the XML file you downloaded. Once the Destination is saved, a New-Relic API-Key will be kept in the api_key_credentials. The key would sent in a header as part of the callback REST call to New-Relic Configure the message template Upon a successful connection, ServiceNow incident table columns are fetched from your account and automatically mapped to your ServiceNow instance. To help you get started, we automatically present the required and recommended fields and values. Required fields must be set with a value. You can add or remove optional fields(use the X mark on their right side) Select, edit or remove fields for the ServiceNow-Incident template. Send a test notification You can see how the ServiceNow incident will appear by clicking a test notification with default field values. If successful, an incident will be created and a link will appear. Slack Send notifications-messages to your Slack channels. Prerequisites Your Slack workspace needs to have the New Relic application installed. The application must be approved by a workspace admin before it can be individually installed by users Set up a Slack destination Click on the `one-click Slack authentication' will lead you to the Slack landing page to continue the OAuth2 authentication process. On the Slack landing page, if you're not signed into the required workspace, you're redirected to Slack to sign in. Add your workspace name or select the relevant workspace and click Continue. When signed in to the selected workspace, you are requested to allow New Relic to perform the specified actions. Clicking `Allow' will redirect you back to the Destination page. Configure the Slack message settings Select a Destination(Workspace) and select a Slack-channel where the messages will be sent. You can create a new destination if there is no pre-defined destination for the required workspace. Note that, for privacy reasons, users need to be authenticated to select private channels (one-time process) Send a test notification You can send a test notification with a pre-defined example payload to the channel. This creates a message in the selected Slack-channel. Webhook Use the webhook notifier to send the notification messages to any endpoint you like. Set up a webhook destination To create a webhook destination, you need the following: Destination Name: A unique destination name URL: the endpoint of the target application, authentication and custom headers if needed. Authorization mechanism (Optional):. Can be basic authentication or a bearer token Configure the webhook event template Pick a webhook destination from the list and configure the HTTP-POST request. The request configuration requires you to: Set a name for the template. Select a pre-configured destination from the destinations list or create a new one. Add custom headers (optional). Configure the requests payload. Customize the webhook payload You can use the default payload or customize it to contain the required data. Pick Variables from the variables menu and apply handlebars syntax to enrich your webhook. Note that the requests content-type is JSON by default. Hence, the payload needs to keep the JSON form. See Usage examples The preview section on the right hand-side shows an expected payload after the template is rendered. If the eventual payload would not form a valid Json, an error will be shown and it wont be possible to save the template. If the webhook payload conforms a valid Json, you can send a test notification to your defined webhook destination We recommend sending a test notification to make sure that everything's connected correctly. Email Send email notifications to users. Configure the email settings Add one or more recipients. Users with New Relic accounts can be found via autocomplete when searching for their name or email address. To add a user without a New Relic account or email distribution list, add the full email address. Every recipient will be translated into a 'destination'. You can follow the email notifications per destination in the notifications-log Send a test notification You can send a test notification to make sure the email notifications reach the inbox.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.60324,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Configure</em> <em>the</em> message template",
        "body": " and New Relic to share updates and stay synced. To create a <em>Jira</em> destination, enter the following information: Destination name: Custom name to identify the destination <em>Jira</em> account endpoint: the URL of the destination User-name: this will be the email address of the user making the <em>connection</em> API"
      },
      "id": "618ff71628ccbc60710321e4"
    }
  ],
  "/docs/codestream/troubleshooting/jira-server-version": [
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-20T01:42:42Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 307.17575,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> triaged errors",
        "sections": "Optional: Integrate Errors Inbox with Slack, <em>Jira</em>, and <em>CodeStream</em>",
        "info": "Managed <em>your</em> triaged errors in Errors Inbox",
        "body": " pika.exceptions:ChannelWrongStateError, you don&#x27;t see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe <em>your</em> ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, <em>Jira</em>, and <em>CodeStream</em>"
      },
      "id": "61be8f01196a67e048eef29c"
    },
    {
      "image": "https://docs.newrelic.com/static/13641ba13c10755096fdee8f67741a02/f96db/ConfigureJiraServer1.png",
      "url": "https://docs.newrelic.com/docs/codestream/troubleshooting/jira-server-integration/",
      "sections": [
        "Configure the Jira Server CodeStream connection",
        "Caution",
        "Generate a public/private key pair",
        "Create an application link",
        "Set up the integration in CodeStream"
      ],
      "published_at": "2021-12-19T17:22:46Z",
      "title": "Configure the Jira Server CodeStream connection",
      "updated_at": "2021-11-13T21:23:33Z",
      "type": "docs",
      "external_id": "fa12660611b9120e3aace8e1abdfb74ff89d82be",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Recent versions of Jira Server (8.14.0 or higher) support the use of API Tokens to access the Jira Server REST API. We recommend you use API Tokens if possible to avoid the more complicated setup described here. Check your Jira Server version. You must be a Jira administrator in order to configure this integration. To determine if you have the proper permissions in order to proceed, look for the Jira settings menu (cog icon, most likely at the top-right, next to your profile and settings menu icon) and make sure there's an Applications option there. If you don't have the Settings menu, or the Applications option, then you won't be able to configure the integration. This integration requires that your Jira Server instance be at a publicly accessible URL. New Relic CodeStream can integrate with Jira Server using Atlassians published REST API. To enable CodeStream to integrate with your Jira Server installation, set up a CodeStream application link. This application link serves as a conduit for users to authenticate against their Jira Server account without ever having to enter their credentials in CodeStream. Jira Server uses the OAuth standard (version 1.0a) for client authorization. For reference, See Atlassian's documentation. However, you don't need to follow the full instructions on that page. The relevant instructions are duplicated and simplified here for clarity. You'll need the openssl command-line tool to generate a public/private key pair for use with the application link. Generate a public/private key pair In a terminal, use openssl to generate your public/private key pair, using these steps: Generate a 1024-bit private key: openssl genrsa -out jira_privatekey.pem 1024 Copy Create an X509 certificate: openssl req -newkey rsa:1024 -x509 -key jira_privatekey.pem -out jira_publickey.cer -days 365 Copy Enter whatever information you see fit to accompany the certificate. Extract the private key (PKCS8 format) to the jira_privatekey.pcks8 file: openssl pkcs8 -topk8 -nocrypt -in jira_privatekey.pem -out jira_privatekey.pcks8 Copy Extract the public key from the certificate to the jira_publickey.pem file: openssl x509 -pubkey -noout -in jira_publickey.cer > jira_publickey.pem Copy Create an application link Follow these steps to create your application link within Jira Server. In Jira, navigate to Jira settings (gear icon in upper-right), click Applications. Enter your administrator password, if needed. Then select Application links under Integrations, in the left sidebar. Where it says Enter the URL of the application you want to link, enter any URL you want, for example, http://example.com/. Then click Create new link. You will likely see a warning starting with: No response was received from the URL you entered. You can ignore the warning; click Continue. Fill out the form as you see here, or as you like. None of the data entered here really matters, except to make sure that Create incoming link is checked. The Application Name can be whatever name works best for you to identify the link. Then click Continue. On the next dialog, enter any unique string you want for the Consumer Key. It does not need to be secure or encoded, just something fairly easy to remember. Make a note of what you enter here; it will be needed when you go to set up the integration with Jira Server from CodeStream. For Consumer Name, you can enter anything meaningful to you, like \"CodeStream app\". The important field to fill out correctly is Public Key. Copy the full text of the contents of the jira_publickey.pem file you created in Step #1. Paste this into the Public Key field, then click Continue. The application link you created should now show like this: Set up the integration in CodeStream Now you're ready to set up the integration from CodeStream to Jira Server for your team, using the application link you created. Assuming you have signed up for CodeStream and have the extension open in your IDE: In CodeStream, go to the Integrations panel by clicking the menu next to your username in the top-left. Then click Jira Server under Issue Providers. Since you won't be using API Tokens with your Jira Server integration, click at the top where it says Click here if your organization uses a version of Jira Server older than... to configure Jira Server using the OAuth method described herein. Fill out the form: For Jira Server Base URL, enter the URL used to access your Jira Server installation as known to your internal network, in the form http(s)://host:port. For Consumer Key, use the consumer key you entered when created the application link, from Step #2, above. Then copy the full contents of the private key, in PCKS8 format, that you created in Step #1 above. The file should be called jira_privatekey.pcks8. Paste those contents into the Private Key field, then click Submit. You'll then be taken to your Jira Server instance, where you'll approve access to your account using the application link. When you are finished, return to your IDE and you should see something similar to this: Now that the integration has been set up for your organization, other users will NOT have to go through the process described above. Other users in your organization will see the integration with your Jira Server (specified by host) alongside other available integrations. Initiating this integration will only require your other users to allow the CodeStream application link to access their account, as you did in the final step.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.43604,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>Jira</em> <em>Server</em> <em>CodeStream</em> connection",
        "sections": "Configure the <em>Jira</em> <em>Server</em> <em>CodeStream</em> connection",
        "body": " with <em>your</em> <em>Jira</em> <em>Server</em> installation, set up a <em>CodeStream</em> application link. This application link serves as a conduit for users to authenticate against their <em>Jira</em> <em>Server</em> account without ever having to enter their credentials in <em>CodeStream</em>. <em>Jira</em> <em>Server</em> uses the OAuth standard (<em>version</em> 1.0a) for client"
      },
      "id": "617441f964441fa1775fe265"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/",
      "sections": [
        "Resolve Errors Faster with Full Stack Error Tracking",
        "Important",
        "Learning Objectives",
        "Requirements",
        "Procedures",
        "1. Spin up your application",
        "2. Set up Errors Inbox",
        "3. Triage your errors",
        "4. Manage your triaged errors"
      ],
      "published_at": "2021-12-20T01:49:34Z",
      "title": "Resolve Errors Faster with Full Stack Error Tracking",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "a96d1a5e8ac7b53af9924ab519c673f316780d13",
      "document_type": "page",
      "popularity": 1,
      "info": "Use New Relic to qucikly track errors in your application with the help of Errors Inbox.",
      "body": "You're one of the developers of an eCommerce website called Geek's Movie Shop, and recently, you introduced some new features. Before you push your changes to production where all your users will have access to them, you want to discover as many errors as you can in your development environment. Then you can decide which ones to fix and which ones to ignore. Errors Inbox is the perfect tool to help you do this. Important Errors Inbox is not available in the EU region. Learning Objectives In this lab, you: Spin up Geek's Movie Shop in your development environment Set up a workload for Errors Inbox Resolve and ignore errors in your inbox Assign unresolved errors Filter errors in your inbox by status Integrate Errors Inbox with Jira, CodeStream, or Slack Requirements Create a free New Relic account in the US region Install Docker Procedures 1. Spin up your application Set up your your environment to deploy Geek's Movie Shop. 5 min 2. Set up Errors Inbox Set up Errors Inbox in New Relic 5 min 3. Triage your errors Track and triage errors across your stack with Errors Inbox 5 min 4. Manage your triaged errors Managed your triaged errors in Errors Inbox 5 min",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.1207,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "1. Spin up <em>your</em> application",
        "info": "Use New Relic to qucikly track errors in <em>your</em> application with the help of Errors Inbox.",
        "body": " Inbox Resolve and ignore errors in <em>your</em> inbox Assign unresolved errors Filter errors in <em>your</em> inbox by status Integrate Errors Inbox with <em>Jira</em>, <em>CodeStream</em>, or Slack Requirements Create a free New Relic account in the US region Install Docker Procedures 1. Spin up <em>your</em> application Set up <em>your</em> <em>your</em>"
      },
      "id": "61be8f0128ccbce013e53496"
    }
  ],
  "/docs/codestream/troubleshooting/keychain-issues": [
    {
      "image": "https://docs.newrelic.com/static/5c1d085b14abf961ca66b96285f0c0fa/69902/QS-Integrations.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/install-codestream/",
      "sections": [
        "Install New Relic CodeStream",
        "Install CodeStream",
        "Instant Observability (I/O) quickstart",
        "Visual Studio Code",
        "Visual Studio",
        "JetBrains",
        "Connect your tools",
        "Tip",
        "Discuss any block of code, at any time",
        "Get feedback on your work in progress",
        "Create or review a pull request",
        "Help and feedback"
      ],
      "published_at": "2021-12-19T14:27:50Z",
      "title": "Install New Relic CodeStream",
      "updated_at": "2021-11-24T09:39:10Z",
      "type": "docs",
      "external_id": "5d431c8f9a2690b64d26ac9fc173b18085153aac",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that makes it easy to discuss and review code in a more natural and contextual way. Once connected to New Relic, collaborate on your application errors directly in your IDE. If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Install CodeStream You can install CodeStream for your specific IDE or install it through our Instant Observability (I/O) quickstart. Instant Observability (I/O) quickstart Install CodeStream with its Instant Observability (I/O) quickstart to connect CodeStream to your New Relic account via your user key. Visual Studio Code Download and install CodeStream for Visual Studio Code. You can also install it directly in Visual Studio Code via the extensions marketplace. Visual Studio Download and install CodeStream for Visual Studio. You can also install it directly in Visual Studio via the extensions marketplace. JetBrains Download and install CodeStream for JetBrains. You can also install it from the JetBrains plugins menu. Connect your tools Create and review pull requests on GitHub, GitLab, or Bitbucket. Create issues on Jira, Trello, and other issue trackers. Investigate errors reported to New Relic One. Share code discussions on Slack or Microsoft Teams. CodeStream brings the tools you use every day together in your IDE. Click your headshot at the top of the CodeStream pane, then click Integrations to connect all of your tools to CodeStream. Tip Once you've installed CodeStream, to connect to New Relic, you'll need your New Relic user key. Go here to learn more about finding or creating your user key. Discuss any block of code, at any time Whether you're trying to understand someone else's code or getting help with some code you just wrote, select the code and click the comment button to ask your question. Learn more about discussing code. Get feedback on your work in progress Click the + menu then click Request Feedback at any time in the development cycle, whether its a quick look over some work in progress (even uncommitted code) or a formal review of a completed effort. Teammates can review your changes right in their IDE, with no need to switch branches or set aside their own work. Learn more about feedback requests. Create or review a pull request In the CodeStream sidebar, look for the Pull Requests section to review an open pull request. Select a pull request (or load one from URL) to get a complete GitHub experience right in your IDE. You can create a pull request in GitHub, GitLab, or Bitbucket, but support for reviewing pull requests is currently only available for GitHub. Learn more about pull requests. Help and feedback Report a bug or suggest an improvement in GitHub issues. Contact us directly at support@codestream.com. Follow @teamcodestream for product updates and to share feedback and questions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 558.6209,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> New Relic <em>CodeStream</em>",
        "sections": "<em>Install</em> New Relic <em>CodeStream</em>",
        "body": " install it directly in Visual Studio via the extensions marketplace. <em>JetBrains</em> Download and install <em>CodeStream</em> for <em>JetBrains</em>. You can also install it from the <em>JetBrains</em> plugins menu. Connect your tools Create and review pull requests on GitHub, GitLab, or Bitbucket. Create issues on Jira, Trello"
      },
      "id": "6174400564441ff1025fd832"
    },
    {
      "image": "https://docs.newrelic.com/static/8945e0a9c512b8638ebf8165d47aee04/69902/QS-SignUp3.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/codestream-user-guide/",
      "sections": [
        "New Relic CodeStream user guide",
        "Jump to a topic",
        "1. Install the CodeStream extension in your IDE and sign up.",
        "2. Connect your tools",
        "3. Discuss any block of code, at any time",
        "4. Get feedback on your work in progress",
        "5. Create or review a pull request",
        "Help and feedback"
      ],
      "published_at": "2021-12-19T15:16:39Z",
      "title": "New Relic CodeStream user guide",
      "updated_at": "2021-11-24T04:44:31Z",
      "type": "docs",
      "external_id": "fa9af0118a8872fea89fda91482c44fb69913ea2",
      "document_type": "page",
      "popularity": 1,
      "body": "Jump to a topic Use the navigation on the left to jump straight to any topic. Otherwise, read on to get started with New Relic CodeStream. If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. 1. Install the CodeStream extension in your IDE and sign up. Install CodeStream for VS Code, Visual Studio or JetBrains. The CodeStream pane automatically appears in the sidebar for VS Code or in a tool window at the right side for JetBrains or Visual Studio. Click Sign Up and Create a team if you're the first person from your team to join CodeStream or paste in your invitation code if you were invited to a team already on CodeStream. Learn more about how to use CodeStream. 2. Connect your tools Create and review pull requests on GitHub, GitLab or Bitbucket. Create issues on Jira, Trello, and other issue trackers. Share code discussions on Slack or Microsoft Teams. CodeStream brings the tools you use every day together in your IDE. Click on your headshot at the top of the CodeStream pane and go to the Integrations page to get all of your tools connected. 3. Discuss any block of code, at any time Whether you're trying to understand someone else's code or getting help with some code you just wrote, just select the code and ask your question. Learn more about discussing code. 4. Get feedback on your work in progress Select Request Feedback from the + menu at any time in the development cycle, whether its a quick look over some work in progress (even uncommitted code!) or a formal review of a completed effort. Teammates can review your changes right in their IDE, with no need to switch branches or set aside their own work. Learn more about feedback requests. 5. Create or review a pull request Look for the Pull Requests section of the CodeStream sidebar to review an open pull request. Just click on a pull request (or load one from URL) to get a complete GitHub experience right in your IDE! Note that you can create a pull request in GitHub, GitLab or Bitbucket, but support for reviewing pull requests is currently only available for GitHub (cloud or Enterprise). Learn more about pull requests. Help and feedback Report a bug or suggest an improvement in GitHub issues. Contact us directly at support@codestream.com. Follow @teamcodestream for product updates and to share feedback and questions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 546.9439,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>CodeStream</em> user guide",
        "sections": "1. <em>Install</em> the <em>CodeStream</em> extension <em>in</em> your <em>IDE</em> and <em>sign</em> up.",
        "body": " in your <em>IDE</em> and <em>sign</em> up. Install <em>CodeStream</em> for VS <em>Code</em>, Visual Studio or <em>JetBrains</em>. The <em>CodeStream</em> pane automatically appears in the sidebar for VS <em>Code</em> or in a tool window at the right side for <em>JetBrains</em> or Visual Studio. Click <em>Sign</em> Up and Create a team if you&#x27;re the first person from your team to join"
      },
      "id": "61744137e7b9d2428b13c6a0"
    },
    {
      "image": "https://docs.newrelic.com/static/ec73595e0bcde8b47ae3040cc556ddd1/f96db/NotificationSettings4.png",
      "url": "https://docs.newrelic.com/docs/codestream/codestream-integrations/notifications/",
      "sections": [
        "CodeStream notifications",
        "Notification settings",
        "Follow or unfollow",
        "Desktop notifications",
        "Other notifications"
      ],
      "published_at": "2021-12-19T17:22:46Z",
      "title": "CodeStream notifications",
      "updated_at": "2021-11-13T21:01:16Z",
      "type": "docs",
      "external_id": "0af3b7458032e1b89f8e3cc7225d7c7b0272354a",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream will notify you about comments, issues, and feedback requests that you follow, and you can choose whether you want to be notified via email, desktop (for the VS Code and JetBrains extensions only), or both. Look for the notifications option under your user profile menu at the top of the CodeStream pane. Notification settings By default, you're set to automatically follow any comment, issue, or feedback request that you created, where youve been mentioned (either in the original post or in a subsequent reply), or to which youve replied. You can always choose to follow or unfollow any individual comment, issue, or feedback request via its ellipses menu. Follow or unfollow Email notifications are sent immediately. You can participate in the discussion by replying to the email. Your reply will get added to CodeStream as a reply to the appropriate comment, issue, or feedback request. Be sure that when you reply you're doing so from the same email address where the notification was sent (that is, your email address listed in My Organization on CodeStream). You can unfollow a codemark or code review by clicking the link at the bottom of the email. Desktop notifications If youre using CodeStream in VS Code or a JetBrains IDE you can also receive desktop notifications in the IDE for comment, issue, or feedback requests that you follow. Click the Open button to open the discussion so that you can participate. Other notifications CodeStream offers the following notifications that can be turned on and off via the checkboxes at the bottom of the page. Notify me about outstanding feedback requests: Get an email reminder about open feedback requests assigned to you that you haven't responded to in the last 24 hours. Notify me about new unreviewed commits from teammates when I pull: Any time you pull, if there are new commits from a teammate on the current branch you'll get a toast notification. Click the Review button to start reviewing your teammate's changes and provide feedback. Send me weekly emails summarizing my activity: Sent every Monday with information about you and your organization's activity for the previous week. If you've connected to GitHub or GitHub Enterprise to leverage CodeStream's pull request integration, you'll also be notified when a pull request is assigned to you or you are added as a reviewer. Click the Open button to open the pull request right in your IDE where you can review the changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 498.25476,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> notifications",
        "sections": "<em>CodeStream</em> notifications",
        "body": " notifications If youre using <em>CodeStream</em> in VS <em>Code</em> or a <em>JetBrains</em> <em>IDE</em> you can also receive desktop notifications in the <em>IDE</em> for comment, issue, or feedback requests that you follow. Click the Open button to open the discussion so that you can participate. Other notifications <em>CodeStream</em> offers the following"
      },
      "id": "6174407564441f5c515fcf66"
    }
  ],
  "/docs/codestream/troubleshooting/proxy-support": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-12-20T03:01:13Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.5112,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CodeStream</em> licenses",
        "sections": "<em>CodeStream</em> licenses",
        "tags": "<em>CodeStream</em>",
        "body": "We love open-source software, and we use the following with <em>CodeStream</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. <em>CodeStream</em> license on GitHub <em>CodeStream</em>&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-20T01:42:42Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.71085,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>",
        "body": " pika.exceptions:ChannelWrongStateError, you don&#x27;t see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and <em>CodeStream</em>"
      },
      "id": "61be8f01196a67e048eef29c"
    },
    {
      "image": "https://docs.newrelic.com/static/3c5d34598b67191429a2a95f8f7b1895/c1b63/error-ide.png",
      "url": "https://docs.newrelic.com/docs/codestream/start-here/what-is-codestream/",
      "sections": [
        "Intro to New Relic CodeStream",
        "Preview release",
        "Discuss code just like commenting on a Google Doc",
        "Get feedback on work-in-progress with pre-PR code review",
        "Create and review pull requests",
        "Monitor your codes performance in production",
        "See your errors and what's causing them"
      ],
      "published_at": "2021-12-20T01:45:46Z",
      "title": "Intro to New Relic CodeStream",
      "updated_at": "2021-12-15T01:41:52Z",
      "type": "docs",
      "external_id": "0b3f4199050df98161ce8c46259a8bad30269d72",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic CodeStream is a developer collaboration platform that enables your development team to discuss and review code in a natural and contextual way. CodeStream not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional knowledge that is currently being lost in Slack channels and emails. Not only that, our observability solutions take you from finding errors to fixing them, all within your IDE. A quick overview of how you can use New Relic CodeStream to discover, troubleshoot, and triage errors in your IDE. (2:27) If you haven't already, sign up for a free New Relic account so that you can get the most out of New Relic CodeStream. Preview release CodeStream's integration with New Relic One is a preview release limited to New Relic One accounts on our US data center, and your use is subject to the pre-release policy. (This does not apply to all other CodeStream functionality.) Discuss code just like commenting on a Google Doc Simply select a block of code and type your question or comment. Teammates can participate in the discussion right from their IDE and you can optionally share the discussion on Slack or Microsoft Teams so teammates can participate from their chat clients as well. Select some code and then click the add comment button. CodeStream turns conversation into documentation by capturing all of the discussion about your code and saving it with your code. And the real magic is that the discussions are automatically repositioned as your code changes, even across branches. All with zero effort on your part. Get feedback on work-in-progress with pre-PR code review CodeStream's lightweight feedback requests let you have someone look over your changes regardless of the current state of your repo, without the friction of committing, pushing, or issuing a pull request. Once you've made some changes to a file, in the Feedback requests section, click the + button to request feedback on that change. Your teammates can review your changes right in their IDE, with full file context, and with no need to set aside their current work to switch branches or pull the latest. Use code comments to respond to a feedback request on a change. CodeStreams feedback requests are so easy that you can start doing them throughout the development process instead of waiting until the end. Youre a few days into a sprint and have some work stubbed out? Maybe some work that hasnt even been committed? Request feedback on your work in progress so that you can identify and resolve issues early instead of saving those gotchas for when you need to get the code merged. Create and review pull requests For most development teams, the final step in the development process is a pull request. Even if your team has decided to use CodeStream's feedback requests as a replacement for, and not just a precursor to, your end-of-cycle PR-based code reviews, you can create and review pull requests right inside your IDE. CodeStream shows a diff view of all the files changed in a PR. Review and approve the PR as you would on GitHub. Monitor your codes performance in production Your pursuit of software quality doesnt end once the code has been merged. Connect CodeStream to your New Relic One account and you can either jump from an error on New Relic One into your IDE or you can discover errors in CodeStream's Observability section. Navigate the stack trace to find the offending code and collaborate with your teammates to resolve the issue. Once you've connected New Relic CodeStream to your repositories and are observing your code's performance, use the observability section to find errors and collaborate with your team on solving them. See your errors and what's causing them After you connect CodeStream and New Relic, use workloads and errors inbox to jump to the offending code in your IDE. Once you've connected CodeStream to your repositories and configured it to connect with New Relic One, you can use errors inbox to find and an error and then jump to that error in your IDE and the branch of your repository that's generating the error.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.56464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to New Relic <em>CodeStream</em>",
        "sections": "Intro to New Relic <em>CodeStream</em>",
        "body": "New Relic <em>CodeStream</em> is a developer collaboration platform that enables your development team to discuss and review <em>code</em> in a natural and contextual way. <em>CodeStream</em> not only makes your discussions easier, by allowing them to happen in context in your IDE, but it also preserves the institutional"
      },
      "id": "617440e3e7b9d2836c13c43c"
    }
  ],
  "/docs/data-apis/convert-to-metrics/analyze-monitor-data-trends-metrics": [
    {
      "sections": [
        "Create metrics from other data types",
        "Create a metrics rule",
        "Step 1. Create NRQL query rule",
        "Tip",
        "Step 2. Create API request",
        "Example NerdGraph API request",
        "Example NerdGraph API response",
        "Step 3. Create a metrics rule with API request",
        "Query and chart your metrics",
        "Summary metric example",
        "Count metric example",
        "Distribution metric example",
        "Troubleshooting"
      ],
      "title": "Create metrics from other data types",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "49b5860f405d53d1d9a630c2e031ab4331458005",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/convert-to-metrics/create-metrics-other-data-types/",
      "published_at": "2021-12-19T14:37:48Z",
      "updated_at": "2021-10-23T17:27:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic's metrics API service to define rules for creating metrics from your other types of data, such as events, logs, or spans. Recommendation: Before you begin, review our requirements and tips for creating rules. Create a metrics rule To create a rule for creating metrics from events, logs, or spans: Construct the metrics rule using NRQL. Construct a NerdGraph (GraphQL format) API request that contains your NRQL rule. Create the metric by making the API request. Once a metric is created, you can query and chart it using NRQL. Step 1. Create NRQL query rule The most important part of creating a metrics rule is constructing the NRQL query that defines the metric for your data from events, logs, or spans. You can create up to 10 metrics with a single NRQL query by following this procedure: Using New Relic's NRQL interface, construct a query for the metric you want to create. For example: FROM ProcessSample SELECT average(ioTotalReadBytes) WHERE nr.entityType = 'HOST' Copy Edit the query to use one of the three available metric types: summary: Use if the query's function is min, max, sum, count, or average. uniqueCount: Use if the query's function is uniqueCount. distribution: Use if the query's function is percentile or histogram. This example query uses average, so use summary: FROM ProcessSample SELECT summary (ioTotalReadBytes) WHERE nr.entityType = 'HOST' Copy This example query uses count on a non-numeric field: FROM ProcessSample SELECT count(hostname) WHERE hostname LIKE '%prod%' Copy For summary on a non-numeric field use summary(1): FROM ProcessSample SELECT summary(1) WHERE hostname LIKE '%prod%' Copy Tip For more detailed information on using these metric types in rules, see Creating metric rules: requirements and tips. Decide on the attributes you want to attach to the metric, following the limits on the cardinality of unique metric-name/attribute-value combinations. Recommendation: Run a separate query to ensure this count isn't over 50,000 for a 24-hour window. For example: FROM ProcessSample SELECT uniqueCount(awsRegion, awsAvailabilityZone, commandName) WHERE nr.entityType = 'HOST' SINCE 1 DAY AGO Copy To be able to aggregate and filter your metrics, add the attributes you want to attach to the metric using the FACET clause. For example: FROM ProcessSample SELECT summary(ioTotalReadBytes) WHERE nr.entityType = 'HOST' FACET awsRegion, awsAvailabilityZone, commandName Copy Set the name of the metric using the AS function. For example: FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'HOST' FACET awsRegion, awsAvailabilityZone, commandName Copy Once your NRQL rule is complete, use it to create the API request. Step 2. Create API request After you build the NRQL rule to convert data from events, logs, or spans to metrics, continue with building the API request. You can use our NerdGraph API tool to explore the data structure and to construct and make your request. To check that the rule was created correctly, you can run a query to return that rule using its ID. For tips on querying the metrics you've created, see Query and chart your metrics. Example NerdGraph API request The following example NerdGraph API request uses the same NRQL rule from step 1. The IO Total Read Bytes Rule creates a metric named io.totalread.bytes. (The rule name can have spaces, which differs from the metric naming rules.) mutation { eventsToMetricsCreateRule(rules: { name: \"io.totalread.bytes for computeSample entities\", description:\"Created by Zach on March 27, 2019. Used by team Network.\", nrql:\"FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName\", accountId: 123456 }) { successes { id name nrql enabled } failures { submitted { name nrql accountId } errors { reason description } } } } Copy In this request: Request elements Description mutation One of the basic API operation types. eventsToMetricsCreateRule The method being called to create a rule. rules Takes four parameters: name: The name of the rule. description: Optional. The description of the rule. We recommend you include information about who created the metric data and who will be using the data. accountId: The New Relic account ID where the events, logs, or spans live and the metrics will be created. nrql: The NRQL query that creates the rule. For more on this, see Create NRQL query. successes and submitted blocks Here you define the data returned by a successful or failed response. Available parameters for these blocks include: id (ruleId for submitted) name description nrql enabled (enabled/disabled status) accountId ruleId and accountId If a failure occurs, then the submitted ruleId and accountId will be returned along with the error reason and error description. Example NerdGraph API response Here's an example of a returned response: { \"data\": { \"eventsToMetricsCreateRule\": { \"failures\": [], \"successes\": [ { \"enabled\": true, \"id\": \"46\", \"name\": \"io.totalread.bytes for computeSample entities\", \"nrql\": \"FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName\" } ] } } } Copy Step 3. Create a metrics rule with API request When your API request is ready, you can use the NerdGraph API to make the request, which will create the metrics. Query and chart your metrics After you create a metrics rule to convert data for your events, logs, or spans, you can view the new metric data in the New Relic UI. To view your data: Go to New Relic's NRQL query interface. Run the following query to see the name of all your metrics: SELECT uniques(metricName) FROM Metric Copy Pick the metric of interest, then run the following query to see the available attributes: SELECT * FROM Metric where metricName = 'yourMetric' Copy If you don't see expected data, follow the troubleshooting procedures. The available NRQL aggregator functions depend on the metric type you created. Here are some examples. Summary metric example If you created a summary metric type, you can use the count, sum, max, min, and average aggregator functions, as shown in the following query: SELECT count(appStartResponseTime), sum(appStartResponseTime), max(appStartResponseTime), min(appStartResponseTime), average(appStartResponseTime) FROM Metric Copy Count metric example If you created a uniqueCount metric type, you can only use the uniqueCount function, as shown in the following query: SELECT uniqueCount(playbackErrorStreamUniqueCount) * 100 / uniqueCount(streamUniqueCount) AS '% of Streams Impacted' FROM Metric Copy Distribution metric example If you created a distribution metric type, use the percentile or histogram functions, as shown in the following queries: SELECT percentile(service.responseTime, 95) FROM Metric Copy OR SELECT histogram(service.responseTime, 10, 20) FROM Metric Copy Troubleshooting If your NerdGraph call is not constructed correctly, you may receive a message like this: Cannot parse the unexpected character \"\\u201C Copy Verify the quotes in the NerdGraph call are not smart quotes (curly quotes). Our NerdGraph API only accepts straight quotes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.76244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>metrics</em> from other <em>data</em> types",
        "sections": "Create <em>metrics</em> from other <em>data</em> types",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " the NerdGraph API to make the request, which will create the <em>metrics</em>. Query and chart your <em>metrics</em> After you create a <em>metrics</em> rule to <em>convert</em> <em>data</em> for your events, logs, or spans, you can view the new <em>metric</em> <em>data</em> in the New Relic UI. To view your <em>data</em>: Go to New Relic&#x27;s NRQL query interface. Run the following"
      },
      "id": "603ebfc8196a67cab0a83d96"
    },
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.10526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of API client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> APIs: the <em>Metric</em> API, Trace API, Log API, and Event API. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Creating metric rules: requirements and tips",
        "Metric aggregation",
        "Rule-creation limits",
        "Cardinality limits",
        "Multiple metrics from one rule",
        "Metric naming"
      ],
      "title": "Creating metric rules: requirements and tips",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "3724b0897ae63f6a25c4cf5eeaf5d2b49be15283",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/convert-to-metrics/creating-metric-rules-requirements-tips/",
      "published_at": "2021-12-19T17:22:46Z",
      "updated_at": "2021-10-23T17:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some limits, requirements, and recommendations when you create metrics from events, logs, or spans. Metric aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate metrics: Function Comments summary Creates a summary metric data point for each time window (currently 1 minute). Use this if your NRQL query uses aggregator functions supported by the summary metric type, such as average, sum, min, or max. Example rule-creation query: SELECT summary(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy uniqueCount Creates a uniqueCount metric data point for each 1-minute time window. Use this if your NRQL query uses the uniqueCount aggregator type. Example rule-creation query: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy distribution Creates a distribution metric data point for each 1-minute time window. Use this if your NRQL query uses aggregator functions such as percentile, histogram, min, max, average, sum, or count. Use only the attribute of interest as the argument, and discard the rest of the arguments from percentile or histogram. The generated metric supports any argument on percentile or histogram. Example of creating a distribution rule: SELECT distribution(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy Simple count: summary(1) and sum If you want a metric that's a simple count of the events, logs, or spans that match a particular WHERE clause, use the summary(1) metric. This metric type counts the number of specified events, logs, or spans per minute. When querying the created metric, use the sum method to see the result. Example: If you want to create a metric named foo.count that counts the transactions named foo, the NRQL would look like this: FROM Transaction SELECT summary(1) AS 'foo.count' WHERE name = 'foo' Copy Then, you would query it like this: FROM Metric SELECT sum(foo.count) SINCE 30 minutes ago Copy For more information about metrics, see our documentation about metric types. Rule-creation limits These limits affect metric rules creation: Limits Comments Account limits An account can have a maximum of 1,000 metric-creation rules. Metric rule limits A rule can: Create a maximum of 10 metrics. Use only one type of data (events, logs, or spans). Select a maximum of 20 attributes (facets) to include on a metric. Time window limits 50K limit on unique metric-name/attribute-value combinations for a single metric in a 24-hour time window. If this limit is exceeded, the rule is disabled and an NrIntegrationError event is created in that account that includes: The rule details A message about having too many facets A newRelicFeature attribute value of eventToMetric Limits on metric name and attribute value combinations The limit on total unique metric name/attribute value combinations in a 24-hour time window for an account is: Equal to three times the purchased monthly average data points per minute Up to a maximum of 10M Cardinality limits Rule-creation limits include limits on the number of unique combinations of metric name and attribute values. This limit exists because a large number of attributes and/or attribute values can lead to an exponential increase in the size of data reported. Example metric creation rule that attaches five attributes: FROM ProcessSample SELECT summary(ioTotalReadBytes) WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName, entityName, processId Copy If each of the five attributes reported ten unique values within a one-minute time window, the number of unique metric-name/attribute combinations would theoretically have a maximum of 10x10x10x10x10, or 100,000. Multiple attributes with multiple unique values can lead to a large number of unique metric entries. In practice, this isn't usually the case, because attributes are often related. For example, if one attribute is hostname and another is awsRegion, when you see hostname A, it will always be in AWS region B; you'd never see hostname A and other AWS region values. This is why it's important, during the NRQL creation process, to use the uniqueCount function to verify how many unique metric-name/attribute-value combinations your NRQL query is generating. Multiple metrics from one rule A rule can create up to ten metrics. There are no functional differences between metrics created one at a time and those created with a single rule. Reasons for creating multiple metrics with a single rule: Less likely to reach rules-per-account limit. Easier to add the same attributes to multiple metrics. Example creating multiple metrics with a single rule: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount', summary(duration) AS 'server.duration', summary(totalTime) AS 'server.totalTime' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy Metric naming A metric is given a name with the AS clause, as part of the NRQL rule-creation process. In the following NRQL example, the name of the metric is io.totalread.bytes: FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName Copy If there is no name assigned with the AS clause, the metric name is the name of the queried attribute. In this example, if no name was assigned, the metric name would be ioTotalReadBytes. Metric names Requirements and recommendations Requirements Requirements for naming a metric: Less than or equal to 255 (UTF-16) 16-bit code units. One way to ensure you are under the limit is to keep each string under 127 of whatever is easiest to count. No spaces. Start with a letter. Examples of strong metric names: rubyvm.memory.heap_used redis.container.cpu.percent memcached.process_virtual_memory.bytes Length and structure Decide on a name and structure that makes it easy for others to find, understand, and use this metric. We recommend keeping your metric name under 40 characters for ideal readability. Longer names can get cut off or overlap with other names. Your metric naming scheme will depend on your business logic. You may want to use namespaces to prefix your metric name, or your names may need to be more general. Components within the name If you want to create components within your metric name (like the source of metrics and the thing youre measuring), we recommend going from broad to specific (left to right): Use a dot to separate those components in order to be consistent with our New Relic metric names. Then, use an underscore to separate words within the dots. Example: application.page_view.duration Copy Attributes Avoid putting attributes in your metric name. Attributes are qualities of your metric that you can use to filter or facet your data, like cluster or availability zone. Example: If you included availability zone in your metric name, it would mean, for that metric, you wouldnt be able to see results across all availability zones. Changing metric names If you change a metric name, historical data will not be updated to that new name. To query or chart that historical data, you will need to specify the older metric name.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.9318,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "sections": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Here are some limits, requirements, and recommendations when you create <em>metrics</em> from events, logs, or spans. <em>Metric</em> aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate <em>metrics</em>: Function Comments summary Creates a summary <em>metric</em> <em>data</em>"
      },
      "id": "603e9b8164441fbcac4e88a6"
    }
  ],
  "/docs/data-apis/convert-to-metrics/create-metrics-other-data-types": [
    {
      "sections": [
        "Analyze and monitor data trends with metrics",
        "Why create metrics from other data types?",
        "Available operations",
        "Mutations",
        "Create a rule",
        "Delete a rule",
        "Important",
        "Enable or disable a rule",
        "Queries",
        "List all rules for a New Relic account",
        "List rule by rule ID",
        "Use the NerdGraph GraphiQL API tool"
      ],
      "title": "Analyze and monitor data trends with metrics",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "06073bcfec2679ac1bc402dfe305426bbd9e2182",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/convert-to-metrics/analyze-monitor-data-trends-metrics/",
      "published_at": "2021-12-19T14:11:14Z",
      "updated_at": "2021-10-23T17:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can generate metric-type data from other types of data in New Relic, including events, logs, and spans. Metrics are aggregates of your data and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How to use our NerdGraph API tool to perform operations Why create metrics from other data types? Using metrics allows for more efficient data storage. This in turn allows you to query your data and build charts more easily. The difference between metrics and other types of data in New Relic is based on time. For more information, see Understand data types. Events, logs, spans: These types of data represent a single record at a specific moment in time. For example, you may have an event for every request to the system. This data is ideal for in-depth troubleshooting and analysis. Metrics: These provide an aggregated view of your events, logs, or spans. Metrics are better for showing trends over longer time ranges. For example, you can aggregate the total number of requests per service to one metric and then examine this information month over month. Why use metrics? Comments Flexibility Metrics are dimensional. You can choose what metadata (like host name or app name) is attached to them. Common metric measurements, like average, sum, minimum, and maximum, are already calculated. Data aggregation and retention The data has already been pre-aggregated into longer-period time buckets. Data retention is 13 months. Query capabilities You can query using the Metric data type. When you create metrics, this does not delete your events or other types of data. However, metrics are better for longer-range querying and charting. To get started converting your data to metrics, create a rule. Available operations To show, create, and delete rules for generating metrics from events, logs, or spans, use NerdGraph, our GraphQL-format API. Before performing any operation, we recommend reading Intro to NerdGraph and exploring your data with the GraphiQL API tool. These operations fall under two basic request types: Mutations, which are operations that make changes to existing rules or settings (for example, creating a new metrics rule). Queries, for fetching existing data (for example, fetching existing metrics rules). All operations are role-based in NerdGraph as the currently logged-in New Relic user. Mutations Mutation operations for events to metrics, logs to metrics, or spans to metrics include: Create a rule See Create metrics. Delete a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To delete a rule, you need the rule ID and the New Relic account ID. Example request: mutation { eventsToMetricsDeleteRule(deletes: {ruleId: \"12\", accountId: 123456}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsDeleteRule The method being called to delete a rule. deletes This takes two parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Example response for the request: { \"data\": { \"eventsToMetricsDeleteRule\": { \"failures\": [], \"successes\": [ { \"id\": \"12\", \"name\": \"Test Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } Copy Enable or disable a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To enable or disable an existing rule for events to metrics, logs to metrics, or spans to metrics, use the same eventsToMetricsUpdateRule operation. The only difference is whether enabled is set to true or false. Example request to enable an existing metrics rule: mutation { eventsToMetricsUpdateRule(updates: {ruleId: \"12\", accountId: 123456, enabled: true}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsUpdateRule The method being called to update an existing rule and either enable it or disable it. updates This takes three required parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. enabled: To enable a disabled rule, set this to true. To disable a rule, set this to false. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Queries Query operations include: List all rules for a New Relic account You can list all rules in a New Relic account or return a specific rule. Example listing all rules for account 123456: query { actor { account(id:123456) { eventsToMetrics{ allRules{ rules{ id name enabled nrql description } } } } } } Copy In this request: Element Description query One of the basic API operation types. Used to query but not make changes. actor This specifies the current New Relic user. account(id: 123456) Specify the ID for the New Relic account where to retrieve data. eventsToMetrics Scope the data only for events-to-metrics, logs-to-metrics, or spans-to-metrics rules. allRules Returns all rules for that account. rules In the rules block, you can define what data you want returned. Available fields include: id name description nrql accountId enabled Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"allRules\": { \"rules\": [ { \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"1\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" }, { \"description\": \"Metric for duration\", \"enabled\": true, \"id\": \"2\", \"name\": \"Duration Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy List rule by rule ID If you know the exact ID for a rule, then you can query for a specific rule. For example, you may have just created a rule and now you want to list its contents so you can review it. Example listing rule 36 for New Relic account 123456: query { actor { account(id: 123456) { eventsToMetrics { rulesById(ruleIds: \"36\") { rules { id name enabled nrql description accountId } } } } } } Copy For more details about the elements in this query, see List all rules. Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"rulesById\": { \"rules\": [ { \"accountId\": 123456, \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"36\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy Use the NerdGraph GraphiQL API tool You can use our GraphiQL tool to explore the data structure. You can also use it to build and run the operations to convert events, logs, and spans to metrics. To use this tool: Create the metrics operation's request with the required parameters. Go to api.newrelic.com/graphiql, and paste your query into the box. To execute the operation, press Play. Or, to get the cURL format, select Copy as cURL.) Validate the response in the response box. Optional: To verify that your rule-creation operation was performed successfully, run a list query for that rule ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.76277,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "sections": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "You can generate <em>metric</em>-type <em>data</em> from other types of <em>data</em> in New Relic, including events, logs, and spans. <em>Metrics</em> are aggregates of your <em>data</em> and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How"
      },
      "id": "603eb239e7b9d2b99d2a07bb"
    },
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.10526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of API client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> APIs: the <em>Metric</em> API, Trace API, Log API, and Event API. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Creating metric rules: requirements and tips",
        "Metric aggregation",
        "Rule-creation limits",
        "Cardinality limits",
        "Multiple metrics from one rule",
        "Metric naming"
      ],
      "title": "Creating metric rules: requirements and tips",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "3724b0897ae63f6a25c4cf5eeaf5d2b49be15283",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/convert-to-metrics/creating-metric-rules-requirements-tips/",
      "published_at": "2021-12-19T17:22:46Z",
      "updated_at": "2021-10-23T17:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some limits, requirements, and recommendations when you create metrics from events, logs, or spans. Metric aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate metrics: Function Comments summary Creates a summary metric data point for each time window (currently 1 minute). Use this if your NRQL query uses aggregator functions supported by the summary metric type, such as average, sum, min, or max. Example rule-creation query: SELECT summary(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy uniqueCount Creates a uniqueCount metric data point for each 1-minute time window. Use this if your NRQL query uses the uniqueCount aggregator type. Example rule-creation query: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy distribution Creates a distribution metric data point for each 1-minute time window. Use this if your NRQL query uses aggregator functions such as percentile, histogram, min, max, average, sum, or count. Use only the attribute of interest as the argument, and discard the rest of the arguments from percentile or histogram. The generated metric supports any argument on percentile or histogram. Example of creating a distribution rule: SELECT distribution(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy Simple count: summary(1) and sum If you want a metric that's a simple count of the events, logs, or spans that match a particular WHERE clause, use the summary(1) metric. This metric type counts the number of specified events, logs, or spans per minute. When querying the created metric, use the sum method to see the result. Example: If you want to create a metric named foo.count that counts the transactions named foo, the NRQL would look like this: FROM Transaction SELECT summary(1) AS 'foo.count' WHERE name = 'foo' Copy Then, you would query it like this: FROM Metric SELECT sum(foo.count) SINCE 30 minutes ago Copy For more information about metrics, see our documentation about metric types. Rule-creation limits These limits affect metric rules creation: Limits Comments Account limits An account can have a maximum of 1,000 metric-creation rules. Metric rule limits A rule can: Create a maximum of 10 metrics. Use only one type of data (events, logs, or spans). Select a maximum of 20 attributes (facets) to include on a metric. Time window limits 50K limit on unique metric-name/attribute-value combinations for a single metric in a 24-hour time window. If this limit is exceeded, the rule is disabled and an NrIntegrationError event is created in that account that includes: The rule details A message about having too many facets A newRelicFeature attribute value of eventToMetric Limits on metric name and attribute value combinations The limit on total unique metric name/attribute value combinations in a 24-hour time window for an account is: Equal to three times the purchased monthly average data points per minute Up to a maximum of 10M Cardinality limits Rule-creation limits include limits on the number of unique combinations of metric name and attribute values. This limit exists because a large number of attributes and/or attribute values can lead to an exponential increase in the size of data reported. Example metric creation rule that attaches five attributes: FROM ProcessSample SELECT summary(ioTotalReadBytes) WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName, entityName, processId Copy If each of the five attributes reported ten unique values within a one-minute time window, the number of unique metric-name/attribute combinations would theoretically have a maximum of 10x10x10x10x10, or 100,000. Multiple attributes with multiple unique values can lead to a large number of unique metric entries. In practice, this isn't usually the case, because attributes are often related. For example, if one attribute is hostname and another is awsRegion, when you see hostname A, it will always be in AWS region B; you'd never see hostname A and other AWS region values. This is why it's important, during the NRQL creation process, to use the uniqueCount function to verify how many unique metric-name/attribute-value combinations your NRQL query is generating. Multiple metrics from one rule A rule can create up to ten metrics. There are no functional differences between metrics created one at a time and those created with a single rule. Reasons for creating multiple metrics with a single rule: Less likely to reach rules-per-account limit. Easier to add the same attributes to multiple metrics. Example creating multiple metrics with a single rule: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount', summary(duration) AS 'server.duration', summary(totalTime) AS 'server.totalTime' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy Metric naming A metric is given a name with the AS clause, as part of the NRQL rule-creation process. In the following NRQL example, the name of the metric is io.totalread.bytes: FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName Copy If there is no name assigned with the AS clause, the metric name is the name of the queried attribute. In this example, if no name was assigned, the metric name would be ioTotalReadBytes. Metric names Requirements and recommendations Requirements Requirements for naming a metric: Less than or equal to 255 (UTF-16) 16-bit code units. One way to ensure you are under the limit is to keep each string under 127 of whatever is easiest to count. No spaces. Start with a letter. Examples of strong metric names: rubyvm.memory.heap_used redis.container.cpu.percent memcached.process_virtual_memory.bytes Length and structure Decide on a name and structure that makes it easy for others to find, understand, and use this metric. We recommend keeping your metric name under 40 characters for ideal readability. Longer names can get cut off or overlap with other names. Your metric naming scheme will depend on your business logic. You may want to use namespaces to prefix your metric name, or your names may need to be more general. Components within the name If you want to create components within your metric name (like the source of metrics and the thing youre measuring), we recommend going from broad to specific (left to right): Use a dot to separate those components in order to be consistent with our New Relic metric names. Then, use an underscore to separate words within the dots. Example: application.page_view.duration Copy Attributes Avoid putting attributes in your metric name. Attributes are qualities of your metric that you can use to filter or facet your data, like cluster or availability zone. Example: If you included availability zone in your metric name, it would mean, for that metric, you wouldnt be able to see results across all availability zones. Changing metric names If you change a metric name, historical data will not be updated to that new name. To query or chart that historical data, you will need to specify the older metric name.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.9318,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "sections": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Here are some limits, requirements, and recommendations when you create <em>metrics</em> from events, logs, or spans. <em>Metric</em> aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate <em>metrics</em>: Function Comments summary Creates a summary <em>metric</em> <em>data</em>"
      },
      "id": "603e9b8164441fbcac4e88a6"
    }
  ],
  "/docs/data-apis/convert-to-metrics/creating-metric-rules-requirements-tips": [
    {
      "sections": [
        "Analyze and monitor data trends with metrics",
        "Why create metrics from other data types?",
        "Available operations",
        "Mutations",
        "Create a rule",
        "Delete a rule",
        "Important",
        "Enable or disable a rule",
        "Queries",
        "List all rules for a New Relic account",
        "List rule by rule ID",
        "Use the NerdGraph GraphiQL API tool"
      ],
      "title": "Analyze and monitor data trends with metrics",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "06073bcfec2679ac1bc402dfe305426bbd9e2182",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/convert-to-metrics/analyze-monitor-data-trends-metrics/",
      "published_at": "2021-12-19T14:11:14Z",
      "updated_at": "2021-10-23T17:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can generate metric-type data from other types of data in New Relic, including events, logs, and spans. Metrics are aggregates of your data and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How to use our NerdGraph API tool to perform operations Why create metrics from other data types? Using metrics allows for more efficient data storage. This in turn allows you to query your data and build charts more easily. The difference between metrics and other types of data in New Relic is based on time. For more information, see Understand data types. Events, logs, spans: These types of data represent a single record at a specific moment in time. For example, you may have an event for every request to the system. This data is ideal for in-depth troubleshooting and analysis. Metrics: These provide an aggregated view of your events, logs, or spans. Metrics are better for showing trends over longer time ranges. For example, you can aggregate the total number of requests per service to one metric and then examine this information month over month. Why use metrics? Comments Flexibility Metrics are dimensional. You can choose what metadata (like host name or app name) is attached to them. Common metric measurements, like average, sum, minimum, and maximum, are already calculated. Data aggregation and retention The data has already been pre-aggregated into longer-period time buckets. Data retention is 13 months. Query capabilities You can query using the Metric data type. When you create metrics, this does not delete your events or other types of data. However, metrics are better for longer-range querying and charting. To get started converting your data to metrics, create a rule. Available operations To show, create, and delete rules for generating metrics from events, logs, or spans, use NerdGraph, our GraphQL-format API. Before performing any operation, we recommend reading Intro to NerdGraph and exploring your data with the GraphiQL API tool. These operations fall under two basic request types: Mutations, which are operations that make changes to existing rules or settings (for example, creating a new metrics rule). Queries, for fetching existing data (for example, fetching existing metrics rules). All operations are role-based in NerdGraph as the currently logged-in New Relic user. Mutations Mutation operations for events to metrics, logs to metrics, or spans to metrics include: Create a rule See Create metrics. Delete a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To delete a rule, you need the rule ID and the New Relic account ID. Example request: mutation { eventsToMetricsDeleteRule(deletes: {ruleId: \"12\", accountId: 123456}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsDeleteRule The method being called to delete a rule. deletes This takes two parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Example response for the request: { \"data\": { \"eventsToMetricsDeleteRule\": { \"failures\": [], \"successes\": [ { \"id\": \"12\", \"name\": \"Test Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } Copy Enable or disable a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To enable or disable an existing rule for events to metrics, logs to metrics, or spans to metrics, use the same eventsToMetricsUpdateRule operation. The only difference is whether enabled is set to true or false. Example request to enable an existing metrics rule: mutation { eventsToMetricsUpdateRule(updates: {ruleId: \"12\", accountId: 123456, enabled: true}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsUpdateRule The method being called to update an existing rule and either enable it or disable it. updates This takes three required parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. enabled: To enable a disabled rule, set this to true. To disable a rule, set this to false. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Queries Query operations include: List all rules for a New Relic account You can list all rules in a New Relic account or return a specific rule. Example listing all rules for account 123456: query { actor { account(id:123456) { eventsToMetrics{ allRules{ rules{ id name enabled nrql description } } } } } } Copy In this request: Element Description query One of the basic API operation types. Used to query but not make changes. actor This specifies the current New Relic user. account(id: 123456) Specify the ID for the New Relic account where to retrieve data. eventsToMetrics Scope the data only for events-to-metrics, logs-to-metrics, or spans-to-metrics rules. allRules Returns all rules for that account. rules In the rules block, you can define what data you want returned. Available fields include: id name description nrql accountId enabled Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"allRules\": { \"rules\": [ { \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"1\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" }, { \"description\": \"Metric for duration\", \"enabled\": true, \"id\": \"2\", \"name\": \"Duration Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy List rule by rule ID If you know the exact ID for a rule, then you can query for a specific rule. For example, you may have just created a rule and now you want to list its contents so you can review it. Example listing rule 36 for New Relic account 123456: query { actor { account(id: 123456) { eventsToMetrics { rulesById(ruleIds: \"36\") { rules { id name enabled nrql description accountId } } } } } } Copy For more details about the elements in this query, see List all rules. Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"rulesById\": { \"rules\": [ { \"accountId\": 123456, \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"36\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy Use the NerdGraph GraphiQL API tool You can use our GraphiQL tool to explore the data structure. You can also use it to build and run the operations to convert events, logs, and spans to metrics. To use this tool: Create the metrics operation's request with the required parameters. Go to api.newrelic.com/graphiql, and paste your query into the box. To execute the operation, press Play. Or, to get the cURL format, select Copy as cURL.) Validate the response in the response box. Optional: To verify that your rule-creation operation was performed successfully, run a list query for that rule ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.76277,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "sections": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "You can generate <em>metric</em>-type <em>data</em> from other types of <em>data</em> in New Relic, including events, logs, and spans. <em>Metrics</em> are aggregates of your <em>data</em> and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How"
      },
      "id": "603eb239e7b9d2b99d2a07bb"
    },
    {
      "sections": [
        "Create metrics from other data types",
        "Create a metrics rule",
        "Step 1. Create NRQL query rule",
        "Tip",
        "Step 2. Create API request",
        "Example NerdGraph API request",
        "Example NerdGraph API response",
        "Step 3. Create a metrics rule with API request",
        "Query and chart your metrics",
        "Summary metric example",
        "Count metric example",
        "Distribution metric example",
        "Troubleshooting"
      ],
      "title": "Create metrics from other data types",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "49b5860f405d53d1d9a630c2e031ab4331458005",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/convert-to-metrics/create-metrics-other-data-types/",
      "published_at": "2021-12-19T14:37:48Z",
      "updated_at": "2021-10-23T17:27:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic's metrics API service to define rules for creating metrics from your other types of data, such as events, logs, or spans. Recommendation: Before you begin, review our requirements and tips for creating rules. Create a metrics rule To create a rule for creating metrics from events, logs, or spans: Construct the metrics rule using NRQL. Construct a NerdGraph (GraphQL format) API request that contains your NRQL rule. Create the metric by making the API request. Once a metric is created, you can query and chart it using NRQL. Step 1. Create NRQL query rule The most important part of creating a metrics rule is constructing the NRQL query that defines the metric for your data from events, logs, or spans. You can create up to 10 metrics with a single NRQL query by following this procedure: Using New Relic's NRQL interface, construct a query for the metric you want to create. For example: FROM ProcessSample SELECT average(ioTotalReadBytes) WHERE nr.entityType = 'HOST' Copy Edit the query to use one of the three available metric types: summary: Use if the query's function is min, max, sum, count, or average. uniqueCount: Use if the query's function is uniqueCount. distribution: Use if the query's function is percentile or histogram. This example query uses average, so use summary: FROM ProcessSample SELECT summary (ioTotalReadBytes) WHERE nr.entityType = 'HOST' Copy This example query uses count on a non-numeric field: FROM ProcessSample SELECT count(hostname) WHERE hostname LIKE '%prod%' Copy For summary on a non-numeric field use summary(1): FROM ProcessSample SELECT summary(1) WHERE hostname LIKE '%prod%' Copy Tip For more detailed information on using these metric types in rules, see Creating metric rules: requirements and tips. Decide on the attributes you want to attach to the metric, following the limits on the cardinality of unique metric-name/attribute-value combinations. Recommendation: Run a separate query to ensure this count isn't over 50,000 for a 24-hour window. For example: FROM ProcessSample SELECT uniqueCount(awsRegion, awsAvailabilityZone, commandName) WHERE nr.entityType = 'HOST' SINCE 1 DAY AGO Copy To be able to aggregate and filter your metrics, add the attributes you want to attach to the metric using the FACET clause. For example: FROM ProcessSample SELECT summary(ioTotalReadBytes) WHERE nr.entityType = 'HOST' FACET awsRegion, awsAvailabilityZone, commandName Copy Set the name of the metric using the AS function. For example: FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'HOST' FACET awsRegion, awsAvailabilityZone, commandName Copy Once your NRQL rule is complete, use it to create the API request. Step 2. Create API request After you build the NRQL rule to convert data from events, logs, or spans to metrics, continue with building the API request. You can use our NerdGraph API tool to explore the data structure and to construct and make your request. To check that the rule was created correctly, you can run a query to return that rule using its ID. For tips on querying the metrics you've created, see Query and chart your metrics. Example NerdGraph API request The following example NerdGraph API request uses the same NRQL rule from step 1. The IO Total Read Bytes Rule creates a metric named io.totalread.bytes. (The rule name can have spaces, which differs from the metric naming rules.) mutation { eventsToMetricsCreateRule(rules: { name: \"io.totalread.bytes for computeSample entities\", description:\"Created by Zach on March 27, 2019. Used by team Network.\", nrql:\"FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName\", accountId: 123456 }) { successes { id name nrql enabled } failures { submitted { name nrql accountId } errors { reason description } } } } Copy In this request: Request elements Description mutation One of the basic API operation types. eventsToMetricsCreateRule The method being called to create a rule. rules Takes four parameters: name: The name of the rule. description: Optional. The description of the rule. We recommend you include information about who created the metric data and who will be using the data. accountId: The New Relic account ID where the events, logs, or spans live and the metrics will be created. nrql: The NRQL query that creates the rule. For more on this, see Create NRQL query. successes and submitted blocks Here you define the data returned by a successful or failed response. Available parameters for these blocks include: id (ruleId for submitted) name description nrql enabled (enabled/disabled status) accountId ruleId and accountId If a failure occurs, then the submitted ruleId and accountId will be returned along with the error reason and error description. Example NerdGraph API response Here's an example of a returned response: { \"data\": { \"eventsToMetricsCreateRule\": { \"failures\": [], \"successes\": [ { \"enabled\": true, \"id\": \"46\", \"name\": \"io.totalread.bytes for computeSample entities\", \"nrql\": \"FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName\" } ] } } } Copy Step 3. Create a metrics rule with API request When your API request is ready, you can use the NerdGraph API to make the request, which will create the metrics. Query and chart your metrics After you create a metrics rule to convert data for your events, logs, or spans, you can view the new metric data in the New Relic UI. To view your data: Go to New Relic's NRQL query interface. Run the following query to see the name of all your metrics: SELECT uniques(metricName) FROM Metric Copy Pick the metric of interest, then run the following query to see the available attributes: SELECT * FROM Metric where metricName = 'yourMetric' Copy If you don't see expected data, follow the troubleshooting procedures. The available NRQL aggregator functions depend on the metric type you created. Here are some examples. Summary metric example If you created a summary metric type, you can use the count, sum, max, min, and average aggregator functions, as shown in the following query: SELECT count(appStartResponseTime), sum(appStartResponseTime), max(appStartResponseTime), min(appStartResponseTime), average(appStartResponseTime) FROM Metric Copy Count metric example If you created a uniqueCount metric type, you can only use the uniqueCount function, as shown in the following query: SELECT uniqueCount(playbackErrorStreamUniqueCount) * 100 / uniqueCount(streamUniqueCount) AS '% of Streams Impacted' FROM Metric Copy Distribution metric example If you created a distribution metric type, use the percentile or histogram functions, as shown in the following queries: SELECT percentile(service.responseTime, 95) FROM Metric Copy OR SELECT histogram(service.responseTime, 10, 20) FROM Metric Copy Troubleshooting If your NerdGraph call is not constructed correctly, you may receive a message like this: Cannot parse the unexpected character \"\\u201C Copy Verify the quotes in the NerdGraph call are not smart quotes (curly quotes). Our NerdGraph API only accepts straight quotes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.76244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>metrics</em> from other <em>data</em> types",
        "sections": "Create <em>metrics</em> from other <em>data</em> types",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " the NerdGraph API to make the request, which will create the <em>metrics</em>. Query and chart your <em>metrics</em> After you create a <em>metrics</em> rule to <em>convert</em> <em>data</em> for your events, logs, or spans, you can view the new <em>metric</em> <em>data</em> in the New Relic UI. To view your <em>data</em>: Go to New Relic&#x27;s NRQL query interface. Run the following"
      },
      "id": "603ebfc8196a67cab0a83d96"
    },
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.10526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Telemetry</em> SDKs: Report custom <em>telemetry</em> <em>data</em>",
        "sections": "<em>Telemetry</em> SDKs: Report custom <em>telemetry</em> <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our <em>Telemetry</em> SDKs are an open source set of API client libraries that send <em>data</em> to the New Relic <em>platform</em>. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> APIs: the <em>Metric</em> API, Trace API, Log API, and Event API. If our pre-built solutions don&#x27;t meet your needs, our <em>Telemetry</em> SDKs"
      },
      "id": "603ea196196a670192a83d83"
    }
  ],
  "/docs/data-apis/custom-data/custom-events/apm-report-custom-events-attributes": [
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "17c97a462616f2b23ead796b62780a1ffeb3dfac",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-12-20T02:58:59Z",
      "updated_at": "2021-10-23T21:59:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Agent version Your browser monitoring agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute browser API call To add a custom attribute to the PageView event via the browser agent, use the setCustomAttribute browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.47496,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "65970eacbedb3360fd1c7394affc8cbc42f2ab0c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-12-20T10:04:06Z",
      "updated_at": "2021-10-23T21:59:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default mobile monitoring events using the mobile agent SDKs. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the crash event trail UI. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.47496,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "77720ef366038ba648a5fbf3cf34e8e48b38440a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T21:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). If the name begins with anything other than an alphabetical character, enclose the name with backticks in your NRQL query. For example: FROM `0_hello` SELECT count(*) Copy Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.4747,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    }
  ],
  "/docs/data-apis/custom-data/custom-events/collect-custom-attributes": [
    {
      "sections": [
        "Networks",
        "Tip",
        "TLS encryption",
        "User-facing domains",
        "APM agents",
        "Port 443 recommended",
        "Agent downloads",
        "Infrastructure agents",
        "Browser domains",
        "Mobile domains",
        "Synthetic monitor public locations",
        "Synthetic monitor private locations",
        "Alerts webhooks, api.newrelic.com, cloud integrations, and ticketing integrations",
        "Pixie integration",
        "OpenTelemetry"
      ],
      "title": "Networks",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "9f7555daaafae1753bf1e741a5d607e7f0f87b7c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/networks/",
      "published_at": "2021-12-20T02:57:01Z",
      "updated_at": "2021-12-15T12:41:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Networks, IPs, domains, ports, and endpoints last updated September 28, 2021. This is a list of the networks, IP addresses, domains, ports, and endpoints used by API clients or agents to communicate with New Relic. TLS is required for all domains. For information on our FedRAMP endpoints, see our FedRAMP endpoints documentation. Tip This doc describes how to ensure our agents and integrations can access New Relic's domains. To monitor the performance of your network, see Get started with Network Performance Monitoring. TLS encryption To ensure data security for our customers and to be in compliance with FedRAMP and other standards for data encryption, Transport Layer Security (TLS) is required for all domains. Our preferred protocol for all domains is TLS 1.2. For more information, see New Relic's Explorers Hub post about TLS 1.2. In addition, TLS 1.2 is required for most domains, except: APM agent connections Browser agent connections Event API For future updates to required and supported protocol versions, follow the Security Notifications tag in New Relic's Explorers Hub. User-facing domains Your browser must be able to communicate with a number of domains for New Relic One to work properly. Update your allow list to ensure New Relic can communicate with a number of integral domains that are listed in this section. Blocking domains can cause issues with individual product features or prevent pages from loading altogether. This list doesn't cover domains that New Relic connects to that can be blocked without affecting your usage of the product. It also doesn't cover Nerdpacks or other features that communicate with external services that have additional domain requirements. If your organization uses a firewall that restricts outbound traffic, follow the specific procedures for the operating system and the firewall you use to add the following domains to the allow list. Domain Description *.newrelic.com New Relic One and supporting services *.nr-assets.net Static New Relic assets *.nr-ext.net New Relic One Nerdpacks and assets *.amazonaws.com New Relic One catalog assets behind AWS S3 *.cloudfront.net Static New Relic assets behind AWS CloudFront CDN secure.gravatar.com Support for Gravatar avatars fonts.googleapis.com Support for Google Fonts fonts.gstatic.com Support for Google Fonts www.google.com Support for reCAPTCHA www.gstatic.com Support for reCAPTCHA *.nr-data.net OpenTelemetry and Pixie APM agents To enhance network performance and data security, New Relic uses a CDN and DDoS prevention service with a large IP range. New Relic agents require your firewall to allow outgoing connections to the following networks and ports. To add the following IP connections to the allow list, follow the specific procedures for the operating system and the firewall you use. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections APM data Networks US region accounts: 162.247.240.0/22 EU region accounts: 185.221.84.0/22 Ports US region accounts: Default: TCP 443 (recommended) TCP 80 EU region accounts: Default: TCP 443 (recommended) TCP 80 Endpoints US region accounts: collector*.newrelic.com EU region accounts: collector*.eu01.nr-data.net:443 (recommended) Port 443 recommended Recommendation: Use port 443, a secured channel for encrypted HTTPS traffic. Some New Relic agents also offer port 80, an unsecured channel open to all HTTP traffic. While some agents can be configured to use both port 80 and port 443, we recommend that you choose the port 443 (default). If you have an existing configuration that uses port 80, you can update it to use port 443, the default New Relic connection. Agent downloads TLS is required for all domains. Service for download.newrelic.com is provided through Fastly and is subject to change without warning. For the most current list of public IP addresses for New Relic agent downloads, see api.fastly.com/public-ip-list. Infrastructure agents In order to report data to New Relic, our infrastructure monitoring needs outbound access to these domains, networks, and ports. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections Infrastructure data Domains infra-api.newrelic.com: Required to submit events, metrics, and inventory data. identity-api.newrelic.com: Required for entity registration (for example, a host entity). infrastructure-command-api.newrelic.com: Required to determine feature flags. Also used for gradual rollout of new capabilities. log-api.newrelic.com: Required to submit logs to a US datacenter. log-api.eu.newrelic.com: Required to submit logs to an EU datacenter. metric-api.newrelic.com: Required to submit dimensional metrics. Networks For US region accounts: 162.247.240.0/22 For EU region accounts: 185.221.84.0/22 Port 443 Domains + Port For US region accounts: infra-api.newrelic.com:443 identity-api.newrelic.com:443 infrastructure-command-api.newrelic.com:443 log-api.newrelic.com:443 metric-api.newrelic.com:443 For EU region accounts: infra-api.eu.newrelic.com:443 identity-api.eu.newrelic.com:443 infrastructure-command-api.eu.newrelic.com:443 log-api.eu.newrelic.com:443 metric-api.eu.newrelic.com:443 Proxy If your system needs a proxy to connect to this domain, use the Infrastructure proxy setting. Browser domains In addition to the IP addresses for APM agents, applications monitored by our browser agents use outgoing connections to the following domains. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: For US region accounts: bam.nr-data.net js-agent.newrelic.com For EU region accounts: eu01.nr-data.net bam.eu01.nr-data.net For more information about CDN access for the js-agent.newrelic.com file to the domain bam.nr-data.net or to one of the New Relic beacons, see Security for browser monitoring. Mobile domains In addition to the IP addresses for APM agents, applications monitored by our mobile agents use outgoing connections to the following domains. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: For US region accounts: mobile-collector.newrelic.com mobile-crash.newrelic.com mobile-symbol-upload.newrelic.com For EU region accounts: mobile-collector.eu01.nr-data.net mobile-crash.eu01.nr-data.net mobile-symbol-upload.eu01.nr-data.net Synthetic monitor public locations To configure your firewall to allow synthetic monitors to access your monitored URL, use Synthetic public minion IPs. TLS is required for all domains. Synthetic monitor private locations Synthetic private minions report to a specific endpoint based on region. To allow the private minion to access the endpoint or the static IP addresses associated with the endpoint, follow the specific procedures for the operating system and the firewall you use. These IP addresses may change in the future. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections Synthetics private location data Endpoint For US region accounts: https://synthetics-horde.nr-data.net/ For EU region accounts: https://synthetics-horde.eu01.nr-data.net/ IP addresses For US region accounts: 13.248.153.51 76.223.21.185 For EU region accounts: 185.221.86.57 185.221.86.25 Alerts webhooks, api.newrelic.com, cloud integrations, and ticketing integrations Endpoints that use api.newrelic.com (such as our GraphQL API for NerdGraph) and our New Relic-generated webhooks for alert policies use an IP address from designated network blocks for the US or European Union region. TLS is required for all addresses in these blocks. Network blocks for US region accounts: 162.247.240.0/22 Network blocks for EU region accounts: 158.177.65.64/29 159.122.103.184/29 161.156.125.32/28 These network blocks also apply to third-party ticketing integrations and New Relic cloud integrations. Pixie integration The Pixie integration runs in your Kubernetes cluster and pulls a set of curated observability data from Pixie to send it to New Relic using the OpenTelemetry line protocol. The Pixie integration requires outbound network access to the following: work.withpixie.ai:443 otlp.nr-data.net:4317 (US region accounts) otlp.eu01.nr-data.net:4317 (EU region accounts) OpenTelemetry New Relic supports the native OpenTelemetry Protocol (OTLP) for exporting telemetry data. This allows you to use the vendor neutral components developed by the OpenTelemetry community to export your data to New Relic. To export OTLP data to New Relic, configure the OTLP exporter to add a header ( api-key ) whose value is your account license key. And, based on your region, configure the endpoint where the exporter sends data to New Relic. See the OpenTelemetry quick start for more information. otlp.nr-data.net:4317 (US region accounts) otlp.eu01.nr-data.net:4317 (EU region accounts) Network blocks for US region accounts: 162.247.240.0/22 Network blocks for EU region accounts: 185.221.84.0/22",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 285.70465,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>User</em>-facing domains",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": " for <em>New</em> <em>Relic</em> One to work properly. Update your allow list to ensure <em>New</em> <em>Relic</em> can communicate with a number of integral domains that are listed in this section. Blocking domains can cause issues with individual <em>product</em> features or prevent pages from loading altogether. This list doesn&#x27;t cover"
      },
      "id": "603eb81364441f64a24e88b6"
    },
    {
      "sections": [
        "Notification of changes to New Relic SaaS features and distributed software",
        "What we communicate",
        "Lead time for notifications",
        "EOL lead times: impact on distributed software",
        "Subject to EOL lead times:",
        "EOL lead times not applicable:",
        "Questions about EOL notifications?"
      ],
      "title": "Notification of changes to New Relic SaaS features and distributed software",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "9a6b696d32c2863811e2df52d736ed2428228a93",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/end-of-life/notification-changes-new-relic-saas-features-distributed-software/",
      "published_at": "2021-12-19T17:26:31Z",
      "updated_at": "2021-12-14T04:01:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we support our customers by continually improving our Software as a Service (SaaS) features and distributed software. Sometimes that means we introduce changes that can include moving away from existing software components and features, called end-of-life (EOL). As we make these decisions, we strive to balance the need to introduce improvements with our customers tolerance for change. We do our best to anticipate the impact of these changes for our customers. What we communicate We're committed to communicating about the changes that impact user experience, especially when these changes have a significant effect on workflow. In assessing impact we evaluate: Potential impact to customer workflow Feature usage information Customer feedback In communicating changes, we strive to: Give as much lead time as possible Minimize interruption Provide a documented alternative Lead time for notifications EOL changes are classified into the following categories: Transition impact Description Notification lead time Low Limited changes to customer processes or procedures are anticipated. None to 90 days Moderate Changes to functionality are limited in scope. Actions such as upgrading retired agents to supported versions may be required. Minimum of 90 days High Changes are highly impactful to customers and will require significant investment from customers to adapt. Minimum of 180 days Critical A third party dependency, security issue, or other critical risk causes an urgent need to change or remove functionality on an accelerated timeline. Notified as soon as reasonably practical EOL lead times: impact on distributed software Subject to EOL lead times: Our lead time notifications also apply to distributed software, which is software developed by New Relic that is installed on customer-owned systems. Distributed software is not cloud-based, and has a lifespan from the date of each released version. After that date, it may cease to function or stop reporting data to New Relic. We have fully open sourced many of our distributed software projects as community projects. We also participate in many community-led software development projects. If we have not open sourced our software projects, or if we have designated them as Community Plus projects, the following timeframes apply to them: Released on or after October 1, 2020: These projects will be compatible with our SaaS offering for at least two years after the date of publishing the release. Released prior to October 1, 2020: These projects will be compatible for at least three years after the date of publishing the release. All fixes and security updates are provided in the latest released version of distributed software, and we encourage our customers to keep installed software up to date. In the event a released version of software will cease normal function sooner than two (or three) years, New Relic will follow the EOL process. EOL lead times not applicable: Some of our distributed software have been open sourced, are designated as such, and are available at github.com/newrelic, including: Community projects New Relic One catalog Example code New Relic experimental Archived Our EOL policy does not apply to these projects, which is why we do not provide advance EOL notification for them. However, you can still find information and support for selected projects through: New Relic's documentation at docs.newrelic.com Project repos at github.com/newrelic Questions about EOL notifications? Share any questions or comments with us in New Relics Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.45013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of changes to <em>New</em> <em>Relic</em> SaaS features <em>and</em> distributed software",
        "sections": "Notification of changes to <em>New</em> <em>Relic</em> SaaS features <em>and</em> distributed software",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": " that is installed on customer-owned systems. Distributed software is not cloud-based, and has a lifespan from the date of each released version. After that date, it may cease to <em>function</em> or stop reporting data to <em>New</em> <em>Relic</em>. We have fully open sourced many of our distributed software projects as community"
      },
      "id": "604454f4e7b9d261f3579a03"
    },
    {
      "sections": [
        "Uninstall New Relic agents",
        "Before you uninstall",
        "Important",
        "Uninstall APM",
        "Remove apps from UI",
        "Uninstall browser agent",
        "Uninstall infrastructure agent",
        "Delete account",
        "Uninstall other tools"
      ],
      "title": "Uninstall New Relic agents",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "15ae05c4370739bb72086bc5bd3ac2e00c438f09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/cross-product-functions/install-configure/uninstall-agent/",
      "published_at": "2021-12-20T13:40:32Z",
      "updated_at": "2021-12-14T03:51:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some New Relic solutions require installation of an agent. You can uninstall the agent if you want it to stop reporting data. If you need to uninstall New Relic completely, follow the procedures for your agent. If you encounter problems, see support.newrelic.com. Before you uninstall Important For paying New Relic accounts, note that an alternative option to uninstalling is to downgrade your account to a less expensive or free tier. Uninstall APM After uninstalling APM agents or making a change to your startup script, you must restart your app (or the app server or web server where it is located). You must do this because New Relic agents typically run in the memory of the process running the app. Simply removing those files will not stop the applications that are currently running from sending data to New Relic. C SDK Go Java .NET Node.js PHP Python Ruby Remove apps from UI See Remove apps from UI. Uninstall browser agent Choose a procedure: Disable browser agent on specific pages Uninstall browser agent Uninstall infrastructure agent Choose a procedure: Uninstall infrastructure agent Uninstall a cloud or on-host integration Delete account See Downgrade/cancel your account. Uninstall other tools For uninstall instructions for solutions not listed here, see the docs for a specific New Relic solution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.40387,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall <em>New</em> <em>Relic</em> agents",
        "sections": "Uninstall <em>New</em> <em>Relic</em> agents",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": "Some <em>New</em> <em>Relic</em> solutions require installation of an agent. You can uninstall the agent if you want it to stop reporting data. If you need to uninstall <em>New</em> <em>Relic</em> completely, follow the procedures for your agent. If you encounter problems, see support.newrelic.com. Before you uninstall Important"
      },
      "id": "61c087d064441fd18799eba6"
    }
  ],
  "/docs/data-apis/custom-data/custom-events/data-requirements-limits-custom-event-data": [
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "17c97a462616f2b23ead796b62780a1ffeb3dfac",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-12-20T02:58:59Z",
      "updated_at": "2021-10-23T21:59:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Agent version Your browser monitoring agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute browser API call To add a custom attribute to the PageView event via the browser agent, use the setCustomAttribute browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.47496,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "65970eacbedb3360fd1c7394affc8cbc42f2ab0c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-12-20T10:04:06Z",
      "updated_at": "2021-10-23T21:59:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default mobile monitoring events using the mobile agent SDKs. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the crash event trail UI. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.47496,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    },
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "8731386e34fbced8d086795e273a1e2392b663ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-12-20T05:44:40Z",
      "updated_at": "2021-10-23T19:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic Universitys tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.43478,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    }
  ],
  "/docs/data-apis/custom-data/custom-events/report-browser-monitoring-custom-events-attributes": [
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "65970eacbedb3360fd1c7394affc8cbc42f2ab0c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-12-20T10:04:06Z",
      "updated_at": "2021-10-23T21:59:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default mobile monitoring events using the mobile agent SDKs. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the crash event trail UI. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.47496,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "77720ef366038ba648a5fbf3cf34e8e48b38440a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T21:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). If the name begins with anything other than an alphabetical character, enclose the name with backticks in your NRQL query. For example: FROM `0_hello` SELECT count(*) Copy Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.4747,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    },
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "8731386e34fbced8d086795e273a1e2392b663ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-12-20T05:44:40Z",
      "updated_at": "2021-10-23T19:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic Universitys tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.43478,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    }
  ],
  "/docs/data-apis/custom-data/custom-events/report-custom-event-data": [
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "8731386e34fbced8d086795e273a1e2392b663ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-12-20T05:44:40Z",
      "updated_at": "2021-10-23T19:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic Universitys tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 825.4071,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: <em>Report</em> <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "sections": "APM: <em>Report</em> <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "tags": "<em>Custom</em> <em>events</em>",
        "body": ". Record <em>custom</em> <em>events</em> and <em>attributes</em> You can add your own <em>custom</em> APM <em>events</em> and <em>attributes</em>, which you can then use for querying and charting. This is one of several ways to <em>report</em> <em>custom</em> data. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> <em>attributes</em>"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "iOS SDK API guide",
        "Caution",
        "Install the SDK",
        "Automatically instrumented classes and methods",
        "Instrument your Objective-C code",
        "Important",
        "Create and complete interactions",
        "Rename a default interaction",
        "Set a custom application version",
        "Set a custom build identifier",
        "Create custom metrics",
        "Objective-C: Report custom attributes and events",
        "Objective-C: Track custom network requests",
        "Instrument your Swift code",
        "Create and complete Swift interactions",
        "Rename a default Swift interaction",
        "Set a custom application version with Swift",
        "Set a custom build identifier with Swift",
        "Create custom metrics with Swift",
        "Swift: Report custom attributes and events",
        "Swift: Track custom network requests"
      ],
      "title": "iOS SDK API guide",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "API guides"
      ],
      "external_id": "211136f4a8e7f940d7f6ef753a1445eaed46bd92",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/ios-sdk-api/ios-sdk-api-guide/",
      "published_at": "2021-12-19T19:53:19Z",
      "updated_at": "2021-11-05T14:07:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the iOS SDK API to add custom data. For example: Instrument your own code. Start and stop interaction traces from events in your mobile app. Record custom metrics. Send custom attributes and events to Insights. Track networking from libraries not supported automatically. Set a custom identifier value with Objective-C or Swift to associate user sessions with analysis events and attributes (iOS SDK version 5.9.0 or higher). Caution Tracing is heavily optimized, but it does impose a performance overhead. Avoid instrumenting methods that are expected to be called hundreds of times. Install the SDK Ensure you have your app instrumented with the latest iOS SDK by going to one.newrelic.com > Add more data and following the instructions for iOS. This document contains the iOS SDK instrumentation requirements for: Objective C Swift For details about the available methods for custom attributes and events you can send to to New Relic Insights, see the iOS SDK API reference. You can also configure feature flags for: Objective-C Swift Automatically instrumented classes and methods The following methods (for the listed classes and their sub-classes) are already instrumented by New Relic. You do not need to add custom instrumentation to trace them. Classes Methods automatically instrumented by New Relic UIViewController viewDidLoad: viewWillAppear: viewDidAppear: viewWillDisappear: viewDidDisappear: viewWillLayoutSubviews: viewDidLayoutSubviews: UIImage imageNamed: imageWithContentsOfFile: imageWithData: imageWithData:scale: initWithContentsOfFile: initWithData: initWithData:scale: NSJSONSerialization JSONObjectWithData:options:error: JSONObjectWithStream:options:error: dataWithJSONObject:options:error: writeJSONObject:toStream:options:error: NSManagedObjectContext executeFetchRequest:error: processPendingChanges The agent aggregates performance for various methods into summary metrics that appear in the Interactions page. Summary categories include: View loading UI layout Database Images JSON Network Instrument your Objective-C code To have your own Objective-C code appear in interaction code breakdowns and timelines, add a _START call to the beginning of your method and a _STOP call to the end of it. Important Always include a _STOP for each _START, and only include one set of these commands in a given method. The trace system will automatically pick up the class and method name, and report performance metrics for your method to New Relic. - (void)myMethod { NR_TRACE_METHOD_START(0); //  existing code NR_TRACE_METHOD_STOP; } Copy If you are not using ARC, use this version of the _STOP macro to avoid memory leaks: NR_NONARC_TRACE_METHOD_STOP; Copy If you want your methods performance to be included in the summary data on the APM Overview page, pass one of the NRTraceType enum values into the _START macro; for example: NR_TRACE_METHOD_START(NRTraceTypeDatabase); Copy Create and complete interactions By default, an interaction starts when a view controller is pushed. To manually start an interaction with Objective-C, use these API calls: NSString* uniqueIdentifier = NR_START_NAMED_INTERACTION(@\"name\"); Copy This macro will automatically begin tracking the name interaction trace from the current line. It will also complete any previously running interaction. It returns a unique identifier that can be used to complete that interaction by using this API call: NR_INTERACTION_STOP(uniqueIdentifier); Copy This macro will complete the interaction associated with the uniqueIdentifier if that interaction has not already completed automatically. You do not need to call this method. Rename a default interaction By default, the iOS agent will start an interaction trace when a new view controller is displayed. The interactions are named using the format Display <ViewController>. To change these default names with Objective-C, implement the - (NSString*) customNewRelicInteractionName instance method in your view controller, where the string returned becomes the interaction's name. Set a custom application version The New Relic iOS SDK allows you to set a custom application version string with Objective-C. Instead of using the string defined in CFBundleShortVersionString, call the +[NewRelic setApplicationVersion:] method and pass along the custom application version before calling +[NewRelic startWithApplicationToken:]; [NewRelic setApplicationVersion:(NSString*) appVersion]; Copy Set a custom build identifier As of version 5.1.0 of the New Relic iOS SDK, an API method allows you to set a custom build identifier that is displayed next to the application version in the Crash details page. Instead of using the CFBundleVersion string defined in Xcode with Objective-C, call the +[NewRelic setApplicationBuild:] method, and pass along the custom build identifier. [NewRelic setApplicationBuild:(NSString*) buildNumber]; Copy Create custom metrics Custom metrics can help track high level events specific to your application. With the recordMetric API, you can record arbitrary numerical data and named events with Objective-C and Swift. You can also use several API calls to record custom metrics that provide different levels of detail. Objective-C: Report custom attributes and events Use methods in the NewRelic object to report custom attributes and events. For details about the available methods for custom attributes and events with Objective-C, see the iOS SDK API reference. Methods that return BOOL results return YES if they succeed, or NO if the operation did not complete. These methods are available in versions 5.0.0 or higher of the New Relic iOS SDK. The SDK can store up to 128 user-defined custom attributes at a time. If you attempt to store more than 128 attributes, the SDK returns NO. Custom attributes names should use the simplest format needed, and New Relic recommends single word attributes, containing no spaces. Attribute phrases can be formatted in camel case, so My Custom Attribute is better specified as myCustomAttribute. As with custom metrics: Avoid using the characters / ] [ | * when naming things. Avoid multi-byte characters. Objective-C: Track custom network requests If you can express a transactional network request in terms similar to an HTTP request, you can track it. Use URLs that are well-formed and do not include highly variable paths or hostnames. For requests that complete, use this method: [NewRelic noticeNetworkRequestForURL:(NSURL*)url httpMethod:(NSString*)httpMethod withTimer:(NRTimer *)timer responseHeaders:(NSDictionary *)headers statusCode:(NSInteger)httpStatusCode bytesSent:(NSUInteger)bytesSent bytesReceived:(NSUInteger)bytesReceived responseData:(NSData *)responseData andParams:(NSDictionary *)params]; Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request headers A dictionary containing the HTTP response headers, if available httpStatusCode The response status code If the httpStatusCode is greater than or equal to 400, the agent will record a server error and may capture the responseData body if provided. bytesSent The size of the request body bytesReceived The size of the responseBody responseData The response body data, captured if the agent records server error params params Additional parameters included in an HTTP error metric if the HTTP transaction is an error For requests that fail due to a socket or operating system error, use this method: [NewRelic noticeNetworkFailureForURL:(NSURL *)url httpMethod:(NSString*)httpMethod withTimer:(NRTimer *)timer andFailureCode:(NSInteger)iOSFailureCode]; Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request iOSFailureCode The failure code Failure codes are interpreted as NSURLError* code. To view a complete list of supported codes, see NRConstants.h. Instrument your Swift code To have your own Swift code appear in interaction code breakdowns and timelines: Add a startTracingMethod() call to the beginning of your method. Add a endTracingMethodWithTimer() call to the end of it. Always include an endTracingMethodWithTimer() call for each startTracingMethod() reference. Include only one set of these commands in a given method. func myMethod(){ let timer = NRTimer(); NewRelic.startTracingMethod(#selector(MyClass.myMethod), object: self, timer: timer, category: NRTraceTypeNone) //  existing code NewRelic.endTracingMethodWithTimer(timer) } Copy If you want your methods performance to be included in the summary data on the APM Overview page, pass one of the NRTraceType enum values into the startTracingMethod() macro; for example: NewRelic.startTracingMethod(#selector(MyClass.myMethod), object: self, timer: timer, category: NRTraceTypeDatabase) Copy Create and complete Swift interactions By default, an interaction starts when a view controller is pushed. To manually start an interaction, use these API calls: let uniqueIdentifier = NewRelic.startInteraction(withName: \"My Interaction\") Copy This call will automatically begin tracking an interaction trace named My Interaction from the current line. It will also complete any previously running interaction. It returns a unique identifier that can be used to complete that interaction by using this API call: NewRelic.stopCurrentInteraction(uniqueIdentifier) Copy This method will complete the interaction associated with the uniqueIdentifier if that interaction has not already completed automatically. You do not need to call this method. Rename a default Swift interaction By default, the iOS agent will start an interaction trace when a new view controller is displayed. The interactions are named using the format Display <ViewController>. To change these default names, implement the @objc func customNewRelicInteractionName() -> String method in your view controller, where the string returned becomes the interaction's name. Set a custom application version with Swift The New Relic iOS SDK allows you to set a custom application version string. Instead of using the string defined in CFBundleShortVersionString, call the NewRelic.setApplicationVersion() method, and pass along the custom application version before calling NewRelic.startWithApplicationToken();. NewRelic.setApplicationVersion(String appVersion) Copy Set a custom build identifier with Swift As of version 5.1.0 of the New Relic iOS SDK, an API method allows you to set a custom build identifier that is displayed next to the application version in the Crash details page. Instead of using the CFBundleVersion string defined in Xcode, call the NewRelic.setApplicationBuild() method, and pass along the custom build identifier. NewRelic.setApplicationBuild(buildNumber) Copy Create custom metrics with Swift Custom metrics can help track high level events specific to your application. With the recordMetric API, you can record arbitrary numerical data and named events with Objective-C and Swift. You can also use several API calls to record custom metrics that provide different levels of detail. Swift: Report custom attributes and events Use methods in the NewRelic object to report custom attributes and events. For details about the available methods for custom attributes and events with Swift, see the iOS SDK API reference. Methods that return BOOL results return YES if they succeed, or NO if the operation did not complete. These methods are available in versions 5.0.0 or higher of the New Relic iOS SDK. The SDK can store up to 128 user-defined custom attributes at a time. If you attempt to store more than 128 attributes, the SDK returns NO. Custom attributes names should use the simplest format needed, and New Relic recommends single word attributes, containing no spaces. Attribute phrases can be formatted in camel case, so My Custom Attribute is better specified as myCustomAttribute. As with custom metrics: Avoid using the characters / ] [ | * when naming things. Avoid multi-byte characters. Swift: Track custom network requests If you can express a transactional network request in terms similar to an HTTP request, you can track it. Use URLs that are well-formed and do not include highly variable paths or hostnames. For requests that complete, use this method: NewRelic.noticeNetworkRequestForURL(url: NSURL!, httpMethod: String!, withTimer: NRTimer!, responseHeaders:[NSObject : AnyObject]!, statusCode: Int, bytesSent: UInt, bytesReceived: UInt, responseData: NSData!, andParams: [NSObject : AnyObject]!) Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request headers A dictionary containing the HTTP response headers, if available httpStatusCode The response status code If the httpStatusCode is greater than or equal to 400, the agent will record a server error and may capture the responseData body if provided. bytesSent The size of the request body bytesReceived The size of the responseBody responseData The response body data, captured if the agent records Server error params params Additional parameters included in an HTTP error metric if the HTTP transaction is an error For requests that fail due to a socket or operating system error, use this method: NewRelic.noticeNetworkFailureForURL(url: NSURL!, httpMethod: NSString!, withTimer: NRTimer!, andFailureCode: Int) Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request iOSFailureCode The failure code Failure codes are interpreted as NSURLError* code. To view a complete list of supported codes, see NRConstants.h.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 349.06934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Objective-C: <em>Report</em> <em>custom</em> <em>attributes</em> <em>and</em> <em>events</em>",
        "body": ". You can also use several API calls to record <em>custom</em> metrics that provide different levels of detail. Objective-C: <em>Report</em> <em>custom</em> <em>attributes</em> and <em>events</em> Use methods in the NewRelic object to <em>report</em> <em>custom</em> <em>attributes</em> and <em>events</em>. For details about the available methods for <em>custom</em> <em>attributes</em> and <em>events</em>"
      },
      "id": "619e9c2128ccbcbf64b9abeb"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "17c97a462616f2b23ead796b62780a1ffeb3dfac",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-12-20T02:58:59Z",
      "updated_at": "2021-10-23T21:59:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Agent version Your browser monitoring agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute browser API call To add a custom attribute to the PageView event via the browser agent, use the setCustomAttribute browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.01596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Report</em> browser monitoring <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "sections": "<em>Report</em> browser monitoring <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "tags": "<em>Custom</em> <em>events</em>",
        "body": " to run and <em>report</em> relevant PageAction <em>events</em>. Run a NRQL query of the PageAction <em>event</em> that includes the actionName attribute you used to capture the <em>event</em> (and any associated <em>attributes</em> you sent along with the action). Add <em>custom</em> <em>attributes</em> to PageView <em>event</em> The PageView <em>event</em> is a default browser"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    }
  ],
  "/docs/data-apis/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes": [
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "17c97a462616f2b23ead796b62780a1ffeb3dfac",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-12-20T02:58:59Z",
      "updated_at": "2021-10-23T21:59:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Agent version Your browser monitoring agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute browser API call To add a custom attribute to the PageView event via the browser agent, use the setCustomAttribute browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.47495,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "77720ef366038ba648a5fbf3cf34e8e48b38440a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T21:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). If the name begins with anything other than an alphabetical character, enclose the name with backticks in your NRQL query. For example: FROM `0_hello` SELECT count(*) Copy Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.47469,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    },
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "8731386e34fbced8d086795e273a1e2392b663ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-12-20T05:44:40Z",
      "updated_at": "2021-10-23T19:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic Universitys tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.43478,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    }
  ],
  "/docs/data-apis/custom-data/intro-custom-data": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/report-custom-event-data/",
      "sections": [
        "Report custom events and attributes",
        "Requirements",
        "Avoid rate limits",
        "Example use cases",
        "Using custom attributes",
        "Using custom events",
        "Send custom events and attributes",
        "Extend data retention"
      ],
      "published_at": "2021-12-20T05:22:32Z",
      "title": "Report custom events and attributes",
      "updated_at": "2021-10-23T21:59:19Z",
      "type": "docs",
      "external_id": "ff7b6544c9a15b49f77c4d86f69c66949c45cb87",
      "document_type": "page",
      "popularity": 1,
      "body": "One of the ways to report custom data to New Relic is with custom events and attributes. Have questions about why you'd use custom data? See Introduction to custom data. Requirements For event and attribute formatting requirements and best practices, see Limits and requirements. Avoid rate limits Reporting a large number of custom events and/or attributes can cause degraded query performance. It may also result in approaching or passing data collection rate limits. For optimal performance, first think about what data you want to analyze, and then create only the events and/or attributes necessary to meet these specific goals. Be aware of the following data and subscription requirements for inserting and accessing custom data: Ensure you follow limits and requirements around event/attribute data types, naming syntax, and size. The amount of data you have access to over time depends on your data retention policy. Example use cases Two popular custom data solutions are custom events and custom attributes. There are several ways to accomplish this (more on that later in this doc), depending on your New Relic implementation and tools. Here are some common use cases for implementing custom events and attributes. Using custom attributes Custom attributes are often used to add important business and operational context to existing events. Business context might include: Customer token Customer market segment Customer value classification Workflow control values not obvious in the URIStem User/product/account privilege context Operational context might include: Which feature flags were used What datastore was accessed What cache was accessed What errors were detected and ignored (fault partitioning) Using custom events Event data is one of New Relic's four core data types. We recommend reading that definition to understand what we mean by \"event\" and why that data type is most used for reporting specific types of activity. The use cases for custom events varies widely: basically they are used for any type of activity that an organization deems important and that is not already being monitored. A couple examples: An event might represent an activity involving multiple actions, like a customer purchasing a certain combination of products. An event might record backup activity. For example, they might set up reporting of events that represent production backups of their SOLR instances into an event table, with a timestamp of when it occurred, which cluster, and the duration. Send custom events and attributes Methods for sending custom events and attributes include: Source How to send custom data APM agent Use APM agent APIs to report custom events and custom attributes. Browser monitoring agent Add custom attributes to the PageView event via the browser API call addCustomAttribute. Send PageAction event and attributes via browser API. Forward APM agent custom attributes to PageView event. Event API To report custom events not associated with other New Relic products, use the Event API. Infrastructure monitoring agent Add custom attributes to default Infrastructure events. Use the Flex integration tool to report your own custom event data. Mobile monitoring agent Use the mobile agent API to send custom events and attributes. Synthetic monitoring Add custom attributes to the SyntheticCheck event via the $util.insights tools. For ways to report other types of custom data, see: Metric API Logs Trace API Extend data retention To learn how to extend how long events are retained in your account, see our documentation about event data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 539.88904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report <em>custom</em> events and attributes",
        "sections": "Report <em>custom</em> events and attributes",
        "body": "One of the ways to report <em>custom</em> <em>data</em> to New Relic is with <em>custom</em> events and attributes. Have questions about why you&#x27;d use <em>custom</em> <em>data</em>? See <em>Introduction</em> to <em>custom</em> <em>data</em>. Requirements For event and attribute formatting requirements and best practices, see Limits and requirements. Avoid rate limits"
      },
      "id": "609fa5fb64441f9ebfd2a1db"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "17c97a462616f2b23ead796b62780a1ffeb3dfac",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-12-20T02:58:59Z",
      "updated_at": "2021-10-23T21:59:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Agent version Your browser monitoring agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute browser API call To add a custom attribute to the PageView event via the browser agent, use the setCustomAttribute browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 73.369705,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> events and attributes",
        "sections": "Forward <em>custom</em> attributes from APM <em>data</em>",
        "tags": "Event <em>data</em> sources",
        "body": " that contains the action name and any <em>custom</em> attribute names and values you capture along with it. The PageAction event also contains any <em>custom</em> attributes you added to the PageView event. Add <em>custom</em> attributes to the PageView event so you can query or filter your <em>data</em> to answer more questions about your"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "65970eacbedb3360fd1c7394affc8cbc42f2ab0c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-12-20T10:04:06Z",
      "updated_at": "2021-10-23T21:59:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default mobile monitoring events using the mobile agent SDKs. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the crash event trail UI. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 73.369705,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> events and attributes",
        "sections": "Set the time <em>to</em> send <em>data</em>",
        "tags": "Event <em>data</em> sources",
        "body": "Mobile monitoring in New Relic sends some default event <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and events for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    }
  ],
  "/docs/data-apis/get-started/nrdb-horsepower-under-hood": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.3284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of API client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Introduction to the Metric API",
        "What is the Metric API?",
        "Requirements",
        "Get started",
        "Find and use your data",
        "Alert on metric data",
        "Data retention",
        "Troubleshooting"
      ],
      "title": "Introduction to the Metric API",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "3d1e1c9bdb5d2cbf172eb055dc83020e39dbd16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/introduction-metric-api/",
      "published_at": "2021-12-20T10:04:06Z",
      "updated_at": "2021-12-04T14:16:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Metric API can be used to send metric data to New Relic from a variety of sources. This API is how metrics from some of our integrations and exporters get into New Relic. Want to try out our Metric API? Create a New Relic account for free! No credit card required. What is the Metric API? The Metric API is a way to get metric data into New Relic. The API works by sending a POST request to our HTTP endpoint with a JSON payload containing the metric data. The Metric API is how metrics are ingested from some of our integrations, including our open source exporters (like DropWizard and Prometheus). The Metric API is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our data-ingest APIs. The Metric API can be used to: Report metric data to New Relic without a New Relic agent. Integrate metric data from an open source or in-house developed tool, library, or framework. Fully control the metric data you're sending, including the resolution and associated dimensions. Leverage the power of NRQL, New Relic's query language, for querying your metric data. Set up alerts for your metric data. Requirements Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name metric-api.newrelic.com or metric-api.eu.newrelic.com. You'll need a New Relic license key for the New Relic account you want to send data to. For information on limits and restricted attributes, see Metric API requirements and limits. Get started If we don't have an existing integration or quickstart that meets your metric-reporting needs, you have two options: Use our Telemetry SDKs, which are language-specific tools that help you send us metrics and other data. Use the Metric API directly. Find and use your data You can find data sent via the Metric API (including from integrations that use this API) in these locations: From one.newrelic.com, select Explorer and look for your service. By querying the Metric data type. For example, you can use NRQL to run: SELECT * FROM Metric Copy For more on querying, see Metric query examples. For information on querying in general, see Query data. Alert on metric data To alert on metrics created with the Metric API, use NRQL alert conditions: Select the NRQL category when defining your condition, then use the FROM Metric ... NRQL query syntax to express it. When you create these alert conditions, Alerts automatically uses the finest granularity data available (the raw metric data points) to evaluate alerts. Data retention All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Troubleshooting See Troubleshoot an NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.70667,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " and restricted attributes, see Metric API requirements and limits. <em>Get</em> <em>started</em> If we don&#x27;t have an existing integration or quickstart that meets your metric-reporting needs, you have two options: Use our Telemetry SDKs, which are language-specific tools that help you send us metrics and other <em>data</em>. Use"
      },
      "id": "6107858fe7b9d2f9dcfc108e"
    },
    {
      "sections": [
        "New Relic data types",
        "Get started",
        "Tip",
        "Metrics",
        "Metrics in the monitoring industry",
        "Metrics at New Relic",
        "Dimensional metrics (used by Metric API and many integrations)",
        "Metric timeslice data (used by APM, browser, mobile)",
        "Metric timeslice examples",
        "Metrics attached to events (used by Infrastructure, other products)",
        "Metrics as a computation of events (used in some charts and queries)",
        "Event data",
        "Events in the monitoring industry",
        "Events at New Relic",
        "Log data",
        "Logs in the monitoring industry",
        "Logs at New Relic",
        "Trace data",
        "Tracing in the monitoring industry",
        "Tracing at New Relic",
        "Query and send data",
        "Learn more"
      ],
      "title": "New Relic data types",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "8e4ab82bb58db47bc412f57231d4956c6068262b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/new-relic-data-types/",
      "published_at": "2021-12-19T15:32:43Z",
      "updated_at": "2021-12-04T21:48:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform is built around the four fundamental telemetry data types we believe are necessary for complete and effective system monitoring: metrics, events, logs, and traces. After you sign up for a free New Relic account and install any of our monitoring services, you can start working with your data. Get started This doc will give you a fairly technical explanation of our core data types, their structure, and how they're used in our features. You can use most of our features without needing to understand the underlying data structure. But having a better understanding of this can help you get data into New Relic, understand the data you see in our UI, and query your data. For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types. Another good way to understand your data is to just start querying it. Tip Access your data easily on one.newrelic.com: Click the Browse data dropdown menu and select the data type (metrics, events, logs, and traces) you want to explore. Metrics First, well explain the definition of metrics from a monitoring industry perspective, and then well explain how New Relic handles metrics. For a list of the metrics we collect, see our documentation on metrics. Metrics in the monitoring industry In the software monitoring industry, a metric means a numeric measurement of an application or system. Metrics are typically reported on a regular schedule. Two major types of metrics are: Aggregated data. For example: a count of events over one minutes time, or the rate of some event per minute. A numeric status at a moment in time. For example: a CPU temperature reading, or a CPU% used status. Metrics are relatively easy to report and store because a single record can represent a range of time. They can also be aggregated more and more over time. For example, per-minute data may be rolled up to per-hour aggregations after some amount of time, and eventually may be rolled up to a per-day aggregation. This approach is efficient for long-term data storage. Metrics are a strong solution for storing data long-term, and understanding trends over time. One potential downside is that it can be difficult to do detailed analysis of older data that has been aggregated over time; when high detail is required about specific important actions, event data can be used. Metrics at New Relic Conceptually, \"metrics\" is a broad, general category. There are various ways New Relic measures and reports metrics but, in practice, when using the New Relic UI, you usually won't have to understand how exactly this happens. In our documentation, we typically will just refer to \"metrics,\" regardless of how that data is reported, unless there's a reason you need to know more (like understanding how to query your data). Here are some of the ways metrics are reported and stored across the New Relic platform: Dimensional metrics (used by Metric API and many integrations) In the monitoring industry, \"dimensional\" metrics refer to metric data that has a variety of attributes (dimensions) attached, such as duration-related attributes (start time, end time), entity ID, region, host, etc. This amount of detail allows for in-depth analysis and querying. At New Relic, this metric data is attached to the Metric data type and is sent from several sources: Some open-source integrations, such as the Prometheus exporter. Our Telemetry SDKs Infrastructure services The Metric API (the underlying API used by the above tools) The events-to-metrics service To query this data and see its attributes (\"dimensions\"), you could use a NRQL query like: Select * from Metric Copy As time passes, these metrics are increasingly aggregated into larger time buckets. This is done to optimize your ability to query data over a long period of time. For more details about the metric data type, see our docs. To learn how this data is ingested and stored, see the Metric API documentation. For tips on querying, see Metric query examples. Metric timeslice data (used by APM, browser, mobile) New Relic's APM, browser, and mobile report and display metrics in a simple data format that we refer to as metric timeslice data. A metric timeslice consists of three parts: a metric name, the segment of time the metric represents (the \"timeslice\"), and a numeric value (the measurement). For example: an APM metric timeslice for time spent in a particular transaction is named WebTransaction/URI/foo, and might have a response time of 0.793 for a one-minute time slice from 10:20am to 10:21am. These metrics usually follow a pattern like <category>/<class>/<method>. Our agents (APM, browser, and mobile) can collect thousands of metric timeslices per minute for a variety of performance metrics. For example: error rate, bandwidth usage, and garbage collection time. You also have the ability to create custom metrics. Metric timeslice data is a lightweight data type and lacks the detail that dimensional metrics have. Ways to explore and query metric timeslice data: For APM: metric timeslice data is converted to dimensional metrics and can be queried via NRQL Use the REST API If you want to learn more about the structure of metric timeslice data and see some examples, expand the collapser below. Metric timeslice examples Here are some common metric timeslice data examples, with a focus on common ones used by Ruby applications. ActiveMerchant New Relic tracks a variety of metrics on ActiveMerchant transactions which can be used for business analytics as well as performance monitoring. The metrics are summarized by operation as well as by gateway. regex sample metric legend name ActiveMerchant/. * ActiveMerchant/PayJunctionGateway ActiveMerchant/gateway/. * ActiveMerchant/gateway/PayJunctionGateway/purchase PayJunctionGateway ActiveMerchant/operation/. * ActiveMerchant/operation/purchase purchase For more information, see the ActiveMerchant website. ActiveRecord ActiveRecord is the Object-Relational Mapping API used by Ruby on Rails applications. The metrics shown here measure the performance of ActiveRecord's find and save methods. regex sample metric legend name ActiveRecord/. * /find ActiveRecord/User/find User#find ActiveRecord/. * /save ActiveRecord/Product/save Product#save For more information, see the API documentation for ActiveRecord. Apdex Apdex is a measure of user satisfaction with page load times. Controller In Ruby on Rails applications, HTTP requests are handled by Controller actions. A Rails application has many controllers, each of which has one or more actions. When your rails application receives an http request, that request is routed to the appropriate controller and action, based on the URL of that request. That action then does whatever processing is neccesary to generate an http response, which is most often a web page, but could also be a page fragment, an xml document, or any other kind of data that is requested by the client. The following metrics track the performance of controller actions, regardless of routing, and without taking into account any network or web server effects. regex sample metric legend name Controller/. * Controller/Users/show /Users/show Controller/. * /(?! \\ (other \\ )). * Controller/Users/show /Users/show Controller$ Controller All Controller Actions ControllerCPU/ ControllerCPU/Users/Show /Users/show For more information, see the API documentation for ActionController. Errors This metric tracks the number of errors or exceptions raised while processing requests. regex sample metric legend name Errors/all Errors/all External services External service instrumentation captures calls to out-of-process services such as web services, resources in the cloud and any other network calls. It does not include other first class back-end components such as MemCache and the database. In Ruby applications we instrument the Net::Http library to capture all HTTP services. regex sample metric legend name External/ [ ^/]+/all$ External/service.example.com/all All service.example.com calls External/ External/host.aws.com/Net::Http : :POST Net::Http : :POST [ host.aws.com] External/all$ External/all External Services External/ [ ^/]+/(?!all)/ External/service.example.com/all All service.example.com calls HTTP dispatcher This metric represents a summary of the throughput and response time of all web requests. regex sample metric legend name ^HttpDispatcher$ HttpDispatcher HttpDispatcher MemCache MemCache is a popular technology that enables applications to access shared memory provided by any number of physical machines as a global cache. Applications that heavily use the database often use MemCache for performance and scalability benefits. These metrics measure the frequency and response time of calls to MemCache to read and write data from the cache. Response times should be low (less than 5 ms) for a well performing MemCache deployment. regex sample metric legend name MemCache/. * MemCache/read MemCache read operations MemCache/read MemCache/read MemCache read operations MemCache/write MemCache/write MemCache write operations Mongrel This metric measures the length of the mongrel queue, which holds pending http requests to be processed by mongrel. The HTTP Activity graph overlays the maximimum queue length for a given period. The value is zero if mongrel is processing a request but has no other requests waiting in its queue. When looking at this value across an aggregate cluster of mongrels, the queue lengths of all mongrels is added together, showing the sum of all queue lengths. A mongrel queue length should be at or near zero; if it is consistently at a higher level, then it indicates that your rails application is having trouble keeping up with its load requirements. regex sample metric legend name Mongrel/Queue Length Mongrel/Queue Length Queue Length View ActionView is a package in Rails that is used to render the output that is the response to an http request, such as an html page or an xml document. The View is rendered by the controller that is handling the request. If View metrics represent a large portion of your controller's response time, it could mean you are doing a lot of database operations inside the view template itself. regex sample metric legend name View/. * View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Partial View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Rendering View/Users/show.html.erb/Rendering Users/show.html.erb For more information, see the API documentation for ActionView. Metrics attached to events (used by Infrastructure, other products) Because event-type data can have any type of key-value pair data attached to it, one way metrics can be reported is as attributes attached to an event. A couple examples of this at New Relic: Our infrastructure monitoring reports many metrics that are attached to events. For example, we report a ProcessSample event, which has various sample-based metrics attached to it, like CPU percentage. To learn more about infrastructure monitoring data, see Infrastructure data. In APM, the Transaction event has several metrics attached to it, including databaseDuration. To learn more about this data and how to query it, see Events. Metrics as a computation of events (used in some charts and queries) Metrics can be formed by counting New Relic events, or doing some other mathematical calculation on those events. For example, if you wanted to measure the total number of Transaction events over the last half hour, you might run this NRQL query: Select count(*) from Transaction since 30 minutes ago Copy Another example: if you wanted to compute the average response time for your service, you might run a query like: FROM Transaction SELECT average(duration) SINCE 30 minutes ago Copy Some New Relic charts are generated with these kinds of queries. The downside of this approach is that there are limits on how many events a monitoring system (including ours) can report. This means that sometimes, for high-throughput systems, the count may not accurately represent the total activity on that system. To learn more about how this can be addressed, see Event limits and sampling. Want to report custom metrics? See Get data into New Relic. Event data First, well explain the definition of events from a monitoring industry perspective, and then well explain some specifics about how New Relic handles event data. Events in the monitoring industry In the software industry, events can be thought of as simply things that occur in a system. For example, a server setting being changed would be an event. Another example: a website user clicking a mouse. Some events will generate a stored record, and that record is typically also called an event. Event data represents discrete occurrences and typically will have a high level of detail, so event data is suited for detailed analysis and querying. The downside to the use of event data is that there are typically so many events reported that it can become difficult to query that large dataset over longer time ranges. Events at New Relic At New Relic, we report events to data objects also called events. These events have multiple attributes (key-value pairs) attached. Event data is used in some UI charts and tables, and you can also query it. How long event data remains available is determined by data retention rules. One example of an event: APM reports an event type named Transaction, which represents a logical unit of work in an application. To see the attributes attached to this event, you could use a NRQL query like: Select * from Transaction Copy For examples of querying event data, see Introduction to NRQL. Other details about New Relic event data: Events can have any type of attributes attached. Some events have attributes that report metric data. You can report custom events. To increase the availability of your event data for querying/charting, you can turn events into metrics. Some systems generate a large number of events that exceeds collection limits and results in incomplete query results. For more on this, see Event sampling. Because event is a general term, in some New Relic contexts it will refer to any data type that can be queried via NRQL. For example, when you run a NRQL query, it returns a count of inspected events: this is a count of all data types queried. Log data First, well explain the definition of logs from a monitoring industry perspective, and then well explain some specifics about how New Relic handles log reporting. Logs in the monitoring industry A log is a message about a system used to understand the activity of the system and to diagnose problems. Logs at New Relic New Relic's Logs gives you a centralized log management platform that connects your log data with other New Relic-monitored data. For example, you can see logs alongside your APM data. In New Relic, log data is reported with multiple attributes (key-value data) attached. To query your log data, you could use a NRQL query like: Select * from Log Copy To report custom log data, see the Log API. Trace data First, well explain the definition of traces from a monitoring industry perspective, and then well explain some specifics about how New Relic handles tracing. Tracing in the monitoring industry In the application/infrastructure-monitoring world, tracing is a general term used to refer to various ways to report information about how a program or system is operating. For example, a stack trace provides in-depth information about a programs subroutines. For large modern systems, which are often distributed across many services and micro-services, tracing often refers to distributed tracing, which is a way to monitor requests as they propagate through a complex, distributed environment. Tracing at New Relic New Relic offers a distributed tracing feature that tracks requests across a distributed system, and provides a dedicated UI for understanding and analyzing your traces. In New Relic, trace data is reported as Span objects, with multiple attributes (key-value pairs) attached. To query your tracing data, you could use a NRQL query like: Select * from Span Copy To learn more about how distributed tracing works, see Understand distributed tracing. To report custom distributed tracing data, see the Trace API. Query and send data Understanding New Relic data types can help you: Query data in New Relic Send data to New Relic Learn more For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.14459,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>data</em> types",
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " with your <em>data</em>. <em>Get</em> <em>started</em> This doc will give you a fairly technical explanation of our core <em>data</em> types, their structure, and how they&#x27;re used in our features. You can use most of our features without needing to understand the underlying <em>data</em> structure. But having a better understanding"
      },
      "id": "6045280de7b9d266e1579a0f"
    }
  ],
  "/docs/data-apis/ingest-apis/introduction-event-api": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.46368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of <em>API</em> client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> <em>APIs</em>: the Metric <em>API</em>, Trace <em>API</em>, Log <em>API</em>, and Event <em>API</em>. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Introduction to the Metric API",
        "What is the Metric API?",
        "Requirements",
        "Get started",
        "Find and use your data",
        "Alert on metric data",
        "Data retention",
        "Troubleshooting"
      ],
      "title": "Introduction to the Metric API",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "3d1e1c9bdb5d2cbf172eb055dc83020e39dbd16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/introduction-metric-api/",
      "published_at": "2021-12-20T10:04:06Z",
      "updated_at": "2021-12-04T14:16:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Metric API can be used to send metric data to New Relic from a variety of sources. This API is how metrics from some of our integrations and exporters get into New Relic. Want to try out our Metric API? Create a New Relic account for free! No credit card required. What is the Metric API? The Metric API is a way to get metric data into New Relic. The API works by sending a POST request to our HTTP endpoint with a JSON payload containing the metric data. The Metric API is how metrics are ingested from some of our integrations, including our open source exporters (like DropWizard and Prometheus). The Metric API is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our data-ingest APIs. The Metric API can be used to: Report metric data to New Relic without a New Relic agent. Integrate metric data from an open source or in-house developed tool, library, or framework. Fully control the metric data you're sending, including the resolution and associated dimensions. Leverage the power of NRQL, New Relic's query language, for querying your metric data. Set up alerts for your metric data. Requirements Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name metric-api.newrelic.com or metric-api.eu.newrelic.com. You'll need a New Relic license key for the New Relic account you want to send data to. For information on limits and restricted attributes, see Metric API requirements and limits. Get started If we don't have an existing integration or quickstart that meets your metric-reporting needs, you have two options: Use our Telemetry SDKs, which are language-specific tools that help you send us metrics and other data. Use the Metric API directly. Find and use your data You can find data sent via the Metric API (including from integrations that use this API) in these locations: From one.newrelic.com, select Explorer and look for your service. By querying the Metric data type. For example, you can use NRQL to run: SELECT * FROM Metric Copy For more on querying, see Metric query examples. For information on querying in general, see Query data. Alert on metric data To alert on metrics created with the Metric API, use NRQL alert conditions: Select the NRQL category when defining your condition, then use the FROM Metric ... NRQL query syntax to express it. When you create these alert conditions, Alerts automatically uses the finest granularity data available (the raw metric data points) to evaluate alerts. Data retention All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Troubleshooting See Troubleshoot an NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.18839,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Metric <em>API</em>",
        "sections": "Find <em>and</em> use your <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " and Prometheus). The Metric <em>API</em> is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our <em>data</em>-<em>ingest</em> <em>APIs</em>. The Metric <em>API</em> can be used to: Report metric <em>data</em> to New Relic without a New Relic agent. Integrate metric <em>data</em> from an open source or in-house"
      },
      "id": "6107858fe7b9d2f9dcfc108e"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "50ad21a895fc1f2644bdbfbadf85ecfd298b08d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-12-20T10:04:56Z",
      "updated_at": "2021-10-23T17:26:33Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responsesfrom the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details For an introduction to using the NrIntegrationError event, see NrIntegrationError. Here's an example NRQL for examining issues with Metric API ingest: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature = 'Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When an NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCOUNT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.2369,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " To programmatically retrieve these errors: Ensure you have an Insights query <em>API</em> key (go to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H"
      },
      "id": "610f2900196a678a5d38ad82"
    }
  ],
  "/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesnt support its use or that hasnt used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hours worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 334.02502,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-12-20T01:38:19Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.13962,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": "One way to <em>query</em> <em>your</em> <em>New</em> <em>Relic</em> <em>data</em> is with the <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>). This resource explains what <em>NRQL</em> is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see <em>NRQL</em> syntax"
      },
      "id": "60445a0e196a67cb09960f6e"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "BETA FEATURE",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-12-19T20:59:14Z",
      "updated_at": "2021-09-14T20:46:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.91824,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits"
      },
      "id": "603e95e8e7b9d286642a07fa"
    }
  ],
  "/docs/data-apis/ingest-apis/metric-api/introduction-metric-api": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.4635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of <em>API</em> client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> <em>APIs</em>: the Metric <em>API</em>, Trace <em>API</em>, Log <em>API</em>, and Event <em>API</em>. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Requirements",
        "Basic workflow",
        "Tip",
        "Get the license key",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Important",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "eea369c63a48d26123e243ed4e8bff412b334146",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/introduction-event-api/",
      "published_at": "2021-12-19T14:36:31Z",
      "updated_at": "2021-10-23T17:26:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Want to try out our Event API? Create a New Relic account for free! No credit card required. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic Universitys tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.newrelic.com or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to a New Relic account: Get a license key for the account you want to report data to. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Get the license key You'll need a license key. License keys are associated with an account, not a specific user. This means that anyone in the account with access to that key can use it. You can submit multiple event types to the same account with the same license key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. Alternatively, you can use an Insights insert keyfor this API, but we recommend using a license key. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"Api-Key: YOUR_LICENSE_KEY\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_LICENSE_KEY\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"Api-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The Api-Key contains the correct license key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, create a NRQL query of your data to verify it's available. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid key: Invalid license key. Register a valid license key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To get alerts for parsing errors, create a NRQL alert condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the license key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.2369,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Event <em>API</em>",
        "sections": "Introduction to the Event <em>API</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "The New Relic Event <em>API</em> is one way to report custom events to New Relic. The Event <em>API</em> lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Want to try out our Event <em>API</em>? Create a New Relic account for free"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "50ad21a895fc1f2644bdbfbadf85ecfd298b08d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-12-20T10:04:56Z",
      "updated_at": "2021-10-23T17:26:33Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responsesfrom the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details For an introduction to using the NrIntegrationError event, see NrIntegrationError. Here's an example NRQL for examining issues with Metric API ingest: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature = 'Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When an NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCOUNT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.23688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " To programmatically retrieve these errors: Ensure you have an Insights query <em>API</em> key (go to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H"
      },
      "id": "610f2900196a678a5d38ad82"
    }
  ],
  "/docs/data-apis/ingest-apis/metric-api/metric-api-limits-restricted-attributes": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.46332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of <em>API</em> client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> <em>APIs</em>: the Metric <em>API</em>, Trace <em>API</em>, Log <em>API</em>, and Event <em>API</em>. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Introduction to the Metric API",
        "What is the Metric API?",
        "Requirements",
        "Get started",
        "Find and use your data",
        "Alert on metric data",
        "Data retention",
        "Troubleshooting"
      ],
      "title": "Introduction to the Metric API",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "3d1e1c9bdb5d2cbf172eb055dc83020e39dbd16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/introduction-metric-api/",
      "published_at": "2021-12-20T10:04:06Z",
      "updated_at": "2021-12-04T14:16:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Metric API can be used to send metric data to New Relic from a variety of sources. This API is how metrics from some of our integrations and exporters get into New Relic. Want to try out our Metric API? Create a New Relic account for free! No credit card required. What is the Metric API? The Metric API is a way to get metric data into New Relic. The API works by sending a POST request to our HTTP endpoint with a JSON payload containing the metric data. The Metric API is how metrics are ingested from some of our integrations, including our open source exporters (like DropWizard and Prometheus). The Metric API is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our data-ingest APIs. The Metric API can be used to: Report metric data to New Relic without a New Relic agent. Integrate metric data from an open source or in-house developed tool, library, or framework. Fully control the metric data you're sending, including the resolution and associated dimensions. Leverage the power of NRQL, New Relic's query language, for querying your metric data. Set up alerts for your metric data. Requirements Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name metric-api.newrelic.com or metric-api.eu.newrelic.com. You'll need a New Relic license key for the New Relic account you want to send data to. For information on limits and restricted attributes, see Metric API requirements and limits. Get started If we don't have an existing integration or quickstart that meets your metric-reporting needs, you have two options: Use our Telemetry SDKs, which are language-specific tools that help you send us metrics and other data. Use the Metric API directly. Find and use your data You can find data sent via the Metric API (including from integrations that use this API) in these locations: From one.newrelic.com, select Explorer and look for your service. By querying the Metric data type. For example, you can use NRQL to run: SELECT * FROM Metric Copy For more on querying, see Metric query examples. For information on querying in general, see Query data. Alert on metric data To alert on metrics created with the Metric API, use NRQL alert conditions: Select the NRQL category when defining your condition, then use the FROM Metric ... NRQL query syntax to express it. When you create these alert conditions, Alerts automatically uses the finest granularity data available (the raw metric data points) to evaluate alerts. Data retention All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Troubleshooting See Troubleshoot an NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.18832,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Metric <em>API</em>",
        "sections": "Find <em>and</em> use your <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " and Prometheus). The Metric <em>API</em> is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our <em>data</em>-<em>ingest</em> <em>APIs</em>. The Metric <em>API</em> can be used to: Report metric <em>data</em> to New Relic without a New Relic agent. Integrate metric <em>data</em> from an open source or in-house"
      },
      "id": "6107858fe7b9d2f9dcfc108e"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Requirements",
        "Basic workflow",
        "Tip",
        "Get the license key",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Important",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "eea369c63a48d26123e243ed4e8bff412b334146",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/introduction-event-api/",
      "published_at": "2021-12-19T14:36:31Z",
      "updated_at": "2021-10-23T17:26:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Want to try out our Event API? Create a New Relic account for free! No credit card required. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic Universitys tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.newrelic.com or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to a New Relic account: Get a license key for the account you want to report data to. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Get the license key You'll need a license key. License keys are associated with an account, not a specific user. This means that anyone in the account with access to that key can use it. You can submit multiple event types to the same account with the same license key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. Alternatively, you can use an Insights insert keyfor this API, but we recommend using a license key. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"Api-Key: YOUR_LICENSE_KEY\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_LICENSE_KEY\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"Api-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The Api-Key contains the correct license key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, create a NRQL query of your data to verify it's available. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid key: Invalid license key. Register a valid license key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To get alerts for parsing errors, create a NRQL alert condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the license key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.23688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Event <em>API</em>",
        "sections": "Introduction to the Event <em>API</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "The New Relic Event <em>API</em> is one way to report custom events to New Relic. The Event <em>API</em> lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Want to try out our Event <em>API</em>? Create a New Relic account for free"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    }
  ],
  "/docs/data-apis/ingest-apis/metric-api/report-metrics-metric-api": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.46332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of <em>API</em> client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> <em>APIs</em>: the Metric <em>API</em>, Trace <em>API</em>, Log <em>API</em>, and Event <em>API</em>. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Introduction to the Metric API",
        "What is the Metric API?",
        "Requirements",
        "Get started",
        "Find and use your data",
        "Alert on metric data",
        "Data retention",
        "Troubleshooting"
      ],
      "title": "Introduction to the Metric API",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "3d1e1c9bdb5d2cbf172eb055dc83020e39dbd16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/introduction-metric-api/",
      "published_at": "2021-12-20T10:04:06Z",
      "updated_at": "2021-12-04T14:16:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Metric API can be used to send metric data to New Relic from a variety of sources. This API is how metrics from some of our integrations and exporters get into New Relic. Want to try out our Metric API? Create a New Relic account for free! No credit card required. What is the Metric API? The Metric API is a way to get metric data into New Relic. The API works by sending a POST request to our HTTP endpoint with a JSON payload containing the metric data. The Metric API is how metrics are ingested from some of our integrations, including our open source exporters (like DropWizard and Prometheus). The Metric API is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our data-ingest APIs. The Metric API can be used to: Report metric data to New Relic without a New Relic agent. Integrate metric data from an open source or in-house developed tool, library, or framework. Fully control the metric data you're sending, including the resolution and associated dimensions. Leverage the power of NRQL, New Relic's query language, for querying your metric data. Set up alerts for your metric data. Requirements Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name metric-api.newrelic.com or metric-api.eu.newrelic.com. You'll need a New Relic license key for the New Relic account you want to send data to. For information on limits and restricted attributes, see Metric API requirements and limits. Get started If we don't have an existing integration or quickstart that meets your metric-reporting needs, you have two options: Use our Telemetry SDKs, which are language-specific tools that help you send us metrics and other data. Use the Metric API directly. Find and use your data You can find data sent via the Metric API (including from integrations that use this API) in these locations: From one.newrelic.com, select Explorer and look for your service. By querying the Metric data type. For example, you can use NRQL to run: SELECT * FROM Metric Copy For more on querying, see Metric query examples. For information on querying in general, see Query data. Alert on metric data To alert on metrics created with the Metric API, use NRQL alert conditions: Select the NRQL category when defining your condition, then use the FROM Metric ... NRQL query syntax to express it. When you create these alert conditions, Alerts automatically uses the finest granularity data available (the raw metric data points) to evaluate alerts. Data retention All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Troubleshooting See Troubleshoot an NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.18832,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Metric <em>API</em>",
        "sections": "Find <em>and</em> use your <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " and Prometheus). The Metric <em>API</em> is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our <em>data</em>-<em>ingest</em> <em>APIs</em>. The Metric <em>API</em> can be used to: Report metric <em>data</em> to New Relic without a New Relic agent. Integrate metric <em>data</em> from an open source or in-house"
      },
      "id": "6107858fe7b9d2f9dcfc108e"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Requirements",
        "Basic workflow",
        "Tip",
        "Get the license key",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Important",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "eea369c63a48d26123e243ed4e8bff412b334146",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/introduction-event-api/",
      "published_at": "2021-12-19T14:36:31Z",
      "updated_at": "2021-10-23T17:26:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Want to try out our Event API? Create a New Relic account for free! No credit card required. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic Universitys tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.newrelic.com or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to a New Relic account: Get a license key for the account you want to report data to. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Get the license key You'll need a license key. License keys are associated with an account, not a specific user. This means that anyone in the account with access to that key can use it. You can submit multiple event types to the same account with the same license key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. Alternatively, you can use an Insights insert keyfor this API, but we recommend using a license key. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"Api-Key: YOUR_LICENSE_KEY\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_LICENSE_KEY\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"Api-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The Api-Key contains the correct license key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, create a NRQL query of your data to verify it's available. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid key: Invalid license key. Register a valid license key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To get alerts for parsing errors, create a NRQL alert condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the license key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.23688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Event <em>API</em>",
        "sections": "Introduction to the Event <em>API</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "The New Relic Event <em>API</em> is one way to report custom events to New Relic. The Event <em>API</em> lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Want to try out our Event <em>API</em>? Create a New Relic account for free"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    }
  ],
  "/docs/data-apis/ingest-apis/metric-api/troubleshoot-nrintegrationerror-events": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.46313,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of <em>API</em> client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> <em>APIs</em>: the Metric <em>API</em>, Trace <em>API</em>, Log <em>API</em>, and Event <em>API</em>. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Introduction to the Metric API",
        "What is the Metric API?",
        "Requirements",
        "Get started",
        "Find and use your data",
        "Alert on metric data",
        "Data retention",
        "Troubleshooting"
      ],
      "title": "Introduction to the Metric API",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "3d1e1c9bdb5d2cbf172eb055dc83020e39dbd16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/introduction-metric-api/",
      "published_at": "2021-12-20T10:04:06Z",
      "updated_at": "2021-12-04T14:16:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Metric API can be used to send metric data to New Relic from a variety of sources. This API is how metrics from some of our integrations and exporters get into New Relic. Want to try out our Metric API? Create a New Relic account for free! No credit card required. What is the Metric API? The Metric API is a way to get metric data into New Relic. The API works by sending a POST request to our HTTP endpoint with a JSON payload containing the metric data. The Metric API is how metrics are ingested from some of our integrations, including our open source exporters (like DropWizard and Prometheus). The Metric API is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our data-ingest APIs. The Metric API can be used to: Report metric data to New Relic without a New Relic agent. Integrate metric data from an open source or in-house developed tool, library, or framework. Fully control the metric data you're sending, including the resolution and associated dimensions. Leverage the power of NRQL, New Relic's query language, for querying your metric data. Set up alerts for your metric data. Requirements Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name metric-api.newrelic.com or metric-api.eu.newrelic.com. You'll need a New Relic license key for the New Relic account you want to send data to. For information on limits and restricted attributes, see Metric API requirements and limits. Get started If we don't have an existing integration or quickstart that meets your metric-reporting needs, you have two options: Use our Telemetry SDKs, which are language-specific tools that help you send us metrics and other data. Use the Metric API directly. Find and use your data You can find data sent via the Metric API (including from integrations that use this API) in these locations: From one.newrelic.com, select Explorer and look for your service. By querying the Metric data type. For example, you can use NRQL to run: SELECT * FROM Metric Copy For more on querying, see Metric query examples. For information on querying in general, see Query data. Alert on metric data To alert on metrics created with the Metric API, use NRQL alert conditions: Select the NRQL category when defining your condition, then use the FROM Metric ... NRQL query syntax to express it. When you create these alert conditions, Alerts automatically uses the finest granularity data available (the raw metric data points) to evaluate alerts. Data retention All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Troubleshooting See Troubleshoot an NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.1883,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Metric <em>API</em>",
        "sections": "Find <em>and</em> use your <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " and Prometheus). The Metric <em>API</em> is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our <em>data</em>-<em>ingest</em> <em>APIs</em>. The Metric <em>API</em> can be used to: Report metric <em>data</em> to New Relic without a New Relic agent. Integrate metric <em>data</em> from an open source or in-house"
      },
      "id": "6107858fe7b9d2f9dcfc108e"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Requirements",
        "Basic workflow",
        "Tip",
        "Get the license key",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Important",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "eea369c63a48d26123e243ed4e8bff412b334146",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/introduction-event-api/",
      "published_at": "2021-12-19T14:36:31Z",
      "updated_at": "2021-10-23T17:26:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Want to try out our Event API? Create a New Relic account for free! No credit card required. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic Universitys tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.newrelic.com or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to a New Relic account: Get a license key for the account you want to report data to. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Get the license key You'll need a license key. License keys are associated with an account, not a specific user. This means that anyone in the account with access to that key can use it. You can submit multiple event types to the same account with the same license key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. Alternatively, you can use an Insights insert keyfor this API, but we recommend using a license key. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"Api-Key: YOUR_LICENSE_KEY\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_LICENSE_KEY\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"Api-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The Api-Key contains the correct license key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, create a NRQL query of your data to verify it's available. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid key: Invalid license key. Register a valid license key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To get alerts for parsing errors, create a NRQL alert condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the license key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.23688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Event <em>API</em>",
        "sections": "Introduction to the Event <em>API</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "The New Relic Event <em>API</em> is one way to report custom events to New Relic. The Event <em>API</em> lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Want to try out our Event <em>API</em>? Create a New Relic account for free"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    }
  ],
  "/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data": [
    {
      "sections": [
        "Introduction to the Metric API",
        "What is the Metric API?",
        "Requirements",
        "Get started",
        "Find and use your data",
        "Alert on metric data",
        "Data retention",
        "Troubleshooting"
      ],
      "title": "Introduction to the Metric API",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "3d1e1c9bdb5d2cbf172eb055dc83020e39dbd16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/introduction-metric-api/",
      "published_at": "2021-12-20T10:04:06Z",
      "updated_at": "2021-12-04T14:16:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Metric API can be used to send metric data to New Relic from a variety of sources. This API is how metrics from some of our integrations and exporters get into New Relic. Want to try out our Metric API? Create a New Relic account for free! No credit card required. What is the Metric API? The Metric API is a way to get metric data into New Relic. The API works by sending a POST request to our HTTP endpoint with a JSON payload containing the metric data. The Metric API is how metrics are ingested from some of our integrations, including our open source exporters (like DropWizard and Prometheus). The Metric API is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our data-ingest APIs. The Metric API can be used to: Report metric data to New Relic without a New Relic agent. Integrate metric data from an open source or in-house developed tool, library, or framework. Fully control the metric data you're sending, including the resolution and associated dimensions. Leverage the power of NRQL, New Relic's query language, for querying your metric data. Set up alerts for your metric data. Requirements Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name metric-api.newrelic.com or metric-api.eu.newrelic.com. You'll need a New Relic license key for the New Relic account you want to send data to. For information on limits and restricted attributes, see Metric API requirements and limits. Get started If we don't have an existing integration or quickstart that meets your metric-reporting needs, you have two options: Use our Telemetry SDKs, which are language-specific tools that help you send us metrics and other data. Use the Metric API directly. Find and use your data You can find data sent via the Metric API (including from integrations that use this API) in these locations: From one.newrelic.com, select Explorer and look for your service. By querying the Metric data type. For example, you can use NRQL to run: SELECT * FROM Metric Copy For more on querying, see Metric query examples. For information on querying in general, see Query data. Alert on metric data To alert on metrics created with the Metric API, use NRQL alert conditions: Select the NRQL category when defining your condition, then use the FROM Metric ... NRQL query syntax to express it. When you create these alert conditions, Alerts automatically uses the finest granularity data available (the raw metric data points) to evaluate alerts. Data retention All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Troubleshooting See Troubleshoot an NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.1883,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Metric <em>API</em>",
        "sections": "Find <em>and</em> use your <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " and Prometheus). The Metric <em>API</em> is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our <em>data</em>-<em>ingest</em> <em>APIs</em>. The Metric <em>API</em> can be used to: Report metric <em>data</em> to New Relic without a New Relic agent. Integrate metric <em>data</em> from an open source or in-house"
      },
      "id": "6107858fe7b9d2f9dcfc108e"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Requirements",
        "Basic workflow",
        "Tip",
        "Get the license key",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Important",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "eea369c63a48d26123e243ed4e8bff412b334146",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/introduction-event-api/",
      "published_at": "2021-12-19T14:36:31Z",
      "updated_at": "2021-10-23T17:26:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Want to try out our Event API? Create a New Relic account for free! No credit card required. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic Universitys tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.newrelic.com or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to a New Relic account: Get a license key for the account you want to report data to. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Get the license key You'll need a license key. License keys are associated with an account, not a specific user. This means that anyone in the account with access to that key can use it. You can submit multiple event types to the same account with the same license key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. Alternatively, you can use an Insights insert keyfor this API, but we recommend using a license key. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"Api-Key: YOUR_LICENSE_KEY\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_LICENSE_KEY\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"Api-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The Api-Key contains the correct license key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, create a NRQL query of your data to verify it's available. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid key: Invalid license key. Register a valid license key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To get alerts for parsing errors, create a NRQL alert condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the license key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.23688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Event <em>API</em>",
        "sections": "Introduction to the Event <em>API</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "The New Relic Event <em>API</em> is one way to report custom events to New Relic. The Event <em>API</em> lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Want to try out our Event <em>API</em>? Create a New Relic account for free"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "50ad21a895fc1f2644bdbfbadf85ecfd298b08d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-12-20T10:04:56Z",
      "updated_at": "2021-10-23T17:26:33Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responsesfrom the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details For an introduction to using the NrIntegrationError event, see NrIntegrationError. Here's an example NRQL for examining issues with Metric API ingest: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature = 'Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When an NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCOUNT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.23688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " To programmatically retrieve these errors: Ensure you have an Insights query <em>API</em> key (go to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H"
      },
      "id": "610f2900196a678a5d38ad82"
    }
  ],
  "/docs/data-apis/manage-data/drop-data-using-nerdgraph": [
    {
      "sections": [
        "Drop data using Prometheus remote write",
        "Tip",
        "Drop entire metric data points from remote write integration",
        "Example",
        "Drop specific labels or attributes from data points",
        "Prometheus or NerdGraph?",
        "Considerations for the Prometheus config file method",
        "Considerations the NerdGraph method",
        "Learn more"
      ],
      "title": "Drop data using Prometheus remote write",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "b3a08d5b6e4c4c04f4046167eb836e6b45523376",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/install-configure/remote-write-drop-data/",
      "published_at": "2021-12-20T06:49:23Z",
      "updated_at": "2021-10-24T02:42:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can drop data you don't want to keep by changing the remote_write section of the YAML config file. Tip You can also drop remote write data using NerdGraph. For more information, see Drop data using NerdGraph. Drop entire metric data points from remote write integration If a target is sending a noisy metric that you don't want sent to New Relic, you can specify that New Relic should drop that data. Example Let's say you don't want to receive data for the metric node_memory_active_bytes from an instance running at localhost:9100. Using the write_relabel_config entry shown below, you can target the metric name using the __name__ label in combination with the instance name. remote_write: - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=macbook-server-cluster bearer_token: <redacted> write_relabel_configs: - source_labels: ['__name__', 'instance'] regex: 'node_memory_active_bytes;localhost:9100' action: 'drop' Copy This tells Prometheus that you want to do some action against metrics with these labels. To limit which metrics with these labels are affected, you must include some value for regex. By default this value is set to .* and it will include all metrics. In this case, it will drop all metric data points coming out of Prometheus via remote write. Drop specific labels or attributes from data points If a target is sending specific labels or attributes you're not interested in receiving, you can drop these from the metrics you receive. Example Let's say one of your targets is sending a bunch of extra attributes you're not interested in receiving. These might include things like high cardinality attributes such as unique machine identifiers, JVM IDs, or similar. In this case, you need to change both the remote_write and the scrape_configs section of the YAML file. The result will look something like this: remote_write: - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=macbook-server-cluster bearer_token: <redacted> write_relabel_configs: - regex: 'extraLabelToRemove.*' action: 'labeldrop' ... scrape_configs: # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config. - job_name: 'node' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:9100'] labels: group: 'production' keepLabelName1: 'please-keep-me' extraLabelToRemove: 'please-remove-me' extraLabelToRemove1: 'please-remove-me' extraLabelToRemove2: 'please-remove-me' extraLabelToRemove4: 'please-remove-me' extraLabelToRemove3: 'please-remove-me' extraLabelToRemove5: 'please-remove-me' Copy Prometheus or NerdGraph? There are advantages to both dropping data using the method described on this page and using NerdGraph. This section is intended to help you figure out which method is better for your specific needs and preferences. Considerations for the Prometheus config file method With this method, your dropped data never leaves the associated Prometheus instance. This is a valuable feature if bytes transferred is a cost consideration on the app hosting side. However, this method may be less appealing than the NerdGraph option due to the following considerations: Maintained via config yaml files that need to be loaded onto each Prometheus instance (or via a shared storage mechanism) Requires access to Prometheus server, meaning that either: The server needs to be restarted Served must be be accessed at port with path /-/reload (assuming the server has lifecycle management enabled as described here in the Prometheus configuration docs. Considerations the NerdGraph method NerdGraph is a great option if you want to manage all your data dropping in a single place. It can also be updated easily via the API and requires no restart or interaction with Prometheus. However, this method applies rules to all incoming data points. This means that you should set up your rules with careful consideration using WHERE filtering. For more information, see Drop data using NerdGraph. Learn more Send Prometheus metric data to New Relic Prometheus High Availability (HA)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1819.2634,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Drop</em> <em>data</em> <em>using</em> Prometheus remote write",
        "sections": "<em>Drop</em> <em>data</em> <em>using</em> Prometheus remote write",
        "body": "You can <em>drop</em> <em>data</em> you don&#x27;t want to keep by changing the remote_write section of the YAML config file. Tip You can also <em>drop</em> remote write <em>data</em> <em>using</em> <em>NerdGraph</em>. For more information, see <em>Drop</em> <em>data</em> <em>using</em> <em>NerdGraph</em>. <em>Drop</em> entire metric <em>data</em> points from remote write integration If a target is sending"
      },
      "id": "617dae7a196a6740e2f7e23d"
    },
    {
      "sections": [
        "Security guide",
        "Tip",
        "Security Program",
        "Security Domains",
        "Security Certifications",
        "Data Control, Facilities, and Encryption",
        "Law Enforcement Request Report"
      ],
      "title": "Security guide",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "356f0d11ffcb62208a743a0a7c127f5f6da9c940",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-guide/",
      "published_at": "2021-12-20T10:48:50Z",
      "updated_at": "2021-12-09T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Last updated September 17, 2021. This is supplement to our security policy and serves as a guide to New Relics description of its Services, functionalities, and features. Tip We may update the URLs in this document without notice. Security Program New Relic follows \"privacy by design\" principles as described here: https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/. Security Domains New Relics policies and procedures cover industry-recognized security domains such as Endpoint Protection; Portable Media Security; Mobile Device Security; Wireless Security; Configuration Management; Vulnerability Management; Network Protection; Transmission Protection; Password Management; Access Control, Audit Logging & Monitoring; Education, Training, and Awareness; Third Party Assurance; Incident Management; Business Continuity and Disaster Recover; Risk Management; Data Protection & Privacy; and Service Management Systems. Security Certifications New Relic audits its Services against industry standards as described at https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/. Data Control, Facilities, and Encryption New Relic's customers can send data to New Relic's APIs by (1) using New Relic's software, (2) using vendor-neutral software that is managed and maintained by a third-party such as via OpenTelemetry instrumentation provided by opentelemetry.io, or (3) from third-party systems that customer's manage and/or control. New Relic's customers can use New Relic's Services such as NerdGraph to filter out and drop data. See https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/drop-data-using-nerdgraph/. New Relic's customers can adjust their data retention periods as appropriate for their needs. See https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-retention/#adjust-retention. New Relic Logs obfuscates numbers that match known patterns, such as bank card and social security numbers as described here: https://docs.newrelic.com/docs/logs/log-management/get-started/new-relics-log-management-security-privacy/. New Relic honors requests to delete personal data in accordance with applicable privacy laws. Please see https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/. Customers may use New Relic's APIs to query data, such as NerdGraph described here, and New Relic Services to export the data to other cloud providers. Customers can configure its log forwarder [https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/] before sending infrastructure logs to New Relic. For New Relic Customers in New Relic US, FedRAMP and HIPAA-enabled environments, Customer Data is replicated to the off-site backup system via Amazon Simple Storage Service (S3). Category of Customer Description FedRAMP HIPAA-enabled US Gen Pop EU Gen Pop Data is stored in Amazon Web Services (AWS). Limited Data is stored in IBM Data for New Relic Incident Intelligence is stored in Google Cloud New Relic regularly tests, assess, and evaluates its measures to ensure the security of processing using industry-recognized standards and uses independent third-party auditors as provided below: Annual SOC 2 Type 2 Annual FedRAMP assessment by an independent third-party pursuant to NIST 800-53 rev 4 Moderate authorization. Annual HITRUST-validated assessment by an independent third-party *Pursuing CY2021 Q4 ISO 27001 TISAX The Services that operate on Amazon Web Services (AWS) are protected by the security and environmental controls of AWS. Detailed information about AWS security is available at https://aws.amazon.com/security/ and http://aws.amazon.com/security/sharing-the-security-responsibility/. Data encryption at rest utilizes FIPS 140-2 compliant encryption methodology. For AWS SOC Reports, please see https://aws.amazon.com/compliance/soc-faqs/. The Services that operate on Google Cloud Platform (\"GCP\") are protected by the security and environmental controls of GCP. Detailed information about GCP security is available at https://cloud.google.com/docs/tutorials#security. For GCP reports, please see https://cloud.google.com/security/compliance/. IBM Deft Zayo QTS Law Enforcement Request Report New Relic has not to date received any request for customer data from a law enforcement or other government agency (including under any national security process), and has not made any corresponding disclosures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1626.5209,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Data</em> Control, Facilities, and Encryption",
        "body": " that customer&#x27;s manage and&#x2F;or control. New Relic&#x27;s customers can <em>use</em> New Relic&#x27;s Services such as <em>NerdGraph</em> to filter out and <em>drop</em> <em>data</em>. See https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;telemetry-<em>data</em>-platform&#x2F;manage-<em>data</em>&#x2F;<em>drop</em>-<em>data</em>-<em>using</em>-<em>nerdgraph</em>&#x2F;. New Relic&#x27;s customers can adjust their <em>data</em> retention periods as appropriate"
      },
      "id": "6147558128ccbc973a56a863"
    },
    {
      "sections": [
        "Manage your data",
        "Important",
        "Where to find the Data management hub",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "999fa6106dd47250e9a5d822aa2f92b6ea088c78",
      "image": "https://docs.newrelic.com/static/8a553ce9643c8513be3200af5d924250/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/manage-your-data/",
      "published_at": "2021-12-19T15:30:18Z",
      "updated_at": "2021-11-13T20:35:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. We also recognize that some data might not be necessary for your business goals. You shouldnt have to wade through data you dont need to get to the data you do. And you definitely shouldnt have to pay for it. Thats where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Data management hub: from the user profile drop down, select Manage your data. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important Not yet a New Relic customer? Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Where to find the Data management hub To locate the data management UI: From one.newrelic.com select the account dropdown, and select Manage your data. If you're on the New Relic One user model, you can also find the Data management hub by selecting Administration > Manage data. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, its important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust whats stored and for how long. Important If you're on our original product-based pricing model, you'll see your data ingest, retention, and limits in the Data management hub. The primary difference is that you're not billed on ingest, as with our New Relic One pricing model. Not sure which plan you're on? See Overview of pricing and user model. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because its a key component of how youre charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data is uncompressed, decorated with queryable attributes, and evaluated. Elements are dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, its also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data thats stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to whats most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1269.6843,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage your <em>data</em>",
        "sections": "Manage your <em>data</em>",
        "tags": "Ingest and manage <em>data</em>",
        "body": ", we have a strategy for you. Learn about reducing the amount of <em>data</em> that comes into NRDB in Manage <em>data</em> coming into New Relic. Learn about customizing storage so you only store the <em>data</em> you want, for the period you want in Manage <em>data</em> stored in New Relic. Learn about dropping <em>data</em> in <em>Drop</em> <em>data</em> <em>using</em> <em>NerdGraph</em>. And for dropping log <em>data</em>, see <em>Drop</em> <em>data</em> with <em>drop</em> filter rules."
      },
      "id": "603e96ff28ccbcf8bceba796"
    }
  ],
  "/docs/data-apis/manage-data/manage-data-coming-new-relic": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.04852,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of API client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "New Relic data types",
        "Get started",
        "Tip",
        "Metrics",
        "Metrics in the monitoring industry",
        "Metrics at New Relic",
        "Dimensional metrics (used by Metric API and many integrations)",
        "Metric timeslice data (used by APM, browser, mobile)",
        "Metric timeslice examples",
        "Metrics attached to events (used by Infrastructure, other products)",
        "Metrics as a computation of events (used in some charts and queries)",
        "Event data",
        "Events in the monitoring industry",
        "Events at New Relic",
        "Log data",
        "Logs in the monitoring industry",
        "Logs at New Relic",
        "Trace data",
        "Tracing in the monitoring industry",
        "Tracing at New Relic",
        "Query and send data",
        "Learn more"
      ],
      "title": "New Relic data types",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "8e4ab82bb58db47bc412f57231d4956c6068262b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/new-relic-data-types/",
      "published_at": "2021-12-19T15:32:43Z",
      "updated_at": "2021-12-04T21:48:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform is built around the four fundamental telemetry data types we believe are necessary for complete and effective system monitoring: metrics, events, logs, and traces. After you sign up for a free New Relic account and install any of our monitoring services, you can start working with your data. Get started This doc will give you a fairly technical explanation of our core data types, their structure, and how they're used in our features. You can use most of our features without needing to understand the underlying data structure. But having a better understanding of this can help you get data into New Relic, understand the data you see in our UI, and query your data. For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types. Another good way to understand your data is to just start querying it. Tip Access your data easily on one.newrelic.com: Click the Browse data dropdown menu and select the data type (metrics, events, logs, and traces) you want to explore. Metrics First, well explain the definition of metrics from a monitoring industry perspective, and then well explain how New Relic handles metrics. For a list of the metrics we collect, see our documentation on metrics. Metrics in the monitoring industry In the software monitoring industry, a metric means a numeric measurement of an application or system. Metrics are typically reported on a regular schedule. Two major types of metrics are: Aggregated data. For example: a count of events over one minutes time, or the rate of some event per minute. A numeric status at a moment in time. For example: a CPU temperature reading, or a CPU% used status. Metrics are relatively easy to report and store because a single record can represent a range of time. They can also be aggregated more and more over time. For example, per-minute data may be rolled up to per-hour aggregations after some amount of time, and eventually may be rolled up to a per-day aggregation. This approach is efficient for long-term data storage. Metrics are a strong solution for storing data long-term, and understanding trends over time. One potential downside is that it can be difficult to do detailed analysis of older data that has been aggregated over time; when high detail is required about specific important actions, event data can be used. Metrics at New Relic Conceptually, \"metrics\" is a broad, general category. There are various ways New Relic measures and reports metrics but, in practice, when using the New Relic UI, you usually won't have to understand how exactly this happens. In our documentation, we typically will just refer to \"metrics,\" regardless of how that data is reported, unless there's a reason you need to know more (like understanding how to query your data). Here are some of the ways metrics are reported and stored across the New Relic platform: Dimensional metrics (used by Metric API and many integrations) In the monitoring industry, \"dimensional\" metrics refer to metric data that has a variety of attributes (dimensions) attached, such as duration-related attributes (start time, end time), entity ID, region, host, etc. This amount of detail allows for in-depth analysis and querying. At New Relic, this metric data is attached to the Metric data type and is sent from several sources: Some open-source integrations, such as the Prometheus exporter. Our Telemetry SDKs Infrastructure services The Metric API (the underlying API used by the above tools) The events-to-metrics service To query this data and see its attributes (\"dimensions\"), you could use a NRQL query like: Select * from Metric Copy As time passes, these metrics are increasingly aggregated into larger time buckets. This is done to optimize your ability to query data over a long period of time. For more details about the metric data type, see our docs. To learn how this data is ingested and stored, see the Metric API documentation. For tips on querying, see Metric query examples. Metric timeslice data (used by APM, browser, mobile) New Relic's APM, browser, and mobile report and display metrics in a simple data format that we refer to as metric timeslice data. A metric timeslice consists of three parts: a metric name, the segment of time the metric represents (the \"timeslice\"), and a numeric value (the measurement). For example: an APM metric timeslice for time spent in a particular transaction is named WebTransaction/URI/foo, and might have a response time of 0.793 for a one-minute time slice from 10:20am to 10:21am. These metrics usually follow a pattern like <category>/<class>/<method>. Our agents (APM, browser, and mobile) can collect thousands of metric timeslices per minute for a variety of performance metrics. For example: error rate, bandwidth usage, and garbage collection time. You also have the ability to create custom metrics. Metric timeslice data is a lightweight data type and lacks the detail that dimensional metrics have. Ways to explore and query metric timeslice data: For APM: metric timeslice data is converted to dimensional metrics and can be queried via NRQL Use the REST API If you want to learn more about the structure of metric timeslice data and see some examples, expand the collapser below. Metric timeslice examples Here are some common metric timeslice data examples, with a focus on common ones used by Ruby applications. ActiveMerchant New Relic tracks a variety of metrics on ActiveMerchant transactions which can be used for business analytics as well as performance monitoring. The metrics are summarized by operation as well as by gateway. regex sample metric legend name ActiveMerchant/. * ActiveMerchant/PayJunctionGateway ActiveMerchant/gateway/. * ActiveMerchant/gateway/PayJunctionGateway/purchase PayJunctionGateway ActiveMerchant/operation/. * ActiveMerchant/operation/purchase purchase For more information, see the ActiveMerchant website. ActiveRecord ActiveRecord is the Object-Relational Mapping API used by Ruby on Rails applications. The metrics shown here measure the performance of ActiveRecord's find and save methods. regex sample metric legend name ActiveRecord/. * /find ActiveRecord/User/find User#find ActiveRecord/. * /save ActiveRecord/Product/save Product#save For more information, see the API documentation for ActiveRecord. Apdex Apdex is a measure of user satisfaction with page load times. Controller In Ruby on Rails applications, HTTP requests are handled by Controller actions. A Rails application has many controllers, each of which has one or more actions. When your rails application receives an http request, that request is routed to the appropriate controller and action, based on the URL of that request. That action then does whatever processing is neccesary to generate an http response, which is most often a web page, but could also be a page fragment, an xml document, or any other kind of data that is requested by the client. The following metrics track the performance of controller actions, regardless of routing, and without taking into account any network or web server effects. regex sample metric legend name Controller/. * Controller/Users/show /Users/show Controller/. * /(?! \\ (other \\ )). * Controller/Users/show /Users/show Controller$ Controller All Controller Actions ControllerCPU/ ControllerCPU/Users/Show /Users/show For more information, see the API documentation for ActionController. Errors This metric tracks the number of errors or exceptions raised while processing requests. regex sample metric legend name Errors/all Errors/all External services External service instrumentation captures calls to out-of-process services such as web services, resources in the cloud and any other network calls. It does not include other first class back-end components such as MemCache and the database. In Ruby applications we instrument the Net::Http library to capture all HTTP services. regex sample metric legend name External/ [ ^/]+/all$ External/service.example.com/all All service.example.com calls External/ External/host.aws.com/Net::Http : :POST Net::Http : :POST [ host.aws.com] External/all$ External/all External Services External/ [ ^/]+/(?!all)/ External/service.example.com/all All service.example.com calls HTTP dispatcher This metric represents a summary of the throughput and response time of all web requests. regex sample metric legend name ^HttpDispatcher$ HttpDispatcher HttpDispatcher MemCache MemCache is a popular technology that enables applications to access shared memory provided by any number of physical machines as a global cache. Applications that heavily use the database often use MemCache for performance and scalability benefits. These metrics measure the frequency and response time of calls to MemCache to read and write data from the cache. Response times should be low (less than 5 ms) for a well performing MemCache deployment. regex sample metric legend name MemCache/. * MemCache/read MemCache read operations MemCache/read MemCache/read MemCache read operations MemCache/write MemCache/write MemCache write operations Mongrel This metric measures the length of the mongrel queue, which holds pending http requests to be processed by mongrel. The HTTP Activity graph overlays the maximimum queue length for a given period. The value is zero if mongrel is processing a request but has no other requests waiting in its queue. When looking at this value across an aggregate cluster of mongrels, the queue lengths of all mongrels is added together, showing the sum of all queue lengths. A mongrel queue length should be at or near zero; if it is consistently at a higher level, then it indicates that your rails application is having trouble keeping up with its load requirements. regex sample metric legend name Mongrel/Queue Length Mongrel/Queue Length Queue Length View ActionView is a package in Rails that is used to render the output that is the response to an http request, such as an html page or an xml document. The View is rendered by the controller that is handling the request. If View metrics represent a large portion of your controller's response time, it could mean you are doing a lot of database operations inside the view template itself. regex sample metric legend name View/. * View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Partial View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Rendering View/Users/show.html.erb/Rendering Users/show.html.erb For more information, see the API documentation for ActionView. Metrics attached to events (used by Infrastructure, other products) Because event-type data can have any type of key-value pair data attached to it, one way metrics can be reported is as attributes attached to an event. A couple examples of this at New Relic: Our infrastructure monitoring reports many metrics that are attached to events. For example, we report a ProcessSample event, which has various sample-based metrics attached to it, like CPU percentage. To learn more about infrastructure monitoring data, see Infrastructure data. In APM, the Transaction event has several metrics attached to it, including databaseDuration. To learn more about this data and how to query it, see Events. Metrics as a computation of events (used in some charts and queries) Metrics can be formed by counting New Relic events, or doing some other mathematical calculation on those events. For example, if you wanted to measure the total number of Transaction events over the last half hour, you might run this NRQL query: Select count(*) from Transaction since 30 minutes ago Copy Another example: if you wanted to compute the average response time for your service, you might run a query like: FROM Transaction SELECT average(duration) SINCE 30 minutes ago Copy Some New Relic charts are generated with these kinds of queries. The downside of this approach is that there are limits on how many events a monitoring system (including ours) can report. This means that sometimes, for high-throughput systems, the count may not accurately represent the total activity on that system. To learn more about how this can be addressed, see Event limits and sampling. Want to report custom metrics? See Get data into New Relic. Event data First, well explain the definition of events from a monitoring industry perspective, and then well explain some specifics about how New Relic handles event data. Events in the monitoring industry In the software industry, events can be thought of as simply things that occur in a system. For example, a server setting being changed would be an event. Another example: a website user clicking a mouse. Some events will generate a stored record, and that record is typically also called an event. Event data represents discrete occurrences and typically will have a high level of detail, so event data is suited for detailed analysis and querying. The downside to the use of event data is that there are typically so many events reported that it can become difficult to query that large dataset over longer time ranges. Events at New Relic At New Relic, we report events to data objects also called events. These events have multiple attributes (key-value pairs) attached. Event data is used in some UI charts and tables, and you can also query it. How long event data remains available is determined by data retention rules. One example of an event: APM reports an event type named Transaction, which represents a logical unit of work in an application. To see the attributes attached to this event, you could use a NRQL query like: Select * from Transaction Copy For examples of querying event data, see Introduction to NRQL. Other details about New Relic event data: Events can have any type of attributes attached. Some events have attributes that report metric data. You can report custom events. To increase the availability of your event data for querying/charting, you can turn events into metrics. Some systems generate a large number of events that exceeds collection limits and results in incomplete query results. For more on this, see Event sampling. Because event is a general term, in some New Relic contexts it will refer to any data type that can be queried via NRQL. For example, when you run a NRQL query, it returns a count of inspected events: this is a count of all data types queried. Log data First, well explain the definition of logs from a monitoring industry perspective, and then well explain some specifics about how New Relic handles log reporting. Logs in the monitoring industry A log is a message about a system used to understand the activity of the system and to diagnose problems. Logs at New Relic New Relic's Logs gives you a centralized log management platform that connects your log data with other New Relic-monitored data. For example, you can see logs alongside your APM data. In New Relic, log data is reported with multiple attributes (key-value data) attached. To query your log data, you could use a NRQL query like: Select * from Log Copy To report custom log data, see the Log API. Trace data First, well explain the definition of traces from a monitoring industry perspective, and then well explain some specifics about how New Relic handles tracing. Tracing in the monitoring industry In the application/infrastructure-monitoring world, tracing is a general term used to refer to various ways to report information about how a program or system is operating. For example, a stack trace provides in-depth information about a programs subroutines. For large modern systems, which are often distributed across many services and micro-services, tracing often refers to distributed tracing, which is a way to monitor requests as they propagate through a complex, distributed environment. Tracing at New Relic New Relic offers a distributed tracing feature that tracks requests across a distributed system, and provides a dedicated UI for understanding and analyzing your traces. In New Relic, trace data is reported as Span objects, with multiple attributes (key-value pairs) attached. To query your tracing data, you could use a NRQL query like: Select * from Span Copy To learn more about how distributed tracing works, see Understand distributed tracing. To report custom distributed tracing data, see the Trace API. Query and send data Understanding New Relic data types can help you: Query data in New Relic Send data to New Relic Learn more For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.15862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>data</em> types",
        "sections": "Query <em>and</em> send <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "The New Relic platform is built around the four fundamental telemetry <em>data</em> types we believe are necessary for complete and effective system monitoring: metrics, events, logs, and traces. After you sign up for a free New Relic account and install any of our monitoring services, you can start working"
      },
      "id": "6045280de7b9d266e1579a0f"
    },
    {
      "sections": [
        "New Relic Database: the horsepower under the hood",
        "Billions of data points per minute",
        "Scale, purpose, and equal access to resources",
        "The lifecycle of a query",
        "The result: flexibility, speed, accuracy, and efficiency",
        "Whats next?",
        "New Relic-built agents and integrations",
        "Report custom data",
        "Learn more"
      ],
      "title": "New Relic Database: the horsepower under the hood",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "73e784610bedcc1bf4ae777e5d6a7a426f37304a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/get-started/nrdb-horsepower-under-hood/",
      "published_at": "2021-12-19T14:27:50Z",
      "updated_at": "2021-12-04T21:44:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If youve been reading our documentation, chances are youve already learned a bit about New Relic and the many tools and capabilities we offer. Were very proud of the utility and design of our dashboards, alerts, and versatile programmability, but none of it would be possible without the computing power needed to make it all run smoothly. Just like a finely calibrated race car, what you see on the outside may be the most exciting features, and these are the parts you interact with to drive. But without an engine designed to win, elegant instrument panels, a responsive clutch, and a great paint job wont get you anywhere. Under the hood of New Relic lies the engine powering it all: the New Relic Database (NRDB). In this resource, we explain how NRDB helps you succeed in your observability goals. Billions of data points per minute New Relic ingests billions of telemetry data points every minute, serving more than 180,000 accounts simultaneously. To run such a high-volume platform, the underlying database and query capabilities need to be fast, flexible, and scalable. They must also be equally effective for organizations of all sizes, supporting a wide spectrum of telemetry needs and business goals. NRDB provides the power, speed, and scalability you need to monitor your performance across your entire landscape quickly and effectively. Scale, purpose, and equal access to resources To meet the challenging demands for speed, efficiency, scalability, and reliability, we built NRDB with three key objectives. Unlimited scalability: Hosted in the cloud, NRDB's distributed architecture has the capacity for virtually unlimited scale. Monitoring and analysis: With this dual purpose in mind, NRDB handles operational monitoring and data analytics equally well. This means that NRDB can ingest massive amounts of data while also giving you real-time alerting, lightning-fast queries, and charting  all without sacrificing speed. Resources when you need them: As a multi-tenant system supporting tens of thousands of customers, NRDB gives you the resources you need when you need them (which single-tenant systems cannot match). The lifecycle of a query NRDB returns results for queries of all sizes astonishingly fast. To do this, we use parallel processing at massive scale. This architectural approach is equally effective for accelerating a single large query and for allowing numerous users to run small queries simultaneously without impacting speed. It works like this: A user enters a query using one of our tools, such as the query builder, or a dashboard or other type of instrumentation sends an automated query. NRDB starts by sending the query to a router, which in turn sends the query components to hundreds or even thousands of query workers. The query workers find the data, and the process is repeated in reverse, with data returning to populate dashboards, create alerts, or answer discrete queries, among other things. This process yields complete query results in a fraction of the time that other methods would require. To further improve efficiency, NRDB also caches recent queries, allowing it to send those results back to users nearly instantaneously. The result: flexibility, speed, accuracy, and efficiency How big is the difference? Because of NDRB's raw power and purposeful design, New Relic's telemetry products are able to analyze tens of billions of events per second while maintaining a median query response time of 45 milliseconds. We would say, Your query results are just a heartbeat away, but mathematically thats more like a tenth of a heartbeat (unless youre a mouse). What do these statistics mean for our customers? At the end of the day, NRDB's speed and unique capabilities enable you to identify, analyze, and fix performance problems much faster, reducing downtime so you can get back to business. Whats next? Now it's time to get data into New Relic! New Relic-built agents and integrations There are many ways to get data into your New Relic account. Any New Relic user can use any of our data ingest methods to report data to our platform.When you enable New Relic solutions like APM, browser monitoring, mobile monitoring, infrastructure monitoring, or any of our wide array of quickstarts, by default you'll receive data from your monitored applications, hosts, services, or other entities. Some options for getting started: Log into one.newrelic.com and click Add more data to get some guidance on setting up New Relic solutions. (Need to create a New Relic account first? Sign up for free!) To browse our solutions, see New Relic Instant Observability. Report custom data If you need to report data that our agents and integrations don't provide, we have tools that will allow you to bring in any type of data you need. To learn more, see Intro to custom data. Learn more Want to know more? Here are a few recommendations for what to do next: Learn about NRDB's data model and flexible schema in our blog post and white paper. Get to know NRQL, our query language, with our Syntax, clauses, and functions page, or read about some of our favorite NRQL capabilities. Read about our query builder, which supports NRQL and PromQL-style queries. Check out UI options for dashboards and charting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.15172,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>Database</em>: the horsepower under the hood",
        "sections": "New Relic <em>Database</em>: the horsepower under the hood",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " that NRDB can <em>ingest</em> massive amounts of <em>data</em> while also giving you real-time alerting, lightning-fast queries, and charting  all without sacrificing speed. Resources when you need them: As a multi-tenant system supporting tens of thousands of customers, NRDB gives you the resources you need when you need"
      },
      "id": "61744743e7b9d212c413d95d"
    }
  ],
  "/docs/data-apis/manage-data/manage-data-retention": [
    {
      "sections": [
        "Security guide",
        "Tip",
        "Security Program",
        "Security Domains",
        "Security Certifications",
        "Data Control, Facilities, and Encryption",
        "Law Enforcement Request Report"
      ],
      "title": "Security guide",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "356f0d11ffcb62208a743a0a7c127f5f6da9c940",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-guide/",
      "published_at": "2021-12-20T10:48:50Z",
      "updated_at": "2021-12-09T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Last updated September 17, 2021. This is supplement to our security policy and serves as a guide to New Relics description of its Services, functionalities, and features. Tip We may update the URLs in this document without notice. Security Program New Relic follows \"privacy by design\" principles as described here: https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/. Security Domains New Relics policies and procedures cover industry-recognized security domains such as Endpoint Protection; Portable Media Security; Mobile Device Security; Wireless Security; Configuration Management; Vulnerability Management; Network Protection; Transmission Protection; Password Management; Access Control, Audit Logging & Monitoring; Education, Training, and Awareness; Third Party Assurance; Incident Management; Business Continuity and Disaster Recover; Risk Management; Data Protection & Privacy; and Service Management Systems. Security Certifications New Relic audits its Services against industry standards as described at https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/. Data Control, Facilities, and Encryption New Relic's customers can send data to New Relic's APIs by (1) using New Relic's software, (2) using vendor-neutral software that is managed and maintained by a third-party such as via OpenTelemetry instrumentation provided by opentelemetry.io, or (3) from third-party systems that customer's manage and/or control. New Relic's customers can use New Relic's Services such as NerdGraph to filter out and drop data. See https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/drop-data-using-nerdgraph/. New Relic's customers can adjust their data retention periods as appropriate for their needs. See https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-retention/#adjust-retention. New Relic Logs obfuscates numbers that match known patterns, such as bank card and social security numbers as described here: https://docs.newrelic.com/docs/logs/log-management/get-started/new-relics-log-management-security-privacy/. New Relic honors requests to delete personal data in accordance with applicable privacy laws. Please see https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/. Customers may use New Relic's APIs to query data, such as NerdGraph described here, and New Relic Services to export the data to other cloud providers. Customers can configure its log forwarder [https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/] before sending infrastructure logs to New Relic. For New Relic Customers in New Relic US, FedRAMP and HIPAA-enabled environments, Customer Data is replicated to the off-site backup system via Amazon Simple Storage Service (S3). Category of Customer Description FedRAMP HIPAA-enabled US Gen Pop EU Gen Pop Data is stored in Amazon Web Services (AWS). Limited Data is stored in IBM Data for New Relic Incident Intelligence is stored in Google Cloud New Relic regularly tests, assess, and evaluates its measures to ensure the security of processing using industry-recognized standards and uses independent third-party auditors as provided below: Annual SOC 2 Type 2 Annual FedRAMP assessment by an independent third-party pursuant to NIST 800-53 rev 4 Moderate authorization. Annual HITRUST-validated assessment by an independent third-party *Pursuing CY2021 Q4 ISO 27001 TISAX The Services that operate on Amazon Web Services (AWS) are protected by the security and environmental controls of AWS. Detailed information about AWS security is available at https://aws.amazon.com/security/ and http://aws.amazon.com/security/sharing-the-security-responsibility/. Data encryption at rest utilizes FIPS 140-2 compliant encryption methodology. For AWS SOC Reports, please see https://aws.amazon.com/compliance/soc-faqs/. The Services that operate on Google Cloud Platform (\"GCP\") are protected by the security and environmental controls of GCP. Detailed information about GCP security is available at https://cloud.google.com/docs/tutorials#security. For GCP reports, please see https://cloud.google.com/security/compliance/. IBM Deft Zayo QTS Law Enforcement Request Report New Relic has not to date received any request for customer data from a law enforcement or other government agency (including under any national security process), and has not made any corresponding disclosures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 654.4833,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Data</em> Control, Facilities, and Encryption",
        "body": " that customer&#x27;s <em>manage</em> and&#x2F;or control. New Relic&#x27;s customers can use New Relic&#x27;s Services such as NerdGraph to filter out and drop <em>data</em>. See https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;telemetry-<em>data</em>-platform&#x2F;<em>manage</em>-<em>data</em>&#x2F;drop-<em>data</em>-using-nerdgraph&#x2F;. New Relic&#x27;s customers can adjust their <em>data</em> <em>retention</em> periods as appropriate"
      },
      "id": "6147558128ccbc973a56a863"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-19T14:39:57Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relics various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isnt used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic Universitys Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, youll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorers API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but weve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 531.8154,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " partitions <em>Manage</em> <em>data</em> partitions Date <em>retention</em> <em>Manage</em> <em>data</em> <em>retention</em> NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only"
      },
      "id": "6043ff97196a67d0a0960f55"
    },
    {
      "sections": [
        "Event data retention (original pricing model)",
        "Important",
        "Data retention UI",
        "Overview of event data retention",
        "Extend your event retention",
        "Insights Pro",
        "How number of events stored is calculated",
        "Insights Pro event overage example",
        "Disable/enable Transaction and Pageview event reporting",
        "Tip",
        "Flexible data retention",
        "How it works",
        "Manage retention via UI",
        "Glossary"
      ],
      "title": "Event data retention (original pricing model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original data retention"
      ],
      "external_id": "76d1289aad7de08b355bb8c313f9e7a42a5779d8",
      "image": "https://docs.newrelic.com/static/e53a1e416eb6116545627d3ec880d08e/e9c9b/flex-2.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-data-retention/event-data-retention-original-pricing-plan/",
      "published_at": "2021-12-19T14:16:05Z",
      "updated_at": "2021-11-14T09:17:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original pricing model, not our New Relic One pricing model. Not sure which you're on? See Overview of pricing models. For organizations on New Relic One pricing, our various New Relic products report a wide range of event data. Different products have different data retention periods, and different ways to extend event data retention. You can customize the length of your event data retention through flexible event retention. Data retention UI For how to find the data retention UI, see Manage data. Overview of event data retention All New Relic product subscriptions come with a certain level of data retention that governs how long different types of data are retained. One type of data governed by data retention rules is event data. Event data is available in some UI charts and tables, and also available for querying via NRQL, our querying language. There are events reported from products by default, and there are custom events: each have their own retention rules, depending on the product and subscription level. Here are some examples of how different product subscriptions can affect event data retention: Free/Lite APM subscription: default-reported events available for 1 day. No custom events available. Pro APM subscription: default-reported events available for 8 days. Custom events available for 1 day (and able to be extended with Insight Pro). To see your subscriptions, go to the Account summary page. Extend your event retention Product Method APM, Browser, and Mobile Event data retention can be extended with a paid subscription to these products (see product data retention). To extend retention of both default-reported events and custom events further, you need an Insights Pro subscription. Infrastructure Event data retention can be extended with a paid Infrastructure subscription. See Infrastructure data retention rules. Synthetics Event data retention can be extended with a paid Synthetics subscription. See Synthetics data retention rules. Custom events Custom events reported by agent APIs or the Event API: Extension requires an Insights Pro subscription. Insights Pro Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. A paid Insights subscription is what governs the extension of event data retention for: Our APM, Browser, Mobile, and Serverless products Custom events that come from an agent API or from the Event API Important Note that having an Insights Pro subscription doesn't require use of the Insights UI (insights.newrelic.com) to query your data: there are other querying options available. To see the data retention governed by your Insights subscription: go to the usage UI and select Insights usage. With an Insights Pro subscription, you can use flexible retention to customize how your event data is retained. This lets you keep only the data you need, for as long as you need it. How number of events stored is calculated This is an explanation of how the number of stored events are calculated by default for an Insights Pro subscription. (Note that with flexible retention, you have more fine-grained control over the retention period.) The events stored is calculated based on 1) total events stored over time (calculated based on the events generated per week) and 2) the weeks of data retention available. This equation can be represented like this: events stored = (events generated per week) * (weeks of retention) Copy An Insights Pro subscription provides a given number of weeks of data retention as well as a given number of events over that retention period. For example: (200M transactions per week) * (4 weeks of retention) = 800M events stored in Insights (16M transactions per week) * (50 weeks of retention) = 800M events stored in Insights For Insights Pro subscriptions, data is purged based on retention window, not volume. It is deleted from the system once it's past the retention window. For example: If your Insights license is for 800 million events with a 4 week retention period, your data would start being purged after it is older than four weeks. Temporary spikes in data exceeding your subscription level will still be recorded, but consistent overage should be solved by upgrading your subscription level or decreasing data collected. For customers without an Insights Pro subscription, New Relic may throttle or downsample events to a limit of not more than than 4,000 events per host per minute. Insights Pro event overage example In this example, you have an Insights Pro subscription with a license for 800 million events over 4 weeks, a rate of 200 million events per week. You have APM Pro, Browser Pro, and Mobile Enterprise. A fifth week of data is added via your subscriptions, bumping you to a total of 1 billion events stored within your plan: If you are using 975 million events, you are not over your retention. If you are using 1.25 billion events, you are over your retention. Disable/enable Transaction and Pageview event reporting Tip Owners or Admins The Insights Data summary UI page is used to see the types of events being reported. You can also use this page to enable and disable the reporting of PageView and Transaction events. To view Data summary: Go to insights.newrelic.com > Manage data. Select the Summary tab. Note: if you disable PageView or Transaction event reporting, this can affect some New Relic UI elements. You may see some empty charts on some UI pages that rely on this data. Go to insights.newrelic.com > Manage data > Summary. From the Summary tab, select Configure data sources. Toggle the appropriate switch on or off, then save. Toggling Transaction on or off will cause reporting agents to restart themselves. For more about configuring event reporting, see Event data retention. Flexible data retention With an Insights Pro subscription, you get access to flexible retention, which lets you define how some types of event data are retained. This lets you keep only the event data you need, for as long as you need it. You can manage your flexible retention through the UI or through our GraphQL API. Requirements to use this feature: An Insights Pro subscription or equivalent trial. Applies only for events governed by an Insights Pro subscription. To use this feature, you must be an account Owner or data retention add-on manager for your account. How it works To understand how standard event data retention works, first read Event data retention. With flexible retention, you specify the data retention for applicable event namespaces across your accounts. This gives you per-event namespace control of your data. The retention that you specify for an event namespace will be shared by all the event types under that namespace. If some namespaces are not relevant to you, you can avoid collecting their event data entirely. Your retention value cant be lower than the included retention or higher than the default retention. You can control data retention either in our UI or by API. Manage retention via UI You can control data retention either using our GraphQL API or in the UI. To do this with the UI, go to the data retention UI. Your retention changes take effect within 24 hours after updating. Glossary To understand the terms used with flexible retention, see the following: Term Description Event namespace An event's namespace corresponds to one or more event types that share a single data retention value. For more information, see Event namespaces (types). You can also use NerdGraph to get the list of customizable event namespaces. Retention value The number (in days) that specifies how long your event data is stored. Retention rule The event namespace and retention value pair that you specify to override the current retention. Licensed retention Retention period thats determined in weeks by your Insights Pro subscription contract. Included retention Retention period for which your data is stored but not charged under the Insights Pro subscription. For details, see the data retention details for a specific product. Paid retention Retention period for which your data is stored and is charged under the Insights Pro subscription. By default, your licensed retention determines this value but Flexible retention lets you override it. Default retention Retention period that comes out of the box. This is based on the total of included retention plus licensed retention. For information on managing retention settings with APIs, see the Manage data retention documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 462.90344,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Event <em>data</em> <em>retention</em> (original pricing model)",
        "sections": "<em>Manage</em> <em>retention</em> via UI",
        "tags": "Original <em>data</em> <em>retention</em>",
        "body": " different <em>data</em> <em>retention</em> periods, and different ways to extend event <em>data</em> <em>retention</em>. You can customize the length of your event <em>data</em> <em>retention</em> through flexible event <em>retention</em>. <em>Data</em> <em>retention</em> UI For how to find the <em>data</em> <em>retention</em> UI, see <em>Manage</em> <em>data</em>. Overview of event <em>data</em> <em>retention</em> All New Relic"
      },
      "id": "6043f713e7b9d2ccee579a1d"
    }
  ],
  "/docs/data-apis/manage-data/manage-your-data": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.04834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of API client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "New Relic data types",
        "Get started",
        "Tip",
        "Metrics",
        "Metrics in the monitoring industry",
        "Metrics at New Relic",
        "Dimensional metrics (used by Metric API and many integrations)",
        "Metric timeslice data (used by APM, browser, mobile)",
        "Metric timeslice examples",
        "Metrics attached to events (used by Infrastructure, other products)",
        "Metrics as a computation of events (used in some charts and queries)",
        "Event data",
        "Events in the monitoring industry",
        "Events at New Relic",
        "Log data",
        "Logs in the monitoring industry",
        "Logs at New Relic",
        "Trace data",
        "Tracing in the monitoring industry",
        "Tracing at New Relic",
        "Query and send data",
        "Learn more"
      ],
      "title": "New Relic data types",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "8e4ab82bb58db47bc412f57231d4956c6068262b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/new-relic-data-types/",
      "published_at": "2021-12-19T15:32:43Z",
      "updated_at": "2021-12-04T21:48:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform is built around the four fundamental telemetry data types we believe are necessary for complete and effective system monitoring: metrics, events, logs, and traces. After you sign up for a free New Relic account and install any of our monitoring services, you can start working with your data. Get started This doc will give you a fairly technical explanation of our core data types, their structure, and how they're used in our features. You can use most of our features without needing to understand the underlying data structure. But having a better understanding of this can help you get data into New Relic, understand the data you see in our UI, and query your data. For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types. Another good way to understand your data is to just start querying it. Tip Access your data easily on one.newrelic.com: Click the Browse data dropdown menu and select the data type (metrics, events, logs, and traces) you want to explore. Metrics First, well explain the definition of metrics from a monitoring industry perspective, and then well explain how New Relic handles metrics. For a list of the metrics we collect, see our documentation on metrics. Metrics in the monitoring industry In the software monitoring industry, a metric means a numeric measurement of an application or system. Metrics are typically reported on a regular schedule. Two major types of metrics are: Aggregated data. For example: a count of events over one minutes time, or the rate of some event per minute. A numeric status at a moment in time. For example: a CPU temperature reading, or a CPU% used status. Metrics are relatively easy to report and store because a single record can represent a range of time. They can also be aggregated more and more over time. For example, per-minute data may be rolled up to per-hour aggregations after some amount of time, and eventually may be rolled up to a per-day aggregation. This approach is efficient for long-term data storage. Metrics are a strong solution for storing data long-term, and understanding trends over time. One potential downside is that it can be difficult to do detailed analysis of older data that has been aggregated over time; when high detail is required about specific important actions, event data can be used. Metrics at New Relic Conceptually, \"metrics\" is a broad, general category. There are various ways New Relic measures and reports metrics but, in practice, when using the New Relic UI, you usually won't have to understand how exactly this happens. In our documentation, we typically will just refer to \"metrics,\" regardless of how that data is reported, unless there's a reason you need to know more (like understanding how to query your data). Here are some of the ways metrics are reported and stored across the New Relic platform: Dimensional metrics (used by Metric API and many integrations) In the monitoring industry, \"dimensional\" metrics refer to metric data that has a variety of attributes (dimensions) attached, such as duration-related attributes (start time, end time), entity ID, region, host, etc. This amount of detail allows for in-depth analysis and querying. At New Relic, this metric data is attached to the Metric data type and is sent from several sources: Some open-source integrations, such as the Prometheus exporter. Our Telemetry SDKs Infrastructure services The Metric API (the underlying API used by the above tools) The events-to-metrics service To query this data and see its attributes (\"dimensions\"), you could use a NRQL query like: Select * from Metric Copy As time passes, these metrics are increasingly aggregated into larger time buckets. This is done to optimize your ability to query data over a long period of time. For more details about the metric data type, see our docs. To learn how this data is ingested and stored, see the Metric API documentation. For tips on querying, see Metric query examples. Metric timeslice data (used by APM, browser, mobile) New Relic's APM, browser, and mobile report and display metrics in a simple data format that we refer to as metric timeslice data. A metric timeslice consists of three parts: a metric name, the segment of time the metric represents (the \"timeslice\"), and a numeric value (the measurement). For example: an APM metric timeslice for time spent in a particular transaction is named WebTransaction/URI/foo, and might have a response time of 0.793 for a one-minute time slice from 10:20am to 10:21am. These metrics usually follow a pattern like <category>/<class>/<method>. Our agents (APM, browser, and mobile) can collect thousands of metric timeslices per minute for a variety of performance metrics. For example: error rate, bandwidth usage, and garbage collection time. You also have the ability to create custom metrics. Metric timeslice data is a lightweight data type and lacks the detail that dimensional metrics have. Ways to explore and query metric timeslice data: For APM: metric timeslice data is converted to dimensional metrics and can be queried via NRQL Use the REST API If you want to learn more about the structure of metric timeslice data and see some examples, expand the collapser below. Metric timeslice examples Here are some common metric timeslice data examples, with a focus on common ones used by Ruby applications. ActiveMerchant New Relic tracks a variety of metrics on ActiveMerchant transactions which can be used for business analytics as well as performance monitoring. The metrics are summarized by operation as well as by gateway. regex sample metric legend name ActiveMerchant/. * ActiveMerchant/PayJunctionGateway ActiveMerchant/gateway/. * ActiveMerchant/gateway/PayJunctionGateway/purchase PayJunctionGateway ActiveMerchant/operation/. * ActiveMerchant/operation/purchase purchase For more information, see the ActiveMerchant website. ActiveRecord ActiveRecord is the Object-Relational Mapping API used by Ruby on Rails applications. The metrics shown here measure the performance of ActiveRecord's find and save methods. regex sample metric legend name ActiveRecord/. * /find ActiveRecord/User/find User#find ActiveRecord/. * /save ActiveRecord/Product/save Product#save For more information, see the API documentation for ActiveRecord. Apdex Apdex is a measure of user satisfaction with page load times. Controller In Ruby on Rails applications, HTTP requests are handled by Controller actions. A Rails application has many controllers, each of which has one or more actions. When your rails application receives an http request, that request is routed to the appropriate controller and action, based on the URL of that request. That action then does whatever processing is neccesary to generate an http response, which is most often a web page, but could also be a page fragment, an xml document, or any other kind of data that is requested by the client. The following metrics track the performance of controller actions, regardless of routing, and without taking into account any network or web server effects. regex sample metric legend name Controller/. * Controller/Users/show /Users/show Controller/. * /(?! \\ (other \\ )). * Controller/Users/show /Users/show Controller$ Controller All Controller Actions ControllerCPU/ ControllerCPU/Users/Show /Users/show For more information, see the API documentation for ActionController. Errors This metric tracks the number of errors or exceptions raised while processing requests. regex sample metric legend name Errors/all Errors/all External services External service instrumentation captures calls to out-of-process services such as web services, resources in the cloud and any other network calls. It does not include other first class back-end components such as MemCache and the database. In Ruby applications we instrument the Net::Http library to capture all HTTP services. regex sample metric legend name External/ [ ^/]+/all$ External/service.example.com/all All service.example.com calls External/ External/host.aws.com/Net::Http : :POST Net::Http : :POST [ host.aws.com] External/all$ External/all External Services External/ [ ^/]+/(?!all)/ External/service.example.com/all All service.example.com calls HTTP dispatcher This metric represents a summary of the throughput and response time of all web requests. regex sample metric legend name ^HttpDispatcher$ HttpDispatcher HttpDispatcher MemCache MemCache is a popular technology that enables applications to access shared memory provided by any number of physical machines as a global cache. Applications that heavily use the database often use MemCache for performance and scalability benefits. These metrics measure the frequency and response time of calls to MemCache to read and write data from the cache. Response times should be low (less than 5 ms) for a well performing MemCache deployment. regex sample metric legend name MemCache/. * MemCache/read MemCache read operations MemCache/read MemCache/read MemCache read operations MemCache/write MemCache/write MemCache write operations Mongrel This metric measures the length of the mongrel queue, which holds pending http requests to be processed by mongrel. The HTTP Activity graph overlays the maximimum queue length for a given period. The value is zero if mongrel is processing a request but has no other requests waiting in its queue. When looking at this value across an aggregate cluster of mongrels, the queue lengths of all mongrels is added together, showing the sum of all queue lengths. A mongrel queue length should be at or near zero; if it is consistently at a higher level, then it indicates that your rails application is having trouble keeping up with its load requirements. regex sample metric legend name Mongrel/Queue Length Mongrel/Queue Length Queue Length View ActionView is a package in Rails that is used to render the output that is the response to an http request, such as an html page or an xml document. The View is rendered by the controller that is handling the request. If View metrics represent a large portion of your controller's response time, it could mean you are doing a lot of database operations inside the view template itself. regex sample metric legend name View/. * View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Partial View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Rendering View/Users/show.html.erb/Rendering Users/show.html.erb For more information, see the API documentation for ActionView. Metrics attached to events (used by Infrastructure, other products) Because event-type data can have any type of key-value pair data attached to it, one way metrics can be reported is as attributes attached to an event. A couple examples of this at New Relic: Our infrastructure monitoring reports many metrics that are attached to events. For example, we report a ProcessSample event, which has various sample-based metrics attached to it, like CPU percentage. To learn more about infrastructure monitoring data, see Infrastructure data. In APM, the Transaction event has several metrics attached to it, including databaseDuration. To learn more about this data and how to query it, see Events. Metrics as a computation of events (used in some charts and queries) Metrics can be formed by counting New Relic events, or doing some other mathematical calculation on those events. For example, if you wanted to measure the total number of Transaction events over the last half hour, you might run this NRQL query: Select count(*) from Transaction since 30 minutes ago Copy Another example: if you wanted to compute the average response time for your service, you might run a query like: FROM Transaction SELECT average(duration) SINCE 30 minutes ago Copy Some New Relic charts are generated with these kinds of queries. The downside of this approach is that there are limits on how many events a monitoring system (including ours) can report. This means that sometimes, for high-throughput systems, the count may not accurately represent the total activity on that system. To learn more about how this can be addressed, see Event limits and sampling. Want to report custom metrics? See Get data into New Relic. Event data First, well explain the definition of events from a monitoring industry perspective, and then well explain some specifics about how New Relic handles event data. Events in the monitoring industry In the software industry, events can be thought of as simply things that occur in a system. For example, a server setting being changed would be an event. Another example: a website user clicking a mouse. Some events will generate a stored record, and that record is typically also called an event. Event data represents discrete occurrences and typically will have a high level of detail, so event data is suited for detailed analysis and querying. The downside to the use of event data is that there are typically so many events reported that it can become difficult to query that large dataset over longer time ranges. Events at New Relic At New Relic, we report events to data objects also called events. These events have multiple attributes (key-value pairs) attached. Event data is used in some UI charts and tables, and you can also query it. How long event data remains available is determined by data retention rules. One example of an event: APM reports an event type named Transaction, which represents a logical unit of work in an application. To see the attributes attached to this event, you could use a NRQL query like: Select * from Transaction Copy For examples of querying event data, see Introduction to NRQL. Other details about New Relic event data: Events can have any type of attributes attached. Some events have attributes that report metric data. You can report custom events. To increase the availability of your event data for querying/charting, you can turn events into metrics. Some systems generate a large number of events that exceeds collection limits and results in incomplete query results. For more on this, see Event sampling. Because event is a general term, in some New Relic contexts it will refer to any data type that can be queried via NRQL. For example, when you run a NRQL query, it returns a count of inspected events: this is a count of all data types queried. Log data First, well explain the definition of logs from a monitoring industry perspective, and then well explain some specifics about how New Relic handles log reporting. Logs in the monitoring industry A log is a message about a system used to understand the activity of the system and to diagnose problems. Logs at New Relic New Relic's Logs gives you a centralized log management platform that connects your log data with other New Relic-monitored data. For example, you can see logs alongside your APM data. In New Relic, log data is reported with multiple attributes (key-value data) attached. To query your log data, you could use a NRQL query like: Select * from Log Copy To report custom log data, see the Log API. Trace data First, well explain the definition of traces from a monitoring industry perspective, and then well explain some specifics about how New Relic handles tracing. Tracing in the monitoring industry In the application/infrastructure-monitoring world, tracing is a general term used to refer to various ways to report information about how a program or system is operating. For example, a stack trace provides in-depth information about a programs subroutines. For large modern systems, which are often distributed across many services and micro-services, tracing often refers to distributed tracing, which is a way to monitor requests as they propagate through a complex, distributed environment. Tracing at New Relic New Relic offers a distributed tracing feature that tracks requests across a distributed system, and provides a dedicated UI for understanding and analyzing your traces. In New Relic, trace data is reported as Span objects, with multiple attributes (key-value pairs) attached. To query your tracing data, you could use a NRQL query like: Select * from Span Copy To learn more about how distributed tracing works, see Understand distributed tracing. To report custom distributed tracing data, see the Trace API. Query and send data Understanding New Relic data types can help you: Query data in New Relic Send data to New Relic Learn more For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.15858,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>data</em> types",
        "sections": "Query <em>and</em> send <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "The New Relic platform is built around the four fundamental telemetry <em>data</em> types we believe are necessary for complete and effective system monitoring: metrics, events, logs, and traces. After you sign up for a free New Relic account and install any of our monitoring services, you can start working"
      },
      "id": "6045280de7b9d266e1579a0f"
    },
    {
      "sections": [
        "New Relic Database: the horsepower under the hood",
        "Billions of data points per minute",
        "Scale, purpose, and equal access to resources",
        "The lifecycle of a query",
        "The result: flexibility, speed, accuracy, and efficiency",
        "Whats next?",
        "New Relic-built agents and integrations",
        "Report custom data",
        "Learn more"
      ],
      "title": "New Relic Database: the horsepower under the hood",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "73e784610bedcc1bf4ae777e5d6a7a426f37304a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/get-started/nrdb-horsepower-under-hood/",
      "published_at": "2021-12-19T14:27:50Z",
      "updated_at": "2021-12-04T21:44:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If youve been reading our documentation, chances are youve already learned a bit about New Relic and the many tools and capabilities we offer. Were very proud of the utility and design of our dashboards, alerts, and versatile programmability, but none of it would be possible without the computing power needed to make it all run smoothly. Just like a finely calibrated race car, what you see on the outside may be the most exciting features, and these are the parts you interact with to drive. But without an engine designed to win, elegant instrument panels, a responsive clutch, and a great paint job wont get you anywhere. Under the hood of New Relic lies the engine powering it all: the New Relic Database (NRDB). In this resource, we explain how NRDB helps you succeed in your observability goals. Billions of data points per minute New Relic ingests billions of telemetry data points every minute, serving more than 180,000 accounts simultaneously. To run such a high-volume platform, the underlying database and query capabilities need to be fast, flexible, and scalable. They must also be equally effective for organizations of all sizes, supporting a wide spectrum of telemetry needs and business goals. NRDB provides the power, speed, and scalability you need to monitor your performance across your entire landscape quickly and effectively. Scale, purpose, and equal access to resources To meet the challenging demands for speed, efficiency, scalability, and reliability, we built NRDB with three key objectives. Unlimited scalability: Hosted in the cloud, NRDB's distributed architecture has the capacity for virtually unlimited scale. Monitoring and analysis: With this dual purpose in mind, NRDB handles operational monitoring and data analytics equally well. This means that NRDB can ingest massive amounts of data while also giving you real-time alerting, lightning-fast queries, and charting  all without sacrificing speed. Resources when you need them: As a multi-tenant system supporting tens of thousands of customers, NRDB gives you the resources you need when you need them (which single-tenant systems cannot match). The lifecycle of a query NRDB returns results for queries of all sizes astonishingly fast. To do this, we use parallel processing at massive scale. This architectural approach is equally effective for accelerating a single large query and for allowing numerous users to run small queries simultaneously without impacting speed. It works like this: A user enters a query using one of our tools, such as the query builder, or a dashboard or other type of instrumentation sends an automated query. NRDB starts by sending the query to a router, which in turn sends the query components to hundreds or even thousands of query workers. The query workers find the data, and the process is repeated in reverse, with data returning to populate dashboards, create alerts, or answer discrete queries, among other things. This process yields complete query results in a fraction of the time that other methods would require. To further improve efficiency, NRDB also caches recent queries, allowing it to send those results back to users nearly instantaneously. The result: flexibility, speed, accuracy, and efficiency How big is the difference? Because of NDRB's raw power and purposeful design, New Relic's telemetry products are able to analyze tens of billions of events per second while maintaining a median query response time of 45 milliseconds. We would say, Your query results are just a heartbeat away, but mathematically thats more like a tenth of a heartbeat (unless youre a mouse). What do these statistics mean for our customers? At the end of the day, NRDB's speed and unique capabilities enable you to identify, analyze, and fix performance problems much faster, reducing downtime so you can get back to business. Whats next? Now it's time to get data into New Relic! New Relic-built agents and integrations There are many ways to get data into your New Relic account. Any New Relic user can use any of our data ingest methods to report data to our platform.When you enable New Relic solutions like APM, browser monitoring, mobile monitoring, infrastructure monitoring, or any of our wide array of quickstarts, by default you'll receive data from your monitored applications, hosts, services, or other entities. Some options for getting started: Log into one.newrelic.com and click Add more data to get some guidance on setting up New Relic solutions. (Need to create a New Relic account first? Sign up for free!) To browse our solutions, see New Relic Instant Observability. Report custom data If you need to report data that our agents and integrations don't provide, we have tools that will allow you to bring in any type of data you need. To learn more, see Intro to custom data. Learn more Want to know more? Here are a few recommendations for what to do next: Learn about NRDB's data model and flexible schema in our blog post and white paper. Get to know NRQL, our query language, with our Syntax, clauses, and functions page, or read about some of our favorite NRQL capabilities. Read about our query builder, which supports NRQL and PromQL-style queries. Check out UI options for dashboards and charting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.15169,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>Database</em>: the horsepower under the hood",
        "sections": "New Relic <em>Database</em>: the horsepower under the hood",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " that NRDB can <em>ingest</em> massive amounts of <em>data</em> while also giving you real-time alerting, lightning-fast queries, and charting  all without sacrificing speed. Resources when you need them: As a multi-tenant system supporting tens of thousands of customers, NRDB gives you the resources you need when you need"
      },
      "id": "61744743e7b9d212c413d95d"
    }
  ],
  "/docs/data-apis/manage-data/nrintegrationerror": [
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "50ad21a895fc1f2644bdbfbadf85ecfd298b08d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-12-20T10:04:56Z",
      "updated_at": "2021-10-23T17:26:33Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responsesfrom the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details For an introduction to using the NrIntegrationError event, see NrIntegrationError. Here's an example NRQL for examining issues with Metric API ingest: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature = 'Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When an NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCOUNT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 290.08328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric API with <em>NRIntegrationError</em> <em>events</em>",
        "sections": "Troubleshoot Metric API with <em>NRIntegrationError</em> <em>events</em>",
        "tags": "<em>Ingest</em> and manage <em>data</em>",
        "body": " various rate limits have been reached. Solution View <em>error</em> details For an introduction to using the <em>NrIntegrationError</em> <em>event</em>, see <em>NrIntegrationError</em>. Here&#x27;s an example NRQL for examining issues with Metric API <em>ingest</em>: SELECT count(*) FROM <em>NrIntegrationError</em> WHERE newRelicFeature = &#x27;Metrics&#x27; facet"
      },
      "id": "610f2900196a678a5d38ad82"
    },
    {
      "sections": [
        "Rate limit errors (Prometheus integration)",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Rate limit errors (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "0fb0d18fde3e5329639abb3dfb90d4e78f576d14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/troubleshooting/rate-limit-errors-prometheus-integration/",
      "published_at": "2021-12-20T05:24:46Z",
      "updated_at": "2021-10-24T02:47:16Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your Prometheus OpenMetrics integration for Docker or Kubernetes exceeded allowable metric rate limits. You want to see more details about why the NrIntegrationError event has been applied to your New Relic account. Solution To examine rate limit errors: Run a query of Prometheus metrics using the NrIntegrationError event, like this: FROM NrIntegrationError SELECT * WHERE newRelicFeature = 'Metrics' Copy Review additional troubleshooting procedures for NrIntegrationError events. To help prevent this from happening, you can use filters to control the types and amount of data that your integration sends to New Relic. For more information, see Ignore or include Prometheus metrics. Cause New Relic does a basic validation of your Prometheus OpenMetrics integration metrics when they are submitted. More extensive validation is performed asynchronously when processing the metrics. If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for Prometheus OpenMetrics integrations, New Relic will apply rate limits to your account and create an associated NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.55365,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limit <em>errors</em> (Prometheus <em>integration</em>)",
        "sections": "Rate limit <em>errors</em> (Prometheus <em>integration</em>)",
        "tags": "<em>Integrations</em>",
        "body": " using the <em>NrIntegrationError</em> <em>event</em>, like this: FROM <em>NrIntegrationError</em> SELECT * WHERE newRelicFeature = &#x27;Metrics&#x27; Copy Review additional troubleshooting procedures for <em>NrIntegrationError</em> events. To help prevent this from happening, you can <em>use</em> filters to control the types and amount of <em>data</em> that your"
      },
      "id": "617da8b064441fb7a9fbca71"
    },
    {
      "sections": [
        "Query system limits",
        "Important",
        "What happens when you reach a limit",
        "Tip",
        "Create a dashboard to view your limit status",
        "Resource Consumption Limits as a %",
        "Max % Consumption in an hour",
        "APM Agent API transaction events request per minute",
        "Trace API With limit line",
        "Impact FACET",
        "NrIntegrationError by limit",
        "Multi-Account limits (on time series charts only)",
        "Limit list and NrIntegrationError",
        "Limit metrics",
        "newrelic.resourceConsumption.limitValue",
        "newrelic.resourceConsumption.currentValue",
        "newrelic.resourceConsumption.impact",
        "Metric attributes",
        "Set alerts on resource metrics",
        "Limits faceted by LimitName and scoped by Timewindow",
        "Alert on a single limit",
        "Alert on limit impact faceted by dataType, impact, resource, and reason",
        "Alert on impact of a single dataType"
      ],
      "title": "Query system limits",
      "type": "docs",
      "tags": [
        "Ingest data manage data",
        "Manage data",
        "Resource metrics",
        "system limits"
      ],
      "external_id": "7ac33e47dfcfb91089e020a39097c9d648389f51",
      "image": "https://docs.newrelic.com/static/16cb17d5244a118d794df354f67bab81/c1b63/limits-dashboard.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/query-limits/",
      "published_at": "2021-12-19T15:30:37Z",
      "updated_at": "2021-11-13T19:58:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has resource limits in place to protect your experience, our systems, and our other customers. These limits range from the maximum number of characters you can have in a query, to API request rates, to how many events your queries inspect, and more. This page describes the limit metrics and NrIntegrationError events that enable you to view your limits, your current data usage and overall resource consumption as compared to those limits, and the impact of experiencing a limit event. We also provide a handful of queries that, when compiled into a dashboard, can give you consistent insight into your limits status. Important While NrIntegrationError events provide data on many limits types, resource limit metrics currently only cover request rate ingestion and API query rate limits. What happens when you reach a limit Our response to reaching a limit depends on a handful of factors: the type of limit thats reached, as well as the duration, frequency, and amount at which you exceed the limit. Exceeding a limit doesnt always mean you experience a limit event, such as dropped data, rejected traffic, or having your data turned off for the rest of the day. We sometimes allow a small buffer before enforcing a limit. That said, any resource consumed above 100% is at risk for limit impact at any time. Many of our rate limits apply proportionally. That means if youre barely exceeding the limit, we will take less action than if you're exceeding by 200%. Limit metrics are only visible if you're sending data in to a corresponding dataType or limitName API. For example, if you send in data via the Metric API, youll see the Metric API resource metrics, but if you don't send any APM data in, you won't see APM resource metrics. Tip Impact metrics will be generated regardless of impact; if there's no impact, youll see a 0. An NrIntegrationError event is generated when you experience impact and is a good way to quickly see if youre experiencing any limit events. See View System Limits for more information. Create a dashboard to view your limit status Using three limit metrics together on a dashboard, you can quickly see detailed visuals of your Ingest Resource Request Per Minute limits, and with NrIntegrationError get a view into more limits. Dashboard displaying limits status using a handful of queries. We used the following queries to create this dashboard. To make a dashboard like this in New Relic One, select Dashboards, and then Create a dashboard. Then, add a new chart for each query you want to regularly monitor. The three limits metrics included in these queries are described in a separate section, below. From left to right, top to bottom: Resource Consumption Limits as a % FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) /latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName where limitTimeInterval = '1 minute' timeseries limit max Copy Max % Consumption in an hour SELECT max(`usage`) FROM (FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 as 'usage' facet limitName timeseries ) facet limitName limit max Copy APM Agent API transaction events request per minute FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) where limitName = 'APM Agent API transaction events requests per minute' TIMESERIES Copy Trace API With limit line FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) as 'usage', latest(newrelic.resourceConsumption.limitValue) as 'limit' where limitName = 'Trace API requests per minute' TIMESERIES Copy Impact FACET From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource TIMESERIES 1 minute limit max Copy NrIntegrationError by limit FROM NrIntegrationError select count(*) facet limitName TIMESERIES MAX since 1 day ago limit max Copy Multi-Account limits (on time series charts only) If you want to see limits for multiple accounts on one chart: run this query from one of the accounts: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName, consumingAccountId where limitTimeInterval = '1 minute' timeseries limit max Copy Click Add another query. Select a different account. Then run this query again: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName, consumingAccountId where limitTimeInterval = '1 minute' timeseries limit max Copy Finally, save it. Limit list and NrIntegrationError FROM Metric, NrIntegrationError select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) as 'Per Minute Count',latest(newrelic.resourceConsumption.limitValue) as ' limit Value',(rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue)*100)as 'Percent Used', filter (count(*), where NrIntegrationError.limitValue is not null) as 'limit reached count' facet limitName limit 1000 Copy Limit metrics These metrics, used in the dashboard queries above, can hone in on a single limit or resource. Or, with the help of FACET limitName or resource provide a view across all your limits. newrelic.resourceConsumption.limitValue limitValue allows you to see the setting for a limit by limitName and understand more about what resource is linked to this limit. The following examples use the limit value metric in the query: Example for Metric API requests per minute. FROM Metric select latest(newrelic.resourceConsumption.limitValue) where limitName = 'Metric API requests per minute' Copy To show all limits, add FACET limitName and consider grouping by limitTimeInterval. FROM Metric select latest(newrelic.resourceConsumption.limitValue) WHERE limitTimeInterval = '1 minute' FACET limitName limit max Copy newrelic.resourceConsumption.currentValue currentValue shows you how much of a given resource youre currently consuming. To get a better glimpse into how our systems are viewing your consumption, use a rate() function with the time period that aligns with the limitTimeInterval. Limit 200. Example for Metric API request per minute: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue),1 minute) where limitName = 'Metric API requests per minute' Copy To show all limits, add FACET limitName and consider grouping by limitTimeInterval. FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue),1 minute) where limitTimeInterval = '1 minute' FACET limitName limit max Copy newrelic.resourceConsumption.impact impact lets you know for any given resource what impact limit events are having. Zeros mean you are not currently impacted. The most granular we have is dataType. It is possible for multiple instances of limitName to impact a single type, such as Metric RPM and DPM. If we know, we will display limitName. From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, resource, impact, limitName TIMESERIES limit max Copy Metric attributes Attributes on newrelic.resourceConsumption.limitValue and newrelic.resourceConsumption.currentValue: limitName: The Name of the limit for the metric data, for example RPM Metric API. dataType: What kind of data the metric is tracking, for example Metric, Log, or APM. Resource: What resource is being consumed, for example Requests or DPM. limitTimeInterval: What time window this resource is evaluated for limiting. consumingAccountId: The New Relic account where the resource is being consumed. Attributes on newrelic.resourceConsumption.impact dataType: The kind of data that is being impacted, for example Metric, Log, or APM. Resource: What resource is being impacted, for example Request Rate. Impact: A count of what is happening when resource has exceeded set limit, for example dropped requests. consumingAccountId: The New Relic account where the resource is being consumed. Set alerts on resource metrics While building a dashboard to see all your limits is handy, being able to automate it is even better. You can set alerts on your limit metrics to provide updates on limits changes. Tip Because we currently only have metrics on 1 minute time windows, setting TimeWindow = 1 minute, will cover them all. Eventually, we make more metrics available, you might want to set separate alerts for limits that are enforced by different time windows. You can use the following NRQL queries to create alerts. Learn about creating alerts with NRQL queries here. Limits faceted by LimitName and scoped by Timewindow From Metric select (rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue))*100 facet limitName Copy Alert on a single limit From Metric select (rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue))*100 where limitName = 'my limit' Copy Alert on limit impact faceted by dataType, impact, resource, and reason From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource, reason Copy Alert on impact of a single dataType From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource, reason WHERE dataType = 'important things' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.85196,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "APM Agent API transaction <em>events</em> request per minute",
        "tags": "<em>Ingest</em> <em>data</em> manage <em>data</em>",
        "body": " and <em>NrIntegrationError</em> events that enable you to view your limits, your current <em>data</em> usage and overall resource consumption as compared to those limits, and the impact of experiencing a limit <em>event</em>. We also provide a handful of queries that, when compiled into a dashboard, can give you consistent"
      },
      "id": "608abed9196a67a63064a7a6"
    }
  ],
  "/docs/data-apis/manage-data/query-limits": [
    {
      "sections": [
        "Know your data limits",
        "Responses to limit violations",
        "System limits UI",
        "Troubleshooting system limits",
        "Account-level limits",
        "Data ingest API limits",
        "Finding other agent and integration limits"
      ],
      "title": "Know your data limits",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "7c540d94a8b5e4f024d175ad53cab9fab343187c",
      "image": "https://docs.newrelic.com/static/8ee61e3091f6e044202cff92026afada/8c557/limits-graph.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/view-system-limits/",
      "published_at": "2021-12-19T15:31:02Z",
      "updated_at": "2021-10-31T06:37:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure our systems are always up and ready to support you, and to keep you from unintended use, we place limits on the amount of data you can send, query, and store. Responses to limit violations Limits are enforced per child account, and across our APIs. You might reach a limit if you start monitoring a new high-traffic application, or have a sudden data spike. When you do reach a limit, New Relic responds according to the type of data and the limit thats reached. For example: We place a limit on the number of ingested requests per minute (RPM) per data type. When this limit is reached, we stop accepting data and return a 429 status code for the duration of the minute. For queries, we place limits on the number of queries per minute and the number of records inspected (see query limits). When the number of queries per minute limit is reached, New Relic will begin rejecting queries until the number of queries is below the limit. When the records inspected limit is reached, New Relic will reject traffic from the source scanning the largest number of records and attempt to allow traffic from other sources. For metrics, we place a limit on the number of unique timeseries (cardinality) per account and per metric. When this limit is reached, aggregated data is turned off for the rest of the UTC day. For every major limit violation, New Relic creates an NrIntegrationError event for that account, which has these limit-related attributes: Attribute Description category RateLimit or ApiLimit. The RateLimit category is used for limits based on a unit of time such as the number of requests ingested per minute. The ApiLimit is used for constant limits, such as the number of attributes on a record. limitName The name of the limit. message Describes the limit and the impact. limitValue The limit reached. System limits UI The system Limits page (from the account dropdown, click Manage your data and click Limits on the left) displays when your account has encountered a rate limit in the specified time period. The page displays a default period of 24 hours; you can set a custom range from the top-right of the page. Non-limit-related NrIntegrationError events are not displayed here. In addition, this page does not display information about limits you have not hit, or how close you are to reaching a limit. For more on creating queries and alerts for data ingest and billing metrics, see Query billing/usage data. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a chart on the Limits UI page displaying a cardinality violation limit issue. To add more detail, or build a dashboard, click the View NRQL button on the chart to see the NRQL powering this view. The graph displays each unique limit type that was reached during the selected time-period. This can help you find any trends based on time. The Limits page also provides a table where you can find the limit name, the limit event message associated with it, and last occurrence time and date. If you click a limit in the table, you see more about what happened, and when. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a limit events table on the Limits UI page. Troubleshooting system limits To troubleshoot limits when you reach them, click the limit info in the table, and then follow the docs link that's provided. Different limits have different solutions. Account-level limits The following table includes general max limits that apply across all New Relic accounts. Specific New Relic tools, like agents and integrations, have their own limits and configurations, and might be lower than these theoretical maximum limits. Limited condition Limit Rate of NRDB record * ingest 55 million per account per minute Max NRDB records * ingested per API call 1MB (10^6 bytes) Max attribute value size 1KB (10^3 bytes) Max payload size 1MB (10^6 bytes) Max total attributes per data type (including default attributes) 254 (less for some tools; for example, 64 for agents) Number of unique custom data types 250 per account per day (applies to custom events because that's source of new data types) APM limits Agent instances: 50K per account Agent instances per app: 10K APM apps/services: 10K per second Browser: number of page views 1M per minute per app Distributed tracing: Max age of span timestamp values 20 minutes. Timestamp must be within 20 minutes of current time at ingest or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Distributed tracing: Max spans per minute per account Dependent on agreement. Max limit: 2M. Distributed tracing: Max spans per trace 50K Distributed tracing: Max attributes per span 200 Rate of metric timeslice data (used by APM, browser, mobile) Ingest: 2 million per minute Rate of names: 4 million per minute per account Number per monitored app: 300K Mobile monitoring: number of crashes reported 10K per hour Infrastructure agents, integrations Number of infrastructure agents and/or integrations: 5K per account Gross number of new monitored containers: 5K per hour per account Query limits NRDB records * inspected: 100 billion per account per hour Rate of queries: 20 per account per second See other query limits * NRDB records refers to database records for our core data types, which includes events, metrics (dimensional), logs, and distributed tracing (span) data, all stored in the New Relic database (NRDB). This does not include metric timeslice data. Data ingest API limits Our ingest APIs have additional limits that may override the more general account-level limits. Note that these limits also apply to our tools that use these APIs (like our Telemetry SDKs or our open source telemetry integrations). Metric API (dimensional metrics) Event API Log API Trace API Finding other agent and integration limits To find limits for our other agents and integrations, which will override more general account-level limits, see the docs for those tools: you can search our quickstarts here. Some default reporting limits are located in these tools' configuration docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.4102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Know your <em>data</em> <em>limits</em>",
        "sections": "<em>Data</em> <em>ingest</em> API <em>limits</em>",
        "tags": "<em>Ingest</em> and <em>manage</em> <em>data</em>",
        "body": ". <em>limit</em>Value The <em>limit</em> reached. <em>System</em> <em>limits</em> UI The <em>system</em> <em>Limits</em> page (from the account dropdown, click <em>Manage</em> your <em>data</em> and click <em>Limits</em> on the left) displays when your account has encountered a rate <em>limit</em> in the specified time period. The page displays a default period of 24 hours; you can set"
      },
      "id": "60446a7c64441f48d7378f2b"
    },
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.854004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> and <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of API client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> APIs: the <em>Metric</em> API, Trace API, Log API, and Event API. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Manage your data",
        "Important",
        "Where to find the Data management hub",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "999fa6106dd47250e9a5d822aa2f92b6ea088c78",
      "image": "https://docs.newrelic.com/static/8a553ce9643c8513be3200af5d924250/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/manage-your-data/",
      "published_at": "2021-12-19T15:30:18Z",
      "updated_at": "2021-11-13T20:35:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. We also recognize that some data might not be necessary for your business goals. You shouldnt have to wade through data you dont need to get to the data you do. And you definitely shouldnt have to pay for it. Thats where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Data management hub: from the user profile drop down, select Manage your data. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important Not yet a New Relic customer? Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Where to find the Data management hub To locate the data management UI: From one.newrelic.com select the account dropdown, and select Manage your data. If you're on the New Relic One user model, you can also find the Data management hub by selecting Administration > Manage data. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, its important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust whats stored and for how long. Important If you're on our original product-based pricing model, you'll see your data ingest, retention, and limits in the Data management hub. The primary difference is that you're not billed on ingest, as with our New Relic One pricing model. Not sure which plan you're on? See Overview of pricing and user model. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because its a key component of how youre charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data is uncompressed, decorated with queryable attributes, and evaluated. Elements are dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, its also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data thats stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to whats most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 75.9223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Ingest</em> and <em>manage</em> <em>data</em>",
        "body": ", and select <em>Manage</em> your <em>data</em>. If you&#x27;re on the New Relic One user model, you can also find the <em>Data</em> management hub by selecting Administration &gt; <em>Manage</em> <em>data</em>. Better cost, performance, and compliance Collecting and storing <em>data</em> in New Relic allows you to analyze, visualize, and alert on all your <em>metrics</em>"
      },
      "id": "603e96ff28ccbcf8bceba796"
    }
  ],
  "/docs/data-apis/manage-data/view-system-limits": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.04816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of API client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "New Relic data types",
        "Get started",
        "Tip",
        "Metrics",
        "Metrics in the monitoring industry",
        "Metrics at New Relic",
        "Dimensional metrics (used by Metric API and many integrations)",
        "Metric timeslice data (used by APM, browser, mobile)",
        "Metric timeslice examples",
        "Metrics attached to events (used by Infrastructure, other products)",
        "Metrics as a computation of events (used in some charts and queries)",
        "Event data",
        "Events in the monitoring industry",
        "Events at New Relic",
        "Log data",
        "Logs in the monitoring industry",
        "Logs at New Relic",
        "Trace data",
        "Tracing in the monitoring industry",
        "Tracing at New Relic",
        "Query and send data",
        "Learn more"
      ],
      "title": "New Relic data types",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "8e4ab82bb58db47bc412f57231d4956c6068262b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/new-relic-data-types/",
      "published_at": "2021-12-19T15:32:43Z",
      "updated_at": "2021-12-04T21:48:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform is built around the four fundamental telemetry data types we believe are necessary for complete and effective system monitoring: metrics, events, logs, and traces. After you sign up for a free New Relic account and install any of our monitoring services, you can start working with your data. Get started This doc will give you a fairly technical explanation of our core data types, their structure, and how they're used in our features. You can use most of our features without needing to understand the underlying data structure. But having a better understanding of this can help you get data into New Relic, understand the data you see in our UI, and query your data. For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types. Another good way to understand your data is to just start querying it. Tip Access your data easily on one.newrelic.com: Click the Browse data dropdown menu and select the data type (metrics, events, logs, and traces) you want to explore. Metrics First, well explain the definition of metrics from a monitoring industry perspective, and then well explain how New Relic handles metrics. For a list of the metrics we collect, see our documentation on metrics. Metrics in the monitoring industry In the software monitoring industry, a metric means a numeric measurement of an application or system. Metrics are typically reported on a regular schedule. Two major types of metrics are: Aggregated data. For example: a count of events over one minutes time, or the rate of some event per minute. A numeric status at a moment in time. For example: a CPU temperature reading, or a CPU% used status. Metrics are relatively easy to report and store because a single record can represent a range of time. They can also be aggregated more and more over time. For example, per-minute data may be rolled up to per-hour aggregations after some amount of time, and eventually may be rolled up to a per-day aggregation. This approach is efficient for long-term data storage. Metrics are a strong solution for storing data long-term, and understanding trends over time. One potential downside is that it can be difficult to do detailed analysis of older data that has been aggregated over time; when high detail is required about specific important actions, event data can be used. Metrics at New Relic Conceptually, \"metrics\" is a broad, general category. There are various ways New Relic measures and reports metrics but, in practice, when using the New Relic UI, you usually won't have to understand how exactly this happens. In our documentation, we typically will just refer to \"metrics,\" regardless of how that data is reported, unless there's a reason you need to know more (like understanding how to query your data). Here are some of the ways metrics are reported and stored across the New Relic platform: Dimensional metrics (used by Metric API and many integrations) In the monitoring industry, \"dimensional\" metrics refer to metric data that has a variety of attributes (dimensions) attached, such as duration-related attributes (start time, end time), entity ID, region, host, etc. This amount of detail allows for in-depth analysis and querying. At New Relic, this metric data is attached to the Metric data type and is sent from several sources: Some open-source integrations, such as the Prometheus exporter. Our Telemetry SDKs Infrastructure services The Metric API (the underlying API used by the above tools) The events-to-metrics service To query this data and see its attributes (\"dimensions\"), you could use a NRQL query like: Select * from Metric Copy As time passes, these metrics are increasingly aggregated into larger time buckets. This is done to optimize your ability to query data over a long period of time. For more details about the metric data type, see our docs. To learn how this data is ingested and stored, see the Metric API documentation. For tips on querying, see Metric query examples. Metric timeslice data (used by APM, browser, mobile) New Relic's APM, browser, and mobile report and display metrics in a simple data format that we refer to as metric timeslice data. A metric timeslice consists of three parts: a metric name, the segment of time the metric represents (the \"timeslice\"), and a numeric value (the measurement). For example: an APM metric timeslice for time spent in a particular transaction is named WebTransaction/URI/foo, and might have a response time of 0.793 for a one-minute time slice from 10:20am to 10:21am. These metrics usually follow a pattern like <category>/<class>/<method>. Our agents (APM, browser, and mobile) can collect thousands of metric timeslices per minute for a variety of performance metrics. For example: error rate, bandwidth usage, and garbage collection time. You also have the ability to create custom metrics. Metric timeslice data is a lightweight data type and lacks the detail that dimensional metrics have. Ways to explore and query metric timeslice data: For APM: metric timeslice data is converted to dimensional metrics and can be queried via NRQL Use the REST API If you want to learn more about the structure of metric timeslice data and see some examples, expand the collapser below. Metric timeslice examples Here are some common metric timeslice data examples, with a focus on common ones used by Ruby applications. ActiveMerchant New Relic tracks a variety of metrics on ActiveMerchant transactions which can be used for business analytics as well as performance monitoring. The metrics are summarized by operation as well as by gateway. regex sample metric legend name ActiveMerchant/. * ActiveMerchant/PayJunctionGateway ActiveMerchant/gateway/. * ActiveMerchant/gateway/PayJunctionGateway/purchase PayJunctionGateway ActiveMerchant/operation/. * ActiveMerchant/operation/purchase purchase For more information, see the ActiveMerchant website. ActiveRecord ActiveRecord is the Object-Relational Mapping API used by Ruby on Rails applications. The metrics shown here measure the performance of ActiveRecord's find and save methods. regex sample metric legend name ActiveRecord/. * /find ActiveRecord/User/find User#find ActiveRecord/. * /save ActiveRecord/Product/save Product#save For more information, see the API documentation for ActiveRecord. Apdex Apdex is a measure of user satisfaction with page load times. Controller In Ruby on Rails applications, HTTP requests are handled by Controller actions. A Rails application has many controllers, each of which has one or more actions. When your rails application receives an http request, that request is routed to the appropriate controller and action, based on the URL of that request. That action then does whatever processing is neccesary to generate an http response, which is most often a web page, but could also be a page fragment, an xml document, or any other kind of data that is requested by the client. The following metrics track the performance of controller actions, regardless of routing, and without taking into account any network or web server effects. regex sample metric legend name Controller/. * Controller/Users/show /Users/show Controller/. * /(?! \\ (other \\ )). * Controller/Users/show /Users/show Controller$ Controller All Controller Actions ControllerCPU/ ControllerCPU/Users/Show /Users/show For more information, see the API documentation for ActionController. Errors This metric tracks the number of errors or exceptions raised while processing requests. regex sample metric legend name Errors/all Errors/all External services External service instrumentation captures calls to out-of-process services such as web services, resources in the cloud and any other network calls. It does not include other first class back-end components such as MemCache and the database. In Ruby applications we instrument the Net::Http library to capture all HTTP services. regex sample metric legend name External/ [ ^/]+/all$ External/service.example.com/all All service.example.com calls External/ External/host.aws.com/Net::Http : :POST Net::Http : :POST [ host.aws.com] External/all$ External/all External Services External/ [ ^/]+/(?!all)/ External/service.example.com/all All service.example.com calls HTTP dispatcher This metric represents a summary of the throughput and response time of all web requests. regex sample metric legend name ^HttpDispatcher$ HttpDispatcher HttpDispatcher MemCache MemCache is a popular technology that enables applications to access shared memory provided by any number of physical machines as a global cache. Applications that heavily use the database often use MemCache for performance and scalability benefits. These metrics measure the frequency and response time of calls to MemCache to read and write data from the cache. Response times should be low (less than 5 ms) for a well performing MemCache deployment. regex sample metric legend name MemCache/. * MemCache/read MemCache read operations MemCache/read MemCache/read MemCache read operations MemCache/write MemCache/write MemCache write operations Mongrel This metric measures the length of the mongrel queue, which holds pending http requests to be processed by mongrel. The HTTP Activity graph overlays the maximimum queue length for a given period. The value is zero if mongrel is processing a request but has no other requests waiting in its queue. When looking at this value across an aggregate cluster of mongrels, the queue lengths of all mongrels is added together, showing the sum of all queue lengths. A mongrel queue length should be at or near zero; if it is consistently at a higher level, then it indicates that your rails application is having trouble keeping up with its load requirements. regex sample metric legend name Mongrel/Queue Length Mongrel/Queue Length Queue Length View ActionView is a package in Rails that is used to render the output that is the response to an http request, such as an html page or an xml document. The View is rendered by the controller that is handling the request. If View metrics represent a large portion of your controller's response time, it could mean you are doing a lot of database operations inside the view template itself. regex sample metric legend name View/. * View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Partial View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Rendering View/Users/show.html.erb/Rendering Users/show.html.erb For more information, see the API documentation for ActionView. Metrics attached to events (used by Infrastructure, other products) Because event-type data can have any type of key-value pair data attached to it, one way metrics can be reported is as attributes attached to an event. A couple examples of this at New Relic: Our infrastructure monitoring reports many metrics that are attached to events. For example, we report a ProcessSample event, which has various sample-based metrics attached to it, like CPU percentage. To learn more about infrastructure monitoring data, see Infrastructure data. In APM, the Transaction event has several metrics attached to it, including databaseDuration. To learn more about this data and how to query it, see Events. Metrics as a computation of events (used in some charts and queries) Metrics can be formed by counting New Relic events, or doing some other mathematical calculation on those events. For example, if you wanted to measure the total number of Transaction events over the last half hour, you might run this NRQL query: Select count(*) from Transaction since 30 minutes ago Copy Another example: if you wanted to compute the average response time for your service, you might run a query like: FROM Transaction SELECT average(duration) SINCE 30 minutes ago Copy Some New Relic charts are generated with these kinds of queries. The downside of this approach is that there are limits on how many events a monitoring system (including ours) can report. This means that sometimes, for high-throughput systems, the count may not accurately represent the total activity on that system. To learn more about how this can be addressed, see Event limits and sampling. Want to report custom metrics? See Get data into New Relic. Event data First, well explain the definition of events from a monitoring industry perspective, and then well explain some specifics about how New Relic handles event data. Events in the monitoring industry In the software industry, events can be thought of as simply things that occur in a system. For example, a server setting being changed would be an event. Another example: a website user clicking a mouse. Some events will generate a stored record, and that record is typically also called an event. Event data represents discrete occurrences and typically will have a high level of detail, so event data is suited for detailed analysis and querying. The downside to the use of event data is that there are typically so many events reported that it can become difficult to query that large dataset over longer time ranges. Events at New Relic At New Relic, we report events to data objects also called events. These events have multiple attributes (key-value pairs) attached. Event data is used in some UI charts and tables, and you can also query it. How long event data remains available is determined by data retention rules. One example of an event: APM reports an event type named Transaction, which represents a logical unit of work in an application. To see the attributes attached to this event, you could use a NRQL query like: Select * from Transaction Copy For examples of querying event data, see Introduction to NRQL. Other details about New Relic event data: Events can have any type of attributes attached. Some events have attributes that report metric data. You can report custom events. To increase the availability of your event data for querying/charting, you can turn events into metrics. Some systems generate a large number of events that exceeds collection limits and results in incomplete query results. For more on this, see Event sampling. Because event is a general term, in some New Relic contexts it will refer to any data type that can be queried via NRQL. For example, when you run a NRQL query, it returns a count of inspected events: this is a count of all data types queried. Log data First, well explain the definition of logs from a monitoring industry perspective, and then well explain some specifics about how New Relic handles log reporting. Logs in the monitoring industry A log is a message about a system used to understand the activity of the system and to diagnose problems. Logs at New Relic New Relic's Logs gives you a centralized log management platform that connects your log data with other New Relic-monitored data. For example, you can see logs alongside your APM data. In New Relic, log data is reported with multiple attributes (key-value data) attached. To query your log data, you could use a NRQL query like: Select * from Log Copy To report custom log data, see the Log API. Trace data First, well explain the definition of traces from a monitoring industry perspective, and then well explain some specifics about how New Relic handles tracing. Tracing in the monitoring industry In the application/infrastructure-monitoring world, tracing is a general term used to refer to various ways to report information about how a program or system is operating. For example, a stack trace provides in-depth information about a programs subroutines. For large modern systems, which are often distributed across many services and micro-services, tracing often refers to distributed tracing, which is a way to monitor requests as they propagate through a complex, distributed environment. Tracing at New Relic New Relic offers a distributed tracing feature that tracks requests across a distributed system, and provides a dedicated UI for understanding and analyzing your traces. In New Relic, trace data is reported as Span objects, with multiple attributes (key-value pairs) attached. To query your tracing data, you could use a NRQL query like: Select * from Span Copy To learn more about how distributed tracing works, see Understand distributed tracing. To report custom distributed tracing data, see the Trace API. Query and send data Understanding New Relic data types can help you: Query data in New Relic Send data to New Relic Learn more For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.15855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>data</em> types",
        "sections": "Query <em>and</em> send <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "The New Relic platform is built around the four fundamental telemetry <em>data</em> types we believe are necessary for complete and effective system monitoring: metrics, events, logs, and traces. After you sign up for a free New Relic account and install any of our monitoring services, you can start working"
      },
      "id": "6045280de7b9d266e1579a0f"
    },
    {
      "sections": [
        "New Relic Database: the horsepower under the hood",
        "Billions of data points per minute",
        "Scale, purpose, and equal access to resources",
        "The lifecycle of a query",
        "The result: flexibility, speed, accuracy, and efficiency",
        "Whats next?",
        "New Relic-built agents and integrations",
        "Report custom data",
        "Learn more"
      ],
      "title": "New Relic Database: the horsepower under the hood",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "73e784610bedcc1bf4ae777e5d6a7a426f37304a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/get-started/nrdb-horsepower-under-hood/",
      "published_at": "2021-12-19T14:27:50Z",
      "updated_at": "2021-12-04T21:44:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If youve been reading our documentation, chances are youve already learned a bit about New Relic and the many tools and capabilities we offer. Were very proud of the utility and design of our dashboards, alerts, and versatile programmability, but none of it would be possible without the computing power needed to make it all run smoothly. Just like a finely calibrated race car, what you see on the outside may be the most exciting features, and these are the parts you interact with to drive. But without an engine designed to win, elegant instrument panels, a responsive clutch, and a great paint job wont get you anywhere. Under the hood of New Relic lies the engine powering it all: the New Relic Database (NRDB). In this resource, we explain how NRDB helps you succeed in your observability goals. Billions of data points per minute New Relic ingests billions of telemetry data points every minute, serving more than 180,000 accounts simultaneously. To run such a high-volume platform, the underlying database and query capabilities need to be fast, flexible, and scalable. They must also be equally effective for organizations of all sizes, supporting a wide spectrum of telemetry needs and business goals. NRDB provides the power, speed, and scalability you need to monitor your performance across your entire landscape quickly and effectively. Scale, purpose, and equal access to resources To meet the challenging demands for speed, efficiency, scalability, and reliability, we built NRDB with three key objectives. Unlimited scalability: Hosted in the cloud, NRDB's distributed architecture has the capacity for virtually unlimited scale. Monitoring and analysis: With this dual purpose in mind, NRDB handles operational monitoring and data analytics equally well. This means that NRDB can ingest massive amounts of data while also giving you real-time alerting, lightning-fast queries, and charting  all without sacrificing speed. Resources when you need them: As a multi-tenant system supporting tens of thousands of customers, NRDB gives you the resources you need when you need them (which single-tenant systems cannot match). The lifecycle of a query NRDB returns results for queries of all sizes astonishingly fast. To do this, we use parallel processing at massive scale. This architectural approach is equally effective for accelerating a single large query and for allowing numerous users to run small queries simultaneously without impacting speed. It works like this: A user enters a query using one of our tools, such as the query builder, or a dashboard or other type of instrumentation sends an automated query. NRDB starts by sending the query to a router, which in turn sends the query components to hundreds or even thousands of query workers. The query workers find the data, and the process is repeated in reverse, with data returning to populate dashboards, create alerts, or answer discrete queries, among other things. This process yields complete query results in a fraction of the time that other methods would require. To further improve efficiency, NRDB also caches recent queries, allowing it to send those results back to users nearly instantaneously. The result: flexibility, speed, accuracy, and efficiency How big is the difference? Because of NDRB's raw power and purposeful design, New Relic's telemetry products are able to analyze tens of billions of events per second while maintaining a median query response time of 45 milliseconds. We would say, Your query results are just a heartbeat away, but mathematically thats more like a tenth of a heartbeat (unless youre a mouse). What do these statistics mean for our customers? At the end of the day, NRDB's speed and unique capabilities enable you to identify, analyze, and fix performance problems much faster, reducing downtime so you can get back to business. Whats next? Now it's time to get data into New Relic! New Relic-built agents and integrations There are many ways to get data into your New Relic account. Any New Relic user can use any of our data ingest methods to report data to our platform.When you enable New Relic solutions like APM, browser monitoring, mobile monitoring, infrastructure monitoring, or any of our wide array of quickstarts, by default you'll receive data from your monitored applications, hosts, services, or other entities. Some options for getting started: Log into one.newrelic.com and click Add more data to get some guidance on setting up New Relic solutions. (Need to create a New Relic account first? Sign up for free!) To browse our solutions, see New Relic Instant Observability. Report custom data If you need to report data that our agents and integrations don't provide, we have tools that will allow you to bring in any type of data you need. To learn more, see Intro to custom data. Learn more Want to know more? Here are a few recommendations for what to do next: Learn about NRDB's data model and flexible schema in our blog post and white paper. Get to know NRQL, our query language, with our Syntax, clauses, and functions page, or read about some of our favorite NRQL capabilities. Read about our query builder, which supports NRQL and PromQL-style queries. Check out UI options for dashboards and charting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.15166,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>Database</em>: the horsepower under the hood",
        "sections": "New Relic <em>Database</em>: the horsepower under the hood",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " that NRDB can <em>ingest</em> massive amounts of <em>data</em> while also giving you real-time alerting, lightning-fast queries, and charting  all without sacrificing speed. Resources when you need them: As a multi-tenant system supporting tens of thousands of customers, NRDB gives you the resources you need when you need"
      },
      "id": "61744743e7b9d212c413d95d"
    }
  ],
  "/docs/data-apis/understand-data/event-data/customized-security-settings-insights": [
    {
      "sections": [
        "Default events reported by New Relic products"
      ],
      "title": "Default events reported by New Relic products",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "598dfde069ba5a8bbbd5834c44b9740d6b338cdc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/event-data/default-events-reported-new-relic-products/",
      "published_at": "2021-12-20T03:00:06Z",
      "updated_at": "2021-10-23T17:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic products report different types of data. One type of data reported is event data. Events are displayed in UI charts and tables, and also made available for querying. To understand the types of data available, see Data available via NRQL. Learn more about the events reported by New Relic products: APM default events Browser default events Infrastructure default events Mobile default events Synthetics default events NrAuditEvent events for understanding changes to your account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.28172,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Default</em> <em>events</em> reported by New Relic products",
        "sections": "<em>Default</em> <em>events</em> reported by New Relic products",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "New Relic products report different types of <em>data</em>. One type of <em>data</em> reported is <em>event</em> <em>data</em>. <em>Events</em> are displayed in UI charts and tables, and also made available for querying. To understand the types of <em>data</em> available, see <em>Data</em> available via NRQL. Learn more about the <em>events</em> reported by New Relic"
      },
      "id": "609f8faf64441f8af9d2a1f0"
    },
    {
      "sections": [
        "Events reported by synthetic monitoring"
      ],
      "title": "Events reported by synthetic monitoring",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "908d6d1bc27321c7d0c330318504e4681c25a400",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/event-data/events-reported-synthetic-monitoring/",
      "published_at": "2021-12-20T10:04:55Z",
      "updated_at": "2021-10-23T17:25:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring in New Relic reports event data that is displayed in some UI displays and is also available for querying and charting. Select an event name in the following table to see its attributes. Event Description SyntheticCheck SyntheticCheck returns metrics from one run of a specific monitor. These metrics include duration information for the monitor, location of the monitor check, size of the request and response headers, the type of monitor, and a timestamp. Each time a synthetic monitor runs a check, details about the check are captured in theSyntheticCheck event type. SyntheticCheck events contain details specific to the check to provide visibility such as the status, type of monitor, and size of request and response headers. SyntheticRequest SyntheticRequest returns results from individual HTTP requests made during a check. The data gathered include job information, location, type of content for request, duration information, request size, and page load information. With each simple or scripted monitor check, we capture each individual HTTP request made during the check. The HTTP details are captured at a more granular level than the SyntheticCheck event type. SyntheticPrivateLocationStatus Every monitor check running on a private location triggers capacity details for that private location. These details are captured in a SyntheticPrivateLocationStatus event. This provides visibility into the capacity of a private location and whether additional minions are required to support the workload. SyntheticPrivateMinion If you have private locations, such as those inside your firewall, you can view information regarding those locations with the SyntheticPrivateMinion event. Each private minion running sends health details to SyntheticPrivateMinion every 30 seconds. This allows you to understand the health of the private minion running at the location. Related documentation: Report custom events Extend data retention See example NRQL queries",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.28049,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Events</em> reported by synthetic monitoring",
        "sections": "<em>Events</em> reported by synthetic monitoring",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Synthetic monitoring in New Relic reports <em>event</em> <em>data</em> that is displayed in some UI displays and is also available for querying and charting. Select an <em>event</em> name in the following table to see its attributes. <em>Event</em> Description SyntheticCheck SyntheticCheck returns metrics from one run of a specific"
      },
      "id": "609f8faf64441f8e99d2a1d5"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "77720ef366038ba648a5fbf3cf34e8e48b38440a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T21:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). If the name begins with anything other than an alphabetical character, enclose the name with backticks in your NRQL query. For example: FROM `0_hello` SELECT count(*) Copy Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.92879,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for custom <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for custom <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: <em>Default</em> <em>events</em> from New Relic agents Custom <em>events</em> from New Relic agents Custom <em>events</em> from <em>Insights</em> custom <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    }
  ],
  "/docs/data-apis/understand-data/event-data/default-events-reported-new-relic-products": [
    {
      "sections": [
        "Security for New Relic-reported events and attributes",
        "Default events and attributes",
        "Adjust the data reported"
      ],
      "title": "Security for New Relic-reported events and attributes ",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "446305a7d17c6dfb44e9e87520a1c08b79f5bcf9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/event-data/customized-security-settings-insights/",
      "published_at": "2021-12-20T06:38:30Z",
      "updated_at": "2021-10-23T17:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By default, New Relic products report a variety of data used in our UI charts and that is available for querying. Our products will not transmit sensitive information without being explicitly instrumented to do so. Default events and attributes Our products report a set of default events and attributes. We will never send request parameters or any other attributes that are not in the default set, unless someone has explicitly enabled this via configuration. Adjust the data reported When evaluating security settings for a New Relic product, review the default events and attributes. The default attributes don't contain sensitive data. In general, it's simply the data needed for effective performance monitoring. Our products don't send other data unless you change the default security settings. Depending on your requirements, either or both of these situations may apply: If the default list contains data you're concerned about, you can disable those attributes from being collected. For how to edit that, see the documentation for the product you're using. If you need to send attributes not reported by default, you can enable those attributes to be reported. In that case, do not use high security mode: this will disable the ability to collect custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.28172,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for New Relic-reported <em>events</em> and attributes ",
        "sections": "<em>Default</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "By <em>default</em>, New Relic products report a variety of <em>data</em> used in our UI charts and that is available for querying. Our products will not transmit sensitive information without being explicitly instrumented to do so. <em>Default</em> <em>events</em> and attributes Our products report a set of <em>default</em> <em>events</em>"
      },
      "id": "60a8ea67e7b9d25ec7aeabfe"
    },
    {
      "sections": [
        "Events reported by synthetic monitoring"
      ],
      "title": "Events reported by synthetic monitoring",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "908d6d1bc27321c7d0c330318504e4681c25a400",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/event-data/events-reported-synthetic-monitoring/",
      "published_at": "2021-12-20T10:04:55Z",
      "updated_at": "2021-10-23T17:25:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring in New Relic reports event data that is displayed in some UI displays and is also available for querying and charting. Select an event name in the following table to see its attributes. Event Description SyntheticCheck SyntheticCheck returns metrics from one run of a specific monitor. These metrics include duration information for the monitor, location of the monitor check, size of the request and response headers, the type of monitor, and a timestamp. Each time a synthetic monitor runs a check, details about the check are captured in theSyntheticCheck event type. SyntheticCheck events contain details specific to the check to provide visibility such as the status, type of monitor, and size of request and response headers. SyntheticRequest SyntheticRequest returns results from individual HTTP requests made during a check. The data gathered include job information, location, type of content for request, duration information, request size, and page load information. With each simple or scripted monitor check, we capture each individual HTTP request made during the check. The HTTP details are captured at a more granular level than the SyntheticCheck event type. SyntheticPrivateLocationStatus Every monitor check running on a private location triggers capacity details for that private location. These details are captured in a SyntheticPrivateLocationStatus event. This provides visibility into the capacity of a private location and whether additional minions are required to support the workload. SyntheticPrivateMinion If you have private locations, such as those inside your firewall, you can view information regarding those locations with the SyntheticPrivateMinion event. Each private minion running sends health details to SyntheticPrivateMinion every 30 seconds. This allows you to understand the health of the private minion running at the location. Related documentation: Report custom events Extend data retention See example NRQL queries",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.28049,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Events</em> reported by synthetic monitoring",
        "sections": "<em>Events</em> reported by synthetic monitoring",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Synthetic monitoring in New Relic reports <em>event</em> <em>data</em> that is displayed in some UI displays and is also available for querying and charting. Select an <em>event</em> name in the following table to see its attributes. <em>Event</em> Description SyntheticCheck SyntheticCheck returns metrics from one run of a specific"
      },
      "id": "609f8faf64441f8e99d2a1d5"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "77720ef366038ba648a5fbf3cf34e8e48b38440a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T21:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). If the name begins with anything other than an alphabetical character, enclose the name with backticks in your NRQL query. For example: FROM `0_hello` SELECT count(*) Copy Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.92879,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for custom <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for custom <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: <em>Default</em> <em>events</em> from New Relic agents Custom <em>events</em> from New Relic agents Custom <em>events</em> from <em>Insights</em> custom <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    }
  ],
  "/docs/data-apis/understand-data/event-data/events-reported-apm": [
    {
      "sections": [
        "Default events reported by New Relic products"
      ],
      "title": "Default events reported by New Relic products",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "598dfde069ba5a8bbbd5834c44b9740d6b338cdc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/event-data/default-events-reported-new-relic-products/",
      "published_at": "2021-12-20T03:00:06Z",
      "updated_at": "2021-10-23T17:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic products report different types of data. One type of data reported is event data. Events are displayed in UI charts and tables, and also made available for querying. To understand the types of data available, see Data available via NRQL. Learn more about the events reported by New Relic products: APM default events Browser default events Infrastructure default events Mobile default events Synthetics default events NrAuditEvent events for understanding changes to your account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 319.69904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>events</em> <em>reported</em> <em>by</em> New Relic products",
        "sections": "Default <em>events</em> <em>reported</em> <em>by</em> New Relic products",
        "tags": "Default <em>events</em>",
        "body": "New Relic products <em>report</em> different types of data. One type of data <em>reported</em> is <em>event</em> data. <em>Events</em> are displayed in UI charts and tables, and also made available for querying. To understand the types of data available, see Data available via NRQL. Learn more about the <em>events</em> <em>reported</em> by New Relic"
      },
      "id": "609f8faf64441f8af9d2a1f0"
    },
    {
      "sections": [
        "Manage error data",
        "View logs for your APM and infrastructure data",
        "Error data types: events and trace details",
        "Events",
        "Trace details",
        "Caps on error reporting",
        "Charting error rates and counts",
        "Report custom errors",
        "Ignore errors",
        "Reduce noise with expected errors",
        "Disable error traces",
        "Delete error traces",
        "Caution"
      ],
      "title": "Manage error data",
      "type": "docs",
      "tags": [
        "APM",
        "APM UI pages",
        "Error analytics"
      ],
      "external_id": "29a2ebdc7b91029a1fada50791b90e9dc548f17e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/apm-ui-pages/error-analytics/manage-error-data/",
      "published_at": "2021-12-19T16:18:15Z",
      "updated_at": "2021-11-14T09:35:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's APM Errors page helps you identify, triage, and fix errors in your services. The Errors page uses data collected by the APM agent to display stack traces, transaction attributes such as HTTP header values, and any other custom attributes, so you can understand the context of the error and fix it. View logs for your APM and infrastructure data You can also bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. No need to switch to another UI page in New Relic One. Error data types: events and trace details By default, our APM agents collect two type of error data: Events Trace details Events The error event data type includes default attributes, as well as any custom attributes instrumented in your service. It doesn't include a stack trace. Find your events data in the Errors UI as follows: The Errors column in the Error traces table. The Top 5 errors chart. When youve drilled into a grouping of errors, those errors not displaying a stack trace are based on this type of data. You can disable Show only errors with stack trace to show errors that have this type of data collected, but no associated trace details. Events are subject to sampling (see Caps on error reporting and Charting error rates and counts). For more on error event data, see Events reported by APM. Trace details The trace details error data type includes stack traces and attributes, and supplements events with more data. It's expected that more events will be reported than trace details--see Caps on error reporting. Find your trace details data in the Errors UI as follows: The Stack traces column of the Error traces table. When youve drilled into a grouping of errors, those errors with a stack trace use this type of data. Show only errors with stack trace is enabled by default, to constrain the errors shown to just those that have this type of data collected. This data is governed by specific retention rules for Error details. Caps on error reporting New Relic caps error reporting at: 100 events per minute per agent instance 20 trace details per minute per agent instance These caps prevent error reporting from negatively impacting application performance. Examples: App running across five EC2 instances, one JVM each. New Relic caps error reporting at: 100 events per minute x 5 instances = 500 events per minute 20 trace details per minute x 5 instances = 100 trace details per minute App running on one host with ten instances. New Relic caps error reporting at: 100 events per minute x 10 instances = 1000 events per minute 20 trace details per minute x 10 instances = 200 events per minute Charting error rates and counts The Error rate chart is driven by a query on metric timeslice data, which is an unsampled aggregate data type that is accurate but has very limited dimensionality. This data can't be faceted or filtered as flexibly as error event data. You can reproduce this chart in a dashboard, or explore the metric timeslice data further by clicking the ... menu on the Error rate chart, and then using the View query or Add to dashboard options. To chart faceted error counts using event data, as in the Top 5 errors chart, use an NRQL event query. Click the ... menu on the Top 5 errors chart and choose View query for a starting point in creating your chart. Since event data can be sampled (see Caps on error reporting), you can use the EXTRAPOLATE keyword to get an accurate error count, even if sampling is occurring. Report custom errors You can report errors not collected by default with our agents using our agent APIs. For more, see the documentation on the API. Ignore errors You can prevent certain errors that would normally be reported to New Relic from being collected using our agent APIs or the server-side configuration UI. For more details, see Manage errors in APM. Reduce noise with expected errors Sometimes you want to collect error data, but not have those errors wake you up through alerts. Using the agent API, you can mark such errors as expected. Theyll still be visible in the Errors page, but wont affect your services error rate or Apdex metrics. Disable error traces To prevent certain errors from being reported to New Relic, disable them in your agent's configuration file. For most agents, you can ignore certain error codes or disable errors completely. For more information, see your specific agent's configuration documentation: C SDK Go (not applicable; the agent only reports errors when configured to do so) Java .NET Node.js PHP Python Ruby Delete error traces Caution You cannot recover error traces after you delete them. Deleting errors is currently only available in the legacy Errors Classic UI. If you want to... Do this... Delete all error traces for your app If you have permissions to delete all error traces for an app: Go to one.newrelic.com > APM > (select an app) > More views > Errors (classic). Select Delete all errors. Delete all error traces for your account To delete all error traces for your New Relic account, get support at support.newrelic.com. Delete individual error traces To delete individual error traces, use APM's Errors (classic) page. Drill into an error from the table of errors, then click Delete this error. In addition to deleting error traces, you may also want to delete transaction traces or database/slow SQL traces. This will remove potentially sensitive data while retaining your other application data (such as Apdex, deployment information, etc.).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.46375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Error data types: <em>events</em> and trace details",
        "tags": "<em>APM</em>",
        "body": " in context of your infrastructure data, such as Kubernetes clusters. No need to switch to another UI page in New Relic One. Error data types: <em>events</em> and trace details By default, our <em>APM</em> agents collect two type of error data: <em>Events</em> Trace details <em>Events</em> The error <em>event</em> data type includes default attributes"
      },
      "id": "6044077e28ccbcab752c60d1"
    },
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesnt support its use or that hasnt used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hours worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.07376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Histogram of response times from PageView <em>events</em>",
        "body": " SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom <em>events</em> <em>reported</em> via <em>APM</em> agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of <em>APM</em> agent sampling"
      },
      "id": "604456c1196a678db8960f41"
    }
  ],
  "/docs/data-apis/understand-data/event-data/events-reported-browser-monitoring": [
    {
      "sections": [
        "Build a custom New Relic One application",
        "Get started",
        "New Relic One: a programmable platform",
        "Tip"
      ],
      "title": "Build a custom New Relic One application ",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Build on New Relic One"
      ],
      "external_id": "0fd7afcf4cd3c15157668bf349e84968062140ed",
      "image": "https://docs.newrelic.com/static/2caff7bdf3bb0fb46bee7c214448c921/c1b63/new-relic-one-browser-analyzer-example-application_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/build-new-relic-one/build-custom-new-relic-one-application/",
      "published_at": "2021-12-19T13:48:02Z",
      "updated_at": "2021-07-27T13:37:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic gives you a framework to build your own React JavaScript applications that: Reside on the New Relic One platform, alongside your other dashboards and data. Feature visualizations that you've tailored specifically for your organization. Display data from any source you want, whether from a New Relic-monitored entity or data from another service or API. Get started Keep reading to learn more about what you can do with New Relic One apps. If you want to get started building quickly, first read the requirements. New Relic One: a programmable platform We strive to have an automated user experience that provides optimal value for all users. But we also know that some organizations have unique business needs that cant be met with our standard visualization options. Now, we give you control over the fundamental building blocks of our platform. Using the same tools our engineers use to build New Relic One, you can build custom applications that align with your unique organizational structure and business needs. If you know how to use React, GraphQL, and NRQL (our query language), building an application will take you only a few minutes. Check out these guides for help building custom applications. Solve any data-driven challenge, no matter how complex. You can: Use our APIs to get data into New Relic from any source. Visualize that data in your custom applications. one.newrelic.com: Heres an example of a custom application built on New Relic One. This application gives a highly detailed analysis of a website, using the PageView events reported from New Relic's browser monitoring. Tip If your visualization needs are relatively simple, consider using custom charts and custom dashboards. Now, visit our developer site and start building!",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 393.8201,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " a highly detailed analysis of a website, using the PageView <em>events</em> <em>reported</em> from New Relic&#x27;s <em>browser</em> <em>monitoring</em>. Tip If your visualization needs are relatively simple, consider using custom charts and custom dashboards. Now, visit our developer site and start building!"
      },
      "id": "603eaaa6e7b9d251572a07d0"
    },
    {
      "sections": [
        "Browser Summary page",
        "View the Summary page",
        "Core Web Vitals widgets",
        "User time on the site",
        "Initial page load and route change chart",
        "User-centric page load times chart",
        "Throughput chart",
        "Tip",
        "Front end vs. back end chart",
        "First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL",
        "Related Entities widget",
        "View Synthetics monitors"
      ],
      "title": "Browser Summary page",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Getting started"
      ],
      "external_id": "a69bb31a3bff73ef8badce5ce435da62e9e7b644",
      "image": "https://docs.newrelic.com/static/e61bbb246d462250e94c99bf637b9cca/c1b63/browser_summary_page.png",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/getting-started/browser-summary-page/",
      "published_at": "2021-12-19T15:18:58Z",
      "updated_at": "2021-12-10T02:30:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's Summary page summarizes the real-user browser performance of your app. Use the Summary page to: View trends in an app's browser-side performance Quickly troubleshoot page load timing issues Navigate to other browser UI pages View the Summary page To view a summary of browser performance for an app: Go to one.newrelic.com > Explorer > Browser applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com, click Browser, and select an app from the Browser index. From the app's Summary page, use standard New Relic page functions to drill down into detailed information. one.newrelic.com > Browser > (select an app) > Summary: After you select an application from the browser apps index, the Summary page shows a summary of browser performance for that app. The Summary page includes: Core Web Vitals widgets User time on the site Initial page load and route change chart User-centric page load times chart Throughput chart Front end vs. back end chart First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL Related Entities widget View Synthetics monitors Core Web Vitals widgets The Core Web Vitals widgets show how your browser performs according to Google's Core Web Vitals. The Core Web Vitals widgets include: LCP - Largest Contentful Paint FID - First Input Delay CLS - Cumulative Layout Shift User time on the site The User time on the site widget shows the time a user remains on the site. Initial page load and route change chart The Initial page load and route change chart shows the load time of a traditional URL change stemming from a load or reload of a URL. This chart appears with more detail about the page load timing process on the page load time page. User-centric page load times chart The User-centric page load times chart shows the load time of a page for a user. This chart appears with more detail about the page load timing process on the page load time page. Throughput chart The Throughput chart displays browser throughput as pages per minute (ppm). The value in the upper right of the chart is the average value for the selected time range. If you have enabled SPA monitoring enabled and the Summary page shows the SPA load time chart, the Throughput chart will also use SPA data. Tip App server requests per minute (rpm) may show a different measurement than the browser page load timing's pages per minute (ppm). Front end vs. back end chart The Front end vs. back end chart links to the connect APM service application. For details on APM and tracing, see Language agents and distributed tracing. First interaction by device type, First interaction by user agent, JavaScript errors, and Longest first input delay by URL You'll also see summary versions of these metrics from the page load time page and JavaScript errors page: First interaction by device type First interaction by user agent JavaScript errors Longest first input delay by URL Related Entities widget The Related Entities widget shows all the entities that are related to the browser. To understand more about connections between entities, read about Entity relationships. View Synthetics monitors The button directs you to the Synthetics page. To read more about Synthetics, see Synthetic monitoring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.35022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> Summary page",
        "sections": "<em>Browser</em> Summary page",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s Summary page summarizes the real-user <em>browser</em> performance of your app. Use the Summary page to: View trends in an app&#x27;s <em>browser</em>-side performance Quickly troubleshoot page load timing issues Navigate to other <em>browser</em> UI pages View the Summary page To view a summary of <em>browser</em>"
      },
      "id": "60440d9c196a674ac8960f5b"
    },
    {
      "sections": [
        "AJAX call fails with a CORS redirect error message",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "AJAX call fails with a CORS redirect error message",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "a4e478428acefb454ab8969cccb666d03ae458f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/ajax-call-fails-cors-redirect-error-message/",
      "published_at": "2021-12-19T13:56:44Z",
      "updated_at": "2021-11-13T07:04:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem A redirected AJAX call is being rejected with a CORS error message, for example: Access to XMLHttpRequest at 'https://my-domain-2/path' (redirected from 'https://my-domain-1/path') from origin 'https://my-website-domain' has been blocked by CORS policy: Request header field x-newrelic-id is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The browser agent automatically adds custom headers to outgoing same-origin AJAX calls in order to support the Distributed Tracing feature. When the server that receives the AJAX call responds with a redirect status code (such as 302), the browser will automatically make the same AJAX call to the redirected URL. And if this new URL is on a different origin and the call does not pass the CORS preflight, the browser will fail the call with the error message listed above.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.330795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " is not allowed by Access-Control-Allow-Headers in preflight response. Copy Solution To resolve this error, update your code to make the AJAX call to the new URL provided by the redirect. For more information, see the MDN article CORS request external redirect not allowed. Cause The <em>browser</em> agent"
      },
      "id": "603eb41ce7b9d2ce042a07db"
    }
  ],
  "/docs/data-apis/understand-data/event-data/events-reported-mobile-monitoring": [
    {
      "sections": [
        "iOS agent compatibility and requirements",
        "Foreground monitoring",
        "iOS requirements",
        "Testing is not supported",
        "Potential method replacement conflicts"
      ],
      "title": "iOS agent compatibility and requirements",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Get started"
      ],
      "external_id": "544e062fdc57c4545c2f36b54b38f95b30b3c25e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/get-started/new-relic-ios-compatibility-requirements/",
      "published_at": "2021-12-19T19:52:39Z",
      "updated_at": "2021-12-19T19:52:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install and configure the iOS agent, follow these guidelines for compatibility and other requirements. Foreground monitoring The iOS agent only monitors your app while it is in the foreground. The agent does not monitor background services while the app is closed. For more information, see our Mobile data privacy and security documentation. iOS requirements Make sure your iOS app meets these requirements: Component iOS application requirements Operating system iOS 9 or higher For Bitcode support, use SDK version 5.3.0 or higher. API/SDK NSURLConnection and AFNetworking are supported. NSURLSession supports upload and data tags only. ASIHttpRequest networking APIs are deprecated as of iOS agent version 5.8.2. Network traffic for UIWebView and WKWebView is supported. However, WKWebView Transfer size and Http errors are not supported. Languages Objective-C Swift: Works with both network traces and crash reporting, but no interaction traces by default. Interaction traces must be enabled for Swift. Devices Any iOS compatible device: iPhones, iPads, etc. File sizes The agent adds about 2 to 12 megabytes to your iOS release app, depending on platform build. Architectures ARM 64-bit. SHA-2 As a standard security measure for data collection, New Relic requires that your application server supports SHA-2 (256-bit). SHA-1 is not supported. Xcode To take advantage of New Relic's iOS features, make sure you have the latest version of Xcode. arm64e support To be able to properly symbolicate crashes from devices with arm64e architectures, make sure your Xcode settings are enabled for pointer authentication. For more information, see the Apple developer documentation. CocoaPods In order to use the latest XCFramework Agent, use CocoaPods version 1.10.1 or higher. Testing is not supported Our agents are designed and tested to work in a normal app lifecycle. New Relic does not support running any testing environment on applications with the agent. Testing can cause conflicts and unpredictable behavior. Potential method replacement conflicts Our iOS agent utilizes method replacement during run time. This may result in a conflict with other libraries that also implement method replacement, such as ReactiveCocoa, Firebase, Aspects, and AppleGuice.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.93988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Foreground <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "Before you install and configure the iOS agent, follow these guidelines for compatibility and other requirements. Foreground <em>monitoring</em> The iOS agent only monitors your app while it is in the foreground. The agent does not <em>monitor</em> background services while the app is closed. For more information"
      },
      "id": "6044196064441f4f10378f04"
    },
    {
      "sections": [
        "HTTP errors: Network failure analysis",
        "Find and use the HTTP errors page",
        "Group, sort, and filter errors and failures",
        "HTTP error profiles",
        "View more details about a specific error",
        "View and share error data with query builder",
        "View legacy HTTP errors UI page",
        "View the Errors page",
        "Error trace details",
        "View error data in query builder",
        "Unknown errors or URL errors"
      ],
      "title": "HTTP errors: Network failure analysis",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "04631e122b061663c6fd261b605202654aadcf96",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-errors-network-failure-analysis/",
      "published_at": "2021-12-20T03:07:05Z",
      "updated_at": "2021-12-04T15:48:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring's HTTP errors page helps you to better understand HTTP errors and network failures associated with your mobile app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager See a list of errors and failures so you can coordinate mobile app teams with backend teams and share the data they need to fix issues. QA engineer Make sure that a new version of your app does not cause a spike in errors compared to a previous version. DevOps engineer See a list of domains and URLs associated with HTTP errors and network failures, so you can focus on the ones that are causing errors and filter out status codes that are too noisy for your alerts. Mobile developer Find out if there are frontend or backend problems affecting your mobile app (even without an error alert going off) so that you can address them in a new version. Support engineer View the errors and session attributes (geography, connection type, device, app version) associated with an error so that you can help customers with their issues. Find and use the HTTP errors page There are two ways to get to the HTTP errors page: Go to one.newrelic.com > Mobile > (select an app) > Network > Network errors. From a mobile app's Overview page in mobile monitoring, select the HTTP errors/network failures chart title link. From the HTTP errors page, investigate HTTP request and network failures: Use any standard page functions to look for trends in Errors and failures charts. Target specific types of errors and failures by grouping, sorting, and filtering the data. Find anomalies in your request errors with HTTP error profiles. Select an error or failure to view details for it. You can also define NRQL alerts that are focused on error types for your critical services or query your app data. Group, sort, and filter errors and failures If you want to do this... Do this... Change how the page groups and sorts errors and network failures Make selections from the Group by and Sort by dropdowns. By default, the Network errors page is grouped by request domain and sorted by errors and failures. Filter for specific errors and network failures Select an error or failure from the Errors and failures list and/or select multiple filters from the Filter dropdown. See which filters you applied or remove filters The filters you select display next to the filter dropdown. To clear filters, select the X next to the filter you want to clear. Change the time window Select a new time period from the Time picker dropdown. View information for one specific app version Select the version that you want to see charts and lists for in the Versions dropdown. HTTP error profiles Error profiles provide visual details about significant differences in the frequency of different values for HTTP error events. For each attribute, the error profile includes: A pie chart showing how the error's attribute is distributed for values that deviate the most A table comparing the error attribute's distribution to that of other errors This helps you take more of the guesswork out of resolving your mobile application's HTTP errors. You can more easily determine if you safely ignore the error, or if you should attempt to resolve the error with a new deployment, code change, customer communication or other actions. View more details about a specific error To view details about an error or failure, select the Request URL link to be directed to the Error summary page. From the Error summary page, you can view the version information, request attributes, and Response body, as well as get a breakdown of error types for the request URL. View and share error data with query builder To explore the data behind any of the charts or lists on the HTTP errors/requests page: Select for any chart. Select View query and then View in Insights. This will open the query builder. From the query builder, you can add the error data to a dashboard and share it via a permalink. To dig deeper into the error data, query your data for the following events and attributes: MobileRequestError events and attributes MobileRequest events and attributes View legacy HTTP errors UI page Accounts that do not have an Enterprise-level subscription see a different HTTP Errors UI page: The Errors page includes details about HTTP errors (403, 404, 422, 500, 502, etc.) and network failures for your hosts; for example: Secure connection failed Timed out Cannot find host Not connected to Internet Cannot connect to host View the Errors page To view HTTP errors or network failures for your mobile app: Go to one.newrelic.com > Mobile > (select an app) > Network > Errors. To change the view to errors or failures, select the Sort by option. To hide low-usage hosts, select the Hide < 1% throughput option. To limit information to a specific version of your app, or to change the time period, select your choice from the Versions menu or the time picker below the menu bar. To view details for a specific host, HTTP status error, or network failure, select its name. Use any of our standard user interface functions to drill down into detailed information. Error trace details Mobile monitoring will capture the response details from HTTP requests that return a 400 or 500 level status code. In addition, error messages generated from Android apps will include a stack trace. To view details about an error trace on the Errors page, select its request URL link. From here you can: View the response body. Share the error details with others by email. Delete or hide the error. The errors chart also appears on the selected mobile app's Overview page. If the chart shows errors, you can select its HTTP errors/network failures title or select anywhere on the Overview page's chart to go directly to this Errors page. View error data in query builder To dig deeper into your request data, use the query builder to query and chart the MobileRequest events and attributes. Unknown errors or URL errors The mobile agents maintain a list of exception types. In some cases, custom exceptions thrown by applications fall outside of this list. When this happens, Unknown may appear in the mobile Errors page. If you find Unknown in your list of errors and need assistance in researching which exception types are being missed, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 88.90941,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "<em>Mobile</em> <em>monitoring</em>&#x27;s HTTP errors page helps you to better understand HTTP errors and network failures associated with your <em>mobile</em> app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager"
      },
      "id": "603e8eb428ccbcd174eba791"
    },
    {
      "sections": [
        "Glossary of New Relic terms",
        "account dropdown",
        "account switcher",
        "administrator",
        "agent",
        "agent API",
        "aggregated metrics",
        "aggregation delay",
        "aggregation function",
        "aggregation method",
        "aggregation timer",
        "aggregation window",
        "alert",
        "alert condition",
        "alert evaluation",
        "alert policy",
        "apdex",
        "apdex_f",
        "apdex_t",
        "API (application programming interface)",
        "APM",
        "application",
        "application ID",
        "application name",
        "Applied Intelligence (AI)",
        "attribute",
        "availability monitoring",
        "browser",
        "Browser monitoring",
        "background external",
        "child account",
        "cloud-based integration",
        "collector",
        "Command line interface (CLI)",
        "compute unit (CU)",
        "condition_id",
        "CPM (calls per minute)",
        "CPU burn",
        "custom attribute",
        "custom dashboard",
        "custom event",
        "custom instrumentation",
        "custom metric",
        "data collector",
        "data explorer",
        "degradation period",
        "dimensional metric",
        "Docker",
        "downtime",
        "entity",
        "event",
        "expected error",
        "exporter",
        "Flex",
        "framework",
        "harvest cycle",
        "health status indicator",
        "host",
        "host ID",
        "ignored error",
        "incident",
        "Infrastructure monitoring",
        "Insights",
        "instance ID",
        "instrumentation",
        "integration",
        "interaction",
        "interaction trace",
        "inventory data",
        "key transaction",
        "launcher",
        "log",
        "Log monitoring",
        "Logs",
        "Logs in context",
        "master account",
        "metric",
        "metric timeslice",
        "metric grouping issue",
        "minion",
        "Mobile monitoring",
        "monitor",
        "NerdGraph",
        "Nerdlet",
        "Nerdpack",
        "New Relic Edge with Infinite Tracing",
        "New Relic One",
        "New Relic One catalog",
        "NRQL (New Relic query language)",
        "non-web transaction",
        "notification",
        "notification channel",
        "on-host integration",
        "owner",
        "page load timing",
        "parameter",
        "parent account",
        "permalink",
        "pinger",
        "polling interval (AWS)",
        "PPM (pages per minute)",
        "private location",
        "recovery period",
        "response time",
        "restricted user",
        "rollup",
        "root span",
        "RPM",
        "RUM (real user monitoring)",
        "runbook",
        "SAML (Security Assertion Markup Language)",
        "Selenium",
        "service",
        "signal",
        "signal filter",
        "span",
        "SSL certificate",
        "SSO (single sign on)",
        "streaming algorithm",
        "sub-accounts",
        "Synthetic monitoring",
        "target",
        "tag",
        "thresholds",
        "throughput",
        "tier",
        "time picker",
        "time range",
        "timeslice data",
        "trace",
        "traffic light",
        "transaction",
        "transaction trace",
        "UI",
        "user",
        "UTC",
        "value function (metrics)",
        "violation",
        "web external",
        "web transaction",
        "WebDriverJS",
        "workload"
      ],
      "title": "Glossary of New Relic terms",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "8f8fc1ec9f41e6a4d6b4e986e9b0589bc2ca1f86",
      "image": "https://docs.newrelic.com/docs/glossary/glossary/images/account-dropdown.png",
      "url": "https://docs.newrelic.com/docs/glossary/glossary/",
      "published_at": "2021-12-20T01:43:05Z",
      "updated_at": "2021-12-18T01:39:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you're considering New Relic One or you're already using our capabilities, this glossary of common terminology can help. And if you don't already have a New Relic account, don't hesitate to sign up at newrelic.com/signup. It's free, forever! account dropdown In the upper right of the New Relic UI, the account dropdown gives you access to your account settings. If you're trying to switch between accounts, use the account switcher. account switcher If you have access to more than one account in a multi-account organization, you can use the account switcher to switch between accounts. This is located in the top right of most New Relic UI pages. For more on factors that affect access to accounts, see Factors affecting access. To find account settings, use the account dropdown. administrator A type of user role on a New Relic account. For more information, see Users. agent At New Relic, an agent is a piece of monitoring software that provides integrations with various technologies (for example, web frameworks, host operating systems, or database types). The agents send that data to New Relic, usually on a specific cadence. For more information, see: New Relic Instant Observability Install agents agent API Some New Relic agents have agent APIs that allow you to extend the functionality of an agent. You can use the API to control, customize and extend the functionality of the agent. Here are some agent API docs: APM agents: C SDK API Go agent API Java agent API .NET agent API Node.js agent API PHP agent API Ruby agent API Python agent API Browser agent: Browser agent API Mobile agents: iOS SDK API Android SDK API aggregated metrics Aggregated metric data summarizes calls to specific methods in your application, including how many times each one was called and response times. In the New Relic UI, you see the class and method names along with their aggregate numbers. Metric data aggregation depends on the New Relic tool and your subscription level. For more information, see the documentation about data retention. aggregation delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. aggregation function You can use NRQL query functions, such as sum(), average(), or latest() to choose how the data points in an aggregation window should be processed into a single data point. The single aggregated data point is what's passed through the alert evaluation process. aggregation method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics) CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer setting. The Timer starts running as soon as the first data point appears for that aggregation window (based on the data points timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. aggregation timer The length of time in seconds to wait after each data point received, to ensure the entire batch is processed. Required when using EVENT_TIMER aggregation_method type. aggregation window Streaming alerts gathers data together into specific amounts of time. These windows of time are customizable. Data points are collected together based their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. alert An alert communicates an event or incident that designated personnel can track through Alerts. For an explanation of how basic alerts concepts are related, see Concepts and workflow. alert condition An alert condition (or condition), identified by its unique numeric condition_id, contains the criteria for creating a violation. The condition includes the threshold that is set for a metric timeslice or a custom metric over time on a chosen target. For an explanation of how a condition relates to other basic alerts concepts, see Concepts and workflow. alert evaluation Streaming data is assessed on a set of aggregation windows to determine if an alert condition is violating or recovering. The aggregation window time is how long we'll collect data before running the NRQL query condition. The offset evaluation time is how long you want us to wait for late data before assessing it. If a window doesn't have any data points, it's treated as a gap for loss of signal. alert policy A collection of one or more conditions, one or more notification channels, and an Incident preference setting. If a condition contained within the policy opens a violation, an incident may be opened depending on the Incident preference setting. Notifications will then be sent to all channels attached to the policy. For an explanation of how a policy relates to other basic alerts concepts, see Concepts and workflow. apdex Apdex is an industry-standard way to measure users' satisfaction with the response time of an application or service. New Relic rates each response as Satisfied, Tolerated, or Frustrated, and uses these ratings to calculate an overall user satisfaction score. For more information, see Apdex: Measure user satisfaction. apdex_f The response time above which a transaction are rated frustrating. Defaults to four times apdex_t. Requests that complete in less than apdex_t are rated satisfied. Requests that take longer than apdex_t, but less than four times apdex_t (apdex_f), are tolerated. Any requests that take longer than apdex_f are rated frustrating. For more information, see Apdex: Measure user satisfaction. apdex_t The response time above which a transaction is considered tolerable. The default value is 0.5 seconds, but you can change this in your Apdex settings. Requests that complete in less than apdex_t are rated satisfied. Requests that take more than apdex_t, but less than apdex_f, are tolerated. Any requests that take longer than apdex_f are rated frustrating. For more information, see Apdex: Measure user satisfaction. API (application programming interface) New Relic offers a variety of APIs and SDKs. For more information, see the introduction to New Relic's APIs. APM New Relic's APM (application performance monitoring) provides monitoring of your web or non-web application's performance. APM supports apps using several programming languages. application For New Relic purposes, any program instrumented by New Relic. application ID Some New Relic solutions assign a monitored application a unique application ID, often shortened to app ID. When present, this ID is available in the UI. It is also reported as an attribute and can be queried. For how to determine this, see Find app ID. application name The name that New Relic combines with your license key to uniquely identify a particular app. For more information, see Name your application. Applied Intelligence (AI) Applied Intelligence (AI) helps you find, troubleshoot, and resolve problems more quickly. Specifically, its a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. Applied Intelligence includes Alerts, Incident Intelligence, and Proactive Detection. attribute Attributes are key-value pairs attached to data objects reported to New Relic. Attributes add detail, and they're similar to tags or labels in other SaaS software. You can explore this data by querying or searching via the UI or by using the data dictionary. Examples: APM reports a Transaction event. This includes timing data for the transaction in a duration attribute, which might have a value of .002. Our Infrastructure Monitoring reports a ProcessSample event. This includes a variety of CPU usage attributes, including a cpuSystemPercent attribute, which might have a value of .01. Our Telemetry SDK reports a Metric data type for storing metrics, with attached attributes like metricName and newrelic.source. Some New Relic tools allow you to report custom attributes to enhance your monitoring. For more information about attributes in APM, see Agent attributes. availability monitoring See Types of Synthetics monitors. browser The New Relic UI supports most browsers. For more information, see Supported browsers. For our end-user browser monitoring tool, see Browser Monitoring. Browser monitoring A Real User Monitoring (RUM) solution that measures the speed and performance of your end users as they navigate to your site from different web browsers, devices, operating systems, and networks. background external See web external. child account See parent account. cloud-based integration New Relic offers cloud-based integrations with providers such as Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. collector The component that collects data from New Relic agents running on an app server, mobile device, or end-user browser. While the agent is installed on a user's app server, the collectors are centrally located in New Relic's data center. In order to contact the collector, the agent must be able to reach New Relic's domains and IP addresses. (The exact domain or IP depends on the New Relic monitoring tool.) The collector receives and interprets this data, and stores it in a database. The data is then retrieved and presented in the New Relic UI and by our various REST APIs. Command line interface (CLI) Our command line interface (CLI) is a tool you can use to build a New Relic application. This is the same tool our own engineers use. Go here for quick start instructions. Go to our Developer site for sample apps and guides. compute unit (CU) A unit of measurement that determines your pricing for some New Relic products governed by our original product-based pricing model. For more information, see Compute unit pricing. condition_id See alert condition. CPM (calls per minute) The number of calls your application receives each minute. This usually corresponds to the number of page views or external connections, and is usually the same as RPM (requests per minute). CPU burn The time consumed by code minus the wait time for a transaction. This is the time actually spent processing the transaction. It appears in the New Relic UI at the top of the transaction view for the agents that provide it (Ruby and PHP only). custom attribute A key-value pair added to a transaction or event in order to gain additional information about it. For more information, see custom attributes. custom dashboard A customizable dashboard with charts and tables that includes data from multiple New Relic data sources. For more information, see dashboards. custom event An event, in New Relic terms, is a data object with attached attributes. New Relic reports default event types, like Transaction and TransactionError. You can also create your own events. Events can be queried, and are used in some other features. You can generate custom events with APM agents, the browser monitoring agent, the mobile monitoring agents, and via the Event API. Alternatively, you can add custom attributes to some existing default New Relic events. custom instrumentation Custom instrumentation allows you to extend New Relic's monitoring to instrument code elements New Relic doesn't automatically instrument. Custom instrumentation is useful when your framework is not supported by New Relic, or when New Relic fails to pick up some element of your program. You can also use custom instrumentation to block a transaction from being reported entirely. For more information, see Custom instrumentation. custom metric Metric timeslice data that is manually recorded via an API call. Custom metrics allow you to record arbitrary metrics; for example, timing or computer resource data. All custom metric names must be prefixed with Custom/. For more information, see Custom metrics. Not to be confused with custom instrumentation data. data collector See collector. data explorer Use the data explorer to access, query and customize your data, create visualizations, and make connections between your services in a consistent and curated experience. For more on using the data explorer, see Introduction to the data explorer. degradation period When a data source enters a violating state, a degradation period of time begins. The degradation period is set in the condition's threshold. A violation will open if the source stays in a violating state for the entire degradation period. In addition: If the data source enters a non-violating state before the entire time has elapsed, the degradation period countdown is reset, and a violation does not open. If your alert condition threshold is configured as at least once in, the degradation period always lasts a single minute. dimensional metric A dimensional metric is a metric that has multiple attributes, also known as dimensions. At New Relic, we report dimensional metrics using the Metric data type. For more on other metric data types, see Metric data. Docker An open platform for distributed applications, which allows you to assemble multi-container portable apps. Infrastructure Monitoring includes integrated Docker monitoring. For more information about Docker, see the Docker website. downtime The period of time when customers cannot access your site and your app is not reporting to New Relic. For more information, see Synthetic Monitoring and Types of synthetic monitors. entity In New Relic, an entity is anything we can identify that has data you can monitor. An entity can be something you monitor directly, like applications and microservices, or indirectly, like data centers. You can identify one or more entities to be targets for alert conditions. In the Alerts API, the entity being monitored is identified with an entity_id. For more on this, see What are entities? event The word event is a general term that can have many meanings. At New Relic, event can have several meanings: At New Relic, event data is one of our core data types. Event data represents a record of a single event at a particular moment in time. Events can vary by type (for example, Transaction or Mobile, and will have associated attributes (for example, timestamp or transactionName). For more details, see Event data. For our infrastructure monitoring, the word event can be used to refer to important system and host activity. For example, a configuration change for a monitored host would be registered on Infrastructure's Events UI page. For alerts, the Events UI page displays a list of alerts-related incidents for your monitored entities. Events are reported for a violation opening and for closing. In some contexts, event can refer to any NRQL-queryable data type. For example, when you run a NRQL query, you will see a count of inspected events: this refers to a count of all data types queried. expected error An expected error is a common error that you don't want to affect your Apdex score or error rate. For more information, see Manage errors in APM. exporter At New Relic, an exporter is a type of integration that reports telemetry data to New Relic from a third-party (non-New Relic) telemetry tool. For examples, see Exporters, or search our integration quickstarts in New Relic I/O. Flex New Relic Flex is an application-agnostic, all-in-one infrastructure integration. With it, you can build your own integration that collects metric data from a wide variety of services, and that can instrument any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format (for example, JSON or plain text) to the terminal. It's a recommended way to create a custom integration, because it doesn't require coding skills. framework A framework is a structured collection of pre-defined functions, into which an application builder inserts their own code to build their application. A framework is not the same as a library. While a library is a collection of functions you can call as needed, a framework is a skeleton for your application. The functions in that framework then call your functions. For more about the distinction between a framework and a library, see What is the difference between a framework and a library?. New Relic automatically instruments many common frameworks. For more about the frameworks New Relic supports, see the agent-specific documentation: C SDK supported frameworks Go supported frameworks Java supported frameworks .NET supported frameworks Node.js supported frameworks PHP supported frameworks Python supported frameworks Ruby supported frameworks harvest cycle The period of time between each connection from a New Relic agent to the collector. Between harvest cycles, an agent collects and caches data. At the end of the cycle an agent reports those data to the collector, then begins a new harvest cycle. health status indicator Some New Relic UI pages have a health status indicator appearing next to an index of monitored entities. This is a colored bar (generally green, yellow, red, or gray) indicating the status of your app or other entity monitored by New Relic. It also indicates whether the entity has any alert policies assigned to it and whether there are any policy violations. In general, the colored bar will be green, yellow, red, or gray to indicate the health status. Exceptions: Our REST API (v2) uses orange instead of yellow for the application's health and reporting status. Service maps use different criteria for reporting the health of a connection between an app and an external service not monitored by New Relic (for example, a third party API). host At New Relic, a host means one of the following: A physical machine is a hardware-based device with dedicated physical resources, including memory, processing, and storage. Each machine has its own OS which applications run on. A virtual machine (VM) is the software implementation of a physical machine that executes programs like a physical machine. One or more virtual machines can run on a physical machine. Each virtual machine has its own OS and allocated virtual machine resources such as RAM and CPU. A cloud instance is a type of virtual machine that is run in the public cloud. In this context, virtual machines and cloud instances are different from Java Virtual Machines (JVMs) and containers. host ID Each host identified by APM is assigned a host ID. This ID is used to uniquely identify it, and to retrieve data about that host via the REST API. For more information, see List host ID. ignored error An error that you have told the APM agent not to report to the collector. For more information, see Manage errors in APM. incident An incident is a collection of one or more violations of the conditions defined in an alert policy. An incident record includes all of the open and close time stamps for each violation, as well as chart snapshots of the data being evaluated around the time of each violation. You can view detailed information from the Incidents pages in the user interface. You can also select your preference for how we roll up violations into the incident. For an explanation of how an incident relates to other basic alerts concepts, see Concepts and workflow. Infrastructure monitoring By connecting changes in host performance to changes in your configuration, infrastructure monitoring provides real-time metrics and powerful analytics that reduce your mean-time-to-resolution (MTTR). Infrastructure is specifically designed for complex environments that need flexible, dynamic server monitoring, from a physical datacenter to thousands of Amazon Elastic Compute Cloud (Amazon EC2) instances and other types of integrations. Insights Insights was the name for the New Relic product that previously governed the reporting of custom events, as well as the ability to query and chart your New Relic data. These features are now a fundamental part of the New Relic One platform and are no longer governed by the Insights product or name. To learn more about these features: Event API for reporting custom events Query and chart data For historical reasons, the word \"Insights\" is still used in some places. For example: Some APM agents still have Insights language in their codebase. For example, the Java agent custom_insights_events configuration. For New Relic organizations on our original pricing model, Insights Pro is still the product name governing custom event data ingest and retention. There is an API key called the Insights insert key. instance ID Each instance identified by New Relic is assigned a unique instance ID. Instance IDs are most commonly found for JVMs (Java Virtual Machines), but can exist for each agent. This ID is used to uniquely identify it, and to retrieve data about that instance via the REST API. For more information, see List instance IDs. instrumentation The collection of data from an application or host. When New Relic instruments a framework, it detects the methods and calls used by that framework, and intelligently groups them together. integration At New Relic, an integration refers to a solution that integrates with a specific technology (like a web framework or a type of database). All our integrations can be found as quickstarts in New Relic Instant Observability. interaction In our mobile monitoring, an interaction is a specific code path initiated by a user interaction (usually a button press). An interaction is the mobile equivalent of a transaction, and like a transaction an interaction can be traced and monitored. You can see much of the data included in an interaction in the BrowserInteraction event. interaction trace An interaction trace is a complete picture of a single interaction. With interaction traces, New Relic gives you much deeper visibility into a single slow interaction, which can help you understand a broader problem. Interaction traces are the mobile equivalent of a transaction trace. For more information, see Creating interactions (iOS) and Creating interactions (Android). inventory data Inventory data is information about the status or configuration of a service or host. Examples of inventory data include: Configuration settings Name of the host the service is on Amazon AWS region Port being used For more information, see Understand and use data. key transaction A web transaction that the user has marked as particularly important; for example, key business events (such as signups or purchase confirmations), or transactions with a high performance impact (such as searches). Key transactions have their own pages in the UI and other customized values. For more information, see Key transactions. launcher A launcher is a specific piece of code you can include when you create a New Relic One app. It creates the tile on the homepage that you click to launch the app. For more information, see the documentation about core UI components. log A log is a message about a system used to understand the activity of the system and to diagnose problems. For more information on how we use log data, see Log management. Log monitoring Our log management and monitoring features give you the tools to collect, process, explore, visualize, and alert on your log data using your existing log forwarder. With all of your log data in one place, you'll be able to make better decisions, detect and resolve problems more quickly, and see your logs in context to troubleshoot faster. Logs Our Logs feature is a scalable log management platform that allows you to connect your log data with the rest of your telemetry data. Pre-built plugins with some of the most common open-source logging tools make it simple to send your data from anywhere to New Relic. Logs in context Logs in context makes it easy to link to your log data with related data across the rest of our platform. Bringing all of this data together in a single tool allows you to quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. master account See parent account. metric A metric is a numeric measurement. Metric data is a broad category because there are several ways to make and report measurements. For more about how metrics are reported at New Relic, see New Relic data types. metric timeslice New Relic reports metrics in several ways. One variety of metric data is called metric timeslice data; this is the type of data used to generate many of the charts in APM, mobile monitoring, and browser monitoring (for more details, see metric timeslice data). Over time, metric timeslice data is aggregated into longer timeslice data records for more efficient storage. For more about how we aggregate this type of data, see Data aggregation. For how to query this type of data, see Query metric timeslice data. metric grouping issue A metric grouping issue occurs when an account sends too many differently named metric timeslice data points to New Relic, and those individual web transactions are not properly aggregated. For example, rather than a single /user/controlpanel/ metric name, you might see /user/controlpanel/alice, /user/controlpanel/bob, and /user/controlpanel/carol. For more information, see Metric grouping issues. minion The software that accepts monitor jobs from a private location. A minion is a packaged virtual appliance that runs in your hypervisor. For more information, see Private locations overview and install and configure private minions. Mobile monitoring Mobile monitoring allows you to monitor and manage the performance of your mobile apps on Android, iOS, tvOS, and other systems. Mobile monitoring provides end-to-end details, including crashes, throughput, HTTP requests, error traces, and more. Not to be confused with New Relic's own mobile apps for Android, iPhone, and iPad. monitor For our Synthetic Monitoring, a monitor ensures your website or API endpoint is available. For more information, see Adding and editing monitors. NerdGraph NerdGraph is our GraphQL API, an efficient and flexible query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph calls get all the data you need in a single request. NerdGraph also makes it easier to evolve APIs over time and enables powerful developer tools. You can use our NerdGraph GraphiQL explorer to explore the schema and find definitions. With valid New Relic API key, you can try it out yourself at api.newrelic.com/graphiql. Nerdlet A Nerdlet is a component of a New Relic One application. It's a specific UI view, represented by a React JavaScript package. For more information, see Nerdpack file structure. Nerdpack A Nerdpack is a component of a New Relic One application. It's the package containing all the files needed by that application. For more information, see Nerdpack file structure. New Relic Edge with Infinite Tracing New Relic Edge with Infinite Tracing is a fully managed, distributed tracing service that observes 100% of your application traces, then provides actionable data so you can solve issues faster. For more information, see /docs/understand-dependencies/distributed-tracing/get-started/how-new-relic-distributed-tracing-works. New Relic One For more information, see Introduction to New Relic One. New Relic One catalog Our catalog is a collection of applications built on the New Relic One platform. The catalog includes custom apps we've built, public open source apps, and any apps that you buid. You can browse the catalog on New Relic One. NRQL (New Relic query language) NRQL is a query language, similar in form to SQL, that allows you to query the data stored in your New Relic account. non-web transaction APM identifies transactions as either web or non-web. When New Relic does not detect a transaction was initiated by a web request, this is called a non-web transaction. For more information, see Background processes and other non-web transactions. notification The message sent when an incident opens, is acknowledged, or closes. The type of notification is defined by the alert policy's notification channel. For an explanation of how notifications relate to other basic alerts concepts, see Concepts and workflow. notification channel Where we send a notification when an incident opens, is acknowledged, or closes. Available channels include email, mobile push notifications, webhooks, and more. on-host integration On-host integrations refer to integrations that reside on your own servers or hosts and that communicate with our infrastructure agent. For more information, see Introduction to on-host integrations. owner For accounts on our original pricing model, this is a type of user role: the user who initially created the account. For more information, see Users. page load timing With page load timing, New Relic monitors the full load time for end-user browsers. New Relic's application agents dynamically inject JavaScript into the page, then capture the following key load points: Navigation start: The user initiates the transaction. First byte: The browser receives the requested page. DOM ready: The browser has finished parsing DOM. Page ready: Page loading is complete. Page load timing is sometimes referred to as RUM, or real user monitoring. Unlike standard RUM, page load timing also captures JavaScript errors and AJAX requests. For more information, see Page load timing process. parameter Deprecated term; see attribute. parent account New Relic organizations can have a parent/child account structure. This structure was much more important for organizations on our original user model, but is still used for some features for organizations on the New Relic One user model. Learn more about account structure. Parent accounts were previously referred to as \"master accounts\", and child accounts were previously referred to as \"sub-accounts\". permalink A unique URL that links to a view of your application at a specific point in time. Permalinks are useful for troubleshooting and for sharing interesting time windows with colleagues. pinger The component of New Relic that connects to your website to verify your website is accessible. New Relic has pingers in Europe, Asia, and the United States. Each pinger attempts to contact your website at least once every two minutes. If enough pingers are unable to reach your website, your application will be considered down. For in-depth scriptable testing, including real browser tests and tests of API endpoints, see Synthetic Monitoring. Synthetic Monitoring includes free ping monitoring, which allows you to monitor your website from locations around the world. For more information, see Types of Synthetic monitors. polling interval (AWS) Our Amazon integrations query your AWS services according to a polling interval, which varies depending on the integration. Each polling interval occurs for every AWS entity. For example, if you have thirteen Elastic Load Balancers (ELB), each one will be polled every five minutes. Depending on the AWS integration, there may be delays in the timing between the API request and the metric data returned. If you notice unusual delays, follow the integration troubleshooting procedures. PPM (pages per minute) The number of pages per minute your application serves. private location A Synthetic monitor feature that allows you to run Synthetic monitors from within your own systems by creating private minions. Private locations allow you to extend your Synthetic coverage to new geographical locations, and to monitor websites behind your firewall such as an intranet site. For more information, see Private locations overview. recovery period A recovery period of time begins when a data source enters a non-violating state after being in a violating state. The recovery period is set in the condition's threshold. A violation will close when a source remains in a non-violating state and the recovery period time has elapsed. If the data source enters a violating state before the time has elapsed, the recovery period clock will reset and the violation won't close. response time The duration of time between a request for service and a response. For more information, see Response time. restricted user A type of user role on a New Relic account. For more information, see Users. rollup Using the same application name for multiple applications. This allows you to combine data in APM, either from multiple applications, or from multiple instances of an application. For more information, see Rolling up app data. root span For distributed tracing, the root span is the first span in a trace. In many cases, the root span duration will represent the duration of the entire trace, or be very close to it. However, for more complex, modern systems that use a lot of asynchronous, non-blocking processes, this will not be true. For those systems, the root spans duration may be significantly less than the duration of the trace. RPM The term RPM usually refers to the number of requests per minute your application receives from users. This is usually the same as CPM (calls per minute). Historically, some New Relic monitoring solutions, like APM and Browser Monitoring, used to contain RPM in the URL; for example, https://rpm.newrelic.com. This language use originally referred to Rails performance management because the first iteration of our product monitored Ruby on Rails applications. We monitor many more languages and systems than Ruby now. RUM (real user monitoring) See page load timing. runbook A runbook contains standard procedures and operations typically used by system administrators, network operations staff, and other personnel to handle outages, alert incidents, and other situations. If your organization stores runbook instructions as URLs, you can link this information to an alerts policy so your personnel has easy access to this information when an incident violates the defined policy thresholds. SAML (Security Assertion Markup Language) SAML is an XML-based data format for sharing authentication data between two parties. New Relic accounts must obtain a SAML certificate in order to enable Single Sign On for their users. For more information, see SAML service providers. Selenium Selenium is an open-source browser testing suite. Synthetics uses Selenium to test monitored websites with real browsers. For more information, see monitor types. service A service is a cluster of runtime server processes that accomplish a particular task, usually service requests. Unlike an application, a service is not usually invoked by a human. New Relic offers a variety of integrations that allow you to report data from your services. signal The stream of telemetry data that's watched and alerted on. You use NRQL queries to define a signal. signal filter When we receive data and it's routed to the streaming alerts platform, your NRQL WHERE clause will filter the data coming in. The filtered streaming data is what's evaluated for loss of signal violations, for example. span In a distributed trace, a span is a \"named, timed operation representing a contiguous segment of work in that trace\" (from OpenTracing.io definition). For distributed tracing, spans are displayed in the distributed tracing UI, and the data type Span is available to be queried. See also root span. SSL certificate SSL certificates encrypt data that is being transmitted. While New Relic refers to security certificates as SSL because it is a more commonly used term, all certificates adhere to industry standards for secure encryption in transit. SSO (single sign on) SSO (single sign on) allows you to manage user authentication in New Relic using an external SSO provider. For more information, see Setting up SSO. streaming algorithm This is what determines when the data in an aggregation window is processed. The streaming algorithm uses your server's clock time and the aggregation window size to trigger the alert evaluation process. sub-accounts See master account. Synthetic monitoring Synthetic monitoring allows you to monitor your website or API endpoint via automated, scriptable tools. Use free ping monitor to ensure your website is accessible, or expand your monitoring with browser monitors, which test your website with real browsers. Go further with scripting, to script browsers or API monitors for sophisticated testing. target A target is a resource or component monitored by a New Relic monitoring tool that has been identified in an alert condition. When the data source for that target crosses the defined critical threshold, we will open a violation. Depending on your policy's Incident preference setting, Alerts may create an incident record and send notifications through the defined channels. See also entity. tag Tags are key:value metadata added to monitored apps, hosts, dashboards, and other entities to help you organize your data at a high level. For details, see Tags. thresholds Thresholds are alert condition settings that define a violation. Threshold values include the value a data source must pass to trigger a violation and the time-related settings that define a violation; for example: Passing a certain value for at least x minutes Passing a certain value only once in x minutes While the data source passes a certain value, a degradation period starts. Likewise, when that data source stops passing a certain value, a recovery period starts. The durations of these two time periods are defined in the alert condition threshold settings. Thresholds have a required critical (red) threshold and an optional warning (yellow) threshold. In the UI, the entity's health status indicator will change to yellow or red when a threshold has been crossed and a violation will open. For more information, see Define thresholds. For an explanation of how thresholds relate to other basic Alerts concepts, see Concepts and workflow. throughput Throughput is a measurement of user activity for a monitored application. APM throughput and Browser Monitoring throughput are measured in different ways: APM: requests per minute (RPM) Browser: page views per minute (PPM) tier A tier can refer to how New Relic categorizes or visualizes the various agent language ecosystems that we support. For example: In APM, the color-coded categories that appear on your app's main Overview chart show response time spent in various functions, processes, or agents as tiers; for example, request queuing, garbage collection, Middleware, JVMs, etc. In New Relic labels, TIER can be used to define or classify the client-server architecture; for example, front-end and back-end tiers. \"Tier\" may sometimes be used to refer to our pricing editions. time picker By default the New Relic UI shows data for the past 30 minutes, ending now. To change the time window, use the time picker. time range A time range can refer to a length of time selected in the New Relic UI. New Relic displays a time range depending on the range you select using the time picker. timeslice data See metric timeslice data. trace A trace is a description of how a request travels through a system. Trace data helps you understand the performance of your system and diagnose problems. For more information on how we use trace data, see New Relic data types. traffic light See health status. transaction A transaction is defined as one logical unit of work in an application. This term primarily refers to server-side transactions monitored by APM. For more information, see documentation about web transactions and non-web transactions. The term transaction is also sometimes used in Browser Monitoring. In that case, it primarily refers to activity beginning with a browser-side web request and ending with a complete page load. transaction trace A transaction trace is a complete picture of a single transaction, down to the database queries and exact invocation patterns. With transaction traces, New Relic gives you much deeper visibility into a single slow transaction, which can help you understand a broader problem. For more information, see Transaction traces. UI The New Relic user interface. For more information, see Standard page functions. user A user can refer to a specific user role in a New Relic account. For more information, see Users. UTC Universal Time Coordinated (UTC), or Coordinated Universal Time, is a standard timestamp for synchronizing time around the world. value function (metrics) The numeric value obtained from metric timeslice data; for example, an average, minimum, maximum, total, sample size, etc. violation A violation occurs when the entity monitored by an alert condition reports a value that crosses the thresholds defined in that condition. For an explanation of how violations relate to other basic alerts concepts, see Concepts and workflow. You can view a summary of the violations for a selected incident's page. You can also view the violations for a specific entity from the product's UI. web external Web external is the term applied to the portion of time spent in transactions to external applications from within the code of the application you are monitoring. That time can be a call to a third party company (a payment provider, for example) or it could be a call to another microservice within your own company. Web external demonstrates how performance is impacted by your code executing outside the application you are measuring. web transaction A transaction is defined as one logical unit of work in an application. This term primarily refers to server-side transactions monitored by APM. Web transactions are initiated with an HTTP request. For most organizations, these represent customer-centric interactions and thus are the most important transactions to monitor. For more information, see Web transactions and Non-web transactions. WebDriverJS WebDriver is a Selenium component, used to control Synthetics scripted browsers. Specifically, Synthetics uses WebDriverJS, a Node.js-based flavor of Selenium. For more information, see Writing scripted browsers and Scripted browser examples. workload A workload represents a group of entities that work together to provide a digital service. For more information, see Workloads.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 79.30156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Mobile</em> <em>monitoring</em>",
        "body": " generate custom <em>events</em> with APM agents, the browser <em>monitoring</em> agent, the <em>mobile</em> <em>monitoring</em> agents, and via the <em>Event</em> API. Alternatively, you can add custom attributes to some existing default New Relic <em>events</em>. custom instrumentation Custom instrumentation allows you to extend New Relic&#x27;s <em>monitoring</em>"
      },
      "id": "61b40189196a672dd0a5aa8c"
    }
  ],
  "/docs/data-apis/understand-data/event-data/events-reported-synthetic-monitoring": [
    {
      "sections": [
        "Security for New Relic-reported events and attributes",
        "Default events and attributes",
        "Adjust the data reported"
      ],
      "title": "Security for New Relic-reported events and attributes ",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "446305a7d17c6dfb44e9e87520a1c08b79f5bcf9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/event-data/customized-security-settings-insights/",
      "published_at": "2021-12-20T06:38:30Z",
      "updated_at": "2021-10-23T17:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By default, New Relic products report a variety of data used in our UI charts and that is available for querying. Our products will not transmit sensitive information without being explicitly instrumented to do so. Default events and attributes Our products report a set of default events and attributes. We will never send request parameters or any other attributes that are not in the default set, unless someone has explicitly enabled this via configuration. Adjust the data reported When evaluating security settings for a New Relic product, review the default events and attributes. The default attributes don't contain sensitive data. In general, it's simply the data needed for effective performance monitoring. Our products don't send other data unless you change the default security settings. Depending on your requirements, either or both of these situations may apply: If the default list contains data you're concerned about, you can disable those attributes from being collected. For how to edit that, see the documentation for the product you're using. If you need to send attributes not reported by default, you can enable those attributes to be reported. In that case, do not use high security mode: this will disable the ability to collect custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.28171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for New Relic-reported <em>events</em> and attributes ",
        "sections": "<em>Default</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "By <em>default</em>, New Relic products report a variety of <em>data</em> used in our UI charts and that is available for querying. Our products will not transmit sensitive information without being explicitly instrumented to do so. <em>Default</em> <em>events</em> and attributes Our products report a set of <em>default</em> <em>events</em>"
      },
      "id": "60a8ea67e7b9d25ec7aeabfe"
    },
    {
      "sections": [
        "Default events reported by New Relic products"
      ],
      "title": "Default events reported by New Relic products",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "598dfde069ba5a8bbbd5834c44b9740d6b338cdc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/event-data/default-events-reported-new-relic-products/",
      "published_at": "2021-12-20T03:00:06Z",
      "updated_at": "2021-10-23T17:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic products report different types of data. One type of data reported is event data. Events are displayed in UI charts and tables, and also made available for querying. To understand the types of data available, see Data available via NRQL. Learn more about the events reported by New Relic products: APM default events Browser default events Infrastructure default events Mobile default events Synthetics default events NrAuditEvent events for understanding changes to your account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.28171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Default</em> <em>events</em> reported by New Relic products",
        "sections": "<em>Default</em> <em>events</em> reported by New Relic products",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "New Relic products report different types of <em>data</em>. One type of <em>data</em> reported is <em>event</em> <em>data</em>. <em>Events</em> are displayed in UI charts and tables, and also made available for querying. To understand the types of <em>data</em> available, see <em>Data</em> available via NRQL. Learn more about the <em>events</em> reported by New Relic"
      },
      "id": "609f8faf64441f8af9d2a1f0"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "77720ef366038ba648a5fbf3cf34e8e48b38440a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T21:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). If the name begins with anything other than an alphabetical character, enclose the name with backticks in your NRQL query. For example: FROM `0_hello` SELECT count(*) Copy Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.92877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for custom <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for custom <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: <em>Default</em> <em>events</em> from New Relic agents Custom <em>events</em> from New Relic agents Custom <em>events</em> from <em>Insights</em> custom <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    }
  ],
  "/docs/data-apis/understand-data/event-data/nrauditevent-event-data-query-examples": [
    {
      "sections": [
        "Log (audit) all data your New Relic agent transmits",
        "Caution",
        "APM agent audit logging",
        "Infrastructure agent logging",
        "New Relic account-related logging"
      ],
      "title": "Log (audit) all data your New Relic agent transmits",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "66cd6ec040e070623d345e5319b1246d2ba4c3b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/log-audit-all-data-your-new-relic-agent-transmits/",
      "published_at": "2021-12-19T20:56:53Z",
      "updated_at": "2021-12-14T04:18:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Every New Relic agent includes strong safeguards to ensure data security. For example, New Relic automatically encrypts sensitive information before it is transmitted. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. If you need to record and view information about all data your app transmits to New Relic, you can enable audit logging for short periods of time. This is useful, for example, with debugging or auditing, when you need detailed information about what exactly is being transmitted. Caution Be sure to disable audit logging as soon as you are finished using it. This feature causes additional overhead, which may overload the audit log file if left turned on for extended periods of time. APM agent audit logging For details about the audit logging options for your APM agent's configuration file, see the agent-specific documentation: Agent Configuration file C SDK When starting the C SDK daemon, add -auditlog <file> to the daemon configuration file. For example: ./newrelic-daemon -f -logfile stdout -loglevel debug -auditlog audit.log Copy Go Logging is optional with the Go agent. If you are using newrelic.NewLogger(w) and want more detailed output, change newrelic.NewLogger(w) to newrelic.NewDebugLogger(w). For more information, see the New Relic Go logging documentation on GitHub. Java Set audit_mode to true. .NET Set auditLog to true. Node.js New Relic's Node.js agent does not use separate audit logs because the payload is already available in the configuration logs. To view increasing levels of detail, use your config file's logging level variables. PHP Use PHP newrelic.daemon.auditlog (for newrelic.ini) or auditlog (for newrelic.cfg). Python Use Python audit_log_file values. Ruby Use audit_log values. For more information, see Ruby agent audit log. Infrastructure agent logging You can generate infrastructure monitoring logs for troubleshooting our infrastructure agent. New Relic account-related logging To audit changes to your New Relic account, run NRQL queries with NrAuditEvent. To customize your query, use any of the available NrAuditEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 394.41193,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Log (<em>audit</em>) all <em>data</em> your New Relic agent transmits",
        "sections": "Log (<em>audit</em>) all <em>data</em> your New Relic agent transmits",
        "body": "_log_file values. Ruby Use <em>audit</em>_log values. For more information, see Ruby agent <em>audit</em> log. Infrastructure agent logging You can generate infrastructure monitoring logs for troubleshooting our infrastructure agent. New Relic account-related logging To <em>audit</em> changes to your New Relic account, run NRQL queries with <em>NrAuditEvent</em>. To customize your <em>query</em>, use any of the available <em>NrAuditEvent</em> attributes."
      },
      "id": "61bf9c95196a67c384eee313"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/event-data/query-account-audit-logs-nrauditevent/",
      "sections": [
        "Query account audit logs (NrAuditEvent)",
        "Account data security and retention",
        "Run NrAuditEvent query"
      ],
      "published_at": "2021-12-20T03:02:32Z",
      "title": "Query account audit logs (NrAuditEvent)",
      "updated_at": "2021-10-23T17:28:33Z",
      "type": "docs",
      "external_id": "8f0c9b883a2146792abb47c7a7245f97dea51525",
      "document_type": "page",
      "popularity": 1,
      "body": "As an additional security measure for managing your New Relic account, you can use the NrAuditEvent event to view audit logs that show changes in your New Relic account. This includes: Individuals added or deleted Role changes Account changes made via API Synthetic monitor changes Dashboard deletion Workload configuration changes You can also use alerts to be notified about changes in your New Relic account. Account data security and retention All New Relic accounts can query up to 13 months of account changes. To ensure account security, the audit logging NRQL query only tracks changes in your currently selected account. It does not show audit log events for any associated child accounts. To query changes in another account or sub-account, select the account and run a NRQL query there. Audit logging is different than configuring audit mode for your APM agent. APM audit mode records information about all data being transmitted from your app. Run NrAuditEvent query To track and view changes in your New Relic account: At any NRQL interface, run the following query, adjusting the time frame as needed up to thirteen months: SELECT * from NrAuditEvent SINCE 1 day ago Copy To customize your query, use any of the available NrAuditEvent attributes. To be notified about account changes, create NRQL conditions with New Relic Alerts. To query changes in another account, select the account and run a separate NRQL query for that account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 312.98923,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> account <em>audit</em> logs (<em>NrAuditEvent</em>)",
        "sections": "<em>Query</em> account <em>audit</em> logs (<em>NrAuditEvent</em>)",
        "body": " information about all <em>data</em> being transmitted from your app. Run <em>NrAuditEvent</em> <em>query</em> To track and view changes in your New Relic account: At any NRQL interface, run the following <em>query</em>, adjusting the time frame as needed up to thirteen months: SELECT * from <em>NrAuditEvent</em> SINCE 1 day ago Copy To customize"
      },
      "id": "60a8eb1fe7b9d202f1aeac03"
    },
    {
      "sections": [
        "Synthetic monitoring audit log: Track changes made by users",
        "Feature description",
        "Query details",
        "Example use case: Finding changes made by a user"
      ],
      "title": "Synthetic monitoring audit log: Track changes made by users",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "4673ae884e9d00a1c90e9577f2b8ff229b73b543",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-monitoring-audit-log-track-changes-made-users/",
      "published_at": "2021-12-20T02:37:05Z",
      "updated_at": "2021-03-16T18:11:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you see a 13-month history of synthetic monitoring audit events. Feature description When you take specific actions in synthetic monitoring like creating or editing a monitor, an NrAuditEvent is generated. This event includes details about the action taken and which user took that action. This data is stored for 13 months. This historical data may be helpful if you'd like to investigate how a problem with your account was created and who made that change. Synthetic monitoring's changes tracked include: Monitors Creation Edits (including location change, mute/unmute, and enable/disable) Script creation, edits, validation (including secure credentials used) Deletion Monitor downtimes Creation Edits Deletion Secure credentials Creation Edits Views Deletion Private locations Creation Edits (including clearing queues) Deletion For details on how to query this data, see Query details. Query details To query changes, use the query builder to explore the NrAuditEvent and its associated attributes. For an introduction to using the NrAuditEvent event, see Query account audit logs. Supported actionIdentifier events currently include: Monitors synthetics_monitor.create synthetics_monitor.update synthetics_monitor.create_script synthetics_monitor.update_script synthetics_monitor.validate_script synthetics_monitor.delete Monitor downtimes synthetics_monitor_downtime.create synthetics_monitor_downtime.update synthetics_monitor_downtime.delete Secure credentials synthetics_secure_credential.create synthetics_secure_credential.update synthetics_secure_credential.view synthetics_secure_credential.delete Private locations synthetics_private_location.create synthetics_private_location.update synthetics_private_location.delete How the change was made: The actorAPIKey attribute indicates if the change was made via the API or by a user via the UI. When this value is null, it's a user update; when not null, it's an API update. For examples of synthetic monitoring's audit log queries, see: The example use case. The synthetic monitoring specific examples in Audit query examples. Example use case: Finding changes made by a user Here's an example of using the synthetic monitoring audit log to solve a common problem: You are a manager at a company that uses synthetic monitoring. A new employee has been playing with your company's accounts to learn how synthetic monitoring works. Unfortunately, this employee was accidentally given full access to the production accounts, instead of the pre-production accounts. You want to determine what synthetic monitors this employee created, deleted, and updated, so that you will know which monitors need to be fixed. Instead of having to review every monitor in the account, you open the query builder and run the following NRQL query of the NrAuditEvent event: SELECT count(*) FROM NrAuditEvent WHERE actionIdentifier = 'synthetics_monitor.update_script' AND actorEmail = 'EMPLOYEE_EMAIL' FACET actionIdentifier, description SINCE 1 week ago LIMIT 1000 Copy The query will return all the synthetic monitors that the employee has updated, deleted, created, disable, or muted. One by one, you and the employee review the list and update the edited monitors.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.30994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Synthetic monitoring <em>audit</em> log: Track changes made by users",
        "sections": "Synthetic monitoring <em>audit</em> log: Track changes made by users",
        "body": " details. <em>Query</em> details To <em>query</em> changes, use the <em>query</em> builder to explore the <em>NrAuditEvent</em> and its associated attributes. For an introduction to using the <em>NrAuditEvent</em> <em>event</em>, see <em>Query</em> account <em>audit</em> logs. Supported actionIdentifier events currently include: Monitors synthetics_monitor.create"
      },
      "id": "603eb96fe7b9d251b82a07cd"
    }
  ],
  "/docs/data-apis/understand-data/event-data/query-account-audit-logs-nrauditevent": [
    {
      "sections": [
        "Log (audit) all data your New Relic agent transmits",
        "Caution",
        "APM agent audit logging",
        "Infrastructure agent logging",
        "New Relic account-related logging"
      ],
      "title": "Log (audit) all data your New Relic agent transmits",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "66cd6ec040e070623d345e5319b1246d2ba4c3b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/log-audit-all-data-your-new-relic-agent-transmits/",
      "published_at": "2021-12-19T20:56:53Z",
      "updated_at": "2021-12-14T04:18:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Every New Relic agent includes strong safeguards to ensure data security. For example, New Relic automatically encrypts sensitive information before it is transmitted. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. If you need to record and view information about all data your app transmits to New Relic, you can enable audit logging for short periods of time. This is useful, for example, with debugging or auditing, when you need detailed information about what exactly is being transmitted. Caution Be sure to disable audit logging as soon as you are finished using it. This feature causes additional overhead, which may overload the audit log file if left turned on for extended periods of time. APM agent audit logging For details about the audit logging options for your APM agent's configuration file, see the agent-specific documentation: Agent Configuration file C SDK When starting the C SDK daemon, add -auditlog <file> to the daemon configuration file. For example: ./newrelic-daemon -f -logfile stdout -loglevel debug -auditlog audit.log Copy Go Logging is optional with the Go agent. If you are using newrelic.NewLogger(w) and want more detailed output, change newrelic.NewLogger(w) to newrelic.NewDebugLogger(w). For more information, see the New Relic Go logging documentation on GitHub. Java Set audit_mode to true. .NET Set auditLog to true. Node.js New Relic's Node.js agent does not use separate audit logs because the payload is already available in the configuration logs. To view increasing levels of detail, use your config file's logging level variables. PHP Use PHP newrelic.daemon.auditlog (for newrelic.ini) or auditlog (for newrelic.cfg). Python Use Python audit_log_file values. Ruby Use audit_log values. For more information, see Ruby agent audit log. Infrastructure agent logging You can generate infrastructure monitoring logs for troubleshooting our infrastructure agent. New Relic account-related logging To audit changes to your New Relic account, run NRQL queries with NrAuditEvent. To customize your query, use any of the available NrAuditEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 504.1681,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Log</em> (<em>audit</em>) all data your New Relic agent transmits",
        "sections": "<em>Log</em> (<em>audit</em>) all data your New Relic agent transmits",
        "body": "_file values. Ruby Use <em>audit_log</em> values. For more information, see Ruby agent <em>audit</em> <em>log</em>. Infrastructure agent logging You can generate infrastructure monitoring <em>logs</em> for troubleshooting our infrastructure agent. New Relic <em>account</em>-related logging To <em>audit</em> changes to your New Relic <em>account</em>, run NRQL queries with <em>NrAuditEvent</em>. To customize your <em>query</em>, use any of the available <em>NrAuditEvent</em> attributes."
      },
      "id": "61bf9c95196a67c384eee313"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/event-data/nrauditevent-event-data-query-examples/",
      "sections": [
        "NrAuditEvent event data and query examples",
        "Available events and attributes",
        "Example queries",
        "General account changes",
        "What changes have been made to the New Relic account?",
        "What type of account change was made the most?",
        "What trends appear in account changes?",
        "What user management changes have been done?",
        "Synthetics: What changes have been made to a monitor?",
        "Workloads: What changes were made to any workload configuration?",
        "Changes made by specific users",
        "What account changes have been made by any user?",
        "What account changes have been made by a specific user?",
        "Who made the most changes to the account?",
        "Synthetics: What monitors were created by a specific user?",
        "Changes made using the API",
        "What account changes have been made using an API key?"
      ],
      "published_at": "2021-12-20T03:13:15Z",
      "title": "NrAuditEvent event data and query examples",
      "updated_at": "2021-11-25T12:48:11Z",
      "type": "docs",
      "external_id": "3619285ba0ba23c989f4abdd90607e4b8ba6aa13",
      "document_type": "page",
      "popularity": 1,
      "body": "To view changes made in your New Relic account, you can query NrAuditEvent events. Available events and attributes The NrAuditEvent is created to record configuration changes made in our products. The data gathered for this event includes the type of account change, actor (user or API key) that made the change, a human-readable description of the action taken, and a timestamp for the change. To see all the attributes attached to this event, see NrAuditEvent. Example queries These examples show some of the ways you can run NRQL queries of the NrAuditEvent event. General account changes What changes have been made to the New Relic account? To view all changes to your New Relic account for a specific time frame, run this basic NRQL query: SELECT * from NrAuditEvent SINCE 1 day ago Copy What type of account change was made the most? To query what type of change to the account users was made the most frequently during a specific time frame, include the actionIdentifier attribute in your query. For example: SELECT count(*) AS Actions FROM NrAuditEvent FACET actionIdentifier SINCE 1 week ago Copy What trends appear in account changes? When you include TIMESERIES in a NRQL query, the results are shown as a line graph. For example: SELECT count(*) from NrAuditEvent TIMESERIES facet actionIdentifier since 1 week ago Copy What user management changes have been done? Note that your users' user model will impact these queries. If your users are on our original user model, you can only query per account. If your users are on the New Relic One user model, you should query the top-level account in your New Relic organization. To see all the changes made to users, you could use: SELECT * FROM NrAuditEvent WHERE targetType = 'user' SINCE this month Copy If you wanted to narrow that down to see changes to user type (full platform user vs basic user), you could use: SELECT * FROM NrAuditEvent WHERE targetType = 'user' AND actionIdentifier IN ('user.self_upgrade', 'user.change_type') SINCE this month Copy Synthetics: What changes have been made to a monitor? To query Synthetics monitor updates during a specific time frame, include the actionIdentifier attribute in your query. For example: SELECT count(*) FROM NrAuditEvent WHERE actionIdentifier = 'synthetics_monitor.update_script' FACET actionIdentifier, description, actorEmail SINCE 1 week ago LIMIT 1000 Copy For more information about this Synthetics feature, see Synthetics audit log. Workloads: What changes were made to any workload configuration? To query what configuration changes were made to any workload, use the query below. The targetId attribute contains the GUID of the workload that was modified, which you can use for searches. Since changes on workloads are often automated, you might want to include the actorType attribute to know if the change was done directly by a user through the UI or through the API. SELECT timestamp, actorEmail, actorType, description, targetId FROM NrAuditEvent WHERE targetType = 'workload' SINCE 1 week ago LIMIT MAX Copy Changes made by specific users What account changes have been made by any user? To see detailed information about any user who made changes to the account during a specific time frame, include actorType = 'user' in the query. For example: SELECT actionIdentifier, description, actorEmail, actorId, targetType, targetId FROM NrAuditEvent WHERE actorType = 'user' SINCE 1 week ago Copy What account changes have been made by a specific user? To query account activities made by a specific person during the selected time frame, you must know their actorId. For example: SELECT actionIdentifier FROM NrAuditEvent WHERE actorId = 829034 SINCE 1 week ago Copy Who made the most changes to the account? To identify who (actorType) has made the most changes to the account, include the actorEmail attribute in your query. For example: SELECT count(*) as Users FROM NrAuditEvent WHERE actorType = 'user' FACET actorEmail SINCE 1 week ago Copy Synthetics: What monitors were created by a specific user? To query Synthetics monitor updates made by a specific user, include the actionIdentifier and actorEmail attribute in your query. For example: SELECT count(*) FROM NrAuditEvent WHERE actionIdentifier = 'synthetics_monitor.update_script' FACET actorEmail, actionIdentifier, description SINCE 1 week ago LIMIT 1000 Copy Changes made using the API What account changes have been made using an API key? To see detailed information about changes to the account that were made using an API key during a specific time frame, include actorType = 'api_key' in the query. For example: SELECT actionIdentifier, description, targetType, targetId, actorAPIKey, actorId, actorEmail FROM NrAuditEvent WHERE actorType = 'api_key' SINCE 1 week ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 415.5214,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NrAuditEvent</em> <em>event</em> data and <em>query</em> examples",
        "sections": "<em>NrAuditEvent</em> <em>event</em> data and <em>query</em> examples",
        "body": "To view changes made in your New Relic <em>account</em>, you can <em>query</em> <em>NrAuditEvent</em> events. Available events and attributes The <em>NrAuditEvent</em> is created to record configuration changes made in our products. The data gathered for this <em>event</em> includes the type of <em>account</em> change, actor (user or API key"
      },
      "id": "60a8e35ce7b9d2b07caeabdd"
    },
    {
      "sections": [
        "Synthetic monitoring audit log: Track changes made by users",
        "Feature description",
        "Query details",
        "Example use case: Finding changes made by a user"
      ],
      "title": "Synthetic monitoring audit log: Track changes made by users",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "4673ae884e9d00a1c90e9577f2b8ff229b73b543",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-monitoring-audit-log-track-changes-made-users/",
      "published_at": "2021-12-20T02:37:05Z",
      "updated_at": "2021-03-16T18:11:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you see a 13-month history of synthetic monitoring audit events. Feature description When you take specific actions in synthetic monitoring like creating or editing a monitor, an NrAuditEvent is generated. This event includes details about the action taken and which user took that action. This data is stored for 13 months. This historical data may be helpful if you'd like to investigate how a problem with your account was created and who made that change. Synthetic monitoring's changes tracked include: Monitors Creation Edits (including location change, mute/unmute, and enable/disable) Script creation, edits, validation (including secure credentials used) Deletion Monitor downtimes Creation Edits Deletion Secure credentials Creation Edits Views Deletion Private locations Creation Edits (including clearing queues) Deletion For details on how to query this data, see Query details. Query details To query changes, use the query builder to explore the NrAuditEvent and its associated attributes. For an introduction to using the NrAuditEvent event, see Query account audit logs. Supported actionIdentifier events currently include: Monitors synthetics_monitor.create synthetics_monitor.update synthetics_monitor.create_script synthetics_monitor.update_script synthetics_monitor.validate_script synthetics_monitor.delete Monitor downtimes synthetics_monitor_downtime.create synthetics_monitor_downtime.update synthetics_monitor_downtime.delete Secure credentials synthetics_secure_credential.create synthetics_secure_credential.update synthetics_secure_credential.view synthetics_secure_credential.delete Private locations synthetics_private_location.create synthetics_private_location.update synthetics_private_location.delete How the change was made: The actorAPIKey attribute indicates if the change was made via the API or by a user via the UI. When this value is null, it's a user update; when not null, it's an API update. For examples of synthetic monitoring's audit log queries, see: The example use case. The synthetic monitoring specific examples in Audit query examples. Example use case: Finding changes made by a user Here's an example of using the synthetic monitoring audit log to solve a common problem: You are a manager at a company that uses synthetic monitoring. A new employee has been playing with your company's accounts to learn how synthetic monitoring works. Unfortunately, this employee was accidentally given full access to the production accounts, instead of the pre-production accounts. You want to determine what synthetic monitors this employee created, deleted, and updated, so that you will know which monitors need to be fixed. Instead of having to review every monitor in the account, you open the query builder and run the following NRQL query of the NrAuditEvent event: SELECT count(*) FROM NrAuditEvent WHERE actionIdentifier = 'synthetics_monitor.update_script' AND actorEmail = 'EMPLOYEE_EMAIL' FACET actionIdentifier, description SINCE 1 week ago LIMIT 1000 Copy The query will return all the synthetic monitors that the employee has updated, deleted, created, disable, or muted. One by one, you and the employee review the list and update the edited monitors.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 329.5785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Synthetic monitoring <em>audit</em> <em>log</em>: Track changes made by users",
        "sections": "Synthetic monitoring <em>audit</em> <em>log</em>: Track changes made by users",
        "body": " details. <em>Query</em> details To <em>query</em> changes, use the <em>query</em> builder to explore the <em>NrAuditEvent</em> and its associated attributes. For an introduction to using the <em>NrAuditEvent</em> <em>event</em>, see <em>Query</em> <em>account</em> <em>audit</em> <em>logs</em>. Supported actionIdentifier events currently include: Monitors synthetics_monitor.create"
      },
      "id": "603eb96fe7b9d251b82a07cd"
    }
  ],
  "/docs/data-apis/understand-data/metric-data/metric-data-type": [
    {
      "sections": [
        "New Relic data types",
        "Get started",
        "Tip",
        "Metrics",
        "Metrics in the monitoring industry",
        "Metrics at New Relic",
        "Dimensional metrics (used by Metric API and many integrations)",
        "Metric timeslice data (used by APM, browser, mobile)",
        "Metric timeslice examples",
        "Metrics attached to events (used by Infrastructure, other products)",
        "Metrics as a computation of events (used in some charts and queries)",
        "Event data",
        "Events in the monitoring industry",
        "Events at New Relic",
        "Log data",
        "Logs in the monitoring industry",
        "Logs at New Relic",
        "Trace data",
        "Tracing in the monitoring industry",
        "Tracing at New Relic",
        "Query and send data",
        "Learn more"
      ],
      "title": "New Relic data types",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "8e4ab82bb58db47bc412f57231d4956c6068262b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/new-relic-data-types/",
      "published_at": "2021-12-19T15:32:43Z",
      "updated_at": "2021-12-04T21:48:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform is built around the four fundamental telemetry data types we believe are necessary for complete and effective system monitoring: metrics, events, logs, and traces. After you sign up for a free New Relic account and install any of our monitoring services, you can start working with your data. Get started This doc will give you a fairly technical explanation of our core data types, their structure, and how they're used in our features. You can use most of our features without needing to understand the underlying data structure. But having a better understanding of this can help you get data into New Relic, understand the data you see in our UI, and query your data. For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types. Another good way to understand your data is to just start querying it. Tip Access your data easily on one.newrelic.com: Click the Browse data dropdown menu and select the data type (metrics, events, logs, and traces) you want to explore. Metrics First, well explain the definition of metrics from a monitoring industry perspective, and then well explain how New Relic handles metrics. For a list of the metrics we collect, see our documentation on metrics. Metrics in the monitoring industry In the software monitoring industry, a metric means a numeric measurement of an application or system. Metrics are typically reported on a regular schedule. Two major types of metrics are: Aggregated data. For example: a count of events over one minutes time, or the rate of some event per minute. A numeric status at a moment in time. For example: a CPU temperature reading, or a CPU% used status. Metrics are relatively easy to report and store because a single record can represent a range of time. They can also be aggregated more and more over time. For example, per-minute data may be rolled up to per-hour aggregations after some amount of time, and eventually may be rolled up to a per-day aggregation. This approach is efficient for long-term data storage. Metrics are a strong solution for storing data long-term, and understanding trends over time. One potential downside is that it can be difficult to do detailed analysis of older data that has been aggregated over time; when high detail is required about specific important actions, event data can be used. Metrics at New Relic Conceptually, \"metrics\" is a broad, general category. There are various ways New Relic measures and reports metrics but, in practice, when using the New Relic UI, you usually won't have to understand how exactly this happens. In our documentation, we typically will just refer to \"metrics,\" regardless of how that data is reported, unless there's a reason you need to know more (like understanding how to query your data). Here are some of the ways metrics are reported and stored across the New Relic platform: Dimensional metrics (used by Metric API and many integrations) In the monitoring industry, \"dimensional\" metrics refer to metric data that has a variety of attributes (dimensions) attached, such as duration-related attributes (start time, end time), entity ID, region, host, etc. This amount of detail allows for in-depth analysis and querying. At New Relic, this metric data is attached to the Metric data type and is sent from several sources: Some open-source integrations, such as the Prometheus exporter. Our Telemetry SDKs Infrastructure services The Metric API (the underlying API used by the above tools) The events-to-metrics service To query this data and see its attributes (\"dimensions\"), you could use a NRQL query like: Select * from Metric Copy As time passes, these metrics are increasingly aggregated into larger time buckets. This is done to optimize your ability to query data over a long period of time. For more details about the metric data type, see our docs. To learn how this data is ingested and stored, see the Metric API documentation. For tips on querying, see Metric query examples. Metric timeslice data (used by APM, browser, mobile) New Relic's APM, browser, and mobile report and display metrics in a simple data format that we refer to as metric timeslice data. A metric timeslice consists of three parts: a metric name, the segment of time the metric represents (the \"timeslice\"), and a numeric value (the measurement). For example: an APM metric timeslice for time spent in a particular transaction is named WebTransaction/URI/foo, and might have a response time of 0.793 for a one-minute time slice from 10:20am to 10:21am. These metrics usually follow a pattern like <category>/<class>/<method>. Our agents (APM, browser, and mobile) can collect thousands of metric timeslices per minute for a variety of performance metrics. For example: error rate, bandwidth usage, and garbage collection time. You also have the ability to create custom metrics. Metric timeslice data is a lightweight data type and lacks the detail that dimensional metrics have. Ways to explore and query metric timeslice data: For APM: metric timeslice data is converted to dimensional metrics and can be queried via NRQL Use the REST API If you want to learn more about the structure of metric timeslice data and see some examples, expand the collapser below. Metric timeslice examples Here are some common metric timeslice data examples, with a focus on common ones used by Ruby applications. ActiveMerchant New Relic tracks a variety of metrics on ActiveMerchant transactions which can be used for business analytics as well as performance monitoring. The metrics are summarized by operation as well as by gateway. regex sample metric legend name ActiveMerchant/. * ActiveMerchant/PayJunctionGateway ActiveMerchant/gateway/. * ActiveMerchant/gateway/PayJunctionGateway/purchase PayJunctionGateway ActiveMerchant/operation/. * ActiveMerchant/operation/purchase purchase For more information, see the ActiveMerchant website. ActiveRecord ActiveRecord is the Object-Relational Mapping API used by Ruby on Rails applications. The metrics shown here measure the performance of ActiveRecord's find and save methods. regex sample metric legend name ActiveRecord/. * /find ActiveRecord/User/find User#find ActiveRecord/. * /save ActiveRecord/Product/save Product#save For more information, see the API documentation for ActiveRecord. Apdex Apdex is a measure of user satisfaction with page load times. Controller In Ruby on Rails applications, HTTP requests are handled by Controller actions. A Rails application has many controllers, each of which has one or more actions. When your rails application receives an http request, that request is routed to the appropriate controller and action, based on the URL of that request. That action then does whatever processing is neccesary to generate an http response, which is most often a web page, but could also be a page fragment, an xml document, or any other kind of data that is requested by the client. The following metrics track the performance of controller actions, regardless of routing, and without taking into account any network or web server effects. regex sample metric legend name Controller/. * Controller/Users/show /Users/show Controller/. * /(?! \\ (other \\ )). * Controller/Users/show /Users/show Controller$ Controller All Controller Actions ControllerCPU/ ControllerCPU/Users/Show /Users/show For more information, see the API documentation for ActionController. Errors This metric tracks the number of errors or exceptions raised while processing requests. regex sample metric legend name Errors/all Errors/all External services External service instrumentation captures calls to out-of-process services such as web services, resources in the cloud and any other network calls. It does not include other first class back-end components such as MemCache and the database. In Ruby applications we instrument the Net::Http library to capture all HTTP services. regex sample metric legend name External/ [ ^/]+/all$ External/service.example.com/all All service.example.com calls External/ External/host.aws.com/Net::Http : :POST Net::Http : :POST [ host.aws.com] External/all$ External/all External Services External/ [ ^/]+/(?!all)/ External/service.example.com/all All service.example.com calls HTTP dispatcher This metric represents a summary of the throughput and response time of all web requests. regex sample metric legend name ^HttpDispatcher$ HttpDispatcher HttpDispatcher MemCache MemCache is a popular technology that enables applications to access shared memory provided by any number of physical machines as a global cache. Applications that heavily use the database often use MemCache for performance and scalability benefits. These metrics measure the frequency and response time of calls to MemCache to read and write data from the cache. Response times should be low (less than 5 ms) for a well performing MemCache deployment. regex sample metric legend name MemCache/. * MemCache/read MemCache read operations MemCache/read MemCache/read MemCache read operations MemCache/write MemCache/write MemCache write operations Mongrel This metric measures the length of the mongrel queue, which holds pending http requests to be processed by mongrel. The HTTP Activity graph overlays the maximimum queue length for a given period. The value is zero if mongrel is processing a request but has no other requests waiting in its queue. When looking at this value across an aggregate cluster of mongrels, the queue lengths of all mongrels is added together, showing the sum of all queue lengths. A mongrel queue length should be at or near zero; if it is consistently at a higher level, then it indicates that your rails application is having trouble keeping up with its load requirements. regex sample metric legend name Mongrel/Queue Length Mongrel/Queue Length Queue Length View ActionView is a package in Rails that is used to render the output that is the response to an http request, such as an html page or an xml document. The View is rendered by the controller that is handling the request. If View metrics represent a large portion of your controller's response time, it could mean you are doing a lot of database operations inside the view template itself. regex sample metric legend name View/. * View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Partial View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Rendering View/Users/show.html.erb/Rendering Users/show.html.erb For more information, see the API documentation for ActionView. Metrics attached to events (used by Infrastructure, other products) Because event-type data can have any type of key-value pair data attached to it, one way metrics can be reported is as attributes attached to an event. A couple examples of this at New Relic: Our infrastructure monitoring reports many metrics that are attached to events. For example, we report a ProcessSample event, which has various sample-based metrics attached to it, like CPU percentage. To learn more about infrastructure monitoring data, see Infrastructure data. In APM, the Transaction event has several metrics attached to it, including databaseDuration. To learn more about this data and how to query it, see Events. Metrics as a computation of events (used in some charts and queries) Metrics can be formed by counting New Relic events, or doing some other mathematical calculation on those events. For example, if you wanted to measure the total number of Transaction events over the last half hour, you might run this NRQL query: Select count(*) from Transaction since 30 minutes ago Copy Another example: if you wanted to compute the average response time for your service, you might run a query like: FROM Transaction SELECT average(duration) SINCE 30 minutes ago Copy Some New Relic charts are generated with these kinds of queries. The downside of this approach is that there are limits on how many events a monitoring system (including ours) can report. This means that sometimes, for high-throughput systems, the count may not accurately represent the total activity on that system. To learn more about how this can be addressed, see Event limits and sampling. Want to report custom metrics? See Get data into New Relic. Event data First, well explain the definition of events from a monitoring industry perspective, and then well explain some specifics about how New Relic handles event data. Events in the monitoring industry In the software industry, events can be thought of as simply things that occur in a system. For example, a server setting being changed would be an event. Another example: a website user clicking a mouse. Some events will generate a stored record, and that record is typically also called an event. Event data represents discrete occurrences and typically will have a high level of detail, so event data is suited for detailed analysis and querying. The downside to the use of event data is that there are typically so many events reported that it can become difficult to query that large dataset over longer time ranges. Events at New Relic At New Relic, we report events to data objects also called events. These events have multiple attributes (key-value pairs) attached. Event data is used in some UI charts and tables, and you can also query it. How long event data remains available is determined by data retention rules. One example of an event: APM reports an event type named Transaction, which represents a logical unit of work in an application. To see the attributes attached to this event, you could use a NRQL query like: Select * from Transaction Copy For examples of querying event data, see Introduction to NRQL. Other details about New Relic event data: Events can have any type of attributes attached. Some events have attributes that report metric data. You can report custom events. To increase the availability of your event data for querying/charting, you can turn events into metrics. Some systems generate a large number of events that exceeds collection limits and results in incomplete query results. For more on this, see Event sampling. Because event is a general term, in some New Relic contexts it will refer to any data type that can be queried via NRQL. For example, when you run a NRQL query, it returns a count of inspected events: this is a count of all data types queried. Log data First, well explain the definition of logs from a monitoring industry perspective, and then well explain some specifics about how New Relic handles log reporting. Logs in the monitoring industry A log is a message about a system used to understand the activity of the system and to diagnose problems. Logs at New Relic New Relic's Logs gives you a centralized log management platform that connects your log data with other New Relic-monitored data. For example, you can see logs alongside your APM data. In New Relic, log data is reported with multiple attributes (key-value data) attached. To query your log data, you could use a NRQL query like: Select * from Log Copy To report custom log data, see the Log API. Trace data First, well explain the definition of traces from a monitoring industry perspective, and then well explain some specifics about how New Relic handles tracing. Tracing in the monitoring industry In the application/infrastructure-monitoring world, tracing is a general term used to refer to various ways to report information about how a program or system is operating. For example, a stack trace provides in-depth information about a programs subroutines. For large modern systems, which are often distributed across many services and micro-services, tracing often refers to distributed tracing, which is a way to monitor requests as they propagate through a complex, distributed environment. Tracing at New Relic New Relic offers a distributed tracing feature that tracks requests across a distributed system, and provides a dedicated UI for understanding and analyzing your traces. In New Relic, trace data is reported as Span objects, with multiple attributes (key-value pairs) attached. To query your tracing data, you could use a NRQL query like: Select * from Span Copy To learn more about how distributed tracing works, see Understand distributed tracing. To report custom distributed tracing data, see the Trace API. Query and send data Understanding New Relic data types can help you: Query data in New Relic Send data to New Relic Learn more For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.95673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>data</em> types",
        "sections": "Query <em>and</em> send <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " with your <em>data</em>. Get started This doc will give you a fairly technical explanation of our core <em>data</em> types, their structure, and how they&#x27;re used in our features. You can use most of our features without needing to <em>understand</em> the underlying <em>data</em> structure. But having a better understanding"
      },
      "id": "6045280de7b9d266e1579a0f"
    },
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.10349,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of API client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Introduction to querying data in New Relic",
        "Important",
        "Our open door to your data",
        "Browse your data in the UI",
        "Query data in the UI",
        "Tip",
        "Query data via API"
      ],
      "title": "Introduction to querying data in New Relic",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "f3f9efbd4d9565c83ad8224f1f1524f9a5957650",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/get-started/introduction-querying-new-relic-data/",
      "published_at": "2021-12-19T20:24:14Z",
      "updated_at": "2021-07-27T22:23:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic One is a powerful observability platform that gives you access to all your data throughout your entire system. We host telemetry data sent by your entities, which basically is anything we can identify that has data you can monitor, including applications, services, hosts, etc. You name it! While we provide you with an out of the box experience to see your data with curated dashboards, you can tailor the access to your data and custom the visibility in several ways, including in the UI or via API. Important To better understand your data stored in New Relic, see Data types. Our open door to your data Regardless of your experience with New Relic, well help you discover, understand and visualize your data. You... Then do this... Just installed an agent and want to see your data in New Relic. Browse your data easily without building queries. With the data explorer, you can understand the data weve stored, see its cardinality, or build charts in a few clicks. Know what data is available, but you want to understand more about what else is coming with that data. If youre an advanced user, use our query builder to tailor the data you want to retrieve. Have a specific question and you want to deep dive on the data to get the answer. Refine your NRQL query to dig down to the bottom of your issues. Want to build a dashboard. Create a custom dashboard easily from the data explorer or the query builder. Browse your data in the UI New Relic One offers several experiences that don't require knowledge of NRQL or any query language. On the UI, go to the Query your data button, or click the Browse data dropdown, then select the data type (metrics, events, logs, and traces) you want to explore. For events and metrics, use the data explorer, an intuitive data navigator to create visualizations. From the explorer you can switch to the query builder to see and refine your query. Distributed tracing query: a specialized UI for querying traces. Logs query: a specialized UI for querying New Relic Logs data. Query data in the UI If you're ready to do more than browsing data, become an all-hands actor and personalize your queries in the New Relic UI. Use query languages, including our New Relic query language or our PromQL-style query language, to edit queries with full flexibility. For example, you can add more WHERE clauses, modify the returned value, change to other types of visualizations, etc. Tip Are you new to querying languages? Start browsing data in the data explorer, then turn to the query builder to see the query you built, and refine it. There are two ways to write your own queries to retrieve data and build charts: Query builder in NRQL mode: Query using New Relic query language (NRQL), the same language we use to build most of our UI experiences, and the most advanced way of querying data in New Relic. Query builder in PromQL-style mode: Write basic queries using a PromQL-style query. Query data via API When getting into the New Relic platform is not an option, you can use APIs to retrieve and query your data in New Relic. For example, you can run NRQL (our query language) queries with NerdGraph (our GraphQL API). For more information, see the introduction to New Relic APIs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.38766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to querying <em>data</em> in New Relic",
        "sections": "Introduction to querying <em>data</em> in New Relic",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " it! While we provide you with an out of the box experience to see your <em>data</em> with curated dashboards, you can tailor the access to your <em>data</em> and custom the visibility in several ways, including in the UI or via API. Important To better <em>understand</em> your <em>data</em> stored in New Relic, see <em>Data</em> types. Our open"
      },
      "id": "609f9e1de7b9d2c96ac3eb08"
    }
  ],
  "/docs/data-apis/understand-data/metric-data/query-apm-metric-timeslice-data-nrql": [
    {
      "sections": [
        "Extract metric timeslice data",
        "Time based data",
        "Time range considerations",
        "Important",
        "Tip",
        "Controlling time period output",
        "Data retention",
        "Extracting non-existent metric timeslice data"
      ],
      "title": "Extract metric timeslice data",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Basic functions"
      ],
      "external_id": "2a144a4b775dd2332592a5d92c199a07c08f49fa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/basic-functions/extract-metric-timeslice-data/",
      "published_at": "2021-12-19T16:09:51Z",
      "updated_at": "2021-03-13T01:07:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One type of New Relic data is metric timeslice data. There are several ways to query metric timeslice data: You can query APM metric timeslice data via NRQL (and therefore via our NerdGraph API). You can query any metric timeslice data via the REST API This doc explains how to do this with the REST API. Note that the API is not intended for bulk data extraction of minute-by-minute data points. Time based data All time values returned by the REST API and the API Explorer are UTC (Universal Time Coordinated). Be sure to adjust the time values for data collection as necessary. Time range considerations Important The minimum time range for data requests is one minute (60 seconds). Requests for anything less will result in a 422 status code and no data will be returned. New Relic only collects data at one minute intervals. The API uses the same mechanism for requesting data as the UI: it depends on the time range for the data you request. The objective is to optimize the number of data points returned and provide an easily digestible graph and report. For example: If you request data from a time range of three hours or less, the API returns the one-minute data values originally collected. If you increase the time range to greater than three hours, the data values returned will be an average for two minutes. If you increase the time range to over six hours, the data values returned will be an average for five minutes, and so on. Tip If the initial time for a requested time range is older than eight days, ten evenly spaced data points will be returned for any time range less than four days in length. Here is a summary of the metric value retrieval for the time ranges available. Between this time range... and this time range Granularity of collected data data age  8 days data age > 8 days  3 hours 1 minute 10 evenly spaced data points > 3 hour  6 hours 2 minutes > 6 hours  14 hours 5 minutes > 14 hours  24 hours 10 minutes > 1 day (24 hrs)  4 days (96 hrs) 30 minutes > 4 days  7 days 1 hour 1 hour > 7 days  3 weeks 3 hours 3 hours > 3 weeks  6 weeks 6 hours 6 hours > 6 weeks  9 weeks 12 hours 12 hours > 63 days 3 days 3 days When the start time for a requested time range is older than eight days, data has been aggregated or averaged to one hour periods due to the data aggregation schedule. This means that for any one hour period, only a single data value is available. Obtaining data at less than an hourly period in the time range would cause oversampling, resulting in duplicate values being returned. Returning only ten values prevents oversampling and presents a smoother chart, which eliminates a possibly misleading \"plateau\" effect. Controlling time period output Sometimes the output data's granularity may be too fine, or the time period for the data returned may be too short. To control this, include the period= parameter in the query command as the number of seconds you want each time period to report. Make sure your specifications follow New Relic's data aggregation schedules. Example #1: Following New Relic's table summarizing granularity of collected data, the following API call would normally return data in 30-minute periods, since the request is for 4 days (from=2018-02-13 and to=2018-02-17). By adding period=3600, the data will be returned as 60-minute periods. curl -X GET 'https://api.newrelic.com/v2/applications/$APPID/metrics/data.xml' \\ -H 'Api-Key:$API_KEY' -i \\ -d'names[]=CPU/User+Time&from=2018-02-13T04:00:00+00:00&to=2018-02-17T04:00:00+00:00&period=3600' Copy You cannot specify a period smaller than the default for the time range you are requesting. For example: In the command example above, you can request 1-hour periods, since that is greater than the default (half hour) granularity for the time range. In the command example above, you cannot request 1-minute periods, since that is less than the default (half hour) granularity for the time range. Example #2: If you request a range > 7 days but  3 weeks, where the default period is 3 hours, you can specify periods such as 6, 12, or 24 hours. However, you cannot request 1-hour periods, because that is less than the default (3 hours). Data retention How long data is available depends on the data retention for specific types of data. Extracting non-existent metric timeslice data Situations may arise where non-existent metric names are requested. For example: The metric timeslice data has not been created for one application, but exists for another. When the same metric extraction query is used on both of these applications, it will not be located for one. The metric name was incorrectly specified. Important Metric values that have existed in the past, but are no longer collected, will return a zero value. A successful response will include a 200 status code and metadata about the request. The metadata will contain the names of the metrics requested and the status of the request for those names. Response Metadata Description Response Metric Data metrics_not_found Lists all metric names for which matching data was not found in the requested time period. Metric timeslice data will not be returned for these metrics metrics_found Lists all metric names for which matching data was found in the requested time period. Metric timeslice data will be returned for these metrics Here is an example of output for a valid metric name, HttpDispatcher. HTTP/1.1 200 OK etag: \"0dc87c63d8dff6b1a9714bdf7531ec09\" Content-Type: application/json cache-control: max-age=0, private, must-revalidate {  \"metric_data\": {   \"from\": \"2016-01-28T18:06:06+00:00\",   \"to\": \"2016-01-28T18:36:06+00:00\",   \"metrics_not_found\": [], <---<<< INDICATES NO INVALID METRIC NAMES REQUESTED   \"metrics_found\": [    \"HttpDispatcher\" <---<<< INDICATES THIS METRIC NAME WAS VALID   ],   \"metrics\": [ <---<<< DATA RETURNED    {     \"name\": \"HttpDispatcher\",     \"timeslices\": [      {       \"from\": \"2016-01-28T18:03:00+00:00\",       \"to\": \"2016-01-28T18:04:00+00:00\",       \"values\": {        \"average_response_time\": 364,        \"calls_per_minute\": 99800,        \"call_count\": 99770,        \"min_response_time\": 3.5,        \"max_response_time\": 85000,        \"average_exclusive_time\": 0,        \"average_value\": 0.364,        \"total_call_time_per_minute\": 36300,        \"requests_per_minute\": 99800,        \"standard_deviation\": 1900,        \"average_call_time\": 364 ... Copy Here is an example of output for a invalid metric name, Foo. HTTP/1.1 200 OK etag: \"e51782cf7c5a5596139a7f5340c3de23\" Content-Type: application/json cache-control: max-age=0, private, must-revalidate {  \"metric_data\": {   \"from\": \"2016-01-28T18:06:33+00:00\",   \"to\": \"2016-01-28T18:36:33+00:00\",   \"metrics_not_found\": [    \"Foo\" <---<<< INDICATES THIS METRIC NAME WAS INVALID   ],   \"metrics_found\": [], <---<<< INDICATES NO VALID METRIC NAMES FOUND   \"metrics\": [] <---<<< NO DATA RETURNED  } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1182.918,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Extract <em>metric</em> <em>timeslice</em> <em>data</em>",
        "sections": "Extract <em>metric</em> <em>timeslice</em> <em>data</em>",
        "body": "One type of New Relic <em>data</em> is <em>metric</em> <em>timeslice</em> <em>data</em>. There are several ways to <em>query</em> <em>metric</em> <em>timeslice</em> <em>data</em>: You can <em>query</em> <em>APM</em> <em>metric</em> <em>timeslice</em> <em>data</em> via <em>NRQL</em> (and therefore via our NerdGraph API). You can <em>query</em> any <em>metric</em> <em>timeslice</em> <em>data</em> via the REST API This doc explains how to do this with the REST"
      },
      "id": "60440691e7b9d201b8579a00"
    },
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesnt support its use or that hasnt used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hours worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.5863,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> <em>metric</em> <em>data</em>",
        "tags": "<em>Query</em> your <em>data</em>",
        "body": " <em>Metric</em> API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). <em>Query</em> <em>metric</em> <em>timeslice</em> <em>data</em>, which is our original <em>metric</em> <em>data</em> type reported by our <em>APM</em>, mobile monitoring, and browser monitoring. For more details about how we report <em>metric</em>"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Glossary of New Relic terms",
        "account dropdown",
        "account switcher",
        "administrator",
        "agent",
        "agent API",
        "aggregated metrics",
        "aggregation delay",
        "aggregation function",
        "aggregation method",
        "aggregation timer",
        "aggregation window",
        "alert",
        "alert condition",
        "alert evaluation",
        "alert policy",
        "apdex",
        "apdex_f",
        "apdex_t",
        "API (application programming interface)",
        "APM",
        "application",
        "application ID",
        "application name",
        "Applied Intelligence (AI)",
        "attribute",
        "availability monitoring",
        "browser",
        "Browser monitoring",
        "background external",
        "child account",
        "cloud-based integration",
        "collector",
        "Command line interface (CLI)",
        "compute unit (CU)",
        "condition_id",
        "CPM (calls per minute)",
        "CPU burn",
        "custom attribute",
        "custom dashboard",
        "custom event",
        "custom instrumentation",
        "custom metric",
        "data collector",
        "data explorer",
        "degradation period",
        "dimensional metric",
        "Docker",
        "downtime",
        "entity",
        "event",
        "expected error",
        "exporter",
        "Flex",
        "framework",
        "harvest cycle",
        "health status indicator",
        "host",
        "host ID",
        "ignored error",
        "incident",
        "Infrastructure monitoring",
        "Insights",
        "instance ID",
        "instrumentation",
        "integration",
        "interaction",
        "interaction trace",
        "inventory data",
        "key transaction",
        "launcher",
        "log",
        "Log monitoring",
        "Logs",
        "Logs in context",
        "master account",
        "metric",
        "metric timeslice",
        "metric grouping issue",
        "minion",
        "Mobile monitoring",
        "monitor",
        "NerdGraph",
        "Nerdlet",
        "Nerdpack",
        "New Relic Edge with Infinite Tracing",
        "New Relic One",
        "New Relic One catalog",
        "NRQL (New Relic query language)",
        "non-web transaction",
        "notification",
        "notification channel",
        "on-host integration",
        "owner",
        "page load timing",
        "parameter",
        "parent account",
        "permalink",
        "pinger",
        "polling interval (AWS)",
        "PPM (pages per minute)",
        "private location",
        "recovery period",
        "response time",
        "restricted user",
        "rollup",
        "root span",
        "RPM",
        "RUM (real user monitoring)",
        "runbook",
        "SAML (Security Assertion Markup Language)",
        "Selenium",
        "service",
        "signal",
        "signal filter",
        "span",
        "SSL certificate",
        "SSO (single sign on)",
        "streaming algorithm",
        "sub-accounts",
        "Synthetic monitoring",
        "target",
        "tag",
        "thresholds",
        "throughput",
        "tier",
        "time picker",
        "time range",
        "timeslice data",
        "trace",
        "traffic light",
        "transaction",
        "transaction trace",
        "UI",
        "user",
        "UTC",
        "value function (metrics)",
        "violation",
        "web external",
        "web transaction",
        "WebDriverJS",
        "workload"
      ],
      "title": "Glossary of New Relic terms",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "8f8fc1ec9f41e6a4d6b4e986e9b0589bc2ca1f86",
      "image": "https://docs.newrelic.com/docs/glossary/glossary/images/account-dropdown.png",
      "url": "https://docs.newrelic.com/docs/glossary/glossary/",
      "published_at": "2021-12-20T01:43:05Z",
      "updated_at": "2021-12-18T01:39:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you're considering New Relic One or you're already using our capabilities, this glossary of common terminology can help. And if you don't already have a New Relic account, don't hesitate to sign up at newrelic.com/signup. It's free, forever! account dropdown In the upper right of the New Relic UI, the account dropdown gives you access to your account settings. If you're trying to switch between accounts, use the account switcher. account switcher If you have access to more than one account in a multi-account organization, you can use the account switcher to switch between accounts. This is located in the top right of most New Relic UI pages. For more on factors that affect access to accounts, see Factors affecting access. To find account settings, use the account dropdown. administrator A type of user role on a New Relic account. For more information, see Users. agent At New Relic, an agent is a piece of monitoring software that provides integrations with various technologies (for example, web frameworks, host operating systems, or database types). The agents send that data to New Relic, usually on a specific cadence. For more information, see: New Relic Instant Observability Install agents agent API Some New Relic agents have agent APIs that allow you to extend the functionality of an agent. You can use the API to control, customize and extend the functionality of the agent. Here are some agent API docs: APM agents: C SDK API Go agent API Java agent API .NET agent API Node.js agent API PHP agent API Ruby agent API Python agent API Browser agent: Browser agent API Mobile agents: iOS SDK API Android SDK API aggregated metrics Aggregated metric data summarizes calls to specific methods in your application, including how many times each one was called and response times. In the New Relic UI, you see the class and method names along with their aggregate numbers. Metric data aggregation depends on the New Relic tool and your subscription level. For more information, see the documentation about data retention. aggregation delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. aggregation function You can use NRQL query functions, such as sum(), average(), or latest() to choose how the data points in an aggregation window should be processed into a single data point. The single aggregated data point is what's passed through the alert evaluation process. aggregation method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics) CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer setting. The Timer starts running as soon as the first data point appears for that aggregation window (based on the data points timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. aggregation timer The length of time in seconds to wait after each data point received, to ensure the entire batch is processed. Required when using EVENT_TIMER aggregation_method type. aggregation window Streaming alerts gathers data together into specific amounts of time. These windows of time are customizable. Data points are collected together based their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. alert An alert communicates an event or incident that designated personnel can track through Alerts. For an explanation of how basic alerts concepts are related, see Concepts and workflow. alert condition An alert condition (or condition), identified by its unique numeric condition_id, contains the criteria for creating a violation. The condition includes the threshold that is set for a metric timeslice or a custom metric over time on a chosen target. For an explanation of how a condition relates to other basic alerts concepts, see Concepts and workflow. alert evaluation Streaming data is assessed on a set of aggregation windows to determine if an alert condition is violating or recovering. The aggregation window time is how long we'll collect data before running the NRQL query condition. The offset evaluation time is how long you want us to wait for late data before assessing it. If a window doesn't have any data points, it's treated as a gap for loss of signal. alert policy A collection of one or more conditions, one or more notification channels, and an Incident preference setting. If a condition contained within the policy opens a violation, an incident may be opened depending on the Incident preference setting. Notifications will then be sent to all channels attached to the policy. For an explanation of how a policy relates to other basic alerts concepts, see Concepts and workflow. apdex Apdex is an industry-standard way to measure users' satisfaction with the response time of an application or service. New Relic rates each response as Satisfied, Tolerated, or Frustrated, and uses these ratings to calculate an overall user satisfaction score. For more information, see Apdex: Measure user satisfaction. apdex_f The response time above which a transaction are rated frustrating. Defaults to four times apdex_t. Requests that complete in less than apdex_t are rated satisfied. Requests that take longer than apdex_t, but less than four times apdex_t (apdex_f), are tolerated. Any requests that take longer than apdex_f are rated frustrating. For more information, see Apdex: Measure user satisfaction. apdex_t The response time above which a transaction is considered tolerable. The default value is 0.5 seconds, but you can change this in your Apdex settings. Requests that complete in less than apdex_t are rated satisfied. Requests that take more than apdex_t, but less than apdex_f, are tolerated. Any requests that take longer than apdex_f are rated frustrating. For more information, see Apdex: Measure user satisfaction. API (application programming interface) New Relic offers a variety of APIs and SDKs. For more information, see the introduction to New Relic's APIs. APM New Relic's APM (application performance monitoring) provides monitoring of your web or non-web application's performance. APM supports apps using several programming languages. application For New Relic purposes, any program instrumented by New Relic. application ID Some New Relic solutions assign a monitored application a unique application ID, often shortened to app ID. When present, this ID is available in the UI. It is also reported as an attribute and can be queried. For how to determine this, see Find app ID. application name The name that New Relic combines with your license key to uniquely identify a particular app. For more information, see Name your application. Applied Intelligence (AI) Applied Intelligence (AI) helps you find, troubleshoot, and resolve problems more quickly. Specifically, its a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. Applied Intelligence includes Alerts, Incident Intelligence, and Proactive Detection. attribute Attributes are key-value pairs attached to data objects reported to New Relic. Attributes add detail, and they're similar to tags or labels in other SaaS software. You can explore this data by querying or searching via the UI or by using the data dictionary. Examples: APM reports a Transaction event. This includes timing data for the transaction in a duration attribute, which might have a value of .002. Our Infrastructure Monitoring reports a ProcessSample event. This includes a variety of CPU usage attributes, including a cpuSystemPercent attribute, which might have a value of .01. Our Telemetry SDK reports a Metric data type for storing metrics, with attached attributes like metricName and newrelic.source. Some New Relic tools allow you to report custom attributes to enhance your monitoring. For more information about attributes in APM, see Agent attributes. availability monitoring See Types of Synthetics monitors. browser The New Relic UI supports most browsers. For more information, see Supported browsers. For our end-user browser monitoring tool, see Browser Monitoring. Browser monitoring A Real User Monitoring (RUM) solution that measures the speed and performance of your end users as they navigate to your site from different web browsers, devices, operating systems, and networks. background external See web external. child account See parent account. cloud-based integration New Relic offers cloud-based integrations with providers such as Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. collector The component that collects data from New Relic agents running on an app server, mobile device, or end-user browser. While the agent is installed on a user's app server, the collectors are centrally located in New Relic's data center. In order to contact the collector, the agent must be able to reach New Relic's domains and IP addresses. (The exact domain or IP depends on the New Relic monitoring tool.) The collector receives and interprets this data, and stores it in a database. The data is then retrieved and presented in the New Relic UI and by our various REST APIs. Command line interface (CLI) Our command line interface (CLI) is a tool you can use to build a New Relic application. This is the same tool our own engineers use. Go here for quick start instructions. Go to our Developer site for sample apps and guides. compute unit (CU) A unit of measurement that determines your pricing for some New Relic products governed by our original product-based pricing model. For more information, see Compute unit pricing. condition_id See alert condition. CPM (calls per minute) The number of calls your application receives each minute. This usually corresponds to the number of page views or external connections, and is usually the same as RPM (requests per minute). CPU burn The time consumed by code minus the wait time for a transaction. This is the time actually spent processing the transaction. It appears in the New Relic UI at the top of the transaction view for the agents that provide it (Ruby and PHP only). custom attribute A key-value pair added to a transaction or event in order to gain additional information about it. For more information, see custom attributes. custom dashboard A customizable dashboard with charts and tables that includes data from multiple New Relic data sources. For more information, see dashboards. custom event An event, in New Relic terms, is a data object with attached attributes. New Relic reports default event types, like Transaction and TransactionError. You can also create your own events. Events can be queried, and are used in some other features. You can generate custom events with APM agents, the browser monitoring agent, the mobile monitoring agents, and via the Event API. Alternatively, you can add custom attributes to some existing default New Relic events. custom instrumentation Custom instrumentation allows you to extend New Relic's monitoring to instrument code elements New Relic doesn't automatically instrument. Custom instrumentation is useful when your framework is not supported by New Relic, or when New Relic fails to pick up some element of your program. You can also use custom instrumentation to block a transaction from being reported entirely. For more information, see Custom instrumentation. custom metric Metric timeslice data that is manually recorded via an API call. Custom metrics allow you to record arbitrary metrics; for example, timing or computer resource data. All custom metric names must be prefixed with Custom/. For more information, see Custom metrics. Not to be confused with custom instrumentation data. data collector See collector. data explorer Use the data explorer to access, query and customize your data, create visualizations, and make connections between your services in a consistent and curated experience. For more on using the data explorer, see Introduction to the data explorer. degradation period When a data source enters a violating state, a degradation period of time begins. The degradation period is set in the condition's threshold. A violation will open if the source stays in a violating state for the entire degradation period. In addition: If the data source enters a non-violating state before the entire time has elapsed, the degradation period countdown is reset, and a violation does not open. If your alert condition threshold is configured as at least once in, the degradation period always lasts a single minute. dimensional metric A dimensional metric is a metric that has multiple attributes, also known as dimensions. At New Relic, we report dimensional metrics using the Metric data type. For more on other metric data types, see Metric data. Docker An open platform for distributed applications, which allows you to assemble multi-container portable apps. Infrastructure Monitoring includes integrated Docker monitoring. For more information about Docker, see the Docker website. downtime The period of time when customers cannot access your site and your app is not reporting to New Relic. For more information, see Synthetic Monitoring and Types of synthetic monitors. entity In New Relic, an entity is anything we can identify that has data you can monitor. An entity can be something you monitor directly, like applications and microservices, or indirectly, like data centers. You can identify one or more entities to be targets for alert conditions. In the Alerts API, the entity being monitored is identified with an entity_id. For more on this, see What are entities? event The word event is a general term that can have many meanings. At New Relic, event can have several meanings: At New Relic, event data is one of our core data types. Event data represents a record of a single event at a particular moment in time. Events can vary by type (for example, Transaction or Mobile, and will have associated attributes (for example, timestamp or transactionName). For more details, see Event data. For our infrastructure monitoring, the word event can be used to refer to important system and host activity. For example, a configuration change for a monitored host would be registered on Infrastructure's Events UI page. For alerts, the Events UI page displays a list of alerts-related incidents for your monitored entities. Events are reported for a violation opening and for closing. In some contexts, event can refer to any NRQL-queryable data type. For example, when you run a NRQL query, you will see a count of inspected events: this refers to a count of all data types queried. expected error An expected error is a common error that you don't want to affect your Apdex score or error rate. For more information, see Manage errors in APM. exporter At New Relic, an exporter is a type of integration that reports telemetry data to New Relic from a third-party (non-New Relic) telemetry tool. For examples, see Exporters, or search our integration quickstarts in New Relic I/O. Flex New Relic Flex is an application-agnostic, all-in-one infrastructure integration. With it, you can build your own integration that collects metric data from a wide variety of services, and that can instrument any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format (for example, JSON or plain text) to the terminal. It's a recommended way to create a custom integration, because it doesn't require coding skills. framework A framework is a structured collection of pre-defined functions, into which an application builder inserts their own code to build their application. A framework is not the same as a library. While a library is a collection of functions you can call as needed, a framework is a skeleton for your application. The functions in that framework then call your functions. For more about the distinction between a framework and a library, see What is the difference between a framework and a library?. New Relic automatically instruments many common frameworks. For more about the frameworks New Relic supports, see the agent-specific documentation: C SDK supported frameworks Go supported frameworks Java supported frameworks .NET supported frameworks Node.js supported frameworks PHP supported frameworks Python supported frameworks Ruby supported frameworks harvest cycle The period of time between each connection from a New Relic agent to the collector. Between harvest cycles, an agent collects and caches data. At the end of the cycle an agent reports those data to the collector, then begins a new harvest cycle. health status indicator Some New Relic UI pages have a health status indicator appearing next to an index of monitored entities. This is a colored bar (generally green, yellow, red, or gray) indicating the status of your app or other entity monitored by New Relic. It also indicates whether the entity has any alert policies assigned to it and whether there are any policy violations. In general, the colored bar will be green, yellow, red, or gray to indicate the health status. Exceptions: Our REST API (v2) uses orange instead of yellow for the application's health and reporting status. Service maps use different criteria for reporting the health of a connection between an app and an external service not monitored by New Relic (for example, a third party API). host At New Relic, a host means one of the following: A physical machine is a hardware-based device with dedicated physical resources, including memory, processing, and storage. Each machine has its own OS which applications run on. A virtual machine (VM) is the software implementation of a physical machine that executes programs like a physical machine. One or more virtual machines can run on a physical machine. Each virtual machine has its own OS and allocated virtual machine resources such as RAM and CPU. A cloud instance is a type of virtual machine that is run in the public cloud. In this context, virtual machines and cloud instances are different from Java Virtual Machines (JVMs) and containers. host ID Each host identified by APM is assigned a host ID. This ID is used to uniquely identify it, and to retrieve data about that host via the REST API. For more information, see List host ID. ignored error An error that you have told the APM agent not to report to the collector. For more information, see Manage errors in APM. incident An incident is a collection of one or more violations of the conditions defined in an alert policy. An incident record includes all of the open and close time stamps for each violation, as well as chart snapshots of the data being evaluated around the time of each violation. You can view detailed information from the Incidents pages in the user interface. You can also select your preference for how we roll up violations into the incident. For an explanation of how an incident relates to other basic alerts concepts, see Concepts and workflow. Infrastructure monitoring By connecting changes in host performance to changes in your configuration, infrastructure monitoring provides real-time metrics and powerful analytics that reduce your mean-time-to-resolution (MTTR). Infrastructure is specifically designed for complex environments that need flexible, dynamic server monitoring, from a physical datacenter to thousands of Amazon Elastic Compute Cloud (Amazon EC2) instances and other types of integrations. Insights Insights was the name for the New Relic product that previously governed the reporting of custom events, as well as the ability to query and chart your New Relic data. These features are now a fundamental part of the New Relic One platform and are no longer governed by the Insights product or name. To learn more about these features: Event API for reporting custom events Query and chart data For historical reasons, the word \"Insights\" is still used in some places. For example: Some APM agents still have Insights language in their codebase. For example, the Java agent custom_insights_events configuration. For New Relic organizations on our original pricing model, Insights Pro is still the product name governing custom event data ingest and retention. There is an API key called the Insights insert key. instance ID Each instance identified by New Relic is assigned a unique instance ID. Instance IDs are most commonly found for JVMs (Java Virtual Machines), but can exist for each agent. This ID is used to uniquely identify it, and to retrieve data about that instance via the REST API. For more information, see List instance IDs. instrumentation The collection of data from an application or host. When New Relic instruments a framework, it detects the methods and calls used by that framework, and intelligently groups them together. integration At New Relic, an integration refers to a solution that integrates with a specific technology (like a web framework or a type of database). All our integrations can be found as quickstarts in New Relic Instant Observability. interaction In our mobile monitoring, an interaction is a specific code path initiated by a user interaction (usually a button press). An interaction is the mobile equivalent of a transaction, and like a transaction an interaction can be traced and monitored. You can see much of the data included in an interaction in the BrowserInteraction event. interaction trace An interaction trace is a complete picture of a single interaction. With interaction traces, New Relic gives you much deeper visibility into a single slow interaction, which can help you understand a broader problem. Interaction traces are the mobile equivalent of a transaction trace. For more information, see Creating interactions (iOS) and Creating interactions (Android). inventory data Inventory data is information about the status or configuration of a service or host. Examples of inventory data include: Configuration settings Name of the host the service is on Amazon AWS region Port being used For more information, see Understand and use data. key transaction A web transaction that the user has marked as particularly important; for example, key business events (such as signups or purchase confirmations), or transactions with a high performance impact (such as searches). Key transactions have their own pages in the UI and other customized values. For more information, see Key transactions. launcher A launcher is a specific piece of code you can include when you create a New Relic One app. It creates the tile on the homepage that you click to launch the app. For more information, see the documentation about core UI components. log A log is a message about a system used to understand the activity of the system and to diagnose problems. For more information on how we use log data, see Log management. Log monitoring Our log management and monitoring features give you the tools to collect, process, explore, visualize, and alert on your log data using your existing log forwarder. With all of your log data in one place, you'll be able to make better decisions, detect and resolve problems more quickly, and see your logs in context to troubleshoot faster. Logs Our Logs feature is a scalable log management platform that allows you to connect your log data with the rest of your telemetry data. Pre-built plugins with some of the most common open-source logging tools make it simple to send your data from anywhere to New Relic. Logs in context Logs in context makes it easy to link to your log data with related data across the rest of our platform. Bringing all of this data together in a single tool allows you to quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. master account See parent account. metric A metric is a numeric measurement. Metric data is a broad category because there are several ways to make and report measurements. For more about how metrics are reported at New Relic, see New Relic data types. metric timeslice New Relic reports metrics in several ways. One variety of metric data is called metric timeslice data; this is the type of data used to generate many of the charts in APM, mobile monitoring, and browser monitoring (for more details, see metric timeslice data). Over time, metric timeslice data is aggregated into longer timeslice data records for more efficient storage. For more about how we aggregate this type of data, see Data aggregation. For how to query this type of data, see Query metric timeslice data. metric grouping issue A metric grouping issue occurs when an account sends too many differently named metric timeslice data points to New Relic, and those individual web transactions are not properly aggregated. For example, rather than a single /user/controlpanel/ metric name, you might see /user/controlpanel/alice, /user/controlpanel/bob, and /user/controlpanel/carol. For more information, see Metric grouping issues. minion The software that accepts monitor jobs from a private location. A minion is a packaged virtual appliance that runs in your hypervisor. For more information, see Private locations overview and install and configure private minions. Mobile monitoring Mobile monitoring allows you to monitor and manage the performance of your mobile apps on Android, iOS, tvOS, and other systems. Mobile monitoring provides end-to-end details, including crashes, throughput, HTTP requests, error traces, and more. Not to be confused with New Relic's own mobile apps for Android, iPhone, and iPad. monitor For our Synthetic Monitoring, a monitor ensures your website or API endpoint is available. For more information, see Adding and editing monitors. NerdGraph NerdGraph is our GraphQL API, an efficient and flexible query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph calls get all the data you need in a single request. NerdGraph also makes it easier to evolve APIs over time and enables powerful developer tools. You can use our NerdGraph GraphiQL explorer to explore the schema and find definitions. With valid New Relic API key, you can try it out yourself at api.newrelic.com/graphiql. Nerdlet A Nerdlet is a component of a New Relic One application. It's a specific UI view, represented by a React JavaScript package. For more information, see Nerdpack file structure. Nerdpack A Nerdpack is a component of a New Relic One application. It's the package containing all the files needed by that application. For more information, see Nerdpack file structure. New Relic Edge with Infinite Tracing New Relic Edge with Infinite Tracing is a fully managed, distributed tracing service that observes 100% of your application traces, then provides actionable data so you can solve issues faster. For more information, see /docs/understand-dependencies/distributed-tracing/get-started/how-new-relic-distributed-tracing-works. New Relic One For more information, see Introduction to New Relic One. New Relic One catalog Our catalog is a collection of applications built on the New Relic One platform. The catalog includes custom apps we've built, public open source apps, and any apps that you buid. You can browse the catalog on New Relic One. NRQL (New Relic query language) NRQL is a query language, similar in form to SQL, that allows you to query the data stored in your New Relic account. non-web transaction APM identifies transactions as either web or non-web. When New Relic does not detect a transaction was initiated by a web request, this is called a non-web transaction. For more information, see Background processes and other non-web transactions. notification The message sent when an incident opens, is acknowledged, or closes. The type of notification is defined by the alert policy's notification channel. For an explanation of how notifications relate to other basic alerts concepts, see Concepts and workflow. notification channel Where we send a notification when an incident opens, is acknowledged, or closes. Available channels include email, mobile push notifications, webhooks, and more. on-host integration On-host integrations refer to integrations that reside on your own servers or hosts and that communicate with our infrastructure agent. For more information, see Introduction to on-host integrations. owner For accounts on our original pricing model, this is a type of user role: the user who initially created the account. For more information, see Users. page load timing With page load timing, New Relic monitors the full load time for end-user browsers. New Relic's application agents dynamically inject JavaScript into the page, then capture the following key load points: Navigation start: The user initiates the transaction. First byte: The browser receives the requested page. DOM ready: The browser has finished parsing DOM. Page ready: Page loading is complete. Page load timing is sometimes referred to as RUM, or real user monitoring. Unlike standard RUM, page load timing also captures JavaScript errors and AJAX requests. For more information, see Page load timing process. parameter Deprecated term; see attribute. parent account New Relic organizations can have a parent/child account structure. This structure was much more important for organizations on our original user model, but is still used for some features for organizations on the New Relic One user model. Learn more about account structure. Parent accounts were previously referred to as \"master accounts\", and child accounts were previously referred to as \"sub-accounts\". permalink A unique URL that links to a view of your application at a specific point in time. Permalinks are useful for troubleshooting and for sharing interesting time windows with colleagues. pinger The component of New Relic that connects to your website to verify your website is accessible. New Relic has pingers in Europe, Asia, and the United States. Each pinger attempts to contact your website at least once every two minutes. If enough pingers are unable to reach your website, your application will be considered down. For in-depth scriptable testing, including real browser tests and tests of API endpoints, see Synthetic Monitoring. Synthetic Monitoring includes free ping monitoring, which allows you to monitor your website from locations around the world. For more information, see Types of Synthetic monitors. polling interval (AWS) Our Amazon integrations query your AWS services according to a polling interval, which varies depending on the integration. Each polling interval occurs for every AWS entity. For example, if you have thirteen Elastic Load Balancers (ELB), each one will be polled every five minutes. Depending on the AWS integration, there may be delays in the timing between the API request and the metric data returned. If you notice unusual delays, follow the integration troubleshooting procedures. PPM (pages per minute) The number of pages per minute your application serves. private location A Synthetic monitor feature that allows you to run Synthetic monitors from within your own systems by creating private minions. Private locations allow you to extend your Synthetic coverage to new geographical locations, and to monitor websites behind your firewall such as an intranet site. For more information, see Private locations overview. recovery period A recovery period of time begins when a data source enters a non-violating state after being in a violating state. The recovery period is set in the condition's threshold. A violation will close when a source remains in a non-violating state and the recovery period time has elapsed. If the data source enters a violating state before the time has elapsed, the recovery period clock will reset and the violation won't close. response time The duration of time between a request for service and a response. For more information, see Response time. restricted user A type of user role on a New Relic account. For more information, see Users. rollup Using the same application name for multiple applications. This allows you to combine data in APM, either from multiple applications, or from multiple instances of an application. For more information, see Rolling up app data. root span For distributed tracing, the root span is the first span in a trace. In many cases, the root span duration will represent the duration of the entire trace, or be very close to it. However, for more complex, modern systems that use a lot of asynchronous, non-blocking processes, this will not be true. For those systems, the root spans duration may be significantly less than the duration of the trace. RPM The term RPM usually refers to the number of requests per minute your application receives from users. This is usually the same as CPM (calls per minute). Historically, some New Relic monitoring solutions, like APM and Browser Monitoring, used to contain RPM in the URL; for example, https://rpm.newrelic.com. This language use originally referred to Rails performance management because the first iteration of our product monitored Ruby on Rails applications. We monitor many more languages and systems than Ruby now. RUM (real user monitoring) See page load timing. runbook A runbook contains standard procedures and operations typically used by system administrators, network operations staff, and other personnel to handle outages, alert incidents, and other situations. If your organization stores runbook instructions as URLs, you can link this information to an alerts policy so your personnel has easy access to this information when an incident violates the defined policy thresholds. SAML (Security Assertion Markup Language) SAML is an XML-based data format for sharing authentication data between two parties. New Relic accounts must obtain a SAML certificate in order to enable Single Sign On for their users. For more information, see SAML service providers. Selenium Selenium is an open-source browser testing suite. Synthetics uses Selenium to test monitored websites with real browsers. For more information, see monitor types. service A service is a cluster of runtime server processes that accomplish a particular task, usually service requests. Unlike an application, a service is not usually invoked by a human. New Relic offers a variety of integrations that allow you to report data from your services. signal The stream of telemetry data that's watched and alerted on. You use NRQL queries to define a signal. signal filter When we receive data and it's routed to the streaming alerts platform, your NRQL WHERE clause will filter the data coming in. The filtered streaming data is what's evaluated for loss of signal violations, for example. span In a distributed trace, a span is a \"named, timed operation representing a contiguous segment of work in that trace\" (from OpenTracing.io definition). For distributed tracing, spans are displayed in the distributed tracing UI, and the data type Span is available to be queried. See also root span. SSL certificate SSL certificates encrypt data that is being transmitted. While New Relic refers to security certificates as SSL because it is a more commonly used term, all certificates adhere to industry standards for secure encryption in transit. SSO (single sign on) SSO (single sign on) allows you to manage user authentication in New Relic using an external SSO provider. For more information, see Setting up SSO. streaming algorithm This is what determines when the data in an aggregation window is processed. The streaming algorithm uses your server's clock time and the aggregation window size to trigger the alert evaluation process. sub-accounts See master account. Synthetic monitoring Synthetic monitoring allows you to monitor your website or API endpoint via automated, scriptable tools. Use free ping monitor to ensure your website is accessible, or expand your monitoring with browser monitors, which test your website with real browsers. Go further with scripting, to script browsers or API monitors for sophisticated testing. target A target is a resource or component monitored by a New Relic monitoring tool that has been identified in an alert condition. When the data source for that target crosses the defined critical threshold, we will open a violation. Depending on your policy's Incident preference setting, Alerts may create an incident record and send notifications through the defined channels. See also entity. tag Tags are key:value metadata added to monitored apps, hosts, dashboards, and other entities to help you organize your data at a high level. For details, see Tags. thresholds Thresholds are alert condition settings that define a violation. Threshold values include the value a data source must pass to trigger a violation and the time-related settings that define a violation; for example: Passing a certain value for at least x minutes Passing a certain value only once in x minutes While the data source passes a certain value, a degradation period starts. Likewise, when that data source stops passing a certain value, a recovery period starts. The durations of these two time periods are defined in the alert condition threshold settings. Thresholds have a required critical (red) threshold and an optional warning (yellow) threshold. In the UI, the entity's health status indicator will change to yellow or red when a threshold has been crossed and a violation will open. For more information, see Define thresholds. For an explanation of how thresholds relate to other basic Alerts concepts, see Concepts and workflow. throughput Throughput is a measurement of user activity for a monitored application. APM throughput and Browser Monitoring throughput are measured in different ways: APM: requests per minute (RPM) Browser: page views per minute (PPM) tier A tier can refer to how New Relic categorizes or visualizes the various agent language ecosystems that we support. For example: In APM, the color-coded categories that appear on your app's main Overview chart show response time spent in various functions, processes, or agents as tiers; for example, request queuing, garbage collection, Middleware, JVMs, etc. In New Relic labels, TIER can be used to define or classify the client-server architecture; for example, front-end and back-end tiers. \"Tier\" may sometimes be used to refer to our pricing editions. time picker By default the New Relic UI shows data for the past 30 minutes, ending now. To change the time window, use the time picker. time range A time range can refer to a length of time selected in the New Relic UI. New Relic displays a time range depending on the range you select using the time picker. timeslice data See metric timeslice data. trace A trace is a description of how a request travels through a system. Trace data helps you understand the performance of your system and diagnose problems. For more information on how we use trace data, see New Relic data types. traffic light See health status. transaction A transaction is defined as one logical unit of work in an application. This term primarily refers to server-side transactions monitored by APM. For more information, see documentation about web transactions and non-web transactions. The term transaction is also sometimes used in Browser Monitoring. In that case, it primarily refers to activity beginning with a browser-side web request and ending with a complete page load. transaction trace A transaction trace is a complete picture of a single transaction, down to the database queries and exact invocation patterns. With transaction traces, New Relic gives you much deeper visibility into a single slow transaction, which can help you understand a broader problem. For more information, see Transaction traces. UI The New Relic user interface. For more information, see Standard page functions. user A user can refer to a specific user role in a New Relic account. For more information, see Users. UTC Universal Time Coordinated (UTC), or Coordinated Universal Time, is a standard timestamp for synchronizing time around the world. value function (metrics) The numeric value obtained from metric timeslice data; for example, an average, minimum, maximum, total, sample size, etc. violation A violation occurs when the entity monitored by an alert condition reports a value that crosses the thresholds defined in that condition. For an explanation of how violations relate to other basic alerts concepts, see Concepts and workflow. You can view a summary of the violations for a selected incident's page. You can also view the violations for a specific entity from the product's UI. web external Web external is the term applied to the portion of time spent in transactions to external applications from within the code of the application you are monitoring. That time can be a call to a third party company (a payment provider, for example) or it could be a call to another microservice within your own company. Web external demonstrates how performance is impacted by your code executing outside the application you are measuring. web transaction A transaction is defined as one logical unit of work in an application. This term primarily refers to server-side transactions monitored by APM. Web transactions are initiated with an HTTP request. For most organizations, these represent customer-centric interactions and thus are the most important transactions to monitor. For more information, see Web transactions and Non-web transactions. WebDriverJS WebDriver is a Selenium component, used to control Synthetics scripted browsers. Specifically, Synthetics uses WebDriverJS, a Node.js-based flavor of Selenium. For more information, see Writing scripted browsers and Scripted browser examples. workload A workload represents a group of entities that work together to provide a digital service. For more information, see Workloads.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.07521,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>metric</em> <em>timeslice</em>",
        "body": " and report measurements. For more about how metrics are reported at New Relic, see New Relic <em>data</em> types. <em>metric</em> <em>timeslice</em> New Relic reports metrics in several ways. One variety of <em>metric</em> <em>data</em> is called <em>metric</em> <em>timeslice</em> <em>data</em>; this is the type of <em>data</em> used to generate many of the charts in <em>APM</em>, mobile"
      },
      "id": "61b40189196a672dd0a5aa8c"
    }
  ],
  "/docs/data-apis/understand-data/metric-data/query-metric-data-type": [
    {
      "sections": [
        "StatsD monitoring integration",
        "Requirements",
        "Install",
        "Install for Kubernetes",
        "Kubernetes manifest examples",
        "Configure",
        "Tip",
        "Example of custom configuration",
        "Docker: overwrite default configuration",
        "Kubernetes: overwrite default configuration",
        "Metric format",
        "Metric types",
        "Counter",
        "Gauge",
        "Timer",
        "Add tags (attributes)",
        "Add default tags that apply to all metrics",
        "Add metric-level tags",
        "Create alerts",
        "Alert example",
        "Find and use data",
        "Check the source code"
      ],
      "title": "StatsD monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "48ab117ae50533224877d767224d85edd939db42",
      "image": "https://docs.newrelic.com/static/9c86375ad0ec12433df78b2116819aab/c1b63/statsd-nrql-alert-condition-example.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/statsd-monitoring-integration-version-2/",
      "published_at": "2021-12-20T10:24:54Z",
      "updated_at": "2021-10-24T00:56:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our StatsD integration lets you easily get StatsD-format data into New Relic. You can also add any arbitrary tags (key-value pairs) to your data. Once your metrics are in New Relic, you can query your data and create custom charts and dashboards. Want to try out our StatsD integration? Create a New Relic account for free! No credit card required. Requirements This integration uses our Metric API and our Event API to ingest data. To use these APIs, you'll need a license key. The integration adheres to the Metric API requirements and data limits. The default rate limit is 100,000 data points per minute (DPM). If you think you're missing metrics or sending more than 100K DPM, see Request data changes. To see if your account is hitting the rate limit, run the following NRQL query of the NrIntegrationError event: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' FACET category, message LIMIT 100 since 1 day ago Copy Install This section will explain how to do a standard install. If you want to run StatsD in Kubernetes, see Kubernetes install. To install the StatsD integration, run the following command and include your New Relic account ID and New Relic license key. This generates a TOML configuration file used by gostatsd. docker run \\ -d --restart unless-stopped \\ --name newrelic-statsd \\ -h $(hostname) \\ -e NR_ACCOUNT_ID=YOUR_ACCOUNT_ID \\ -e NR_API_KEY=NEW_RELIC_LICENSE_KEY \\ -p 8125:8125/udp \\ newrelic/nri-statsd:2.0.0 Copy If your account is in the EU data center region, add this to the above command: -e NR_EU_REGION=true \\ Copy After installing, you can: Do optional additional configuration Define your metrics Add custom tags to your data Create alerts Install for Kubernetes Here are examples of Kubernetes manifests for deployment and service objects: Kubernetes manifest examples Below are examples of Kubernetes manifests to deploy StatsD in a Kubernetes environment and create a StatsD service named newrelic-statsd. You need to insert your account ID and your license key. deployment.yml: apiVersion: apps/v1 kind: Deployment metadata: name: newrelic-statsd namespace: tooling labels: app: newrelic-statsd spec: selector: matchLabels: app: newrelic-statsd replicas: 2 revisionHistoryLimit: 2 template: metadata: labels: app: newrelic-statsd spec: containers: - name: newrelic-statsd image: newrelic/nri-statsd:2.0.0 env: - name: NR_ACCOUNT_ID value: \"NEW_RELIC_ACCOUNT_ID\" - name: NR_API_KEY value: \"NEW_RELIC_LICENSE_KEY\" Copy service.yml: apiVersion: v1 kind: Service metadata: name: newrelic-statsd namespace: tooling labels: app: newrelic-statsd spec: type: ClusterIP ports: - name: newrelic-statsd port: 80 targetPort: 8125 protocol: UDP selector: app: newrelic-statsd Copy For configuration details, see Kubernetes configuration. Configure In the install procedure, you run nri-statsd with environment variables, and this generates a TOML configuration file. Additionally, you can set these configuration options: Configuration options Description expiry-interval string If a metric is not updated for this amount of time, we stop reporting that metric. Default is 5m. If you want to send the metrics only if the value was updated between the flush intervals, configure this to 1ms. To never expire metrics, set it to 0. percent-threshold list of integers Specifies the percentiles used for metrics aggregation. Default: 90. metrics-addr string Indicates address on which to listen for metrics. Default: :8125. Tip To ensure FedRAMP compliance when using the StatsD integration you must define the following endpoints in the custom configuration: address = 'https://gov-insights-collector.newrelic.com/v1/accounts/ $NR_ACCOUNT_ID/events' Copy address-metrics = 'https://gov-infra-api.newrelic.com/metric/v1' Copy Here are some examples of customizing configuration by overwriting the default configuration: Example of custom configuration # Specify after how long do we expire metrics, default:5m expiry-interval = '1ms' # percent-threshold specify a list of percentiles for metrics aggregation, default:90 percent-threshold = [90, 99] backends='newrelic' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address = 'https://insights-collector.newrelic.com/v1/accounts/$NR_ACCOUNT_ID/events' address-metrics = 'https://metric-api.newrelic.com/metric/v1' api-key = 'NEW_RELIC_LICENSE_KEY' Copy Disable timer sub-metrics: By default, nri_statsd calculates the following for timer metrics: standard deviation, mean, median, sum, lower, and upper bounds for the flush interval. If you want to disable those metrics you can do it by adding a disabled-sub-metrics configuration section and set true for the ones you want disabled. Here's an example: # disabled-sub-metrics configuration section allows disabling timer sub-metrics [disabled-sub-metrics] # Regular metrics count=false count-per-second=false mean=false median=false lower=false upper=false stddev=false sum=false sum-squares=false # Percentile metrics count-pct=false mean-pct=false sum-pct=false sum-squares-pct=false lower-pct=false upper-pct=false Copy Docker: overwrite default configuration To overwrite the default nri-statsd configuration while running in a container, you can mount a configuration file inside the container. You can adopt the following template as needed for your situation. Example: backends='newrelic' flush-interval='10s' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address-metrics = 'https://metric-api.newrelic.com/metric/v1' api-key = 'NEW_RELIC_LICENSE_KEY' Copy To run the container with the file mounted in the appropriate path: docker run \\ ... -v ${PWD}/nri-statsd.toml:/etc/opt/newrelic/nri-statsd.toml \\ ... newrelic/nri-statsd:2.0.0 Copy Kubernetes: overwrite default configuration The best approach to configure nri-statsd running in Kubernetes is to use a configMap and mount the configMap into the container. (This is a similar process to mounting the configuration file in Docker.) Example: apiVersion: v1 kind: ConfigMap metadata: name: nri-statsd-config namespace: default data: nri-statsd.toml: | backends='newrelic' flush-interval='10s' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address = 'https://metric-api.newrelic.com/metric/v1' api-key = '$NEW_RELIC_LICENSE_KEY' Copy To use the configMap, declare a volume on your deployment spec template and then declare a volumeMount on your container spec. Example: apiVersion: apps/v1 kind: Deployment spec: template: spec: containers: .... volumeMounts: - mountPath: /etc/opt/newrelic/ name: nri-statsd-config volumes: - name: nri-statsd-config configMap: name: nri-statsd-config Copy Metric format The integration receives metrics using the StatsD protocol. Optionally, the sample rate can be configured and tags can be added. Here's the metric data format we use: <metric name>:<value>|<type>|@<sample rate>|#<tags> Copy Here are explanations of these fields: Field name Description < metric name> string Required. Name of the metric. < value> string Required. The metric type: c = counter g = gauge ms = timer @ < sample rate> float Optional for simple counters or timer counters. When many metrics must be sent, you can use sampling to reduce network traffic. The downside is a reduction in the resolution of the data. An example of how this would work for sample rates below 1: If you set this to 0.1, the counter would send a measurement one out of every 10 times. # < tags> string Optional. Tags attached to your metrics are converted into attributes (key-value pairs). For more on tagging options, see Tags. Metric types Here are the types of metrics and how to format them: Counter A counter measures the number of occurrences of an event. Examples include cache hits per reporting interval and the number of threads created per reporting interval. A counter can be incremented or decremented during the same flush interval by adding a sign to the value. In the following example, the counter value will be 2: counter:4|c counter:-2|c Copy At each flush, the current count is sent and reset to 0. If the count is not updated, at the next flush it will send the value 0. You can opt to disable this behavior by setting expiry-interval to 1ms. Heres an example of a counter that is being sampled 1 out of 10 times: counter:4|c@0.1 Copy Gauge A gauge represents a value that can increase or decrease with time. Examples of gauges include temperature, CPU usage, and memory. Here's an example: temperature:40|g Copy If the gauge is not updated, at the next flush it will send the previous value. You can opt to disable this behavior by setting expiry-interval to 1ms. Timer The timer metric type measures timing data. By default, nri_statsd calculates the following for timer metrics: standard deviation, mean, median, sum, lower, and upper bounds for the flush interval. These are sent as sub-metrics in the following format: <metric_base_name>.std_dev <metric_base_name>.median <metric_base_name>.summary <metric_base_name>.sum_squares <metric_base_name>.mean <metric_base_name>.per_second Copy The configured percentiles will generate the following metrics. The percentile threshold value will be attached as a tag. <metric_base_name>.sum_squares.percentiles <metric_base_name>.sum.percentiles <metric_base_name>.count.percentiles <metric_base_name>.upper.percentiles <metric_base_name>.mean.percentiles Copy The percentile threshold can be tweaked with the percent-threshold config option. These can be controlled through the disabled-sub-metrics configuration section. Add tags (attributes) You can add tags to your data, which we save as attributes (key-value pairs). There are two options for adding tags: Add default tags that apply to all metrics: These apply to all metrics. They are fixed and don't change over time. Add metric-level tags: These apply to specific metrics and allow the value to be changed between two submits. Add default tags that apply to all metrics Add tags to metrics and events by defining an environment variable in the startup command. Here's an example that would create two tags: -e TAGS=\"environment:production region:us\" Copy Here's that environment variable used in the startup command: docker run \\ -d --restart unless-stopped \\ --name newrelic-statsd \\ -h $(hostname) \\ -e NR_ACCOUNT_ID=YOUR_ACCOUNT_ID \\ -e NR_API_KEY=NEW_RELIC_LICENSE_KEY \\ -e TAGS=\"environment:production region:us\" \\ -p 8125:8125/udp \\ newrelic/nri-statsd:2.0.0 Copy Add metric-level tags When defining the metric format, you can add tags using this format: <bucket name>:<value>|<type>|#<tags> Copy In this example, <tags> is a comma-separated list of tags. Tags format is: simple or key:value. Here's an example NRQL query that includes a custom tag: SELECT count(*) FROM Metric WHERE environment = 'production' Copy Create alerts You can alert on StatsD data using NRQL alert conditions. Alert example This procedure walks you through sending some sample data and then creating an alert condition using that data. First, send this data to New Relics StatsD container: echo \"prod.test.num:32|g\" | nc -v -w 1 -u localhost 8125 Copy Next, create a NRQL alert condition using this query: SELECT latest(prod.test.num) FROM Metric WHERE metricName = 'prod.test.num' Copy Here's an image showing creating this NRQL alert condition. Notice that the sample data sent in is represented by the blue dot on the upper right of the chart. Now we can create the alert condition with these settings: When you create the NRQL alert condition, be sure to set the Condition name. If a metric with a value above 50 is sent, then an incident is created and notified. The incident is closed automatically after 24 hours. To test that the alert is working, run this command: echo \"prod.test.num:60|g\" | nc -v -w 1 -u localhost 8125 Copy Find and use data To query your data, you'd use any New Relic query option. For example, you might run a NRQL query like: SELECT count(*) FROM Metric WHERE metricName = 'myMetric' and environment = 'production' Copy For more on how to query the Metric data type, see Query metric data. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 404.2807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Metric</em> <em>types</em>",
        "body": " <em>query</em> option. For example, you might run a NRQL <em>query</em> like: SELECT count(*) FROM <em>Metric</em> WHERE <em>metric</em>Name = &#x27;my<em>Metric</em>&#x27; and environment = &#x27;production&#x27; Copy For more on how to <em>query</em> the <em>Metric</em> <em>data</em> <em>type</em>, see <em>Query</em> <em>metric</em> <em>data</em>. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it."
      },
      "id": "6174af22e7b9d253c613b73d"
    },
    {
      "sections": [
        "Transition to New Relic One from Insights",
        "Important",
        "Features",
        "Improved query abilities",
        "Improved visualizations",
        "Steps for a successful transition"
      ],
      "title": "Transition to New Relic One from Insights",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "4af99cd8030909a71d21a359a60af5ac93b93a66",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/transition-new-relic-one-insights/",
      "published_at": "2021-12-20T09:44:31Z",
      "updated_at": "2021-07-21T20:51:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we're upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. Released in 2014, New Relic Insights was our original way to create custom queries, charts, and dashboards. With New Relic One, we have modernized the experience for you to access, analyze, and visualize your data. New Relic One offers an improved charts and dashboards experience, and it provides a platform where we can more rapidly bring new innovations to you. This transition guide can help you understand: What are some of the new and improved features you get with New Relic One charts, dashboards, and queries Why it's easy to transition to New Relic One What to know and considerations when you make the switch How to get the most out of using New Relic One Features You can scroll down to the transition details, but first here are some features we've added that show how New Relic One dashboards are a clear improvement over Insights dashboards. Improved query abilities With New Relic One, you get: Ability to query many accounts from the same widget: New Relic One lets you query across all your associated accounts in one place. Better querying and charting experiences: Query access is available globally, no matter where you are in New Relic One. Learn how to browse and query data in New Relic. Improved query experience: You can query both the Metric data type and metric timeslice data. Easy customization: Every visualization now has the query accessible. You can augment any curated chart just by changing the NRQL query. Improved visualizations Not only can you select a wide range of visualization options, you can also add more to your dashboards: Better display options: Make your data easier to understand by using visualizations other than dense, line-heavy charts. New Relic One also offers a better TV mode. Facet linking: You can filter your dashboards by faceted attributes, making your dashboards more interactive and easy to use. There's also support for cases. Learn more. More charts or widgets in an area: Insights restricted you to a 3-across limit. Now you can display up to 12 across your dashboard, providing increased data density along with improved tooltips and tracking across charts. Easier creation of multi-page dashboards: Insights referred to these as data apps. Your Insights data apps are preserved as multi-page dashboards in New Relic One. Chart consistency and flexibility: Dashboards include facet color consistency across widgets and faster loading times for more performant dashboards. Also, you can add any chart type to a dashboard in New Relic One! The New Relic Insights UI has served our users well for many years, but it's time to give you an even better experience. Join us and make the switch to New Relic One! Steps for a successful transition The transition to New Relic One has two parts: the UI and mobile app experience (April 12, 2021) and the Dashboard API (July 2021). Insights functionality Transition to New Relic One UI We have already taken care of your transition from Insights to New Relic One for you! As of April 12, 2021, your old Insights URLs redirect automatically to New Relic One. We recommend that you familiarize yourself with the new UI features available to you, as described in this transition guide. If you need to view any Insights charts embedded in other websites, go to one.newrelic.com > More > Manage Data. (These older embedded charts will continue to function as expected.) Mobile apps The Insights mobile app is deprecated as of April 11, 2021. Go to the Google Play Store 2 or Apple App store. Delete your old Insights mobile app, and download the New Relic One mobile app. tvOS apps and large displays New Relic's tvOS app is still available. No action is needed by you at this time. Some New Relic customers with the original pricing model may have set up dashboards on wall screens for restricted users with kiosk mode. No action is required for you to continue to view these dashboards. APIs In July of 2021, the Insights Dashboard API will be deprecated and replaced with NerdGraph functionality. For more on this change, and tips on how to migrate, see NerdGraph API for dashboards. Partnership accounts This applies only if your account is one of the few using our partnership account structure to deliver New Relic services to your direct customers. In this situation, the Insights EOL will not affect your customers pricing. This is simply an EOL for the UI, not an EOL for the account type. Questions If you have questions about the transition, please comment in our Explorers Hub post. Or, if you work with an account team, they will be happy to help you.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 370.47372,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Improved <em>query</em> abilities",
        "body": " to browse and <em>query</em> <em>data</em> in New Relic. Improved <em>query</em> experience: You can <em>query</em> both the <em>Metric</em> <em>data</em> <em>type</em> and <em>metric</em> timeslice <em>data</em>. Easy customization: Every visualization now has the <em>query</em> accessible. You can augment any curated chart just by changing the NRQL <em>query</em>. Improved visualizations Not only"
      },
      "id": "6044171164441f454a378ee2"
    },
    {
      "sections": [
        "Analyze and monitor data trends with metrics",
        "Why create metrics from other data types?",
        "Available operations",
        "Mutations",
        "Create a rule",
        "Delete a rule",
        "Important",
        "Enable or disable a rule",
        "Queries",
        "List all rules for a New Relic account",
        "List rule by rule ID",
        "Use the NerdGraph GraphiQL API tool"
      ],
      "title": "Analyze and monitor data trends with metrics",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "06073bcfec2679ac1bc402dfe305426bbd9e2182",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/convert-to-metrics/analyze-monitor-data-trends-metrics/",
      "published_at": "2021-12-19T14:11:14Z",
      "updated_at": "2021-10-23T17:28:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can generate metric-type data from other types of data in New Relic, including events, logs, and spans. Metrics are aggregates of your data and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How to use our NerdGraph API tool to perform operations Why create metrics from other data types? Using metrics allows for more efficient data storage. This in turn allows you to query your data and build charts more easily. The difference between metrics and other types of data in New Relic is based on time. For more information, see Understand data types. Events, logs, spans: These types of data represent a single record at a specific moment in time. For example, you may have an event for every request to the system. This data is ideal for in-depth troubleshooting and analysis. Metrics: These provide an aggregated view of your events, logs, or spans. Metrics are better for showing trends over longer time ranges. For example, you can aggregate the total number of requests per service to one metric and then examine this information month over month. Why use metrics? Comments Flexibility Metrics are dimensional. You can choose what metadata (like host name or app name) is attached to them. Common metric measurements, like average, sum, minimum, and maximum, are already calculated. Data aggregation and retention The data has already been pre-aggregated into longer-period time buckets. Data retention is 13 months. Query capabilities You can query using the Metric data type. When you create metrics, this does not delete your events or other types of data. However, metrics are better for longer-range querying and charting. To get started converting your data to metrics, create a rule. Available operations To show, create, and delete rules for generating metrics from events, logs, or spans, use NerdGraph, our GraphQL-format API. Before performing any operation, we recommend reading Intro to NerdGraph and exploring your data with the GraphiQL API tool. These operations fall under two basic request types: Mutations, which are operations that make changes to existing rules or settings (for example, creating a new metrics rule). Queries, for fetching existing data (for example, fetching existing metrics rules). All operations are role-based in NerdGraph as the currently logged-in New Relic user. Mutations Mutation operations for events to metrics, logs to metrics, or spans to metrics include: Create a rule See Create metrics. Delete a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To delete a rule, you need the rule ID and the New Relic account ID. Example request: mutation { eventsToMetricsDeleteRule(deletes: {ruleId: \"12\", accountId: 123456}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsDeleteRule The method being called to delete a rule. deletes This takes two parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Example response for the request: { \"data\": { \"eventsToMetricsDeleteRule\": { \"failures\": [], \"successes\": [ { \"id\": \"12\", \"name\": \"Test Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } Copy Enable or disable a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To enable or disable an existing rule for events to metrics, logs to metrics, or spans to metrics, use the same eventsToMetricsUpdateRule operation. The only difference is whether enabled is set to true or false. Example request to enable an existing metrics rule: mutation { eventsToMetricsUpdateRule(updates: {ruleId: \"12\", accountId: 123456, enabled: true}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsUpdateRule The method being called to update an existing rule and either enable it or disable it. updates This takes three required parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. enabled: To enable a disabled rule, set this to true. To disable a rule, set this to false. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Queries Query operations include: List all rules for a New Relic account You can list all rules in a New Relic account or return a specific rule. Example listing all rules for account 123456: query { actor { account(id:123456) { eventsToMetrics{ allRules{ rules{ id name enabled nrql description } } } } } } Copy In this request: Element Description query One of the basic API operation types. Used to query but not make changes. actor This specifies the current New Relic user. account(id: 123456) Specify the ID for the New Relic account where to retrieve data. eventsToMetrics Scope the data only for events-to-metrics, logs-to-metrics, or spans-to-metrics rules. allRules Returns all rules for that account. rules In the rules block, you can define what data you want returned. Available fields include: id name description nrql accountId enabled Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"allRules\": { \"rules\": [ { \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"1\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" }, { \"description\": \"Metric for duration\", \"enabled\": true, \"id\": \"2\", \"name\": \"Duration Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy List rule by rule ID If you know the exact ID for a rule, then you can query for a specific rule. For example, you may have just created a rule and now you want to list its contents so you can review it. Example listing rule 36 for New Relic account 123456: query { actor { account(id: 123456) { eventsToMetrics { rulesById(ruleIds: \"36\") { rules { id name enabled nrql description accountId } } } } } } Copy For more details about the elements in this query, see List all rules. Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"rulesById\": { \"rules\": [ { \"accountId\": 123456, \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"36\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy Use the NerdGraph GraphiQL API tool You can use our GraphiQL tool to explore the data structure. You can also use it to build and run the operations to convert events, logs, and spans to metrics. To use this tool: Create the metrics operation's request with the required parameters. Go to api.newrelic.com/graphiql, and paste your query into the box. To execute the operation, press Play. Or, to get the cURL format, select Copy as cURL.) Validate the response in the response box. Optional: To verify that your rule-creation operation was performed successfully, run a list query for that rule ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 331.89642,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Analyze and monitor <em>data</em> trends with <em>metrics</em>",
        "sections": "Why create <em>metrics</em> from other <em>data</em> <em>types</em>?",
        "tags": "Convert <em>data</em> to <em>metrics</em>",
        "body": " retention is 13 months. <em>Query</em> capabilities You can <em>query</em> using the <em>Metric</em> <em>data</em> <em>type</em>. When you create metrics, this does not delete your events or other types of <em>data</em>. However, metrics are better for longer-range querying and charting. To get started converting your <em>data</em> to metrics, create a rule"
      },
      "id": "603eb239e7b9d2b99d2a07bb"
    }
  ],
  "/docs/data-apis/understand-data/new-relic-data-types": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.10336,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of API client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Metric data structure",
        "Metric types"
      ],
      "title": "Metric data structure",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "179e9cbddd7ef1025e4803d79842140acd3a674b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/metric-data/metric-data-type/",
      "published_at": "2021-12-20T10:05:52Z",
      "updated_at": "2021-10-23T17:24:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform reports four main telemetry data types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric data, aka the Metric data type. To learn about how to query this type of data, see Query metrics. Metric types The metric type determines how the data is aggregated over longer time windows. It also determines which functions you can use to query the data. Metric types Description Available query functions count Measures the number of occurrences of an event. The count should be reset to 0 every time the metric is reported. Examples include cache hits per reporting interval and the number of threads created per reporting interval. You must specify a value for interval.ms when reporting the count metric type using the Metric API. The value must be a positive double. Generally, you want to take the rate of the sum: From Metric select rate(sum(myMetric), 1 minute) . . . sum distribution Tracks the statistical distribution on a numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type: Supports statistical functions like percentile and histogram, and all functions supported by the summary type. Uses the same algorithm as the percentile function. percentile histogram min max sum count average gauge Represents a value that can increase or decrease with time. Examples of gauges include the temperature, CPU usage, and memory. For example, there is always a temperature, but you are periodically taking the temperature and reporting it. The value must fit into the range of a Java double. latest min max sum count average summary Used to report pre-aggregated data, or information on aggregated discrete events. A summary includes a count, sum value, min value, and max value. The count value must be positive. Examples include transaction count/durations and queue count/ durations. You must specify a value for interval.ms when reporting the summary metric type using the Metric API. min max sum count average uniqueCount Tracks the number of unique values on a string or numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type is generated only via the event-to-metrics service. uniqueCount",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.77185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>data</em> structure",
        "sections": "Metric <em>data</em> structure",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "The New Relic platform reports four main telemetry <em>data</em> types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric <em>data</em>, aka the Metric <em>data</em> type. To learn about how to query this type of <em>data</em>, see Query metrics. Metric types The metric type determines"
      },
      "id": "609f9cbfe7b9d205f0c3eb54"
    },
    {
      "sections": [
        "Introduction to querying data in New Relic",
        "Important",
        "Our open door to your data",
        "Browse your data in the UI",
        "Query data in the UI",
        "Tip",
        "Query data via API"
      ],
      "title": "Introduction to querying data in New Relic",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "f3f9efbd4d9565c83ad8224f1f1524f9a5957650",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/get-started/introduction-querying-new-relic-data/",
      "published_at": "2021-12-19T20:24:14Z",
      "updated_at": "2021-07-27T22:23:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic One is a powerful observability platform that gives you access to all your data throughout your entire system. We host telemetry data sent by your entities, which basically is anything we can identify that has data you can monitor, including applications, services, hosts, etc. You name it! While we provide you with an out of the box experience to see your data with curated dashboards, you can tailor the access to your data and custom the visibility in several ways, including in the UI or via API. Important To better understand your data stored in New Relic, see Data types. Our open door to your data Regardless of your experience with New Relic, well help you discover, understand and visualize your data. You... Then do this... Just installed an agent and want to see your data in New Relic. Browse your data easily without building queries. With the data explorer, you can understand the data weve stored, see its cardinality, or build charts in a few clicks. Know what data is available, but you want to understand more about what else is coming with that data. If youre an advanced user, use our query builder to tailor the data you want to retrieve. Have a specific question and you want to deep dive on the data to get the answer. Refine your NRQL query to dig down to the bottom of your issues. Want to build a dashboard. Create a custom dashboard easily from the data explorer or the query builder. Browse your data in the UI New Relic One offers several experiences that don't require knowledge of NRQL or any query language. On the UI, go to the Query your data button, or click the Browse data dropdown, then select the data type (metrics, events, logs, and traces) you want to explore. For events and metrics, use the data explorer, an intuitive data navigator to create visualizations. From the explorer you can switch to the query builder to see and refine your query. Distributed tracing query: a specialized UI for querying traces. Logs query: a specialized UI for querying New Relic Logs data. Query data in the UI If you're ready to do more than browsing data, become an all-hands actor and personalize your queries in the New Relic UI. Use query languages, including our New Relic query language or our PromQL-style query language, to edit queries with full flexibility. For example, you can add more WHERE clauses, modify the returned value, change to other types of visualizations, etc. Tip Are you new to querying languages? Start browsing data in the data explorer, then turn to the query builder to see the query you built, and refine it. There are two ways to write your own queries to retrieve data and build charts: Query builder in NRQL mode: Query using New Relic query language (NRQL), the same language we use to build most of our UI experiences, and the most advanced way of querying data in New Relic. Query builder in PromQL-style mode: Write basic queries using a PromQL-style query. Query data via API When getting into the New Relic platform is not an option, you can use APIs to retrieve and query your data in New Relic. For example, you can run NRQL (our query language) queries with NerdGraph (our GraphQL API). For more information, see the introduction to New Relic APIs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.38766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to querying <em>data</em> in New Relic",
        "sections": "Introduction to querying <em>data</em> in New Relic",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " it! While we provide you with an out of the box experience to see your <em>data</em> with curated dashboards, you can tailor the access to your <em>data</em> and custom the visibility in several ways, including in the UI or via API. Important To better <em>understand</em> your <em>data</em> stored in New Relic, see <em>Data</em> types. Our open"
      },
      "id": "609f9e1de7b9d2c96ac3eb08"
    }
  ],
  "/docs/distributed-tracing/concepts/distributed-tracing-planning-guide": [
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-19T15:31:59Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observerall other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the traces shape. A traces shape is the unique combination of the root spans entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If its 100%, the trace is automatically kept. If its anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent thats part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.55487,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Here are some technical details about how New Relic <em>distributed</em> <em>tracing</em> works: How <em>trace</em> sampling works How we structure <em>trace</em> data How we store <em>trace</em> data How <em>trace</em> context is passed between applications Tip For instructions about setting up <em>distributed</em> <em>tracing</em>, see Overview: Enable <em>distributed</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-19T15:33:43Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.0982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " enabled, traces will have configuration conflict issues. Instructions for setting up Infinite <em>Tracing</em> are in the specific docs for our solutions. To <em>get</em> <em>started</em>, see our quick <em>start</em> guide. Configure Infinite <em>Tracing</em> After enabling Infinite <em>Tracing</em>, there are various ways you can configure it to ensure it&#x27;s keeping the data you want. See Configure."
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "https://docs.newrelic.com/static/2878076657e1173d9f8c92a6e7547a9f/83b75/intro-DT.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-12-19T15:31:39Z",
      "updated_at": "2021-11-13T19:56:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, its nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. You can also bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. No need to switch to another UI page in New Relic One. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.27173,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>distributed</em> <em>trace</em> data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick <em>start</em>. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    }
  ],
  "/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works": [
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-19T15:33:43Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.0982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " enabled, traces will have configuration conflict issues. Instructions for setting up Infinite <em>Tracing</em> are in the specific docs for our solutions. To <em>get</em> <em>started</em>, see our quick <em>start</em> guide. Configure Infinite <em>Tracing</em> After enabling Infinite <em>Tracing</em>, there are various ways you can configure it to ensure it&#x27;s keeping the data you want. See Configure."
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "https://docs.newrelic.com/static/2878076657e1173d9f8c92a6e7547a9f/83b75/intro-DT.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-12-19T15:31:39Z",
      "updated_at": "2021-11-13T19:56:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, its nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. You can also bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. No need to switch to another UI page in New Relic One. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.27173,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>distributed</em> <em>trace</em> data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick <em>start</em>. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-19T15:33:44Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, youll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.8374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> API, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/concepts/introduction-distributed-tracing": [
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-19T15:31:59Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observerall other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the traces shape. A traces shape is the unique combination of the root spans entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If its 100%, the trace is automatically kept. If its anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent thats part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.55487,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Here are some technical details about how New Relic <em>distributed</em> <em>tracing</em> works: How <em>trace</em> sampling works How we structure <em>trace</em> data How we store <em>trace</em> data How <em>trace</em> context is passed between applications Tip For instructions about setting up <em>distributed</em> <em>tracing</em>, see Overview: Enable <em>distributed</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-19T15:33:43Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.0982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " enabled, traces will have configuration conflict issues. Instructions for setting up Infinite <em>Tracing</em> are in the specific docs for our solutions. To <em>get</em> <em>started</em>, see our quick <em>start</em> guide. Configure Infinite <em>Tracing</em> After enabling Infinite <em>Tracing</em>, there are various ways you can configure it to ensure it&#x27;s keeping the data you want. See Configure."
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-19T15:33:44Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, youll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.8374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> API, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing": [
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-19T15:32:16Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.77536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Examine logs for trace details",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-12-19T15:44:57Z",
      "updated_at": "2021-11-13T20:42:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. Examine logs for trace details You can bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. From the Transactions page, click on a trace to go to the Trace details page. From the trace details page, click See logs. To view details related to an individual log message, click directly on the message. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever or -1. For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.30768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "sections": "<em>Configure</em> standard <em>distributed</em> <em>tracing</em> for your older agents",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up Infinite <em>Tracing</em> (advanced option) Standard <em>distributed</em> <em>tracing</em> for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-19T15:33:43Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.93141,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "<em>Enable</em> Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see <em>Enable</em> <em>distributed</em> <em>tracing</em>. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can <em>configure</em> Infinite <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing": [
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-19T15:31:19Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.7772,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to <em>enable</em> Infinite <em>Tracing</em>. Choosing Infinite <em>Tracing</em> has implications for how you <em>configure</em> sampling in your telemetry tool: Standard installation without Infinite <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-19T15:32:16Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.77536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-19T15:33:43Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.93141,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "<em>Enable</em> Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see <em>Enable</em> <em>distributed</em> <em>tracing</em>. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can <em>configure</em> Infinite <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing": [
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-19T15:31:19Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.77716,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to <em>enable</em> Infinite <em>Tracing</em>. Choosing Infinite <em>Tracing</em> has implications for how you <em>configure</em> sampling in your telemetry tool: Standard installation without Infinite <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Examine logs for trace details",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-12-19T15:44:57Z",
      "updated_at": "2021-11-13T20:42:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. Examine logs for trace details You can bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. From the Transactions page, click on a trace to go to the Trace details page. From the trace details page, click See logs. To view details related to an individual log message, click directly on the message. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever or -1. For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.30766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "sections": "<em>Configure</em> standard <em>distributed</em> <em>tracing</em> for your older agents",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up Infinite <em>Tracing</em> (advanced option) Standard <em>distributed</em> <em>tracing</em> for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-19T15:33:43Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.93127,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "<em>Enable</em> Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see <em>Enable</em> <em>distributed</em> <em>tracing</em>. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can <em>configure</em> Infinite <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/enable-configure/quick-start": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Examine logs for trace details",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-12-19T15:44:57Z",
      "updated_at": "2021-11-13T20:42:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. Examine logs for trace details You can bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. From the Transactions page, click on a trace to go to the Trace details page. From the trace details page, click See logs. To view details related to an individual log message, click directly on the message. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever or -1. For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 653.8745,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "<em>Quick</em> <em>start</em> for standard <em>distributed</em> <em>tracing</em> (recommended):",
        "tags": "<em>Distributed</em> <em>tracing</em>",
        "body": " <em>distributed</em> <em>tracing</em> in the <em>quick</em> <em>start</em> above The Infinite <em>Tracing</em> setup builds on the instrumentation step from the <em>Quick</em> <em>start</em> for standard <em>distributed</em> <em>tracing</em>. Step 2. Set up the <em>trace</em> observer The <em>trace</em> observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-19T15:33:43Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.25302,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Distributed</em> <em>tracing</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-19T15:31:59Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observerall other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the traces shape. A traces shape is the unique combination of the root spans entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If its 100%, the trace is automatically kept. If its anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent thats part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.54608,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Distributed</em> <em>tracing</em>",
        "body": "Here are some technical details about how New Relic <em>distributed</em> <em>tracing</em> works: How <em>trace</em> sampling works How we structure <em>trace</em> data How we store <em>trace</em> data How <em>trace</em> context is passed between applications Tip For instructions about setting up <em>distributed</em> <em>tracing</em>, see Overview: Enable <em>distributed</em>"
      },
      "id": "6072a66664441f14089d856c"
    }
  ],
  "/docs/distributed-tracing/index": [
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-19T15:33:43Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 932.95776,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Distributed</em> <em>tracing</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "https://docs.newrelic.com/static/2878076657e1173d9f8c92a6e7547a9f/83b75/intro-DT.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-12-19T15:31:39Z",
      "updated_at": "2021-11-13T19:56:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, its nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. You can also bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. No need to switch to another UI page in New Relic One. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Distributed</em> <em>tracing</em>",
        "body": " <em>distributed</em> <em>trace</em> data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "image": "https://docs.newrelic.com/static/f487e8c287d614c494f56bd35fd38bb5/c1b63/arrow-step-diagram-trans.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/quick-start/",
      "sections": [
        "Distributed tracing quick start"
      ],
      "published_at": "2021-12-19T15:32:43Z",
      "title": "Distributed tracing quick start",
      "updated_at": "2021-11-06T02:12:11Z",
      "type": "docs",
      "external_id": "f9f4aa287602eee82a0eb7d15775d033ada26d63",
      "document_type": "page",
      "popularity": 1,
      "body": "To set up distributed tracing, you'll complete these three general steps: Identify services: Identify and write down the endpoints, services, languages, and systems that are used to complete this request (you'll need this information in the next step). If you have an environment diagram like the following, you could use it to create a list of services handling requests: Instrument services: Instrument each service you identify so it can send your trace data. Some tools, such as APM agents, instrument services automatically, while other tools require you to insert some code in the services. Click the icon below for instrumentation steps: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Browser monitoring Mobile monitoring AWS Lambda Functions Kamon OpenTelemetry X-Ray Zipkin format: custom integration New Relic format: custom integration View traces: After you instrument the services, generate some traffic in your application, and then go to the New Relic UI to see your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em> quick start",
        "sections": "<em>Distributed</em> <em>tracing</em> quick start",
        "body": "To set up <em>distributed</em> <em>tracing</em>, you&#x27;ll complete these three general steps: Identify services: Identify and write down the endpoints, services, languages, and systems that are used to complete this request (you&#x27;ll need this information in the next step). If you have an environment diagram like"
      },
      "id": "6072a60564441f2f6f9d8541"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-proxy-support": [
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-19T15:33:43Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 411.95822,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-19T15:31:59Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observerall other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the traces shape. A traces shape is the unique combination of the root spans entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If its 100%, the trace is automatically kept. If its anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent thats part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 360.71915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em>. <em>Trace</em> sampling How your traces are sampled will <em>depend</em> on your setup and the New Relic <em>tracing</em> tool you&#x27;re using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you&#x27;re using <em>Infinite</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-19T15:31:19Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.1719,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to enable <em>Infinite</em> <em>Tracing</em>. Choosing <em>Infinite</em> <em>Tracing</em> has implications for how you configure sampling in your telemetry tool: Standard installation without <em>Infinite</em> <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-random-trace-filter": [
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-19T15:33:43Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 411.958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-19T15:31:59Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observerall other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the traces shape. A traces shape is the unique combination of the root spans entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If its 100%, the trace is automatically kept. If its anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent thats part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 360.71893,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em>. <em>Trace</em> sampling How your traces are sampled will <em>depend</em> on your setup and the New Relic <em>tracing</em> tool you&#x27;re using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you&#x27;re using <em>Infinite</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-19T15:31:19Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.17188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to enable <em>Infinite</em> <em>Tracing</em>. Choosing <em>Infinite</em> <em>Tracing</em> has implications for how you configure sampling in your telemetry tool: Standard installation without <em>Infinite</em> <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    }
  ]
}