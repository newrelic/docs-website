{
  "/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/prioritize-migration-order": [
    {
      "sections": [
        "Optimize your cloud spend",
        "1. Deploy the New Relic Infrastructure agent",
        "2. Create dashboard charts for cloud performance",
        "Break out data by cloud performance and application metrics",
        "3. Configure the Amazon AWS integration",
        "4. Set up billing budgets in AWS",
        "5. Add cloud spend and budget widgets to Insights dashboard",
        "Break out data by application and by AWS budget",
        "6. Create dashboards for every level of your organization",
        "Dashboards for developers",
        "Dashboards for DevOps",
        "Dashboards for executives",
        "7. Set up alerts",
        "Configure a baseline query using the forecasted amount"
      ],
      "title": "Optimize your cloud spend",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "7a0ac1127aee1ef0668e8aad47af8813f0ed7259",
      "image": "https://docs.newrelic.com/static/2f167e48441b82a62aae1463592e0aed/8c557/CloudPerformanceForAppX.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/optimize-your-cloud-spend/",
      "published_at": "2021-05-05T18:44:57Z",
      "updated_at": "2021-03-13T07:30:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Now that you are using cloud-hosted infrastructure and services, it is important to start looking very early and very closely at your cloud spend: Make sure that your assumptions about your cloud spend are playing out as expected. Quickly catch and correct any unexpected spikes in spending. Start fine-tuning the usage of your cloud-based resources. For example, if you have a set of 20 instances all running at 10% CPU, you can think about using smaller instances or consolidating more work onto those instances. This kind of thinking about your cloud spend helps you optimize and save money quickly. New Relic can help you monitor all this. From a data perspective, it is really just another metric that our platform can collect for you. As with any other metric, you can visualize, report, and alert on your cloud spend data, just like you can with any data New Relic can help you collect. Using the New Relic applied intelligence platform is a great way to help you learn about your cloud spending or about any of your performance data. 1. Deploy the New Relic Infrastructure agent Review the requirements for the New Relic Infrastructure agent and follow the documentation for instructions on installing the agent. After you install the Infrastructure agent on your hosts, you immediately have access to the broad spectrum of metrics that the agent receives automatically. Then, you can set up the cloud integration to start collecting billing information. 2. Create dashboard charts for cloud performance New Relic Dashboards is the product that you use to write powerful custom queries about your data, and then visualize the results in charts that you collect on a dashboard. You can also feed the results of your dashboard queries directly into New Relic Alerts, where you can get notifications on any deviations that you specify. Include charts for various Infrastructure metrics related to performance and usage; for example: CPU Memory Disk Database You may also want to include charts that represent the application using this cloud infrastructure. In this way you can correlate the cloud infrastructure performance with that of the application. As you right-size your cloud infrastructure, you will want to monitor application performance to make sure you are achieving any targets. Here is an example of an Insights dashboard for cloud performance. Break out data by cloud performance and application metrics The following dashboard shows several charts that present key cloud infrastructure metrics and an associated application metric. Every one of these charts represents the result of a query. [ Downs: Updated image based on New Relic One can be found at: https://www.dropbox.com/s/rjq7tqrswxwtte9/Tutorial-Run-OptimizeCloudSpen... Image caption: one.newrelic.com > Dashboards: Create dashboards that include both cloud infrastructure and application metrics.] insights.newrelic.com: Create dashboards that include both cloud infrastructure and application metrics. 3. Configure the Amazon AWS integration New Relic Infrastructure comes with several types of integrations, including Amazon Web Services (AWS), Microsoft Azure, and on-host integrations. This tutorial focuses on the AWS Billing integration. First, configure the integration with your AWS account, and then you can set up the AWS Billing integration. 4. Set up billing budgets in AWS The Amazon AWS Billing integration requires some additional configuration on the AWS side. Specifically, you need to go into your AWS Billing dashboard and set up Budgets. Our documentation and the blog post Show Me (Where I’m Spending) the Money! AWS Billing Comes to New Relic Insights provide walk-throughs of this process. When creating Budgets, be sure to: Fill in an application name. Decide whether you are doing cost or service-based budgeting. Decide if your budget is open-ended or has a definite ending date. 5. Add cloud spend and budget widgets to Insights dashboard New Relic Insights is the product that you use to write powerful custom queries about your data, and then visualize the results in widgets that you collect on a dashboard. You can also feed the results of your Insights queries directly into New Relic Alerts, where you can get notifications on any deviations that you specify. Here are some examples of ways to use Insights dashboards to visualize your AWS cloud spend data. Break out data by application and by AWS budget The following dashboard shows several widgets that present key information about an AWS budget vs. actual spending, with data broken out by an application AWS budget. Every one of these widgets represents the result of an Insights query, and the data in the supporting Insights tables is the data that our integration automatically receives from AWS. [ Downs: Updated image based on New Relic One can be found at: https://www.dropbox.com/s/ecp5mrnkezh6hjh/Tutorial-Run-OptimizeCloudSpen... Image caption: one.newrelic.com > Dashboards: Add charts that include AWS cloud and budgets data.] [ Downs: put this 'code' section below the image please. Here is the query to create the Application X Cloud Cost budget chart in this dashboard example: SELECT latest(`provider.actualAmount`) as '$ Actual', latest(`provider.forecastedAmount`) as '$ Forecast', max(`provider.limitAmount`) as '$ Limit' FROM FinanceSample WHERE provider = 'BillingBudget' AND `provider.budgetName` = 'NAME_OF_YOUR_CLOUD_BUDGET' Copy ] insights.newrelic.com: Create dashboards that include AWS cloud and budgets. 6. Create dashboards for every level of your organization Whether you are a developer, in DevOps, or an executive, having information about your cloud spend can help you optimize your cloud environment. Here are a few ways dashboards can help at each level of your organization: Dashboards for developers Understanding how much applications cost to run helps developers properly configure applications to use more efficient services. For example, could developers save cloud costs using Amazon AWS Lambda or properly sized instances instead of randomly selecting an instance? Dashboards for DevOps Monitoring application costs allows operators to catch possible overruns due to misconfigured services. For example, is the DevOps team’s auto-scaling configuration not scaling down properly? Are they spending money on instances that are not being used? Dashboards for executives An overall view of both forecasted and actual cloud spends for individual applications on a per region basis, as well as total costs, helps executives make better business decisions. Use New Relic to keep control of your cloud spending costs, and get your teams alerted when you go over your budgets. 7. Set up alerts After you write queries on your data in Insights, you can easily use them to create alert conditions. New Relic gives you the ability to write baseline queries against your data. A baseline query is a query that you write without setting hard limits on the results and instead let New Relic Applied Intelligence “machine-learn” your performance data. New Relic alerts you when you go too far outside of your baseline numbers. Configure a baseline query using the forecasted amount Configuring a baseline query using a forecasted amount is a great starting point for monitoring any cloud budget, as you grow to understand what your cloud spend will be over time. New Relic notifies you if something spikes beyond your forecasted trend. That query looks like this: SELECT latest(`provider.forecastedAmount`) FROM FinanceSample WHERE provider = 'BillingBudget' and `provider.budgetName` = 'NAME_OF_YOUR_CLOUD_BUDGET' Copy When you create a baseline query and alert on it, you decide how restrictively Applied Intelligence should analyze your data using a simple slider and visualization based on your recent performance. The slider either increases or decreases the gray band around your budget threshold (the blue line): alerts.newrelic.com > Alert policies > (select a policy) > Alert conditions: Create alert conditions based on your NRQL queries and Insights data. This example would have resulted in zero violations based on recent data, and that is exactly what you are looking for. However, if that blue line spikes up out of the gray band, New Relic notifies you. For more detailed information about creating, managing, and using alerts, view these New Relic University tutorials: Intro to alerting Alert policies Alerting incident lifecycle Notification channels",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.98692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Optimize your <em>cloud</em> spend",
        "sections": "1. Deploy the <em>New</em> <em>Relic</em> Infrastructure agent",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " quickly. <em>New</em> <em>Relic</em> can help you monitor all this. From a data perspective, it is really just another metric that our platform can collect for you. As with any other metric, you can visualize, report, and alert on your <em>cloud</em> spend data, just like you can with any data <em>New</em> <em>Relic</em> can help you collect. Using"
      },
      "id": "60445c4928ccbcd0132c6094"
    },
    {
      "sections": [
        "Modern and cloud services",
        "1. Identify applications, cloud services, infrastructure, and technologies",
        "2. Deploy Infrastructure",
        "Tip",
        "3. Configure cloud integrations",
        "4. Track data on your dashboards",
        "AWS EC2 monitoring integration dashboard",
        "Azure VMs monitoring integration dashboard",
        "GCP Compute Engine monitoring integration dashboard",
        "Example modern and cloud services dashboard",
        "5. Add alerts for cloud-based metrics",
        "6. Set up additional monitoring",
        "7. CI/CD Pipeline integration"
      ],
      "title": "Modern and cloud services ",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "824d892c1faf24fb7eb5bf6e205571446261f699",
      "image": "https://docs.newrelic.com/static/425a652fcbd53bbbea3454793047bd01/8c557/ModernAndCloudServiceDashboardNew.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/cloud-adoption/modern-cloud-services/",
      "published_at": "2021-05-05T18:40:37Z",
      "updated_at": "2021-03-13T05:44:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you've just completed your cloud migration, have been using cloud based services for awhile, or have always been in the cloud, you may find yourself deploying or running technologies and services that are new and modern. These modern technologies could be container solutions such as Docker, Kubernetes, and Amazon AWS ECS or Fargate for example. Or they could be serverless services such as AWS Lambda, Microsoft Azure, or Google Cloud Platform Functions, cloud based databases, or any number of cloud services that abstract the service away from an operations-maintained infrastructure. In these situations you still want to monitor, query, and alert on the performance and usage metrics for both modern technologies and cloud-based services, allowing for faster deployments, the ability to adopt new services, better business decisions, and to expand horizons. This doc demonstrates how to use the New Relic Platform to monitor your modern technologies and cloud services. 1. Identify applications, cloud services, infrastructure, and technologies Determine the components you need to monitor by answering the following the questions: What cloud-based applications do I have? What are the underlying cloud-based services, technologies, and infrastructure supporting those applications? When you have a full understanding of your architecture, you reduce the possibility of missing dependencies during your migration. 2. Deploy Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts you identified so you can start to monitor your cloud services. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. 3. Configure cloud integrations Once your applications are migrated to the cloud and you start to integrate new cloud services, you can use New Relic to monitor and report data about your cloud services, offering you a comprehensive view of your entire architecture in one place. To get started configuring cloud service integrations, link your cloud service provider account with New Relic, depending on whether you use Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP). 4. Track data on your dashboards New Relic Infrastructure integrations auto-populate dashboards with metrics from cloud providers like AWS, Azure, and GCP so you can track the data that is critical to your cloud adoption success. Tip If you adopt a hybrid cloud of multiple cloud providers, New Relic can provide a holistic perspective that is agnostic to cloud providers. AWS EC2 monitoring integration dashboard In this default dashboard for the AWS EC2 monitoring integration, New Relic captures metrics for EC2 instances per region, instance state, and instance type. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. infrastructure.newrelic.com > Integrations > Amazon Web Services: View AWS EC2 data on the default dashboard for the AWS EC2 monitoring integration. Azure VMs monitoring integration dashboard The default Azure virtual machine integration dashboard shows data for VM sizes, VMs per region, and VMs per resource group. infrastructure.newrelic.com > Integrations > Microsoft Azure: View Azure virtual machine data on the default dashboard for the Azure VMs monitoring integration. GCP Compute Engine monitoring integration dashboard In this default dashboard for the Google Cloud Platform, New Relic captures metrics for instances per zone, instance status, firewall dropped packets, reserved cores, and disk throttled operations. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. infrastructure.newrelic.com > Integrations > Google Cloud Platform: View GCP Compute Engine data on the default dashboard for the GCP Compute Engine monitoring integration. Example modern and cloud services dashboard In this example dashboard, three different cloud vendors, modern technologies, cloud services, infrastructure instance locations, and DevOps widgets are combined for an overall view. one.newrelic.com > Dashboards: Here is an example of a dashboard with data about vendors, technologies, services, instances, and other important details. 5. Add alerts for cloud-based metrics When monitoring cloud-based services, it is essential to keep track of all the changes happening with the system by alerting on them. Integrations with New Relic Infrastructure allow you to create alerts on the metrics that are the most important to you. Here is an example of a baseline alert that will notify you based on the number of requests received on all ALB systems for the AWS Elastic Load Balancing (ALB) monitoring integration: alerts.newrelic.com > Alert policies > (selected policy) > Alert conditions: Create a NRQL baseline alert to monitor the number of requests received your ALB systems. 6. Set up additional monitoring In addition to monitoring cloud services, you can deploy New Relic APM, Browser, Mobile, and Synthetics to gain full-stack visibility into all of the components of your applications: Use New Relic APM to report application-tier performance metrics. Use New Relic Browser to report front-end web metrics. Use New Relic Mobile to report front-end mobile app metrics. Use New Relic Synthetics to monitor websites, critical business transactions, and API endpoints. 7. CI/CD Pipeline integration It's important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. New Relic APM's deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change log, etc.). APM displays a vertical line, or marker, on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip Recommendation: Make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate CI/CD deployments: Chef (see newrelic_deployment) Jenkins Ansible",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.95271,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Modern and <em>cloud</em> services ",
        "sections": "Modern and <em>cloud</em> services",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": ", and GCP so you can track the data that is critical to your <em>cloud</em> <em>adoption</em> success. Tip If you <em>adopt</em> a hybrid <em>cloud</em> of multiple <em>cloud</em> providers, <em>New</em> <em>Relic</em> can provide a holistic perspective that is agnostic to <em>cloud</em> providers. AWS EC2 monitoring integration dashboard In this default dashboard"
      },
      "id": "60440f13e7b9d20f275799ca"
    },
    {
      "sections": [
        "Identify application dependencies and inventory",
        "1. Identify applications and components",
        "2. Install New Relic agents",
        "New Relic APM",
        "New Relic Infrastructure",
        "Infrastructure on-host integrations",
        "3. Visualize application dependencies with APM",
        "4. Inventory underlining instances with Infrastructure",
        "5. Uncover unknown applications and components",
        "6. Resolve errors or other issues",
        "7. Create Dashboards",
        "Expert tip for reporting custom data",
        "For more help"
      ],
      "title": "Identify application dependencies and inventory",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "b1159866272377cc25c356317d171a3325ebe9f3",
      "image": "https://docs.newrelic.com/static/4e6e64bb47951c91d6f027331b05fb5f/c1b63/new-relic-one-application-issues.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/identify-application-dependencies-inventory/",
      "published_at": "2021-05-05T18:41:17Z",
      "updated_at": "2021-03-13T04:22:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you are planning a migration to the cloud, it is important to analyze your current on-premise architecture and identify the scope of your migration. When you have a full understanding of your applications, your hosts, and their architecture, you reduce the possibility of missing dependencies during your migration. 1. Identify applications and components First, you need to determine the level of instrumentation that is possible or allowed within your organization. The deeper you instrument, the more visibility you gain into your applications. Then, address the scope of your cloud migration by answering the following questions and keeping track of your answers: What applications do I need to include in the migration? What are the dependencies of each application? What are the underlying services/inventory supporting these applications? 2. Install New Relic agents Based on your answers when you determined the scope of your cloud migration, verify that the applications that you want to migrate are compatible with New Relic products and install the agents: New Relic APM New Relic APM delivers data about your application's performance, providing information about app availability and external services so you can visualize your application dependencies. Confirm that your system meets the requirements for the APM agents that you want to install, and then install the APM agent on your application stack. Steps for installing APM agents vary based on language. New Relic Infrastructure New Relic Infrastructure provides flexible, dynamic server monitoring so you can inventory your hosts and their configuration settings. Confirm that your underlying infrastructure meets the requirements for New Relic Infrastructure. Install the Infrastructure agent on instances that host your applications. Infrastructure on-host integrations Infrastructure on-host integrations monitor the services that your code depends on. Install the on-host integrations for the services that you are using. 3. Visualize application dependencies with APM After you install the APM agent, use service maps to get a full view of your application’s architecture. Service maps allow you to identify any connections from applications to external services, web services, databases, or APIs. After creating a service map for the application that has dependencies that you want to explore, add an application node on the map. Then, begin to add connections to the map including databases, external services, third-party APIs, and even New Relic Browser-monitored applications. New Relic pulls every node you add into the map, and you can watch the shape of your architecture emerge. one.newrelic.com > APM > (select an application) > Service map: View a service map to see a visual overview of your system architecture and the health of entities. Based on the visibility into internal and external dependencies that the service map provides, you can create a migration plan that includes all aspects of an application’s ecosystem. 4. Inventory underlining instances with Infrastructure New Relic Infrastructure's inventory page gives you visibility into the software packages installed on your servers. Essentially, the inventory page displays detailed information about a system’s per-host configuration, including details about system modules, configuration files, metadata, packages, services, and user sessions. The inventory page provides a real-time, filterable, searchable view into each host’s configuration. The inventory page not only provides you with the list of packages installed but also provides version information as well. Use this version information to know which packages to upgrade and which packages to replicate for your cloud migration. It also helps you track the dependencies between the software packages and configuration files. one.newrelic.com > Infrastructure > Inventory: View the inventory page for details about your hosts and their configurations. You can also use the Inventory page to get a sense of what software or packages you no longer need, which is a great way to “clean up” your servers before you migrate to the cloud. 5. Uncover unknown applications and components Since anything can happen during an application’s lifecycle, like an application changing ownership, you may come across applications or component dependencies that you did not know about. If you discover any unknown dependencies, assess their relationship to other applications and components in your infrastructure to determine if they should be pulled into your migration plan. If you discover any applications or components while viewing service maps or while reviewing the inventory page, remember to instrument them before you migrate them. 6. Resolve errors or other issues After you instrument your applications, APM may uncover errors or issues with your current on-prem applications. Use APM error analytics to determine the root cause of any errors or issues in your applications. one.newrelic.com > APM > (select an app) > Events > Errors: Use error analytics to determine the root cause of errors in your applications. Start with the Error rate chart to see if there are any unexpected spikes, dips, or error patterns. Correlate any patterns on the Top 5 errors chart to alerts occurring during the same time period. The Error traces table includes specific stack trace details, such as associated host, user, framework code, and custom attributes to help you identify the root cause of an error. 7. Create Dashboards In addition to the application baselines you built, create dashboards to assess your on-premises applications in preparation for migrating them to the cloud. Use Dashboards to gain visibility into the average response times, the top transactions, the associated average duration, and the overall CPU usage for your instrumented application. Drill down into individual applications to see your top processes and the CPU percent for each process. You can also view an error analysis for a set of instrumented applications: one.newrelic.com > Dashboards > (select a dashboard): View errors visualize issues with your applications. Check out the best practices guide for tips on creating and utilizing dashboards. Sharing New Relic Dashboards with your teams and stakeholders is a powerful way to communicate the impact of your migration during your cloud adoption process. Expert tip for reporting custom data Utilizing service maps, errors, and inventory management gives you a critical look at the architecture of your applications and their dependencies. If you find that you need data that is not available by default, New Relic products allow you to capture custom data: APM Browser Infrastructure Dashboards Mobile Synthetics For more help Explore the New Relic Platform.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.92676,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Install <em>New</em> <em>Relic</em> agents",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " answers when you determined the scope of your <em>cloud</em> migration, verify that the applications that you want to migrate are compatible with <em>New</em> <em>Relic</em> products and install the agents: <em>New</em> <em>Relic</em> APM <em>New</em> <em>Relic</em> APM delivers data about your application&#x27;s performance, providing information about app availability"
      },
      "id": "60445fcc64441f498e378efb"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/refactor-your-applications": [
    {
      "sections": [
        "Prioritize migration order",
        "1. Identify components",
        "2. Instrument applications",
        "3. Instrument hosts",
        "Tip",
        "4. Identify and track issues",
        "5. Create baselines",
        "6. Determine next steps",
        "Use service maps to find connections",
        "Use the New Relic Explorer to analyze health",
        "Use the Inventory page to identify components",
        "Expert tips for organizing your data"
      ],
      "title": "Prioritize migration order",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "f728804bace8dbe4a8176df74986fbf094e1ba62",
      "image": "https://docs.newrelic.com/static/9c3844bf72e803766bcb7b5146bf279b/c1b63/screen-service-maps_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/prioritize-migration-order/",
      "published_at": "2021-05-05T18:42:07Z",
      "updated_at": "2021-03-30T01:17:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you migrate any applications to the cloud, verify that the applications and their underlying server infrastructures are candidates for migration. When you instrument every layer of an application’s architecture, you get end-to-end visibility and are able to identify additional cloud migration risks or dependencies. Such analysis provides a more focused cloud migration priority list. 1. Identify components Create a list all of applications, services, and their underlying server infrastructures in your application portfolio that you want to migrate to the cloud. 2. Instrument applications Before you install any New Relic agents, review the compatibility and requirements for New Relic agents. Then, install the agents in your environment. After installing the agents, review the architecture of all the applications that you instrumented with an agent. Take note of the host for each tier of the application stack (database, application, web server, etc.), as you will install Infrastructure agents on each of those hosts in the next step. 3. Instrument hosts After reviewing the requirements for New Relic Infrastructure, follow the instructions for installing the Infrastructure agent on all hosts in your application stack: Install for Linux Install for Windows Server Install on AWS Elastic Beanstalk Install with a configuration management tool Also, in order to report data to New Relic, Infrastructure agents must have outbound access to certain domains and ports. If your system requires a proxy to connect to these domains, use the proxy setting. To gain extended visibility into applications that your code depends on, deploy on-host integrations. New Relic supports several commonly used application components, such as MySQL, Apache, and NGINX. Tip If you discover any applications, dependencies, or server infrastructure that you did not include in your list of components, instrument them with New Relic by installing the appropriate agents before moving forward. 4. Identify and track issues After installing, New Relic APM and Browser show you error events, error metrics, and detailed error traces for your applications. If an error or unhandled exception happens, the data appears on the Browser JavaScript errors page and the APM Error analytics page. From these pages, you can quickly troubleshoot runtime errors. Then, further analyze errors by grouping them according to attributes, by filtering them, or by searching for keywords in the event data. Each unhandled exception generates a transaction error event in Insights, and the dashboards are updated in real time. Event data is a record of a single event at a particular moment in time and consists of default attributes, like a timestamp, and an event type. You can also add custom attributes to provide more context. Tip Once you start capturing JavaScript errors as events in Insights, set up NRQL alerting so you can stay on top of your error data. 5. Create baselines One of the benefits of using APM while you are planning your cloud migration is that you get a deeper understanding of your application’s baseline. A baseline is a measurement of the current performance and availability of your application, which you then use as a comparison after your migration to validate your business case. 6. Determine next steps Use the following New Relic features to determine the next steps for your application: Use service maps to find connections After you install the APM agent, use service maps to get a full view into your application’s architecture. service maps allow you to identify any external services, web services, databases, or APIs that the application might be connecting to. Once you have an application node on the map, you can add its connections to the map, including New Relic Browser apps, databases, or external services (for example, third-party APIs). Every node you add is automatically connected to the map, so you see the shape of your application’s architecture emerge. one.newrelic.com > APM > (select an application) > Service map: Use service maps to understand the connections between different parts of your architecture. Use the New Relic Explorer to analyze health Use the explorer to see a high level overview of your services, which includes applications. Select the service to view a summary of your instrumented applications. You can then select dependencies to view the underlying infrastructure. To view this information at a glance, use the New Relic Explorer by going to one.newrelic.com > Explorer. From the explorer, you can: Sort applications by labels: Name Response Time Throughput Error Rate Identify owners Identify which users will be affected by a migration Discover application architecture details, such as the number of tiers and data sources Discover any dependencies Extract operational costs of each application or group one.newrelic.com > Explorer: The explorer allows you to see an overview of your services. Use the Inventory page to identify components Infrastructure's inventory page gives you visibility into the software packages installed on your servers. New Relic Infrastructure reports detailed information about a system’s per-host configuration, including system modules, configuration files, metadata, packages, services, user sessions, and more. The inventory page provides a real-time, filterable, searchable view into each host’s configuration. Use this data to identify various components of the applications you want to migrate. one.newrelic.com > Infrastructure > Inventory: Use the filter and search functions to find information for specific items across all your hosts. Analyze these criteria for each of your apps to determine the next steps for your migration: Should you move your app to a new host or platform, or re-factor its code before migrating it? Should you retire the application without moving it to the cloud? By using the information that New Relic provides, you are better equipped to create a prioritized list of applications ready for cloud migration. Expert tips for organizing your data In APM, use labels to group the instrumented applications into meaningful categories like environments, functional areas, technologies, business units. Or, you can separate them for development or operational teams. In Infrastructure, use filter sets to organize hosts into cluster, environment, role, or any Infrastructure attribute based on criteria that you define.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.5282,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Use the <em>New</em> <em>Relic</em> Explorer to analyze health",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " to determine the next steps for your migration: Should you move your app to a <em>new</em> host or platform, or re-factor its code before migrating it? Should you retire the application without moving it to the <em>cloud</em>? By using the information that <em>New</em> <em>Relic</em> provides, you are better equipped to create a prioritized list"
      },
      "id": "604458bd64441f87e0378ebf"
    },
    {
      "sections": [
        "Optimize your cloud spend",
        "1. Deploy the New Relic Infrastructure agent",
        "2. Create dashboard charts for cloud performance",
        "Break out data by cloud performance and application metrics",
        "3. Configure the Amazon AWS integration",
        "4. Set up billing budgets in AWS",
        "5. Add cloud spend and budget widgets to Insights dashboard",
        "Break out data by application and by AWS budget",
        "6. Create dashboards for every level of your organization",
        "Dashboards for developers",
        "Dashboards for DevOps",
        "Dashboards for executives",
        "7. Set up alerts",
        "Configure a baseline query using the forecasted amount"
      ],
      "title": "Optimize your cloud spend",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "7a0ac1127aee1ef0668e8aad47af8813f0ed7259",
      "image": "https://docs.newrelic.com/static/2f167e48441b82a62aae1463592e0aed/8c557/CloudPerformanceForAppX.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/optimize-your-cloud-spend/",
      "published_at": "2021-05-05T18:44:57Z",
      "updated_at": "2021-03-13T07:30:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Now that you are using cloud-hosted infrastructure and services, it is important to start looking very early and very closely at your cloud spend: Make sure that your assumptions about your cloud spend are playing out as expected. Quickly catch and correct any unexpected spikes in spending. Start fine-tuning the usage of your cloud-based resources. For example, if you have a set of 20 instances all running at 10% CPU, you can think about using smaller instances or consolidating more work onto those instances. This kind of thinking about your cloud spend helps you optimize and save money quickly. New Relic can help you monitor all this. From a data perspective, it is really just another metric that our platform can collect for you. As with any other metric, you can visualize, report, and alert on your cloud spend data, just like you can with any data New Relic can help you collect. Using the New Relic applied intelligence platform is a great way to help you learn about your cloud spending or about any of your performance data. 1. Deploy the New Relic Infrastructure agent Review the requirements for the New Relic Infrastructure agent and follow the documentation for instructions on installing the agent. After you install the Infrastructure agent on your hosts, you immediately have access to the broad spectrum of metrics that the agent receives automatically. Then, you can set up the cloud integration to start collecting billing information. 2. Create dashboard charts for cloud performance New Relic Dashboards is the product that you use to write powerful custom queries about your data, and then visualize the results in charts that you collect on a dashboard. You can also feed the results of your dashboard queries directly into New Relic Alerts, where you can get notifications on any deviations that you specify. Include charts for various Infrastructure metrics related to performance and usage; for example: CPU Memory Disk Database You may also want to include charts that represent the application using this cloud infrastructure. In this way you can correlate the cloud infrastructure performance with that of the application. As you right-size your cloud infrastructure, you will want to monitor application performance to make sure you are achieving any targets. Here is an example of an Insights dashboard for cloud performance. Break out data by cloud performance and application metrics The following dashboard shows several charts that present key cloud infrastructure metrics and an associated application metric. Every one of these charts represents the result of a query. [ Downs: Updated image based on New Relic One can be found at: https://www.dropbox.com/s/rjq7tqrswxwtte9/Tutorial-Run-OptimizeCloudSpen... Image caption: one.newrelic.com > Dashboards: Create dashboards that include both cloud infrastructure and application metrics.] insights.newrelic.com: Create dashboards that include both cloud infrastructure and application metrics. 3. Configure the Amazon AWS integration New Relic Infrastructure comes with several types of integrations, including Amazon Web Services (AWS), Microsoft Azure, and on-host integrations. This tutorial focuses on the AWS Billing integration. First, configure the integration with your AWS account, and then you can set up the AWS Billing integration. 4. Set up billing budgets in AWS The Amazon AWS Billing integration requires some additional configuration on the AWS side. Specifically, you need to go into your AWS Billing dashboard and set up Budgets. Our documentation and the blog post Show Me (Where I’m Spending) the Money! AWS Billing Comes to New Relic Insights provide walk-throughs of this process. When creating Budgets, be sure to: Fill in an application name. Decide whether you are doing cost or service-based budgeting. Decide if your budget is open-ended or has a definite ending date. 5. Add cloud spend and budget widgets to Insights dashboard New Relic Insights is the product that you use to write powerful custom queries about your data, and then visualize the results in widgets that you collect on a dashboard. You can also feed the results of your Insights queries directly into New Relic Alerts, where you can get notifications on any deviations that you specify. Here are some examples of ways to use Insights dashboards to visualize your AWS cloud spend data. Break out data by application and by AWS budget The following dashboard shows several widgets that present key information about an AWS budget vs. actual spending, with data broken out by an application AWS budget. Every one of these widgets represents the result of an Insights query, and the data in the supporting Insights tables is the data that our integration automatically receives from AWS. [ Downs: Updated image based on New Relic One can be found at: https://www.dropbox.com/s/ecp5mrnkezh6hjh/Tutorial-Run-OptimizeCloudSpen... Image caption: one.newrelic.com > Dashboards: Add charts that include AWS cloud and budgets data.] [ Downs: put this 'code' section below the image please. Here is the query to create the Application X Cloud Cost budget chart in this dashboard example: SELECT latest(`provider.actualAmount`) as '$ Actual', latest(`provider.forecastedAmount`) as '$ Forecast', max(`provider.limitAmount`) as '$ Limit' FROM FinanceSample WHERE provider = 'BillingBudget' AND `provider.budgetName` = 'NAME_OF_YOUR_CLOUD_BUDGET' Copy ] insights.newrelic.com: Create dashboards that include AWS cloud and budgets. 6. Create dashboards for every level of your organization Whether you are a developer, in DevOps, or an executive, having information about your cloud spend can help you optimize your cloud environment. Here are a few ways dashboards can help at each level of your organization: Dashboards for developers Understanding how much applications cost to run helps developers properly configure applications to use more efficient services. For example, could developers save cloud costs using Amazon AWS Lambda or properly sized instances instead of randomly selecting an instance? Dashboards for DevOps Monitoring application costs allows operators to catch possible overruns due to misconfigured services. For example, is the DevOps team’s auto-scaling configuration not scaling down properly? Are they spending money on instances that are not being used? Dashboards for executives An overall view of both forecasted and actual cloud spends for individual applications on a per region basis, as well as total costs, helps executives make better business decisions. Use New Relic to keep control of your cloud spending costs, and get your teams alerted when you go over your budgets. 7. Set up alerts After you write queries on your data in Insights, you can easily use them to create alert conditions. New Relic gives you the ability to write baseline queries against your data. A baseline query is a query that you write without setting hard limits on the results and instead let New Relic Applied Intelligence “machine-learn” your performance data. New Relic alerts you when you go too far outside of your baseline numbers. Configure a baseline query using the forecasted amount Configuring a baseline query using a forecasted amount is a great starting point for monitoring any cloud budget, as you grow to understand what your cloud spend will be over time. New Relic notifies you if something spikes beyond your forecasted trend. That query looks like this: SELECT latest(`provider.forecastedAmount`) FROM FinanceSample WHERE provider = 'BillingBudget' and `provider.budgetName` = 'NAME_OF_YOUR_CLOUD_BUDGET' Copy When you create a baseline query and alert on it, you decide how restrictively Applied Intelligence should analyze your data using a simple slider and visualization based on your recent performance. The slider either increases or decreases the gray band around your budget threshold (the blue line): alerts.newrelic.com > Alert policies > (select a policy) > Alert conditions: Create alert conditions based on your NRQL queries and Insights data. This example would have resulted in zero violations based on recent data, and that is exactly what you are looking for. However, if that blue line spikes up out of the gray band, New Relic notifies you. For more detailed information about creating, managing, and using alerts, view these New Relic University tutorials: Intro to alerting Alert policies Alerting incident lifecycle Notification channels",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.98692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Optimize your <em>cloud</em> spend",
        "sections": "1. Deploy the <em>New</em> <em>Relic</em> Infrastructure agent",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " quickly. <em>New</em> <em>Relic</em> can help you monitor all this. From a data perspective, it is really just another metric that our platform can collect for you. As with any other metric, you can visualize, report, and alert on your <em>cloud</em> spend data, just like you can with any data <em>New</em> <em>Relic</em> can help you collect. Using"
      },
      "id": "60445c4928ccbcd0132c6094"
    },
    {
      "sections": [
        "Modern and cloud services",
        "1. Identify applications, cloud services, infrastructure, and technologies",
        "2. Deploy Infrastructure",
        "Tip",
        "3. Configure cloud integrations",
        "4. Track data on your dashboards",
        "AWS EC2 monitoring integration dashboard",
        "Azure VMs monitoring integration dashboard",
        "GCP Compute Engine monitoring integration dashboard",
        "Example modern and cloud services dashboard",
        "5. Add alerts for cloud-based metrics",
        "6. Set up additional monitoring",
        "7. CI/CD Pipeline integration"
      ],
      "title": "Modern and cloud services ",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "824d892c1faf24fb7eb5bf6e205571446261f699",
      "image": "https://docs.newrelic.com/static/425a652fcbd53bbbea3454793047bd01/8c557/ModernAndCloudServiceDashboardNew.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/cloud-adoption/modern-cloud-services/",
      "published_at": "2021-05-05T18:40:37Z",
      "updated_at": "2021-03-13T05:44:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you've just completed your cloud migration, have been using cloud based services for awhile, or have always been in the cloud, you may find yourself deploying or running technologies and services that are new and modern. These modern technologies could be container solutions such as Docker, Kubernetes, and Amazon AWS ECS or Fargate for example. Or they could be serverless services such as AWS Lambda, Microsoft Azure, or Google Cloud Platform Functions, cloud based databases, or any number of cloud services that abstract the service away from an operations-maintained infrastructure. In these situations you still want to monitor, query, and alert on the performance and usage metrics for both modern technologies and cloud-based services, allowing for faster deployments, the ability to adopt new services, better business decisions, and to expand horizons. This doc demonstrates how to use the New Relic Platform to monitor your modern technologies and cloud services. 1. Identify applications, cloud services, infrastructure, and technologies Determine the components you need to monitor by answering the following the questions: What cloud-based applications do I have? What are the underlying cloud-based services, technologies, and infrastructure supporting those applications? When you have a full understanding of your architecture, you reduce the possibility of missing dependencies during your migration. 2. Deploy Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts you identified so you can start to monitor your cloud services. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. 3. Configure cloud integrations Once your applications are migrated to the cloud and you start to integrate new cloud services, you can use New Relic to monitor and report data about your cloud services, offering you a comprehensive view of your entire architecture in one place. To get started configuring cloud service integrations, link your cloud service provider account with New Relic, depending on whether you use Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP). 4. Track data on your dashboards New Relic Infrastructure integrations auto-populate dashboards with metrics from cloud providers like AWS, Azure, and GCP so you can track the data that is critical to your cloud adoption success. Tip If you adopt a hybrid cloud of multiple cloud providers, New Relic can provide a holistic perspective that is agnostic to cloud providers. AWS EC2 monitoring integration dashboard In this default dashboard for the AWS EC2 monitoring integration, New Relic captures metrics for EC2 instances per region, instance state, and instance type. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. infrastructure.newrelic.com > Integrations > Amazon Web Services: View AWS EC2 data on the default dashboard for the AWS EC2 monitoring integration. Azure VMs monitoring integration dashboard The default Azure virtual machine integration dashboard shows data for VM sizes, VMs per region, and VMs per resource group. infrastructure.newrelic.com > Integrations > Microsoft Azure: View Azure virtual machine data on the default dashboard for the Azure VMs monitoring integration. GCP Compute Engine monitoring integration dashboard In this default dashboard for the Google Cloud Platform, New Relic captures metrics for instances per zone, instance status, firewall dropped packets, reserved cores, and disk throttled operations. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. infrastructure.newrelic.com > Integrations > Google Cloud Platform: View GCP Compute Engine data on the default dashboard for the GCP Compute Engine monitoring integration. Example modern and cloud services dashboard In this example dashboard, three different cloud vendors, modern technologies, cloud services, infrastructure instance locations, and DevOps widgets are combined for an overall view. one.newrelic.com > Dashboards: Here is an example of a dashboard with data about vendors, technologies, services, instances, and other important details. 5. Add alerts for cloud-based metrics When monitoring cloud-based services, it is essential to keep track of all the changes happening with the system by alerting on them. Integrations with New Relic Infrastructure allow you to create alerts on the metrics that are the most important to you. Here is an example of a baseline alert that will notify you based on the number of requests received on all ALB systems for the AWS Elastic Load Balancing (ALB) monitoring integration: alerts.newrelic.com > Alert policies > (selected policy) > Alert conditions: Create a NRQL baseline alert to monitor the number of requests received your ALB systems. 6. Set up additional monitoring In addition to monitoring cloud services, you can deploy New Relic APM, Browser, Mobile, and Synthetics to gain full-stack visibility into all of the components of your applications: Use New Relic APM to report application-tier performance metrics. Use New Relic Browser to report front-end web metrics. Use New Relic Mobile to report front-end mobile app metrics. Use New Relic Synthetics to monitor websites, critical business transactions, and API endpoints. 7. CI/CD Pipeline integration It's important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. New Relic APM's deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change log, etc.). APM displays a vertical line, or marker, on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip Recommendation: Make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate CI/CD deployments: Chef (see newrelic_deployment) Jenkins Ansible",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.95271,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Modern and <em>cloud</em> services ",
        "sections": "Modern and <em>cloud</em> services",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": ", and GCP so you can track the data that is critical to your <em>cloud</em> <em>adoption</em> success. Tip If you <em>adopt</em> a hybrid <em>cloud</em> of multiple <em>cloud</em> providers, <em>New</em> <em>Relic</em> can provide a holistic perspective that is agnostic to <em>cloud</em> providers. AWS EC2 monitoring integration dashboard In this default dashboard"
      },
      "id": "60440f13e7b9d20f275799ca"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/validate-cloud-improvements": [
    {
      "sections": [
        "Prioritize migration order",
        "1. Identify components",
        "2. Instrument applications",
        "3. Instrument hosts",
        "Tip",
        "4. Identify and track issues",
        "5. Create baselines",
        "6. Determine next steps",
        "Use service maps to find connections",
        "Use the New Relic Explorer to analyze health",
        "Use the Inventory page to identify components",
        "Expert tips for organizing your data"
      ],
      "title": "Prioritize migration order",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "f728804bace8dbe4a8176df74986fbf094e1ba62",
      "image": "https://docs.newrelic.com/static/9c3844bf72e803766bcb7b5146bf279b/c1b63/screen-service-maps_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/prioritize-migration-order/",
      "published_at": "2021-05-05T18:42:07Z",
      "updated_at": "2021-03-30T01:17:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you migrate any applications to the cloud, verify that the applications and their underlying server infrastructures are candidates for migration. When you instrument every layer of an application’s architecture, you get end-to-end visibility and are able to identify additional cloud migration risks or dependencies. Such analysis provides a more focused cloud migration priority list. 1. Identify components Create a list all of applications, services, and their underlying server infrastructures in your application portfolio that you want to migrate to the cloud. 2. Instrument applications Before you install any New Relic agents, review the compatibility and requirements for New Relic agents. Then, install the agents in your environment. After installing the agents, review the architecture of all the applications that you instrumented with an agent. Take note of the host for each tier of the application stack (database, application, web server, etc.), as you will install Infrastructure agents on each of those hosts in the next step. 3. Instrument hosts After reviewing the requirements for New Relic Infrastructure, follow the instructions for installing the Infrastructure agent on all hosts in your application stack: Install for Linux Install for Windows Server Install on AWS Elastic Beanstalk Install with a configuration management tool Also, in order to report data to New Relic, Infrastructure agents must have outbound access to certain domains and ports. If your system requires a proxy to connect to these domains, use the proxy setting. To gain extended visibility into applications that your code depends on, deploy on-host integrations. New Relic supports several commonly used application components, such as MySQL, Apache, and NGINX. Tip If you discover any applications, dependencies, or server infrastructure that you did not include in your list of components, instrument them with New Relic by installing the appropriate agents before moving forward. 4. Identify and track issues After installing, New Relic APM and Browser show you error events, error metrics, and detailed error traces for your applications. If an error or unhandled exception happens, the data appears on the Browser JavaScript errors page and the APM Error analytics page. From these pages, you can quickly troubleshoot runtime errors. Then, further analyze errors by grouping them according to attributes, by filtering them, or by searching for keywords in the event data. Each unhandled exception generates a transaction error event in Insights, and the dashboards are updated in real time. Event data is a record of a single event at a particular moment in time and consists of default attributes, like a timestamp, and an event type. You can also add custom attributes to provide more context. Tip Once you start capturing JavaScript errors as events in Insights, set up NRQL alerting so you can stay on top of your error data. 5. Create baselines One of the benefits of using APM while you are planning your cloud migration is that you get a deeper understanding of your application’s baseline. A baseline is a measurement of the current performance and availability of your application, which you then use as a comparison after your migration to validate your business case. 6. Determine next steps Use the following New Relic features to determine the next steps for your application: Use service maps to find connections After you install the APM agent, use service maps to get a full view into your application’s architecture. service maps allow you to identify any external services, web services, databases, or APIs that the application might be connecting to. Once you have an application node on the map, you can add its connections to the map, including New Relic Browser apps, databases, or external services (for example, third-party APIs). Every node you add is automatically connected to the map, so you see the shape of your application’s architecture emerge. one.newrelic.com > APM > (select an application) > Service map: Use service maps to understand the connections between different parts of your architecture. Use the New Relic Explorer to analyze health Use the explorer to see a high level overview of your services, which includes applications. Select the service to view a summary of your instrumented applications. You can then select dependencies to view the underlying infrastructure. To view this information at a glance, use the New Relic Explorer by going to one.newrelic.com > Explorer. From the explorer, you can: Sort applications by labels: Name Response Time Throughput Error Rate Identify owners Identify which users will be affected by a migration Discover application architecture details, such as the number of tiers and data sources Discover any dependencies Extract operational costs of each application or group one.newrelic.com > Explorer: The explorer allows you to see an overview of your services. Use the Inventory page to identify components Infrastructure's inventory page gives you visibility into the software packages installed on your servers. New Relic Infrastructure reports detailed information about a system’s per-host configuration, including system modules, configuration files, metadata, packages, services, user sessions, and more. The inventory page provides a real-time, filterable, searchable view into each host’s configuration. Use this data to identify various components of the applications you want to migrate. one.newrelic.com > Infrastructure > Inventory: Use the filter and search functions to find information for specific items across all your hosts. Analyze these criteria for each of your apps to determine the next steps for your migration: Should you move your app to a new host or platform, or re-factor its code before migrating it? Should you retire the application without moving it to the cloud? By using the information that New Relic provides, you are better equipped to create a prioritized list of applications ready for cloud migration. Expert tips for organizing your data In APM, use labels to group the instrumented applications into meaningful categories like environments, functional areas, technologies, business units. Or, you can separate them for development or operational teams. In Infrastructure, use filter sets to organize hosts into cluster, environment, role, or any Infrastructure attribute based on criteria that you define.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.52818,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Use the <em>New</em> <em>Relic</em> Explorer to analyze health",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " to determine the next steps for your migration: Should you move your app to a <em>new</em> host or platform, or re-factor its code before migrating it? Should you retire the application without moving it to the <em>cloud</em>? By using the information that <em>New</em> <em>Relic</em> provides, you are better equipped to create a prioritized list"
      },
      "id": "604458bd64441f87e0378ebf"
    },
    {
      "sections": [
        "Optimize your cloud spend",
        "1. Deploy the New Relic Infrastructure agent",
        "2. Create dashboard charts for cloud performance",
        "Break out data by cloud performance and application metrics",
        "3. Configure the Amazon AWS integration",
        "4. Set up billing budgets in AWS",
        "5. Add cloud spend and budget widgets to Insights dashboard",
        "Break out data by application and by AWS budget",
        "6. Create dashboards for every level of your organization",
        "Dashboards for developers",
        "Dashboards for DevOps",
        "Dashboards for executives",
        "7. Set up alerts",
        "Configure a baseline query using the forecasted amount"
      ],
      "title": "Optimize your cloud spend",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "7a0ac1127aee1ef0668e8aad47af8813f0ed7259",
      "image": "https://docs.newrelic.com/static/2f167e48441b82a62aae1463592e0aed/8c557/CloudPerformanceForAppX.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/plan-your-cloud-adoption/optimize-your-cloud-spend/",
      "published_at": "2021-05-05T18:44:57Z",
      "updated_at": "2021-03-13T07:30:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Now that you are using cloud-hosted infrastructure and services, it is important to start looking very early and very closely at your cloud spend: Make sure that your assumptions about your cloud spend are playing out as expected. Quickly catch and correct any unexpected spikes in spending. Start fine-tuning the usage of your cloud-based resources. For example, if you have a set of 20 instances all running at 10% CPU, you can think about using smaller instances or consolidating more work onto those instances. This kind of thinking about your cloud spend helps you optimize and save money quickly. New Relic can help you monitor all this. From a data perspective, it is really just another metric that our platform can collect for you. As with any other metric, you can visualize, report, and alert on your cloud spend data, just like you can with any data New Relic can help you collect. Using the New Relic applied intelligence platform is a great way to help you learn about your cloud spending or about any of your performance data. 1. Deploy the New Relic Infrastructure agent Review the requirements for the New Relic Infrastructure agent and follow the documentation for instructions on installing the agent. After you install the Infrastructure agent on your hosts, you immediately have access to the broad spectrum of metrics that the agent receives automatically. Then, you can set up the cloud integration to start collecting billing information. 2. Create dashboard charts for cloud performance New Relic Dashboards is the product that you use to write powerful custom queries about your data, and then visualize the results in charts that you collect on a dashboard. You can also feed the results of your dashboard queries directly into New Relic Alerts, where you can get notifications on any deviations that you specify. Include charts for various Infrastructure metrics related to performance and usage; for example: CPU Memory Disk Database You may also want to include charts that represent the application using this cloud infrastructure. In this way you can correlate the cloud infrastructure performance with that of the application. As you right-size your cloud infrastructure, you will want to monitor application performance to make sure you are achieving any targets. Here is an example of an Insights dashboard for cloud performance. Break out data by cloud performance and application metrics The following dashboard shows several charts that present key cloud infrastructure metrics and an associated application metric. Every one of these charts represents the result of a query. [ Downs: Updated image based on New Relic One can be found at: https://www.dropbox.com/s/rjq7tqrswxwtte9/Tutorial-Run-OptimizeCloudSpen... Image caption: one.newrelic.com > Dashboards: Create dashboards that include both cloud infrastructure and application metrics.] insights.newrelic.com: Create dashboards that include both cloud infrastructure and application metrics. 3. Configure the Amazon AWS integration New Relic Infrastructure comes with several types of integrations, including Amazon Web Services (AWS), Microsoft Azure, and on-host integrations. This tutorial focuses on the AWS Billing integration. First, configure the integration with your AWS account, and then you can set up the AWS Billing integration. 4. Set up billing budgets in AWS The Amazon AWS Billing integration requires some additional configuration on the AWS side. Specifically, you need to go into your AWS Billing dashboard and set up Budgets. Our documentation and the blog post Show Me (Where I’m Spending) the Money! AWS Billing Comes to New Relic Insights provide walk-throughs of this process. When creating Budgets, be sure to: Fill in an application name. Decide whether you are doing cost or service-based budgeting. Decide if your budget is open-ended or has a definite ending date. 5. Add cloud spend and budget widgets to Insights dashboard New Relic Insights is the product that you use to write powerful custom queries about your data, and then visualize the results in widgets that you collect on a dashboard. You can also feed the results of your Insights queries directly into New Relic Alerts, where you can get notifications on any deviations that you specify. Here are some examples of ways to use Insights dashboards to visualize your AWS cloud spend data. Break out data by application and by AWS budget The following dashboard shows several widgets that present key information about an AWS budget vs. actual spending, with data broken out by an application AWS budget. Every one of these widgets represents the result of an Insights query, and the data in the supporting Insights tables is the data that our integration automatically receives from AWS. [ Downs: Updated image based on New Relic One can be found at: https://www.dropbox.com/s/ecp5mrnkezh6hjh/Tutorial-Run-OptimizeCloudSpen... Image caption: one.newrelic.com > Dashboards: Add charts that include AWS cloud and budgets data.] [ Downs: put this 'code' section below the image please. Here is the query to create the Application X Cloud Cost budget chart in this dashboard example: SELECT latest(`provider.actualAmount`) as '$ Actual', latest(`provider.forecastedAmount`) as '$ Forecast', max(`provider.limitAmount`) as '$ Limit' FROM FinanceSample WHERE provider = 'BillingBudget' AND `provider.budgetName` = 'NAME_OF_YOUR_CLOUD_BUDGET' Copy ] insights.newrelic.com: Create dashboards that include AWS cloud and budgets. 6. Create dashboards for every level of your organization Whether you are a developer, in DevOps, or an executive, having information about your cloud spend can help you optimize your cloud environment. Here are a few ways dashboards can help at each level of your organization: Dashboards for developers Understanding how much applications cost to run helps developers properly configure applications to use more efficient services. For example, could developers save cloud costs using Amazon AWS Lambda or properly sized instances instead of randomly selecting an instance? Dashboards for DevOps Monitoring application costs allows operators to catch possible overruns due to misconfigured services. For example, is the DevOps team’s auto-scaling configuration not scaling down properly? Are they spending money on instances that are not being used? Dashboards for executives An overall view of both forecasted and actual cloud spends for individual applications on a per region basis, as well as total costs, helps executives make better business decisions. Use New Relic to keep control of your cloud spending costs, and get your teams alerted when you go over your budgets. 7. Set up alerts After you write queries on your data in Insights, you can easily use them to create alert conditions. New Relic gives you the ability to write baseline queries against your data. A baseline query is a query that you write without setting hard limits on the results and instead let New Relic Applied Intelligence “machine-learn” your performance data. New Relic alerts you when you go too far outside of your baseline numbers. Configure a baseline query using the forecasted amount Configuring a baseline query using a forecasted amount is a great starting point for monitoring any cloud budget, as you grow to understand what your cloud spend will be over time. New Relic notifies you if something spikes beyond your forecasted trend. That query looks like this: SELECT latest(`provider.forecastedAmount`) FROM FinanceSample WHERE provider = 'BillingBudget' and `provider.budgetName` = 'NAME_OF_YOUR_CLOUD_BUDGET' Copy When you create a baseline query and alert on it, you decide how restrictively Applied Intelligence should analyze your data using a simple slider and visualization based on your recent performance. The slider either increases or decreases the gray band around your budget threshold (the blue line): alerts.newrelic.com > Alert policies > (select a policy) > Alert conditions: Create alert conditions based on your NRQL queries and Insights data. This example would have resulted in zero violations based on recent data, and that is exactly what you are looking for. However, if that blue line spikes up out of the gray band, New Relic notifies you. For more detailed information about creating, managing, and using alerts, view these New Relic University tutorials: Intro to alerting Alert policies Alerting incident lifecycle Notification channels",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.98692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Optimize your <em>cloud</em> spend",
        "sections": "1. Deploy the <em>New</em> <em>Relic</em> Infrastructure agent",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " quickly. <em>New</em> <em>Relic</em> can help you monitor all this. From a data perspective, it is really just another metric that our platform can collect for you. As with any other metric, you can visualize, report, and alert on your <em>cloud</em> spend data, just like you can with any data <em>New</em> <em>Relic</em> can help you collect. Using"
      },
      "id": "60445c4928ccbcd0132c6094"
    },
    {
      "sections": [
        "Modern and cloud services",
        "1. Identify applications, cloud services, infrastructure, and technologies",
        "2. Deploy Infrastructure",
        "Tip",
        "3. Configure cloud integrations",
        "4. Track data on your dashboards",
        "AWS EC2 monitoring integration dashboard",
        "Azure VMs monitoring integration dashboard",
        "GCP Compute Engine monitoring integration dashboard",
        "Example modern and cloud services dashboard",
        "5. Add alerts for cloud-based metrics",
        "6. Set up additional monitoring",
        "7. CI/CD Pipeline integration"
      ],
      "title": "Modern and cloud services ",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "824d892c1faf24fb7eb5bf6e205571446261f699",
      "image": "https://docs.newrelic.com/static/425a652fcbd53bbbea3454793047bd01/8c557/ModernAndCloudServiceDashboardNew.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/cloud-adoption/modern-cloud-services/",
      "published_at": "2021-05-05T18:40:37Z",
      "updated_at": "2021-03-13T05:44:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you've just completed your cloud migration, have been using cloud based services for awhile, or have always been in the cloud, you may find yourself deploying or running technologies and services that are new and modern. These modern technologies could be container solutions such as Docker, Kubernetes, and Amazon AWS ECS or Fargate for example. Or they could be serverless services such as AWS Lambda, Microsoft Azure, or Google Cloud Platform Functions, cloud based databases, or any number of cloud services that abstract the service away from an operations-maintained infrastructure. In these situations you still want to monitor, query, and alert on the performance and usage metrics for both modern technologies and cloud-based services, allowing for faster deployments, the ability to adopt new services, better business decisions, and to expand horizons. This doc demonstrates how to use the New Relic Platform to monitor your modern technologies and cloud services. 1. Identify applications, cloud services, infrastructure, and technologies Determine the components you need to monitor by answering the following the questions: What cloud-based applications do I have? What are the underlying cloud-based services, technologies, and infrastructure supporting those applications? When you have a full understanding of your architecture, you reduce the possibility of missing dependencies during your migration. 2. Deploy Infrastructure After reviewing the requirements for New Relic Infrastructure, install the Infrastructure agent on the hosts you identified so you can start to monitor your cloud services. Tip If you use Ansible, Chef, or Puppet for automation, you can use those tools to deploy Infrastructure agents to your hosts. 3. Configure cloud integrations Once your applications are migrated to the cloud and you start to integrate new cloud services, you can use New Relic to monitor and report data about your cloud services, offering you a comprehensive view of your entire architecture in one place. To get started configuring cloud service integrations, link your cloud service provider account with New Relic, depending on whether you use Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP). 4. Track data on your dashboards New Relic Infrastructure integrations auto-populate dashboards with metrics from cloud providers like AWS, Azure, and GCP so you can track the data that is critical to your cloud adoption success. Tip If you adopt a hybrid cloud of multiple cloud providers, New Relic can provide a holistic perspective that is agnostic to cloud providers. AWS EC2 monitoring integration dashboard In this default dashboard for the AWS EC2 monitoring integration, New Relic captures metrics for EC2 instances per region, instance state, and instance type. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. infrastructure.newrelic.com > Integrations > Amazon Web Services: View AWS EC2 data on the default dashboard for the AWS EC2 monitoring integration. Azure VMs monitoring integration dashboard The default Azure virtual machine integration dashboard shows data for VM sizes, VMs per region, and VMs per resource group. infrastructure.newrelic.com > Integrations > Microsoft Azure: View Azure virtual machine data on the default dashboard for the Azure VMs monitoring integration. GCP Compute Engine monitoring integration dashboard In this default dashboard for the Google Cloud Platform, New Relic captures metrics for instances per zone, instance status, firewall dropped packets, reserved cores, and disk throttled operations. The dashboard also shows inventory for different software packages and configurations that are installed on those instances. infrastructure.newrelic.com > Integrations > Google Cloud Platform: View GCP Compute Engine data on the default dashboard for the GCP Compute Engine monitoring integration. Example modern and cloud services dashboard In this example dashboard, three different cloud vendors, modern technologies, cloud services, infrastructure instance locations, and DevOps widgets are combined for an overall view. one.newrelic.com > Dashboards: Here is an example of a dashboard with data about vendors, technologies, services, instances, and other important details. 5. Add alerts for cloud-based metrics When monitoring cloud-based services, it is essential to keep track of all the changes happening with the system by alerting on them. Integrations with New Relic Infrastructure allow you to create alerts on the metrics that are the most important to you. Here is an example of a baseline alert that will notify you based on the number of requests received on all ALB systems for the AWS Elastic Load Balancing (ALB) monitoring integration: alerts.newrelic.com > Alert policies > (selected policy) > Alert conditions: Create a NRQL baseline alert to monitor the number of requests received your ALB systems. 6. Set up additional monitoring In addition to monitoring cloud services, you can deploy New Relic APM, Browser, Mobile, and Synthetics to gain full-stack visibility into all of the components of your applications: Use New Relic APM to report application-tier performance metrics. Use New Relic Browser to report front-end web metrics. Use New Relic Mobile to report front-end mobile app metrics. Use New Relic Synthetics to monitor websites, critical business transactions, and API endpoints. 7. CI/CD Pipeline integration It's important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. New Relic APM's deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change log, etc.). APM displays a vertical line, or marker, on charts and graphs at the deployment event's timestamp. When you hover over the line, APM displays the associated metadata for that deployment. Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip Recommendation: Make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate CI/CD deployments: Chef (see newrelic_deployment) Jenkins Ansible",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.9527,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Modern and <em>cloud</em> services ",
        "sections": "Modern and <em>cloud</em> services",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": ", and GCP so you can track the data that is critical to your <em>cloud</em> <em>adoption</em> success. Tip If you <em>adopt</em> a hybrid <em>cloud</em> of multiple <em>cloud</em> providers, <em>New</em> <em>Relic</em> can provide a holistic perspective that is agnostic to <em>cloud</em> providers. AWS EC2 monitoring integration dashboard In this default dashboard"
      },
      "id": "60440f13e7b9d20f275799ca"
    }
  ],
  "/docs/new-relic-titanium": [
    {
      "sections": [
        "Security for mobile apps",
        "Data collection",
        "Secure data endpoints",
        "Unique identifiers",
        "No remote updates",
        "Data storage",
        "Instrumentation added to your code",
        "User's IP address"
      ],
      "title": "Security for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile",
        "Get started"
      ],
      "external_id": "c1f31e708e4710eb4823467a43ab30af1f29243c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/get-started/security-mobile-apps/",
      "published_at": "2021-05-05T05:08:34Z",
      "updated_at": "2021-05-05T05:08:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To protect your mobile application's security and your users' data privacy, New Relic only records performance data, as described in this document. We do not collect any data used or stored by the monitored app. For more information about New Relic's security measures, see our security and data privacy documentation, or visit the New Relic security website. Data collection When you install New Relic, our mobile monitoring capabilities become part of your iOS or Android app. These capabilities live within your application's \"sandbox,\" so they cannot access anything other than performance data from your mobile app. We do not collect performance data about the device itself, such as battery level. Our mobile SDK agent collects and sends specific data to the New Relic collector, including: Mobile data collected Comments Devices Length of application session Wireless carrier's name The device's model name and manufacturer, and its operating system version Certain package, class, method, and thread names A unique instance identifier Requests and responses URLs of HTTP requests, along with HTTP status code, response time, and size of the request and response body Operating system error code for network failures (HTTP requests that fail to complete) The first 2KB of the response body when the HTTP request receives a 4xx or 5xx response status code Android only: A stack trace when the HTTP request receives a 4xx or 5xx response status code The agent sends all data using HTTPS encryption and validates the collector's SSL certificate. This prevents common data sniffing and server spoofing attacks. The agent also removes the query string, fragment identifier, username, and password from each URL before sending the data. Secure data endpoints Our mobile SDK agent sends harvested data to the collectors for processing. You can redirect those data posts to proxy or delegate servers for secure data handling. Android: You can use APIs to specify the URI authority of harvest and crash collector data endpoints. For more information, see the Android agent configuration and feature flags documentation. iOS: For more information, see the iOS agent configuration and feature flags documentation. Unique identifiers Our mobile SDK agent assigns a unique identifier to each installed app instance in order to track discrete installs, identify recurring sessions, and correlate performance over time. Mobile agent Identifiers Android Our Android agent generates a cryptographically strong UUID and stores it in the app's SharedPreferences. For more information, see our Android compatibility and requirements documentation. iOS The security measures used for iOS depend on the agent version. In versions 5.3.5 or higher, the iOS agent uses the IdentifierForVendor property to provide a unique device ID. In versions 5.3.4 or lower, the iOS agent used the SecureUDID open source library. SecureUDID is used by many third party libraries and is an accepted industry standard that does not violate Apple App store guidelines. SecureUDID does not use device hardware identifiers such as IMEI. Note that our mobile SDK does not collect IDFA (Identity For Advertisers). For more information, see our iOS compatibility and requirements documentation. No remote updates New Relic does not have the ability to update mobile agents remotely. Using the agent will not introduce any code into your mobile app without your knowledge. Data storage Our mobile SDK agent stores configuration information using your app's normal preferences or settings API on the mobile device. This configuration includes your: Application token Application version number Android or iOS SDK agent version number Settings such as the maximum number of HTTP requests to track per minute Performance data is buffered in memory. It is never written to the device's storage. Server-side data storage for mobile apps is handled in the same way as all other applications monitored by New Relic. For more information, see our security documentation about hosting and data storage. In general, we retain performance data according to the more generous time period of either your web or your mobile subscription. We also retain aggregate records of the number of active instances of your application. Instrumentation added to your code Our mobile SDK agent injects code into certain method calls within your application in order to collect performance data. This can have the effect of adding stack frames to your application's call graph where our code executes. This allows us to time and monitor the inputs and outputs of various APIs. This added code has been reviewed and tested for security-related flaws, and it incorporates best practices related to secure coding. Because our code runs within your application's process, it is subject to the same rights and restrictions as your own code. In addition, our iOS agent registers an NSURLProtocol handler to track NSURLConnection-based networking activity. This instrumentation is compatible with other custom NSURLProtocol handlers your application may register. The handler is registered within a single application process, so it is unable to monitor networking requests originating from other applications or the underlying operating system. User's IP address Our mobile SDK agent captures the user's IP address to enrich data for additional user information. The IP address is used as a lookup value that maps to additional details and allows our customers to diagnose performance issues. IP address lookup values include: App name Country code Region Postal code Latitude Longitude Area code For more information about events and attributes for mobile monitoring, see our data dictionary. New Relic does not retain the user's IP address after the attributes have been mapped. The IP address value is cached in memory for up to six hours before being discarded. If you have questions or concerns about this use of IP addresses with regards to your own regulatory obligations for notice and consent, please contact your privacy or legal teams.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.29889,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security <em>for</em> <em>mobile</em> apps",
        "sections": "Security <em>for</em> <em>mobile</em> apps",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em>",
        "body": "To protect your <em>mobile</em> application&#x27;s security and your users&#x27; data privacy, <em>New</em> <em>Relic</em> only records performance data, as described in this document. We do not collect any data used or stored by the monitored app. For more information about <em>New</em> <em>Relic</em>&#x27;s security measures, see our security and data"
      },
      "id": "603eb1c564441fa7e44e88a5"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-05-04T17:30:55Z",
      "updated_at": "2021-05-04T17:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon (;). For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module.prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string <a href=\"https://docs.newrelic.com/docs/apm/new-relic-apm/getting-started/glossary#apdex_f\">apdex_f</a>. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when <a href=\"#transaction_tracer.explain_enabled\">explain_enabled</a> is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitorig page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations. attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 79.889496,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>force_install_exit_handler</em>",
        "body": "&#x2F;newrelic.yml and $HOME&#x2F;newrelic.yml. apdex_t Type Float Default 0.5 Environ variable <em>NEW_RELIC</em>_APDEX_T <em>DEPRECATED</em> <em>Deprecated</em>. For agent versions 3.5.0 or higher, set your Apdex T via the <em>New</em> <em>Relic</em> UI. sync_startup Type Boolean Default false Environ variable <em>NEW_RELIC</em>_SYNC_STARTUP When set to true"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "No data appears (Android)",
        "Problem",
        "Solution"
      ],
      "title": "No data appears (Android)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Troubleshoot"
      ],
      "external_id": "cab2851a6f3c8bfddb1ed445f8722b3dddff7442",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/troubleshoot/no-data-appears-android/",
      "published_at": "2021-05-04T17:40:35Z",
      "updated_at": "2021-03-16T09:51:07Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After installing New Relic Mobile for Android and waiting at least 5 minutes, no data appears in New Relic UI. Solution If no data appears after you wait at least five minutes, use New Relic Diagnostics to automatically detect common problems and suggest troubleshooting. If that does not solve your issue, try the following: Make sure your system meets the compatibility and requirements. Make sure that you are calling the New Relic Mobile for Android agent on the first line of onCreate() in the MainActivity class and that you are running the agent on the main thread. New Relic Mobile for Android does not support starting the agent in another class. Check whether your Android app exceeds the 64k multidex limit. Increase the logging level and examine your logs for errors: Increase the New Relic logging level to AUDIT using withLogLevel: NewRelic.withApplicationToken(\"YOUR_APP_TOKEN\") .withLogLevel(AgentLog.AUDIT) .start(this.getApplication()); Copy Generate a few minutes of activity in your app. Examine your device log and your application build logs for issues. Confirm the device can reach the New Relic Mobile endpoint at mobile-collector.newrelic.com. If you need additional help, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 79.43136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> Android",
        "body": "Problem After installing <em>New</em> <em>Relic</em> <em>Mobile</em> for Android and waiting at least 5 minutes, no data appears in <em>New</em> <em>Relic</em> UI. Solution If no data appears after you wait at least five minutes, use <em>New</em> <em>Relic</em> Diagnostics to automatically detect common problems and suggest troubleshooting. If that does"
      },
      "id": "603e8eb6196a67b64ea83d81"
    }
  ],
  "/docs/okta-scim-assign-users-automated-provisioning-beta": [
    {
      "sections": [
        "Okta SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Add SCIM/SSO application",
        "Step 2. Configure provisioning",
        "Step 3. Assign users and groups",
        "Assignments tab",
        "Push groups tab",
        "Step 4. Additional considerations",
        "Moving users between groups",
        "What's next?"
      ],
      "title": "Okta SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "7a00399a6ce11aaa2cb52046f994a80f5986c0e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/okta-scimsso-application-configuration/",
      "published_at": "2021-05-06T04:53:57Z",
      "updated_at": "2021-05-06T04:53:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Okta specific details on how to configure the New Relic Okta SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Step 1. Add SCIM/SSO application Add the New Relic SCIM/SSO application to your Okta applications. Go to okta.com/ and sign in with an account that has administrator permissions. From the Okta home page, click on Admin. From the Okta admin Dashboard, choose the Applications page. Click Add Application. In the search field on the Okta Add Applications page, enter \"New Relic by Organization\" and then click on the application when it shows in the search results. From the New Relic by Organization page, click on Add. From the Add New Relic by Organization page, check the two Application Visibility \"Do not display...\" checkboxes and click on Done. We will make the application visible later after configuration is complete and provisioning has begun. Step 2. Configure provisioning Configure the New Relic SCIM/SSO application to automatically provision your users to New Relic. From the New Relic SCIM/SSO application page, click on the Provisioning tab. From the Integration form, click on Configure API Integration. Check the Enable API integration checkbox. In New Relic's authentication domain UI, set up a new domain with SCIM enabled. From the authentication domain UI, get the SCIM bearer token and input it in the New Relic SCIM/SSO app's API token field. Optional: click on Test API Credentials to verify a SCIM connection can be established to New Relic. If a connection can be established, a success message is displayed. If a connection was not established, re-enter the API Token and try the test again. Click Save. Note that the save process does a test of the API credentials. If a connection is not established to New Relic, the save will fail. On the newly displayed To App form, click on Edit. Check the Enable checkbox in the Create Users, Update User Attributes, and Deactivate Users sections. Click Save. Step 3. Assign users and groups After the New Relic SCIM/SSO application provisioning configuration and the New Relic side SSO configuration is finished, you can assign users to the application. Assigning users is done using two different tabs on the the New Relic SCIM/SSO application page. We recommend having your New Relic users selected on the Assignments tab and their associated groups selected on the Push Groups tab. Assignments tab From the New Relic SCIM/SSO application page, click on the Assignments tab. From the Assignments form, click on Assign. From the pop up menu, click on Assign to Groups. From the Assign ... to Groups form, click on Assign for the group you wish to assign to the application. Optional: in the Time zone field, enter the default time zone for members of the group. Members without a time zone configured, will use the group time zone. Time zone affects how date/times are shown in New Relic. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). Click on Save and Go Back. Repeat the steps to add a group until all desired groups have been assigned to the application. Click Done. Push groups tab From the New Relic SCIM/SSO application page, click on the Push Groups tab. From the Push Groups form, click on Push Groups. From the pop up menu, click on Find groups by name. From the Push Groups to... form, in the search field enter the first few characters of the name of the group you want to send to New Relic. Leave the Push group memberships immediately checkbox checked. Click on your group in the pop up search results list. In the Match result & push action section, No Match found should be displayed, meaning that the group does not yet exist at New Relic. Leave the selector set to Create Group and leave the default name for the group. The intent here is to have a group of the same name created at New Relic. If this is the last group you wish to send to New Relic, click on Save. Otherwise, if you have more groups to configure, click on Save & Add Another and repeat the steps to add a group. Step 4. Additional considerations In this section we discuss other important things to know when using the New Relic SCIM/SSO application. This section includes tips to work around potential issues that could cause undesired results when integrating between Okta and New Relic. Moving users between groups When moving a user between groups, you must manually synchronize the old group's membership with New Relic. This is because Okta does not send a SCIM request to remove a user from a group. So, the admin needs to push the old group's membership to New Relic manually to inform New Relic that the user is no longer a member of the old group. Here are the steps to manually synchronize a group's membership: From the New Relic SCIM/SSO application page, click on the Push Groups tab. From the Push Groups form, open the pick list on the desired group's button under the Push Status column. From the displayed pick list on the button, click Push now. This causes an immediate synchronization of the group's membership with New Relic. What's next? When you're done importing users, here are some potential next steps: Users created via your identity provider start out as full users. If your organization is on New Relic One pricing, these users are billable. To convert users to free basic users, use the User management UI. After adding users, you'll want to grant them access to specific New Relic accounts, specific groups, and specific roles. To learn how to do this, see Manage users.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 568.7706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Okta</em> <em>SCIM</em>&#x2F;SSO application configuration",
        "sections": "Step 3. <em>Assign</em> <em>users</em> and groups",
        "tags": "<em>Automated</em> <em>user</em> management",
        "body": "Our <em>automated</em> <em>user</em> management (AUM) allows allows you to import and configure your New Relic <em>users</em> from your identity provider via <em>SCIM</em>. This guide provides <em>Okta</em> specific details on how to configure the New Relic <em>Okta</em> <em>SCIM</em>&#x2F;SSO application. Requirements Before using this guide, read our AUM"
      },
      "id": "6043f5cae7b9d2758b579a0c"
    },
    {
      "sections": [
        "Azure AD SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Add SCIM/SSO application",
        "Step 2. Configure connection",
        "Step 3. Configure provisioning rules",
        "Tip",
        "Step 4. Assign users and groups",
        "What's next?"
      ],
      "title": "Azure AD SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "d6e7f7e95daa833451159a3db4e2c4257270b5e9",
      "image": "https://docs.newrelic.com/static/0a9a32fd5041e6e2ea37cc5f032b6910/8c557/Azure_AD_Provisioning_Attribute_Mapping_2_0.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/azure-ad-scimsso-application-configuration/",
      "published_at": "2021-05-06T04:52:58Z",
      "updated_at": "2021-05-06T04:52:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Azure AD-specific details on how to configure the New Relic Azure AD SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Step 1. Add SCIM/SSO application Azure AD provides an application gallery, which includes various integrations for Azure AD, including the ones that New Relic offers. Add the New Relic SCIM/SSO application to your list of applications. Go to the Azure Active Directory admin center, and sign in if necessary. https://aad.portal.azure.com/ Click on All services in the left hand menu. In the main pane, click on Enterprise applications. Click on +New Application. Find our SCIM/SSO application by entering New Relic in the name search box, and click on the application New Relic by Organization. Click on Add. Continue with the following section to connect the New Relic SCIM/SSO application to New Relic. Step 2. Configure connection Configure the New Relic SCIM/SSO application to automatically provision your users to New Relic. From the New Relic SCIM/SSO application page, click on the Provisioning link in the sidebar. In the main pane, click on Get started. In the Provisioning Mode pick-list, choose Automatic. In New Relic's authentication domain UI, set up a new domain with SCIM enabled. In Azure AD's New Relic SCIM/SSO app, in the Admin credentials section, fill out the Tenant URL and Secret token fields with the values provided in New Relic's authentication domain UI. To verify you can connect to New Relic, click Test Connection. When you see a message indicating verification success, click Save. The New Relic SCIM/SSO application can now connect with New Relic. Continue with the following section to configure the provisioning rules. Step 3. Configure provisioning rules Initially, nothing is configured to be sent to New Relic. You must configure Azure AD to send changes for user creation, updates, and deactivation. Go to the Provisioning page and complete the following: Expand the Mappings section. Click Provision Azure Active Directory Users. Verify the Target Object Actions Create Update and Delete checkboxes are all checked. Verify the Attribute Mappings look correct for your environment. Each of the New Relic attributes shown in the list must receive a value. Tip Ensure that the Azure Active Directory attributes shown in the list on the left are good sources for the information to send to New Relic. In particular, not all environments set the mail attribute. If your environment does not set the mail attribute, userPrincipalName could be a good alternative. Leave the switch for Enabled set to Off until you're done with the user and group configuration in the next section. Once all configuration is ready, return to this page and set the switch to On. Click Save. Here's an example of a filled-in attribute mapping page with the default values. Your values may be configured differently depending on your situation. After saving the provisioning rules, the New Relic SCIM/SSO application is ready to provision any changes made to users assigned to the application. Continue with the following section to assign users and groups to the New Relic SCIM/SSO application. Step 4. Assign users and groups After the New Relic SCIM/SSO application configuration and the New Relic side configuration is finished, you can assign users and groups to the application. From the New Relic SCIM/SSO application page, click on Users and groups in the sidebar. Click +Add user. From the Add Assignment page, click on Users and groups, and select the appropriate users or groups that you'd like to provision. Then click Select and Assign. The selected users and groups appear on the Users and groups page, indicating that they're candidates for provisioning. Repeat the steps to add users and groups until all desired entities have been assigned to the application. What's next? When you're done importing users, here are some potential next steps: Users created via your identity provider start out as full users. If your organization is on New Relic One pricing, these users are billable. To convert users to free basic users, use the User management UI. After adding users, you'll want to grant them access to specific New Relic accounts, specific groups, and specific roles. To learn how to do this, see Manage users.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 475.58383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Azure AD <em>SCIM</em>&#x2F;SSO application configuration",
        "sections": "Step 4. <em>Assign</em> <em>users</em> and groups",
        "tags": "<em>Automated</em> <em>user</em> management",
        "body": "Our <em>automated</em> <em>user</em> management (AUM) allows allows you to import and configure your New Relic <em>users</em> from your identity provider via <em>SCIM</em>. This guide provides Azure AD-specific details on how to configure the New Relic Azure AD <em>SCIM</em>&#x2F;SSO application. Requirements Before using this guide, read our AUM"
      },
      "id": "6043f5c964441fcfb0378ef3"
    },
    {
      "sections": [
        "Introduction to automated user management (AUM) and single-sign on (SSO)",
        "Requirements",
        "Import user groups from an identity provider using AUM"
      ],
      "title": "Introduction to automated user management (AUM) and single-sign on (SSO)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "831a5f1137eccac9540d716302645b4e976a6332",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign/",
      "published_at": "2021-05-06T04:53:56Z",
      "updated_at": "2021-05-06T04:53:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you set up automated user management (AUM), which allows you to import, update, and deactivate your New Relic users from your identity provider. Once this automated provisioning is complete, your users can log in to New Relic via their identity provider. Requirements Requirements and impacts: Requires Enterprise edition. User model-related requirements: This feature creates users on our New Relic One user model. To implement AUM, you must be on our New Relic One user model and have user management roles assigned. If you're on our original user model (or otherwise can't seem to implement this feature), talk to your New Relic account representative. Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM 2.0 standard. Supported identity providers: Okta, Azure AD, OneLogin. For unsupported identity providers, we have a SCIM API. Notes on initial enabling of AUM: We don't currently support toggling SCIM on or off. If an authentication domain has already been set up with the source of users as Manual, you can't change it to SCIM. When first enabled, the bearer token is generated and only shown once. If you need to view a bearer token later, the only way to do this is to generate a new one, and that will invalidate the old one and any integrations using the old token. Import user groups from an identity provider using AUM For an explanation of how your identity provider groups map over to New Relic groups, see Group and role mapping. To use automated user management to import users from your identity provider: It's important to first review the requirements. Use the Organization and access UI to enable SCIM and configure SAML SSO. Configure your identity provider using one of our relevant guides:Azure AD | Okta | OneLogin. If you don't use one of those, we also have a SCIM API. Note that your users are created in New Relic as full users. If your organization is on New Relic One pricing, these users are billable. To convert users to free basic users, use the User management UI. Recommended: Set a time zone in your identity provider. If not specified, our UI shows date/times with the UTC time zone. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). If you have issues, contact your account representative. After being provisioned, your users can click on the New Relic SCIM/SSO application tile in their identity provider to be logged into New Relic. To learn more about New Relic's roles and capabilities, see Standard roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 463.24963,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>automated</em> <em>user</em> management (AUM) and single-sign on (SSO)",
        "sections": "Introduction to <em>automated</em> <em>user</em> management (AUM) and single-sign on (SSO)",
        "tags": "<em>Automated</em> <em>user</em> management",
        "body": "New Relic lets you set up <em>automated</em> <em>user</em> management (AUM), which allows you to import, update, and deactivate your New Relic <em>users</em> from your identity provider. Once this <em>automated</em> <em>provisioning</em> is complete, your <em>users</em> can log in to New Relic via their identity provider. Requirements Requirements"
      },
      "id": "6043d60e64441ff8f5378f37"
    }
  ],
  "/docs/plugins/index": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-05-05T16:28:21Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 73.22304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs <em>plugin</em> licenses",
        "sections": "<em>Plugins</em> for Logs",
        "body": "We love open-source software, and use the following in the New Relic Logs <em>plugins</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the licenses"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic One CLI reference",
        "Installing the New Relic One CLI",
        "Tip",
        "New Relic One CLI Commands",
        "Get started",
        "Configure your CLI preferences",
        "Set up your Nerdpacks",
        "Manage your Nerdpack subscriptions",
        "Install and manage plugins",
        "Manage catalog information"
      ],
      "title": "New Relic One CLI reference",
      "type": "developer",
      "tags": [
        "New Relic One app",
        "nerdpack commands"
      ],
      "external_id": "858339a44ead21c83257778ce60b4c352cd30d3b",
      "image": "https://developer.newrelic.com/static/2c6d337608b38a3312b4fc740afe6167/7272b/developercenter.png",
      "url": "https://developer.newrelic.com/explore-docs/nr1-cli/",
      "published_at": "2021-05-07T01:42:20Z",
      "updated_at": "2021-05-05T01:53:28Z",
      "document_type": "page",
      "popularity": 1,
      "info": "An overview of the CLI to help you build, deploy, and manage New Relic apps.",
      "body": "To build a New Relic One app, you must install the New Relic One CLI. The CLI helps you build, publish, and manage your New Relic app. We provide a variety of tools for building apps, including the New Relic One CLI (command line interface). This page explains how to use CLI commands to: Generate Nerdpack/Nerdlet templates Locally serve Nerdpacks (when developing) Publish and deploy Subscribe to Nerdpacks Add screenshots and metadata to the catalog Installing the New Relic One CLI In New Relic, click Apps and then in the New Relic One catalog area, click the Build your own application launcher and follow the quick start instructions. The quick start automatically generates an API key for the account you select, and gives you the pre-populated commands to create a profile, generate your first \"Hello World\" app, and serve it locally. Tip Use the NR1 VS Code extension to build your apps. New Relic One CLI Commands This table provides descriptions for the New Relic One commands. For more context, including usage and option details, click any individual command or the command category. For details on user permissions, see Permissions. For more on how to serve and publish your application, see our guide on Deploying your New Relic One app. Get started nr1 help Shows all nr1 commands or details about each command. nr1 update Updates to the latest version of the CLI. nr1 create Creates a new component from a template (Nerdpack, Nerdlet, launcher, or catalog). nr1 profiles Manages the profiles you use to run CLI commands. nr1 autocomplete Displays autocomplete installation instructions. nr1 nrql Fetches data using NRQL (New Relic query language). Configure your CLI preferences nr1 config:set Sets a specific configuration value. nr1 config:get Shows a specific configuration. nr1 config:list Lists your configuration choices. nr1 config:delete Removes the value of a specific configuration. Set up your Nerdpacks nr1 nerdpack:build Assembles your Nerdpack into bundles. nr1 nerdpack:clone Clones an open source Nerdpack from our GitHub repository. nr1 nerdpack:serve Serves your Nerdpack for testing and development purposes. nr1 nerdpack:uuid Shows or regenerates the UUID of a Nerdpack. nr1 nerdpack:publish Publishes your Nerdpack to New Relic. nr1 nerdpack:deploy Deploys a Nerdpack version to a specific channel. nr1 nerdpack:undeploy Undeploys a Nerdpack version from a specific channel. nr1 nerdpack:clean Cleans your developtment folders. nr1 nerdpack:validate Validates the contents of your Nerdpack. nr1 nerdpack:info Shows the state of your Nerdpack in the New Relic's registry. Manage your Nerdpack subscriptions nr1 subscription:set Subscribes your account to a Nerdpack and channel. nr1 subscription:list Lists all the Nerdpacks your account is subscribed to. nr1 subscription:unset Unsubscribes your account from a Nerdpack. Install and manage plugins nr1 plugins:install Installs a plugin into the CLI. nr1 plugins:link Links a plugin into the CLI for development. nr1 plugins:update Updates your installed plugins. nr1 plugins:uninstall Removes a plugin from the CLI. Manage catalog information nr1 catalog:info Shows the Nerdpack info stored in the catalog. nr1 catalog:submit Gathers and submits the catalog info on the current folder.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 67.38588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Install and manage <em>plugins</em>",
        "body": " to a Nerdpack and channel. nr1 subscription:list Lists all the Nerdpacks your account is subscribed to. nr1 subscription:unset Unsubscribes your account from a Nerdpack. Install and manage <em>plugins</em> nr1 <em>plugins</em>:install Installs a <em>plugin</em> into the CLI. nr1 <em>plugins</em>:link Links a <em>plugin</em> into the CLI for development"
      },
      "id": "6091fa9864441feb412f36d4"
    },
    {
      "sections": [
        "Maintain plugin versions",
        "Important",
        "Limited access to legacy plugins",
        "Plugin agents and dashboards",
        "Agent versioning",
        "Update a SaaS agent",
        "Update an on-premises agent",
        "Update plugin dashboards"
      ],
      "title": "Maintain plugin versions",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "70efb125146afeda3c6e672e6c9b0e769ce4eb37",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/maintain-plugin-versions/",
      "published_at": "2021-05-03T06:32:45Z",
      "updated_at": "2021-03-16T11:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Plugin agents and dashboards As a plugin publisher, typically you need to have two versions of your plugin running simultaneously: The stable production version that users can acquire from Plugin Central in New Relic A development version that you are actively improving, testing, or otherwise have in a non-production state Plugins contain two versioned parts: The agent collects metrics from the source and transmits those metrics to the Plugin API. The dashboard is a collection of visualizations and configurations that you make in the Plugins user interface. Plugin users view this automatically from their own Plugins dashboards in New Relic. Versioning works differently for these two parts. Agent versioning There are two types of plugin agents, with two different versioning situations: SaaS agents are agents that you, the SaaS application developer, deploy and run on behalf of your SaaS users. On-premises agents are agents that your users install into their systems. Plugin agents Versioning SaaS agents There is only one copy of this agent running anywhere (the one you developed and deployed on behalf of your users), so whatever version you are running will inherently be the latest version. Whatever metrics the latest version is sending to New Relic will be the metrics available to (but not necessarily charted for) your users in their Plugins dashboards. On-premises agents When you publish a new version of your agent, all of your plugin users' dashboards will note that a new agent version is available. They will be directed to your Plugin Central listing, where they can download and install the new version of your agent. Recommendation: Provide a streamlined agent update procedure in your own documentation. Update a SaaS agent This procedure assumes: You are starting with a plugin published to the Plugin Central (the production version). Your plugin has a SaaS agent running inside your app, and you want to make improvements to the SaaS agent portion of your plugin. As part of your normal development process you have a second dev version of your agent running, which is not published in Plugin Central. Your plugin's dev version uses a different GUID (for example, com.company.service.plugin.dev). Both your dev and your production plugins have the same plugin dashboards. To update your plugin's SaaS agent: Make changes to your dev agent. Do not change the version number or GUID of your dev agent in the agent config file. When you are ready to make your latest dev agent the production agent for your customers, follow your standard procedures to deploy your dev code to production. If applicable, make any necessary changes to your plugin's dashboards. Your users will receive no notification, and they do not need to take any action. You didn't change the version number, so your agent changes are transparent to your users. Update an on-premises agent This procedure assumes you are starting with a plugin published in Plugin Central, and you want to make improvements to the on-premises agent portion of your plugin. Make a copy of your agent code. Change the version number in the agent config file. To ensure that New Relic knows two different versions of your agent exist now, run the agent so that it reports metrics to the Plugin API. Continue working on your agent and making improvements, but do not change the version number again. When you are ready to make this new agent version the latest version for your plugin users, save it to the location where you distribute your agent code (for example, GitHub). From the New Relic UI, select your published plugin, select Edit, and then select Save. Select Publish, and then select the new agent version you are publishing. At this point, all of your plugin users will see a notice in the Plugins UI that a new version is available. They will be directed to your listing in Plugin Central, which points to your download location. From there your users can acquire your new agent version. Update plugin dashboards If you add metrics to your agent, be sure to add them to charts on your dashboard, and then save your dashboard and re-publish. All your users will see the new dashboard, and the new metrics will either be populated immediately (if you are running a SaaS agent on their behalf) or as soon as they update their agent (if you are offering an on-premises agent). If you need to migrate dashboards between GUIDs, get help at support.newrelic.com. Otherwise, to update your dashboard, follow this workflow. These steps assume you are starting with a plugin already published in Plugin Central, and you want to make improvements to the dashboard portion of your plugin. Go to one.newrelic.com > More > Plugins, and select your plugin's name. From your plugin's summary page, select Edit > Dashboards, then add, edit, or delete dashboards. When you are ready to publish: From your plugin's summary page, select Publish. At this point, all of your plugin users will see your new dashboard version the next time they select your plugin's dashboard in the New Relic UI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 59.440746,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Maintain <em>plugin</em> versions",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugins</em>",
        "body": " to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy <em>plugins</em> As of December 2, 2020, <em>plugin</em> access has been limited to accounts that have accessed a legacy <em>plugin</em> in the past 30 days. The legacy <em>plugin</em> experience will reach end of life (EoL"
      },
      "id": "603e956fe7b9d28f062a07b5"
    }
  ],
  "/docs/plugins/plugin-developer-resources/develop-plugins/checklist-developing-plugins": [
    {
      "sections": [
        "Maintain plugin versions",
        "Important",
        "Limited access to legacy plugins",
        "Plugin agents and dashboards",
        "Agent versioning",
        "Update a SaaS agent",
        "Update an on-premises agent",
        "Update plugin dashboards"
      ],
      "title": "Maintain plugin versions",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "70efb125146afeda3c6e672e6c9b0e769ce4eb37",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/maintain-plugin-versions/",
      "published_at": "2021-05-03T06:32:45Z",
      "updated_at": "2021-03-16T11:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Plugin agents and dashboards As a plugin publisher, typically you need to have two versions of your plugin running simultaneously: The stable production version that users can acquire from Plugin Central in New Relic A development version that you are actively improving, testing, or otherwise have in a non-production state Plugins contain two versioned parts: The agent collects metrics from the source and transmits those metrics to the Plugin API. The dashboard is a collection of visualizations and configurations that you make in the Plugins user interface. Plugin users view this automatically from their own Plugins dashboards in New Relic. Versioning works differently for these two parts. Agent versioning There are two types of plugin agents, with two different versioning situations: SaaS agents are agents that you, the SaaS application developer, deploy and run on behalf of your SaaS users. On-premises agents are agents that your users install into their systems. Plugin agents Versioning SaaS agents There is only one copy of this agent running anywhere (the one you developed and deployed on behalf of your users), so whatever version you are running will inherently be the latest version. Whatever metrics the latest version is sending to New Relic will be the metrics available to (but not necessarily charted for) your users in their Plugins dashboards. On-premises agents When you publish a new version of your agent, all of your plugin users' dashboards will note that a new agent version is available. They will be directed to your Plugin Central listing, where they can download and install the new version of your agent. Recommendation: Provide a streamlined agent update procedure in your own documentation. Update a SaaS agent This procedure assumes: You are starting with a plugin published to the Plugin Central (the production version). Your plugin has a SaaS agent running inside your app, and you want to make improvements to the SaaS agent portion of your plugin. As part of your normal development process you have a second dev version of your agent running, which is not published in Plugin Central. Your plugin's dev version uses a different GUID (for example, com.company.service.plugin.dev). Both your dev and your production plugins have the same plugin dashboards. To update your plugin's SaaS agent: Make changes to your dev agent. Do not change the version number or GUID of your dev agent in the agent config file. When you are ready to make your latest dev agent the production agent for your customers, follow your standard procedures to deploy your dev code to production. If applicable, make any necessary changes to your plugin's dashboards. Your users will receive no notification, and they do not need to take any action. You didn't change the version number, so your agent changes are transparent to your users. Update an on-premises agent This procedure assumes you are starting with a plugin published in Plugin Central, and you want to make improvements to the on-premises agent portion of your plugin. Make a copy of your agent code. Change the version number in the agent config file. To ensure that New Relic knows two different versions of your agent exist now, run the agent so that it reports metrics to the Plugin API. Continue working on your agent and making improvements, but do not change the version number again. When you are ready to make this new agent version the latest version for your plugin users, save it to the location where you distribute your agent code (for example, GitHub). From the New Relic UI, select your published plugin, select Edit, and then select Save. Select Publish, and then select the new agent version you are publishing. At this point, all of your plugin users will see a notice in the Plugins UI that a new version is available. They will be directed to your listing in Plugin Central, which points to your download location. From there your users can acquire your new agent version. Update plugin dashboards If you add metrics to your agent, be sure to add them to charts on your dashboard, and then save your dashboard and re-publish. All your users will see the new dashboard, and the new metrics will either be populated immediately (if you are running a SaaS agent on their behalf) or as soon as they update their agent (if you are offering an on-premises agent). If you need to migrate dashboards between GUIDs, get help at support.newrelic.com. Otherwise, to update your dashboard, follow this workflow. These steps assume you are starting with a plugin already published in Plugin Central, and you want to make improvements to the dashboard portion of your plugin. Go to one.newrelic.com > More > Plugins, and select your plugin's name. From your plugin's summary page, select Edit > Dashboards, then add, edit, or delete dashboards. When you are ready to publish: From your plugin's summary page, select Publish. At this point, all of your plugin users will see your new dashboard version the next time they select your plugin's dashboard in the New Relic UI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.24716,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Maintain <em>plugin</em> versions",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603e956fe7b9d28f062a07b5"
    },
    {
      "sections": [
        "Use the New Relic Platform Installer (NPI) utility",
        "Important",
        "Limited access to legacy plugins",
        "NPI compatibility requirements",
        "Distribution",
        "NPI command line utility",
        "Updates",
        "Privately-published plugins"
      ],
      "title": "Use the New Relic Platform Installer (NPI) utility",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "a8a5c308f1e4f69ea801fd595bc7b679ae5eaac9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/use-new-relic-platform-installer-npi-utility/",
      "published_at": "2021-05-03T06:33:05Z",
      "updated_at": "2021-03-16T11:00:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. NPI compatibility requirements The New Relic Platform Installer (NPI) is a command line utility for plugins in Plugin Central. It allows users to easily download, configure, and manage a plugin by installing it with a single command. The NPI is available for plugins written with Java or .NET plugin SDKs. If you are a plugin developer, follow these steps to meet the NPI requirements for a consistent installation experience, and publish your plugin in Plugin Central as NPI Compatible. In order to make your plugin NPI-compatible, make sure it meets each of these requirements: NPI compatibility Requirements Writing your plugin Java: See the Java SDK README file in GitHub for plugins. .NET: See the .NET SDK README file in GitHub for plugins. Packaging Use the tar.gz or zip compression protocol to package your plugin. Executable Name the executable file plugin.jar (for Java) or plugin.exe (for .NET), and store it in the root of your plugin folder. Code Do not use any relative references in your code. Configuration files Create a ./config directory containing a plugin.template.json file and a newrelic.template.json file. Make sure that plugin configuration is read from the plugin.json file in the ./config directory. For more information, refer to the README in GitHub. Distribution Once your plugin is NPI-compatible from a code perspective, place it somewhere that is accessible for consumers to download. For example, add the compressed distributable to a dist folder in your GitHub repository. When your plugin is ready for distribution, follow standard procedures to publish it in Plugin Central. Be sure to select the Platform Installer (NPI) distribution option. NPI command line utility When users select an NPI Compatible plugin from Plugin Central, they also have the option to download the NPI tool. The tool allows users to easily download, configure, and manage a plugin. They can also use a series of commands to manage their plugins or pass the --help flag for more information about available options. Updates After you create and publish an NPI-compatible plugin, follow standard procedures to update it as needed. Then, when you publish the updated plugin, the NPI tool automatically will pick up your most current version for users who have installed your NPI-compatible plugin. Privately-published plugins In general, the NPI tool will try to pull download (manifest) information from New Relic's Plugins service. You can also provide a file named manifest.json in the config directory of your NPI installation to provide this information. Use this file format: [ { \"guid\": \"arbitrary_identifier\", \"download_url\": \"https://plugin.download.url.com\", \"publisher\": \"New Relic Inc.\", \"version\": \"1.0.1\", \"installer_compatible\": true, \"implementation\": \"Java\" }, { \"guid\": \"arbitrary_identifier2\", \"download_url\": \"https://plugin2.download.url.com\", \"publisher\": \"New Relic Inc.\", \"version\": \"2.0.0\", \"installer_compatible\": true, \"implementation\": \".NET\" } ] Copy After you set this up, you can run all the same commands with your private plugin's GUID. To install or fetch a plugin, you must pass the --untrusted flag to allow downloading plugins from a local file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.23785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": " command. The NPI is available for <em>plugins</em> written with Java or .NET <em>plugin</em> SDKs. If you are a <em>plugin</em> <em>developer</em>, follow these steps to meet the NPI requirements for a consistent installation experience, and publish your <em>plugin</em> in <em>Plugin</em> Central as NPI Compatible. In order to make your <em>plugin</em> NPI-compatible"
      },
      "id": "603eae7c28ccbc8e3ceba799"
    },
    {
      "sections": [
        "Create a plugin",
        "Important",
        "Limited access to legacy plugins",
        "Plugin SDKs",
        "Chef and Puppet installation templates",
        "Multiple agents example",
        "Define hosts and ports in YAML",
        "Edit the plugin code",
        "Create summary metrics",
        "SaaS developer plugins",
        "New Relic license key",
        "Metric reporting",
        "Example: Multiple accounts",
        "Example: Single account",
        "Additional publisher details",
        "View plugin usage"
      ],
      "title": "Create a plugin",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "7700a7def38cbe3fc9a77293305519d73c747f41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/create-plugin/",
      "published_at": "2021-05-04T22:23:25Z",
      "updated_at": "2021-03-16T11:00:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Plugin SDKs To get started with writing a plugin agent that generates example metric data, refer to the README files in GitHub for the Plugin agent SDK, including: Java .NET Ruby Chef and Puppet installation templates After developing a plugin with a plugin SDK, you can use Chef and Puppet installation scripts. This makes plugin installation easier from Plugin Central in New Relic, especially when your plugin has required runtime dependencies, such as Java or Ruby. Managing plugins with user permissions and startup scripts also is easier. Several Chef and Puppet installation scripts have been written for supported plugins. You can use these Chef recipes and Puppet manifests as templates for other plugins. For more information about installation scripts for plugins in Plugin Central, see: Chef cookbook for New Relic Puppet module for New Relic Multiple agents example This is an example of how to configure your plugin to create multiple agents with different configurations. In this example: The plugin is called Wikipedia. Wikipedia has 3 hosts: English, Spanish, and German. Each host uses a different port in New Relic Plugins. Define hosts and ports in YAML Edit your YAML configuration file to include a list of entries for the component (instance) as a collection of block sequences. For example: agents: wikipedia - hostname: en.wikipedia.org port: 80 - hostname: sp.wikipedia.org port: 81 - hostname: de.wikipedia.org port: 82 Copy Edit the plugin code Edit your plugin code to identify specific options; for example, names, hostnames, ports, etc.: agent_human_labels(\"Wikipedia\") { \"Wikipedia on #{hostname} on port # {port}\" } agent_config_options :hostname, :port Copy Create summary metrics Within your plugin's setup_metrics method, the symbols referenced in the agent_config_options are available as local variables. You can view the summary metrics in the user interface, create one or more dashboards, and continue editing your plugin. SaaS developer plugins The Plugin API is useful when you need to: Use a programming language not supported by the plugin SDKs. Write plugins to in-house standards or as part of a larger running application. Report metrics for a large number of individual accounts. The Plugin API can be used by plugin developers to POST metrics for multiple components (instances) directly to the New Relic collectors using JSON. Each POST typically is consumed by the collector in under 3ms, so this is a very fast way to send large amounts of metric data. New Relic license key In order to provide your customers with New Relic metrics via your plugin, you must have access to the New Relic license key for each individual account. You can capture this information when provisioning new customers via the New Relic Partner API, or you can provide a mechanism whereby customers can share their existing New Relic license key with you. Metric reporting Once you have access to the New Relic license key, your plugin can use the Plugin API to POST metrics for multiple components (instances) using JSON. You should POST metrics for each of your accounts to New Relic no more frequently than every 60 seconds and no less than every 300 seconds. Multiple components (instances) can include multiple metrics within a single POST, corresponding to a particular New Relic account. You can provide metrics for your SaaS users that cover many database components, web server components, cache components, message queue components, etc. Example: Multiple accounts Here is an example of the steps to follow in order to report plugin metrics for a collection of accounts: # Ruby language example # Define the Plugin API endpoint URL url = URI.parse(\"https://platform-api.newrelic.com/platform/v1/metrics\") # Assuming the Account model has a scope that provides all accounts # having a New Relic license key, fetch those accounts and iterate # over them to POST the metrics to New Relic Plugins Account.with_new_relic_license.each do |account| # Prepare an HTTP POST request request = Net::HTTP::Post.new(url.request_uri) # Set the BODY to the JSON structure containing the metrics request.body = account.gather_new_relic_metrics.as_json # Set the required headers request.add_field('X-License-Key', account.new_relic_license_key) request.add_field('Content-Type', 'application/json') request.delete('accept') # Need to remove the default 'Accept: */*' request.add_field('Accept', 'application/json') # Post the metric data to the New Relic Servers response = Net::HTTP.new(url.host, url.port).start do |http| http.request(request) end # Test for success success = JSON.parse(response.body)['status'] == 'ok' end Copy Example: Single account Here is a large JSON data example showing what could be sent to New Relic Plugins via HTTP POST for a single licensee. This example contains multiple metrics for multiple components or instances for a single plugin. This example represents a sample size of 60 seconds. { \"agent\": { \"host\" : \"host.service_name.com\", \"pid\" : 1234, \"version\" : \"1.0.0\" }, \"components\": [ { \"name\": \"Database Server\", \"guid\": \"com.saas_company_name.postgresql\", \"duration\" : 60, \"metrics\" : { \"Component/Connections/Bytes received[bytes/sec]\" : 200, \"Component/Connections/Bytes sent[bytes/sec]\" : 30, \"Component/Queries/Query rate[Queries/sec]\" : 10 } }, { \"name\": \"Cache Server\", \"guid\": \"com.saas_company_name.memcached\", \"duration\" : 60, \"metrics\" : { \"Component/Cache/Writes[count]\" : 220, \"Component/Cache/Hits[count]\" : 300, \"Component/Cache/Misses[count]\" : 100, \"Component/Cache/Memory/Used[bytes]\" : 1000, \"Component/Cache/Memory/Free[bytes]\" : 10 } }, { \"name\": \"Message Queue\", \"guid\": \"com.saas_company_name.sidekiq\", \"duration\" : 60, \"metrics\" : { \"Component/Jobs/Queued[count]\" : 2000, \"Component/Jobs/Running[count]\" : 100, \"Component/Jobs/Failed[count]\" : 10, \"Component/Jobs/Processed[count]\" : 1000000 } } ] } Copy Additional publisher details Once your plugin has reported some data, you can edit it to include: Your publisher (organization) name Link to your website landing page Link to your support page URL to a branding image Detailed description of the plugin When publishing your plugin, the Type of download field offers options for a file download or website URL. SaaS providers can enter their website landing page URL. View plugin usage After you publish your plugin, New Relic will update usage data about accounts and components or instances every 24 hours, including: Number of accounts using your plugin Components or instances that are reporting data Review comments Ratings Plugins that are publicly published in Plugin Central will have more details in the Usage dashboard than unlisted (privately published) ones. In addition to providing a central location to examine review comments and ratings, the Usage dashboard is useful for verifying public information about the plugin, including the download link and a shortcut link to Plugin Central. Anyone on the authoring account can view the published plugin's Usage dashboard. Go to one.newrelic.com > More > Plugins, and select the plugin's name or icon. From the plugin's Summary page, select Usage.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.23785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create a <em>plugin</em>",
        "sections": "SaaS <em>developer</em> <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": " <em>plugin</em>&#x27;s setup_metrics method, the symbols referenced in the agent_config_options are available as local variables. You can view the summary metrics in the user interface, create one or more dashboards, and continue editing your <em>plugin</em>. SaaS <em>developer</em> <em>plugins</em> The <em>Plugin</em> API is useful when you need"
      },
      "id": "603e9450196a67c29ca83d9a"
    }
  ],
  "/docs/plugins/plugin-developer-resources/develop-plugins/create-plugin": [
    {
      "sections": [
        "Maintain plugin versions",
        "Important",
        "Limited access to legacy plugins",
        "Plugin agents and dashboards",
        "Agent versioning",
        "Update a SaaS agent",
        "Update an on-premises agent",
        "Update plugin dashboards"
      ],
      "title": "Maintain plugin versions",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "70efb125146afeda3c6e672e6c9b0e769ce4eb37",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/maintain-plugin-versions/",
      "published_at": "2021-05-03T06:32:45Z",
      "updated_at": "2021-03-16T11:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Plugin agents and dashboards As a plugin publisher, typically you need to have two versions of your plugin running simultaneously: The stable production version that users can acquire from Plugin Central in New Relic A development version that you are actively improving, testing, or otherwise have in a non-production state Plugins contain two versioned parts: The agent collects metrics from the source and transmits those metrics to the Plugin API. The dashboard is a collection of visualizations and configurations that you make in the Plugins user interface. Plugin users view this automatically from their own Plugins dashboards in New Relic. Versioning works differently for these two parts. Agent versioning There are two types of plugin agents, with two different versioning situations: SaaS agents are agents that you, the SaaS application developer, deploy and run on behalf of your SaaS users. On-premises agents are agents that your users install into their systems. Plugin agents Versioning SaaS agents There is only one copy of this agent running anywhere (the one you developed and deployed on behalf of your users), so whatever version you are running will inherently be the latest version. Whatever metrics the latest version is sending to New Relic will be the metrics available to (but not necessarily charted for) your users in their Plugins dashboards. On-premises agents When you publish a new version of your agent, all of your plugin users' dashboards will note that a new agent version is available. They will be directed to your Plugin Central listing, where they can download and install the new version of your agent. Recommendation: Provide a streamlined agent update procedure in your own documentation. Update a SaaS agent This procedure assumes: You are starting with a plugin published to the Plugin Central (the production version). Your plugin has a SaaS agent running inside your app, and you want to make improvements to the SaaS agent portion of your plugin. As part of your normal development process you have a second dev version of your agent running, which is not published in Plugin Central. Your plugin's dev version uses a different GUID (for example, com.company.service.plugin.dev). Both your dev and your production plugins have the same plugin dashboards. To update your plugin's SaaS agent: Make changes to your dev agent. Do not change the version number or GUID of your dev agent in the agent config file. When you are ready to make your latest dev agent the production agent for your customers, follow your standard procedures to deploy your dev code to production. If applicable, make any necessary changes to your plugin's dashboards. Your users will receive no notification, and they do not need to take any action. You didn't change the version number, so your agent changes are transparent to your users. Update an on-premises agent This procedure assumes you are starting with a plugin published in Plugin Central, and you want to make improvements to the on-premises agent portion of your plugin. Make a copy of your agent code. Change the version number in the agent config file. To ensure that New Relic knows two different versions of your agent exist now, run the agent so that it reports metrics to the Plugin API. Continue working on your agent and making improvements, but do not change the version number again. When you are ready to make this new agent version the latest version for your plugin users, save it to the location where you distribute your agent code (for example, GitHub). From the New Relic UI, select your published plugin, select Edit, and then select Save. Select Publish, and then select the new agent version you are publishing. At this point, all of your plugin users will see a notice in the Plugins UI that a new version is available. They will be directed to your listing in Plugin Central, which points to your download location. From there your users can acquire your new agent version. Update plugin dashboards If you add metrics to your agent, be sure to add them to charts on your dashboard, and then save your dashboard and re-publish. All your users will see the new dashboard, and the new metrics will either be populated immediately (if you are running a SaaS agent on their behalf) or as soon as they update their agent (if you are offering an on-premises agent). If you need to migrate dashboards between GUIDs, get help at support.newrelic.com. Otherwise, to update your dashboard, follow this workflow. These steps assume you are starting with a plugin already published in Plugin Central, and you want to make improvements to the dashboard portion of your plugin. Go to one.newrelic.com > More > Plugins, and select your plugin's name. From your plugin's summary page, select Edit > Dashboards, then add, edit, or delete dashboards. When you are ready to publish: From your plugin's summary page, select Publish. At this point, all of your plugin users will see your new dashboard version the next time they select your plugin's dashboard in the New Relic UI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.24716,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Maintain <em>plugin</em> versions",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603e956fe7b9d28f062a07b5"
    },
    {
      "sections": [
        "Checklist for developing plugins",
        "Important",
        "Limited access to legacy plugins",
        "Plan your plugin",
        "Create your plugin",
        "Publish your plugin",
        "Documentation",
        "\"About us\" URL",
        "Branding image URL",
        "Developer terms of service",
        "Publication",
        "Versions",
        "Plugin support",
        "Support for your plugin users",
        "Escalated plugin support"
      ],
      "title": "Checklist for developing plugins",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "c60d87c25a2c835d2b7e44340bddb678117ddd07",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/checklist-developing-plugins/",
      "published_at": "2021-05-03T06:33:12Z",
      "updated_at": "2021-03-16T11:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Plan your plugin When planning your plugin for Plugin Central: Sketch the types of metrics you want to collect and how you want to present them on dashboards. Include any necessary mathematical calculations. Sketch the types of summary metrics you want to collect and how you want to present them on the plugin's summary page. Include any necessary mathematical calculations. Optional: Define alert conditions for your metrics. Optional: If you want to receive alert notifications for your plugin, verify the email address to be used and confirm any other notification options as necessary. Decide whether to develop the plugin with one of the plugin SDKs or to use the Plugin API. Create your plugin When creating your plugin for Plugin Central: Select a unique, meaningful GUID name. Write the plugin agent. Test your plugin, including summary metrics, customized dashboards, alert conditions, and your process to disable or uninstall your plugin. Consider writing Chef and Puppet installation scripts to make plugin installation easier. Publish your plugin The following items are required for plugins published through New Relic's Plugin Central. If you do not plan to make your plugin publicly accessible to users, some of these items are not applicable. Documentation When documenting your plugin, include requirements and procedures to install, configure, use, troubleshoot, uninstall, and contact your support resources. Documentation requirements Guidelines Title Descriptive title; for example, \"Wikipedia plugin for New Relic.\" Table of contents List of main topics with anchors to each section. Description Explanation of how the plugin can be used in New Relic to monitor and improve the associated software's performance. What systems does it monitor (for example, memcache, versions X-Y, on the local host, sets and gets)? What problem does it solve? Plugin requirements Requirements or dependencies; for example: Internet access via SSL (HTTPS) Supported operating systems Minimum environment requirements (Java, Ruby, glibc, etc.) Supported monitored systems Any known limitations Metrics source documentation Plugin users may not be familiar with all the metrics displayed, their source, what the metrics mean, etc. If you have documentation that provides these details, be sure to include links to that information. For example: Description of data expected from source, frequency, mechanism, etc.; for example, \"Data is read from a file socket and exported from the source once per second.\") Description of data itself; for example, a well-formatted JSON such as {X: {y: z}} Description of data being sent; for example, average response time in milliseconds, of a set or get, taken over a minute, recorded from the specified data Installation Step-by-step procedures to obtain and install the plugin. Do not require su or sudo permission in order to install your agent or support software unless absolutely required. These requirements must be limited in scope and well documented. Configuration Instructions to configure the plugin, expected format, and how to set them. Include how to find the user's New Relic license key. Troubleshooting Include instructions as applicable; for example: How to resolve common problems: Unable to connect to New Relic, unable to connect to the monitored server, incorrect license key How to enable logging or verbose logging How to restart the plugin How to test connectivity to New Relic How to handle errors; for example, failure to read, aggregate, or send data Disabling and uninstalling Questions to consider: Are there other dependencies before disabling or uninstalling the plugin? For example, are there any special procedures your plugin users need to know in order to have their operating system stop the process from running, so that they can remove components (instances) from their installed plugin? Can you temporarily disable and then re-enable the plugin (for example, for troubleshooting or updating it), or must you completely uninstall and reinstall? Can the uninstall procedure be done from a command line? Support resources Make a plan for supporting your plugin and identifying a support URL for users. In your plugin's support information, describe how users can contact you for support in whatever way works best for you: documentation website, phone, email, forum, Twitter, ticketing system, etc. \"About us\" URL Identify the About Us URL for your plugin. Branding image URL Identify a URL to a branding image for when you publish your plugin. Follow these formatting guidelines: Set the image size to 64 x 64px. Save as a .png or .gif file. Use transparency for the background unless it is a square icon. Design the image to display well on both white and black backgrounds. Developer terms of service Review the Developer Terms of Service for New Relic Plugins. A link to this document appears on your plugin's Publish page in the UI. Publication Plugin Central is the repository of plugins available in New Relic. If you want to distribute your plugin through Plugin Central, make sure your documentation and support plans are in place, then select your plugin's Publish option in the New Relic UI. The Publish page in the UI prompts you to verify all requirements. As soon as your plugin is published, all of its dashboards and summary metrics are available for your plugin users. The Distribution method identifies how users can obtain your plugin from Plugin Central. File download: Most developers typically select this option for plugin setup and installation. Webpage link: SaaS providers typically select this option for plugin configuration and identify their website's landing page URL. Platform Installer (NPI): If you use the New Relic Platform Installer (NPI) command line utility to package your plugin, select this option. You can also publish a plugin without listing it in Plugin Central; for example, if you want to beta test it first, or if you only want specific users to be able to use it. When publishing an unlisted plugin, make sure the checkbox option in the UI for List this plugin in Plugin Central is not selected. You will need to communicate directly with your users when your unlisted plugin is added, updated, or removed. Versions You can update and re-publish your plugin as often as you want. Every time you publish changes to your plugin and list them in Plugin Central, the changes are immediately visible in Plugin Central. In addition, your published plugin changes typically appear in New Relic's website within five minutes. Recommendation: To avoid development and testing impacts on your users, maintain dev and production versions when updating your plugin. Plugin support Plugin publishers are responsible for providing first-line support if users have problems using their plugin. This includes verifying correct data acquisition and transmission. If problems continue with getting the expected data into New Relic's user interface after you complete your troubleshooting procedures, then you (not your users) can escalate the problem to New Relic. We will work with you to resolve the problem, and then you can communicate the solution to your users. Support for your plugin users Follow these guidelines for supporting your plugin's users by confirming data collection and transmission. Check that the plugin configuration is correct, including: Necessary credentials for the target system IP addresses or DNS names for the target system Any settings that might affect data acquisition Review transmission logs for errors, including: Authentication errors Connection errors Error responses from the target system Review transaction logs for useful data. How much data is being collected? Does the data make sense? Verify if the plugin is converting acquired data into useful metrics. Do the metrics make sense? Would the metrics make a good chart? Are the metrics being aggregated into valid JSON? Is the JSON size within limits? Confirm transmission of the plugin data. If you are using an SDK for New Relic Plugins and the Plugin API, does your data transmission conform to New Relic's rate limits? Are the 50X codes sporadic or continuous? Do your transaction logs indicate any data transmission problems? Escalated plugin support If you have verified good data acquisition and transmission, but there still is trouble getting the expected data in New Relic's user interface, escalate the support request to New Relic on behalf of your users. Do not have your users contact us. Include as much of the following information as possible: Plugin support requests Notes User affected by the problem Information such as: Permalink to the plugin page where you see the problem, so that we can view the endpoint. Recommendation: Ask the user if you can add your user ID to the New Relic account so that you can obtain a permalink yourself. User's New Relic account ID. If you do not have the user's permalink or account ID, include the user's email address they used to sign up for their New Relic account. (This may be a different email than the one they used to contact you.) User's name and New Relic account name. Detailed description of the problem For example: The user can see data, but it's not the data they are expecting. The user can see no data at all. The user configured and started the plugin correctly, but it does not appear in the user interface for New Relic Plugins. Any other specific details about the problem. Other evidence This includes: Explain the troubleshooting you have done so far and what you expected to happen in contrast to the actual results. Provide any available permalinks, screenshots, and log files. Summarize your understanding of the problem. We will work with you to characterize and resolve the problem. Keep the user updated with progress. After we provide you with a resolution, ask the user to verify the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.24716,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Checklist for <em>developing</em> <em>plugins</em>",
        "sections": "Checklist for <em>developing</em> <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": " white and black backgrounds. <em>Developer</em> terms of service Review the <em>Developer</em> Terms of Service for New Relic <em>Plugins</em>. A link to this document appears on your <em>plugin</em>&#x27;s Publish page in the UI. Publication <em>Plugin</em> Central is the repository of <em>plugins</em> available in New Relic. If you want to distribute your"
      },
      "id": "603ec26f64441fe6484e885f"
    },
    {
      "sections": [
        "Use the New Relic Platform Installer (NPI) utility",
        "Important",
        "Limited access to legacy plugins",
        "NPI compatibility requirements",
        "Distribution",
        "NPI command line utility",
        "Updates",
        "Privately-published plugins"
      ],
      "title": "Use the New Relic Platform Installer (NPI) utility",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "a8a5c308f1e4f69ea801fd595bc7b679ae5eaac9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/use-new-relic-platform-installer-npi-utility/",
      "published_at": "2021-05-03T06:33:05Z",
      "updated_at": "2021-03-16T11:00:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. NPI compatibility requirements The New Relic Platform Installer (NPI) is a command line utility for plugins in Plugin Central. It allows users to easily download, configure, and manage a plugin by installing it with a single command. The NPI is available for plugins written with Java or .NET plugin SDKs. If you are a plugin developer, follow these steps to meet the NPI requirements for a consistent installation experience, and publish your plugin in Plugin Central as NPI Compatible. In order to make your plugin NPI-compatible, make sure it meets each of these requirements: NPI compatibility Requirements Writing your plugin Java: See the Java SDK README file in GitHub for plugins. .NET: See the .NET SDK README file in GitHub for plugins. Packaging Use the tar.gz or zip compression protocol to package your plugin. Executable Name the executable file plugin.jar (for Java) or plugin.exe (for .NET), and store it in the root of your plugin folder. Code Do not use any relative references in your code. Configuration files Create a ./config directory containing a plugin.template.json file and a newrelic.template.json file. Make sure that plugin configuration is read from the plugin.json file in the ./config directory. For more information, refer to the README in GitHub. Distribution Once your plugin is NPI-compatible from a code perspective, place it somewhere that is accessible for consumers to download. For example, add the compressed distributable to a dist folder in your GitHub repository. When your plugin is ready for distribution, follow standard procedures to publish it in Plugin Central. Be sure to select the Platform Installer (NPI) distribution option. NPI command line utility When users select an NPI Compatible plugin from Plugin Central, they also have the option to download the NPI tool. The tool allows users to easily download, configure, and manage a plugin. They can also use a series of commands to manage their plugins or pass the --help flag for more information about available options. Updates After you create and publish an NPI-compatible plugin, follow standard procedures to update it as needed. Then, when you publish the updated plugin, the NPI tool automatically will pick up your most current version for users who have installed your NPI-compatible plugin. Privately-published plugins In general, the NPI tool will try to pull download (manifest) information from New Relic's Plugins service. You can also provide a file named manifest.json in the config directory of your NPI installation to provide this information. Use this file format: [ { \"guid\": \"arbitrary_identifier\", \"download_url\": \"https://plugin.download.url.com\", \"publisher\": \"New Relic Inc.\", \"version\": \"1.0.1\", \"installer_compatible\": true, \"implementation\": \"Java\" }, { \"guid\": \"arbitrary_identifier2\", \"download_url\": \"https://plugin2.download.url.com\", \"publisher\": \"New Relic Inc.\", \"version\": \"2.0.0\", \"installer_compatible\": true, \"implementation\": \".NET\" } ] Copy After you set this up, you can run all the same commands with your private plugin's GUID. To install or fetch a plugin, you must pass the --untrusted flag to allow downloading plugins from a local file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.23785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": " command. The NPI is available for <em>plugins</em> written with Java or .NET <em>plugin</em> SDKs. If you are a <em>plugin</em> <em>developer</em>, follow these steps to meet the NPI requirements for a consistent installation experience, and publish your <em>plugin</em> in <em>Plugin</em> Central as NPI Compatible. In order to make your <em>plugin</em> NPI-compatible"
      },
      "id": "603eae7c28ccbc8e3ceba799"
    }
  ],
  "/docs/plugins/plugin-developer-resources/develop-plugins/maintain-plugin-versions": [
    {
      "sections": [
        "Checklist for developing plugins",
        "Important",
        "Limited access to legacy plugins",
        "Plan your plugin",
        "Create your plugin",
        "Publish your plugin",
        "Documentation",
        "\"About us\" URL",
        "Branding image URL",
        "Developer terms of service",
        "Publication",
        "Versions",
        "Plugin support",
        "Support for your plugin users",
        "Escalated plugin support"
      ],
      "title": "Checklist for developing plugins",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "c60d87c25a2c835d2b7e44340bddb678117ddd07",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/checklist-developing-plugins/",
      "published_at": "2021-05-03T06:33:12Z",
      "updated_at": "2021-03-16T11:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Plan your plugin When planning your plugin for Plugin Central: Sketch the types of metrics you want to collect and how you want to present them on dashboards. Include any necessary mathematical calculations. Sketch the types of summary metrics you want to collect and how you want to present them on the plugin's summary page. Include any necessary mathematical calculations. Optional: Define alert conditions for your metrics. Optional: If you want to receive alert notifications for your plugin, verify the email address to be used and confirm any other notification options as necessary. Decide whether to develop the plugin with one of the plugin SDKs or to use the Plugin API. Create your plugin When creating your plugin for Plugin Central: Select a unique, meaningful GUID name. Write the plugin agent. Test your plugin, including summary metrics, customized dashboards, alert conditions, and your process to disable or uninstall your plugin. Consider writing Chef and Puppet installation scripts to make plugin installation easier. Publish your plugin The following items are required for plugins published through New Relic's Plugin Central. If you do not plan to make your plugin publicly accessible to users, some of these items are not applicable. Documentation When documenting your plugin, include requirements and procedures to install, configure, use, troubleshoot, uninstall, and contact your support resources. Documentation requirements Guidelines Title Descriptive title; for example, \"Wikipedia plugin for New Relic.\" Table of contents List of main topics with anchors to each section. Description Explanation of how the plugin can be used in New Relic to monitor and improve the associated software's performance. What systems does it monitor (for example, memcache, versions X-Y, on the local host, sets and gets)? What problem does it solve? Plugin requirements Requirements or dependencies; for example: Internet access via SSL (HTTPS) Supported operating systems Minimum environment requirements (Java, Ruby, glibc, etc.) Supported monitored systems Any known limitations Metrics source documentation Plugin users may not be familiar with all the metrics displayed, their source, what the metrics mean, etc. If you have documentation that provides these details, be sure to include links to that information. For example: Description of data expected from source, frequency, mechanism, etc.; for example, \"Data is read from a file socket and exported from the source once per second.\") Description of data itself; for example, a well-formatted JSON such as {X: {y: z}} Description of data being sent; for example, average response time in milliseconds, of a set or get, taken over a minute, recorded from the specified data Installation Step-by-step procedures to obtain and install the plugin. Do not require su or sudo permission in order to install your agent or support software unless absolutely required. These requirements must be limited in scope and well documented. Configuration Instructions to configure the plugin, expected format, and how to set them. Include how to find the user's New Relic license key. Troubleshooting Include instructions as applicable; for example: How to resolve common problems: Unable to connect to New Relic, unable to connect to the monitored server, incorrect license key How to enable logging or verbose logging How to restart the plugin How to test connectivity to New Relic How to handle errors; for example, failure to read, aggregate, or send data Disabling and uninstalling Questions to consider: Are there other dependencies before disabling or uninstalling the plugin? For example, are there any special procedures your plugin users need to know in order to have their operating system stop the process from running, so that they can remove components (instances) from their installed plugin? Can you temporarily disable and then re-enable the plugin (for example, for troubleshooting or updating it), or must you completely uninstall and reinstall? Can the uninstall procedure be done from a command line? Support resources Make a plan for supporting your plugin and identifying a support URL for users. In your plugin's support information, describe how users can contact you for support in whatever way works best for you: documentation website, phone, email, forum, Twitter, ticketing system, etc. \"About us\" URL Identify the About Us URL for your plugin. Branding image URL Identify a URL to a branding image for when you publish your plugin. Follow these formatting guidelines: Set the image size to 64 x 64px. Save as a .png or .gif file. Use transparency for the background unless it is a square icon. Design the image to display well on both white and black backgrounds. Developer terms of service Review the Developer Terms of Service for New Relic Plugins. A link to this document appears on your plugin's Publish page in the UI. Publication Plugin Central is the repository of plugins available in New Relic. If you want to distribute your plugin through Plugin Central, make sure your documentation and support plans are in place, then select your plugin's Publish option in the New Relic UI. The Publish page in the UI prompts you to verify all requirements. As soon as your plugin is published, all of its dashboards and summary metrics are available for your plugin users. The Distribution method identifies how users can obtain your plugin from Plugin Central. File download: Most developers typically select this option for plugin setup and installation. Webpage link: SaaS providers typically select this option for plugin configuration and identify their website's landing page URL. Platform Installer (NPI): If you use the New Relic Platform Installer (NPI) command line utility to package your plugin, select this option. You can also publish a plugin without listing it in Plugin Central; for example, if you want to beta test it first, or if you only want specific users to be able to use it. When publishing an unlisted plugin, make sure the checkbox option in the UI for List this plugin in Plugin Central is not selected. You will need to communicate directly with your users when your unlisted plugin is added, updated, or removed. Versions You can update and re-publish your plugin as often as you want. Every time you publish changes to your plugin and list them in Plugin Central, the changes are immediately visible in Plugin Central. In addition, your published plugin changes typically appear in New Relic's website within five minutes. Recommendation: To avoid development and testing impacts on your users, maintain dev and production versions when updating your plugin. Plugin support Plugin publishers are responsible for providing first-line support if users have problems using their plugin. This includes verifying correct data acquisition and transmission. If problems continue with getting the expected data into New Relic's user interface after you complete your troubleshooting procedures, then you (not your users) can escalate the problem to New Relic. We will work with you to resolve the problem, and then you can communicate the solution to your users. Support for your plugin users Follow these guidelines for supporting your plugin's users by confirming data collection and transmission. Check that the plugin configuration is correct, including: Necessary credentials for the target system IP addresses or DNS names for the target system Any settings that might affect data acquisition Review transmission logs for errors, including: Authentication errors Connection errors Error responses from the target system Review transaction logs for useful data. How much data is being collected? Does the data make sense? Verify if the plugin is converting acquired data into useful metrics. Do the metrics make sense? Would the metrics make a good chart? Are the metrics being aggregated into valid JSON? Is the JSON size within limits? Confirm transmission of the plugin data. If you are using an SDK for New Relic Plugins and the Plugin API, does your data transmission conform to New Relic's rate limits? Are the 50X codes sporadic or continuous? Do your transaction logs indicate any data transmission problems? Escalated plugin support If you have verified good data acquisition and transmission, but there still is trouble getting the expected data in New Relic's user interface, escalate the support request to New Relic on behalf of your users. Do not have your users contact us. Include as much of the following information as possible: Plugin support requests Notes User affected by the problem Information such as: Permalink to the plugin page where you see the problem, so that we can view the endpoint. Recommendation: Ask the user if you can add your user ID to the New Relic account so that you can obtain a permalink yourself. User's New Relic account ID. If you do not have the user's permalink or account ID, include the user's email address they used to sign up for their New Relic account. (This may be a different email than the one they used to contact you.) User's name and New Relic account name. Detailed description of the problem For example: The user can see data, but it's not the data they are expecting. The user can see no data at all. The user configured and started the plugin correctly, but it does not appear in the user interface for New Relic Plugins. Any other specific details about the problem. Other evidence This includes: Explain the troubleshooting you have done so far and what you expected to happen in contrast to the actual results. Provide any available permalinks, screenshots, and log files. Summarize your understanding of the problem. We will work with you to characterize and resolve the problem. Keep the user updated with progress. After we provide you with a resolution, ask the user to verify the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.24716,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Checklist for <em>developing</em> <em>plugins</em>",
        "sections": "Checklist for <em>developing</em> <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": " white and black backgrounds. <em>Developer</em> terms of service Review the <em>Developer</em> Terms of Service for New Relic <em>Plugins</em>. A link to this document appears on your <em>plugin</em>&#x27;s Publish page in the UI. Publication <em>Plugin</em> Central is the repository of <em>plugins</em> available in New Relic. If you want to distribute your"
      },
      "id": "603ec26f64441fe6484e885f"
    },
    {
      "sections": [
        "Use the New Relic Platform Installer (NPI) utility",
        "Important",
        "Limited access to legacy plugins",
        "NPI compatibility requirements",
        "Distribution",
        "NPI command line utility",
        "Updates",
        "Privately-published plugins"
      ],
      "title": "Use the New Relic Platform Installer (NPI) utility",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "a8a5c308f1e4f69ea801fd595bc7b679ae5eaac9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/use-new-relic-platform-installer-npi-utility/",
      "published_at": "2021-05-03T06:33:05Z",
      "updated_at": "2021-03-16T11:00:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. NPI compatibility requirements The New Relic Platform Installer (NPI) is a command line utility for plugins in Plugin Central. It allows users to easily download, configure, and manage a plugin by installing it with a single command. The NPI is available for plugins written with Java or .NET plugin SDKs. If you are a plugin developer, follow these steps to meet the NPI requirements for a consistent installation experience, and publish your plugin in Plugin Central as NPI Compatible. In order to make your plugin NPI-compatible, make sure it meets each of these requirements: NPI compatibility Requirements Writing your plugin Java: See the Java SDK README file in GitHub for plugins. .NET: See the .NET SDK README file in GitHub for plugins. Packaging Use the tar.gz or zip compression protocol to package your plugin. Executable Name the executable file plugin.jar (for Java) or plugin.exe (for .NET), and store it in the root of your plugin folder. Code Do not use any relative references in your code. Configuration files Create a ./config directory containing a plugin.template.json file and a newrelic.template.json file. Make sure that plugin configuration is read from the plugin.json file in the ./config directory. For more information, refer to the README in GitHub. Distribution Once your plugin is NPI-compatible from a code perspective, place it somewhere that is accessible for consumers to download. For example, add the compressed distributable to a dist folder in your GitHub repository. When your plugin is ready for distribution, follow standard procedures to publish it in Plugin Central. Be sure to select the Platform Installer (NPI) distribution option. NPI command line utility When users select an NPI Compatible plugin from Plugin Central, they also have the option to download the NPI tool. The tool allows users to easily download, configure, and manage a plugin. They can also use a series of commands to manage their plugins or pass the --help flag for more information about available options. Updates After you create and publish an NPI-compatible plugin, follow standard procedures to update it as needed. Then, when you publish the updated plugin, the NPI tool automatically will pick up your most current version for users who have installed your NPI-compatible plugin. Privately-published plugins In general, the NPI tool will try to pull download (manifest) information from New Relic's Plugins service. You can also provide a file named manifest.json in the config directory of your NPI installation to provide this information. Use this file format: [ { \"guid\": \"arbitrary_identifier\", \"download_url\": \"https://plugin.download.url.com\", \"publisher\": \"New Relic Inc.\", \"version\": \"1.0.1\", \"installer_compatible\": true, \"implementation\": \"Java\" }, { \"guid\": \"arbitrary_identifier2\", \"download_url\": \"https://plugin2.download.url.com\", \"publisher\": \"New Relic Inc.\", \"version\": \"2.0.0\", \"installer_compatible\": true, \"implementation\": \".NET\" } ] Copy After you set this up, you can run all the same commands with your private plugin's GUID. To install or fetch a plugin, you must pass the --untrusted flag to allow downloading plugins from a local file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.23785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": " command. The NPI is available for <em>plugins</em> written with Java or .NET <em>plugin</em> SDKs. If you are a <em>plugin</em> <em>developer</em>, follow these steps to meet the NPI requirements for a consistent installation experience, and publish your <em>plugin</em> in <em>Plugin</em> Central as NPI Compatible. In order to make your <em>plugin</em> NPI-compatible"
      },
      "id": "603eae7c28ccbc8e3ceba799"
    },
    {
      "sections": [
        "Create a plugin",
        "Important",
        "Limited access to legacy plugins",
        "Plugin SDKs",
        "Chef and Puppet installation templates",
        "Multiple agents example",
        "Define hosts and ports in YAML",
        "Edit the plugin code",
        "Create summary metrics",
        "SaaS developer plugins",
        "New Relic license key",
        "Metric reporting",
        "Example: Multiple accounts",
        "Example: Single account",
        "Additional publisher details",
        "View plugin usage"
      ],
      "title": "Create a plugin",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "7700a7def38cbe3fc9a77293305519d73c747f41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/create-plugin/",
      "published_at": "2021-05-04T22:23:25Z",
      "updated_at": "2021-03-16T11:00:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Plugin SDKs To get started with writing a plugin agent that generates example metric data, refer to the README files in GitHub for the Plugin agent SDK, including: Java .NET Ruby Chef and Puppet installation templates After developing a plugin with a plugin SDK, you can use Chef and Puppet installation scripts. This makes plugin installation easier from Plugin Central in New Relic, especially when your plugin has required runtime dependencies, such as Java or Ruby. Managing plugins with user permissions and startup scripts also is easier. Several Chef and Puppet installation scripts have been written for supported plugins. You can use these Chef recipes and Puppet manifests as templates for other plugins. For more information about installation scripts for plugins in Plugin Central, see: Chef cookbook for New Relic Puppet module for New Relic Multiple agents example This is an example of how to configure your plugin to create multiple agents with different configurations. In this example: The plugin is called Wikipedia. Wikipedia has 3 hosts: English, Spanish, and German. Each host uses a different port in New Relic Plugins. Define hosts and ports in YAML Edit your YAML configuration file to include a list of entries for the component (instance) as a collection of block sequences. For example: agents: wikipedia - hostname: en.wikipedia.org port: 80 - hostname: sp.wikipedia.org port: 81 - hostname: de.wikipedia.org port: 82 Copy Edit the plugin code Edit your plugin code to identify specific options; for example, names, hostnames, ports, etc.: agent_human_labels(\"Wikipedia\") { \"Wikipedia on #{hostname} on port # {port}\" } agent_config_options :hostname, :port Copy Create summary metrics Within your plugin's setup_metrics method, the symbols referenced in the agent_config_options are available as local variables. You can view the summary metrics in the user interface, create one or more dashboards, and continue editing your plugin. SaaS developer plugins The Plugin API is useful when you need to: Use a programming language not supported by the plugin SDKs. Write plugins to in-house standards or as part of a larger running application. Report metrics for a large number of individual accounts. The Plugin API can be used by plugin developers to POST metrics for multiple components (instances) directly to the New Relic collectors using JSON. Each POST typically is consumed by the collector in under 3ms, so this is a very fast way to send large amounts of metric data. New Relic license key In order to provide your customers with New Relic metrics via your plugin, you must have access to the New Relic license key for each individual account. You can capture this information when provisioning new customers via the New Relic Partner API, or you can provide a mechanism whereby customers can share their existing New Relic license key with you. Metric reporting Once you have access to the New Relic license key, your plugin can use the Plugin API to POST metrics for multiple components (instances) using JSON. You should POST metrics for each of your accounts to New Relic no more frequently than every 60 seconds and no less than every 300 seconds. Multiple components (instances) can include multiple metrics within a single POST, corresponding to a particular New Relic account. You can provide metrics for your SaaS users that cover many database components, web server components, cache components, message queue components, etc. Example: Multiple accounts Here is an example of the steps to follow in order to report plugin metrics for a collection of accounts: # Ruby language example # Define the Plugin API endpoint URL url = URI.parse(\"https://platform-api.newrelic.com/platform/v1/metrics\") # Assuming the Account model has a scope that provides all accounts # having a New Relic license key, fetch those accounts and iterate # over them to POST the metrics to New Relic Plugins Account.with_new_relic_license.each do |account| # Prepare an HTTP POST request request = Net::HTTP::Post.new(url.request_uri) # Set the BODY to the JSON structure containing the metrics request.body = account.gather_new_relic_metrics.as_json # Set the required headers request.add_field('X-License-Key', account.new_relic_license_key) request.add_field('Content-Type', 'application/json') request.delete('accept') # Need to remove the default 'Accept: */*' request.add_field('Accept', 'application/json') # Post the metric data to the New Relic Servers response = Net::HTTP.new(url.host, url.port).start do |http| http.request(request) end # Test for success success = JSON.parse(response.body)['status'] == 'ok' end Copy Example: Single account Here is a large JSON data example showing what could be sent to New Relic Plugins via HTTP POST for a single licensee. This example contains multiple metrics for multiple components or instances for a single plugin. This example represents a sample size of 60 seconds. { \"agent\": { \"host\" : \"host.service_name.com\", \"pid\" : 1234, \"version\" : \"1.0.0\" }, \"components\": [ { \"name\": \"Database Server\", \"guid\": \"com.saas_company_name.postgresql\", \"duration\" : 60, \"metrics\" : { \"Component/Connections/Bytes received[bytes/sec]\" : 200, \"Component/Connections/Bytes sent[bytes/sec]\" : 30, \"Component/Queries/Query rate[Queries/sec]\" : 10 } }, { \"name\": \"Cache Server\", \"guid\": \"com.saas_company_name.memcached\", \"duration\" : 60, \"metrics\" : { \"Component/Cache/Writes[count]\" : 220, \"Component/Cache/Hits[count]\" : 300, \"Component/Cache/Misses[count]\" : 100, \"Component/Cache/Memory/Used[bytes]\" : 1000, \"Component/Cache/Memory/Free[bytes]\" : 10 } }, { \"name\": \"Message Queue\", \"guid\": \"com.saas_company_name.sidekiq\", \"duration\" : 60, \"metrics\" : { \"Component/Jobs/Queued[count]\" : 2000, \"Component/Jobs/Running[count]\" : 100, \"Component/Jobs/Failed[count]\" : 10, \"Component/Jobs/Processed[count]\" : 1000000 } } ] } Copy Additional publisher details Once your plugin has reported some data, you can edit it to include: Your publisher (organization) name Link to your website landing page Link to your support page URL to a branding image Detailed description of the plugin When publishing your plugin, the Type of download field offers options for a file download or website URL. SaaS providers can enter their website landing page URL. View plugin usage After you publish your plugin, New Relic will update usage data about accounts and components or instances every 24 hours, including: Number of accounts using your plugin Components or instances that are reporting data Review comments Ratings Plugins that are publicly published in Plugin Central will have more details in the Usage dashboard than unlisted (privately published) ones. In addition to providing a central location to examine review comments and ratings, the Usage dashboard is useful for verifying public information about the plugin, including the download link and a shortcut link to Plugin Central. Anyone on the authoring account can view the published plugin's Usage dashboard. Go to one.newrelic.com > More > Plugins, and select the plugin's name or icon. From the plugin's Summary page, select Usage.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.23785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create a <em>plugin</em>",
        "sections": "SaaS <em>developer</em> <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": " <em>plugin</em>&#x27;s setup_metrics method, the symbols referenced in the agent_config_options are available as local variables. You can view the summary metrics in the user interface, create one or more dashboards, and continue editing your <em>plugin</em>. SaaS <em>developer</em> <em>plugins</em> The <em>Plugin</em> API is useful when you need"
      },
      "id": "603e9450196a67c29ca83d9a"
    }
  ],
  "/docs/plugins/plugin-developer-resources/develop-plugins/plugin-summary-metrics-dashboards": [
    {
      "sections": [
        "Maintain plugin versions",
        "Important",
        "Limited access to legacy plugins",
        "Plugin agents and dashboards",
        "Agent versioning",
        "Update a SaaS agent",
        "Update an on-premises agent",
        "Update plugin dashboards"
      ],
      "title": "Maintain plugin versions",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "70efb125146afeda3c6e672e6c9b0e769ce4eb37",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/maintain-plugin-versions/",
      "published_at": "2021-05-03T06:32:45Z",
      "updated_at": "2021-03-16T11:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Plugin agents and dashboards As a plugin publisher, typically you need to have two versions of your plugin running simultaneously: The stable production version that users can acquire from Plugin Central in New Relic A development version that you are actively improving, testing, or otherwise have in a non-production state Plugins contain two versioned parts: The agent collects metrics from the source and transmits those metrics to the Plugin API. The dashboard is a collection of visualizations and configurations that you make in the Plugins user interface. Plugin users view this automatically from their own Plugins dashboards in New Relic. Versioning works differently for these two parts. Agent versioning There are two types of plugin agents, with two different versioning situations: SaaS agents are agents that you, the SaaS application developer, deploy and run on behalf of your SaaS users. On-premises agents are agents that your users install into their systems. Plugin agents Versioning SaaS agents There is only one copy of this agent running anywhere (the one you developed and deployed on behalf of your users), so whatever version you are running will inherently be the latest version. Whatever metrics the latest version is sending to New Relic will be the metrics available to (but not necessarily charted for) your users in their Plugins dashboards. On-premises agents When you publish a new version of your agent, all of your plugin users' dashboards will note that a new agent version is available. They will be directed to your Plugin Central listing, where they can download and install the new version of your agent. Recommendation: Provide a streamlined agent update procedure in your own documentation. Update a SaaS agent This procedure assumes: You are starting with a plugin published to the Plugin Central (the production version). Your plugin has a SaaS agent running inside your app, and you want to make improvements to the SaaS agent portion of your plugin. As part of your normal development process you have a second dev version of your agent running, which is not published in Plugin Central. Your plugin's dev version uses a different GUID (for example, com.company.service.plugin.dev). Both your dev and your production plugins have the same plugin dashboards. To update your plugin's SaaS agent: Make changes to your dev agent. Do not change the version number or GUID of your dev agent in the agent config file. When you are ready to make your latest dev agent the production agent for your customers, follow your standard procedures to deploy your dev code to production. If applicable, make any necessary changes to your plugin's dashboards. Your users will receive no notification, and they do not need to take any action. You didn't change the version number, so your agent changes are transparent to your users. Update an on-premises agent This procedure assumes you are starting with a plugin published in Plugin Central, and you want to make improvements to the on-premises agent portion of your plugin. Make a copy of your agent code. Change the version number in the agent config file. To ensure that New Relic knows two different versions of your agent exist now, run the agent so that it reports metrics to the Plugin API. Continue working on your agent and making improvements, but do not change the version number again. When you are ready to make this new agent version the latest version for your plugin users, save it to the location where you distribute your agent code (for example, GitHub). From the New Relic UI, select your published plugin, select Edit, and then select Save. Select Publish, and then select the new agent version you are publishing. At this point, all of your plugin users will see a notice in the Plugins UI that a new version is available. They will be directed to your listing in Plugin Central, which points to your download location. From there your users can acquire your new agent version. Update plugin dashboards If you add metrics to your agent, be sure to add them to charts on your dashboard, and then save your dashboard and re-publish. All your users will see the new dashboard, and the new metrics will either be populated immediately (if you are running a SaaS agent on their behalf) or as soon as they update their agent (if you are offering an on-premises agent). If you need to migrate dashboards between GUIDs, get help at support.newrelic.com. Otherwise, to update your dashboard, follow this workflow. These steps assume you are starting with a plugin already published in Plugin Central, and you want to make improvements to the dashboard portion of your plugin. Go to one.newrelic.com > More > Plugins, and select your plugin's name. From your plugin's summary page, select Edit > Dashboards, then add, edit, or delete dashboards. When you are ready to publish: From your plugin's summary page, select Publish. At this point, all of your plugin users will see your new dashboard version the next time they select your plugin's dashboard in the New Relic UI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.24713,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Maintain <em>plugin</em> versions",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603e956fe7b9d28f062a07b5"
    },
    {
      "sections": [
        "Checklist for developing plugins",
        "Important",
        "Limited access to legacy plugins",
        "Plan your plugin",
        "Create your plugin",
        "Publish your plugin",
        "Documentation",
        "\"About us\" URL",
        "Branding image URL",
        "Developer terms of service",
        "Publication",
        "Versions",
        "Plugin support",
        "Support for your plugin users",
        "Escalated plugin support"
      ],
      "title": "Checklist for developing plugins",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "c60d87c25a2c835d2b7e44340bddb678117ddd07",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/checklist-developing-plugins/",
      "published_at": "2021-05-03T06:33:12Z",
      "updated_at": "2021-03-16T11:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Plan your plugin When planning your plugin for Plugin Central: Sketch the types of metrics you want to collect and how you want to present them on dashboards. Include any necessary mathematical calculations. Sketch the types of summary metrics you want to collect and how you want to present them on the plugin's summary page. Include any necessary mathematical calculations. Optional: Define alert conditions for your metrics. Optional: If you want to receive alert notifications for your plugin, verify the email address to be used and confirm any other notification options as necessary. Decide whether to develop the plugin with one of the plugin SDKs or to use the Plugin API. Create your plugin When creating your plugin for Plugin Central: Select a unique, meaningful GUID name. Write the plugin agent. Test your plugin, including summary metrics, customized dashboards, alert conditions, and your process to disable or uninstall your plugin. Consider writing Chef and Puppet installation scripts to make plugin installation easier. Publish your plugin The following items are required for plugins published through New Relic's Plugin Central. If you do not plan to make your plugin publicly accessible to users, some of these items are not applicable. Documentation When documenting your plugin, include requirements and procedures to install, configure, use, troubleshoot, uninstall, and contact your support resources. Documentation requirements Guidelines Title Descriptive title; for example, \"Wikipedia plugin for New Relic.\" Table of contents List of main topics with anchors to each section. Description Explanation of how the plugin can be used in New Relic to monitor and improve the associated software's performance. What systems does it monitor (for example, memcache, versions X-Y, on the local host, sets and gets)? What problem does it solve? Plugin requirements Requirements or dependencies; for example: Internet access via SSL (HTTPS) Supported operating systems Minimum environment requirements (Java, Ruby, glibc, etc.) Supported monitored systems Any known limitations Metrics source documentation Plugin users may not be familiar with all the metrics displayed, their source, what the metrics mean, etc. If you have documentation that provides these details, be sure to include links to that information. For example: Description of data expected from source, frequency, mechanism, etc.; for example, \"Data is read from a file socket and exported from the source once per second.\") Description of data itself; for example, a well-formatted JSON such as {X: {y: z}} Description of data being sent; for example, average response time in milliseconds, of a set or get, taken over a minute, recorded from the specified data Installation Step-by-step procedures to obtain and install the plugin. Do not require su or sudo permission in order to install your agent or support software unless absolutely required. These requirements must be limited in scope and well documented. Configuration Instructions to configure the plugin, expected format, and how to set them. Include how to find the user's New Relic license key. Troubleshooting Include instructions as applicable; for example: How to resolve common problems: Unable to connect to New Relic, unable to connect to the monitored server, incorrect license key How to enable logging or verbose logging How to restart the plugin How to test connectivity to New Relic How to handle errors; for example, failure to read, aggregate, or send data Disabling and uninstalling Questions to consider: Are there other dependencies before disabling or uninstalling the plugin? For example, are there any special procedures your plugin users need to know in order to have their operating system stop the process from running, so that they can remove components (instances) from their installed plugin? Can you temporarily disable and then re-enable the plugin (for example, for troubleshooting or updating it), or must you completely uninstall and reinstall? Can the uninstall procedure be done from a command line? Support resources Make a plan for supporting your plugin and identifying a support URL for users. In your plugin's support information, describe how users can contact you for support in whatever way works best for you: documentation website, phone, email, forum, Twitter, ticketing system, etc. \"About us\" URL Identify the About Us URL for your plugin. Branding image URL Identify a URL to a branding image for when you publish your plugin. Follow these formatting guidelines: Set the image size to 64 x 64px. Save as a .png or .gif file. Use transparency for the background unless it is a square icon. Design the image to display well on both white and black backgrounds. Developer terms of service Review the Developer Terms of Service for New Relic Plugins. A link to this document appears on your plugin's Publish page in the UI. Publication Plugin Central is the repository of plugins available in New Relic. If you want to distribute your plugin through Plugin Central, make sure your documentation and support plans are in place, then select your plugin's Publish option in the New Relic UI. The Publish page in the UI prompts you to verify all requirements. As soon as your plugin is published, all of its dashboards and summary metrics are available for your plugin users. The Distribution method identifies how users can obtain your plugin from Plugin Central. File download: Most developers typically select this option for plugin setup and installation. Webpage link: SaaS providers typically select this option for plugin configuration and identify their website's landing page URL. Platform Installer (NPI): If you use the New Relic Platform Installer (NPI) command line utility to package your plugin, select this option. You can also publish a plugin without listing it in Plugin Central; for example, if you want to beta test it first, or if you only want specific users to be able to use it. When publishing an unlisted plugin, make sure the checkbox option in the UI for List this plugin in Plugin Central is not selected. You will need to communicate directly with your users when your unlisted plugin is added, updated, or removed. Versions You can update and re-publish your plugin as often as you want. Every time you publish changes to your plugin and list them in Plugin Central, the changes are immediately visible in Plugin Central. In addition, your published plugin changes typically appear in New Relic's website within five minutes. Recommendation: To avoid development and testing impacts on your users, maintain dev and production versions when updating your plugin. Plugin support Plugin publishers are responsible for providing first-line support if users have problems using their plugin. This includes verifying correct data acquisition and transmission. If problems continue with getting the expected data into New Relic's user interface after you complete your troubleshooting procedures, then you (not your users) can escalate the problem to New Relic. We will work with you to resolve the problem, and then you can communicate the solution to your users. Support for your plugin users Follow these guidelines for supporting your plugin's users by confirming data collection and transmission. Check that the plugin configuration is correct, including: Necessary credentials for the target system IP addresses or DNS names for the target system Any settings that might affect data acquisition Review transmission logs for errors, including: Authentication errors Connection errors Error responses from the target system Review transaction logs for useful data. How much data is being collected? Does the data make sense? Verify if the plugin is converting acquired data into useful metrics. Do the metrics make sense? Would the metrics make a good chart? Are the metrics being aggregated into valid JSON? Is the JSON size within limits? Confirm transmission of the plugin data. If you are using an SDK for New Relic Plugins and the Plugin API, does your data transmission conform to New Relic's rate limits? Are the 50X codes sporadic or continuous? Do your transaction logs indicate any data transmission problems? Escalated plugin support If you have verified good data acquisition and transmission, but there still is trouble getting the expected data in New Relic's user interface, escalate the support request to New Relic on behalf of your users. Do not have your users contact us. Include as much of the following information as possible: Plugin support requests Notes User affected by the problem Information such as: Permalink to the plugin page where you see the problem, so that we can view the endpoint. Recommendation: Ask the user if you can add your user ID to the New Relic account so that you can obtain a permalink yourself. User's New Relic account ID. If you do not have the user's permalink or account ID, include the user's email address they used to sign up for their New Relic account. (This may be a different email than the one they used to contact you.) User's name and New Relic account name. Detailed description of the problem For example: The user can see data, but it's not the data they are expecting. The user can see no data at all. The user configured and started the plugin correctly, but it does not appear in the user interface for New Relic Plugins. Any other specific details about the problem. Other evidence This includes: Explain the troubleshooting you have done so far and what you expected to happen in contrast to the actual results. Provide any available permalinks, screenshots, and log files. Summarize your understanding of the problem. We will work with you to characterize and resolve the problem. Keep the user updated with progress. After we provide you with a resolution, ask the user to verify the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.24713,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Checklist for <em>developing</em> <em>plugins</em>",
        "sections": "Checklist for <em>developing</em> <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": " white and black backgrounds. <em>Developer</em> terms of service Review the <em>Developer</em> Terms of Service for New Relic <em>Plugins</em>. A link to this document appears on your <em>plugin</em>&#x27;s Publish page in the UI. Publication <em>Plugin</em> Central is the repository of <em>plugins</em> available in New Relic. If you want to distribute your"
      },
      "id": "603ec26f64441fe6484e885f"
    },
    {
      "sections": [
        "Use the New Relic Platform Installer (NPI) utility",
        "Important",
        "Limited access to legacy plugins",
        "NPI compatibility requirements",
        "Distribution",
        "NPI command line utility",
        "Updates",
        "Privately-published plugins"
      ],
      "title": "Use the New Relic Platform Installer (NPI) utility",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "a8a5c308f1e4f69ea801fd595bc7b679ae5eaac9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/use-new-relic-platform-installer-npi-utility/",
      "published_at": "2021-05-03T06:33:05Z",
      "updated_at": "2021-03-16T11:00:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. NPI compatibility requirements The New Relic Platform Installer (NPI) is a command line utility for plugins in Plugin Central. It allows users to easily download, configure, and manage a plugin by installing it with a single command. The NPI is available for plugins written with Java or .NET plugin SDKs. If you are a plugin developer, follow these steps to meet the NPI requirements for a consistent installation experience, and publish your plugin in Plugin Central as NPI Compatible. In order to make your plugin NPI-compatible, make sure it meets each of these requirements: NPI compatibility Requirements Writing your plugin Java: See the Java SDK README file in GitHub for plugins. .NET: See the .NET SDK README file in GitHub for plugins. Packaging Use the tar.gz or zip compression protocol to package your plugin. Executable Name the executable file plugin.jar (for Java) or plugin.exe (for .NET), and store it in the root of your plugin folder. Code Do not use any relative references in your code. Configuration files Create a ./config directory containing a plugin.template.json file and a newrelic.template.json file. Make sure that plugin configuration is read from the plugin.json file in the ./config directory. For more information, refer to the README in GitHub. Distribution Once your plugin is NPI-compatible from a code perspective, place it somewhere that is accessible for consumers to download. For example, add the compressed distributable to a dist folder in your GitHub repository. When your plugin is ready for distribution, follow standard procedures to publish it in Plugin Central. Be sure to select the Platform Installer (NPI) distribution option. NPI command line utility When users select an NPI Compatible plugin from Plugin Central, they also have the option to download the NPI tool. The tool allows users to easily download, configure, and manage a plugin. They can also use a series of commands to manage their plugins or pass the --help flag for more information about available options. Updates After you create and publish an NPI-compatible plugin, follow standard procedures to update it as needed. Then, when you publish the updated plugin, the NPI tool automatically will pick up your most current version for users who have installed your NPI-compatible plugin. Privately-published plugins In general, the NPI tool will try to pull download (manifest) information from New Relic's Plugins service. You can also provide a file named manifest.json in the config directory of your NPI installation to provide this information. Use this file format: [ { \"guid\": \"arbitrary_identifier\", \"download_url\": \"https://plugin.download.url.com\", \"publisher\": \"New Relic Inc.\", \"version\": \"1.0.1\", \"installer_compatible\": true, \"implementation\": \"Java\" }, { \"guid\": \"arbitrary_identifier2\", \"download_url\": \"https://plugin2.download.url.com\", \"publisher\": \"New Relic Inc.\", \"version\": \"2.0.0\", \"installer_compatible\": true, \"implementation\": \".NET\" } ] Copy After you set this up, you can run all the same commands with your private plugin's GUID. To install or fetch a plugin, you must pass the --untrusted flag to allow downloading plugins from a local file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.23782,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": " command. The NPI is available for <em>plugins</em> written with Java or .NET <em>plugin</em> SDKs. If you are a <em>plugin</em> <em>developer</em>, follow these steps to meet the NPI requirements for a consistent installation experience, and publish your <em>plugin</em> in <em>Plugin</em> Central as NPI Compatible. In order to make your <em>plugin</em> NPI-compatible"
      },
      "id": "603eae7c28ccbc8e3ceba799"
    }
  ],
  "/docs/plugins/plugin-developer-resources/develop-plugins/use-new-relic-platform-installer-npi-utility": [
    {
      "sections": [
        "Maintain plugin versions",
        "Important",
        "Limited access to legacy plugins",
        "Plugin agents and dashboards",
        "Agent versioning",
        "Update a SaaS agent",
        "Update an on-premises agent",
        "Update plugin dashboards"
      ],
      "title": "Maintain plugin versions",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "70efb125146afeda3c6e672e6c9b0e769ce4eb37",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/maintain-plugin-versions/",
      "published_at": "2021-05-03T06:32:45Z",
      "updated_at": "2021-03-16T11:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Plugin agents and dashboards As a plugin publisher, typically you need to have two versions of your plugin running simultaneously: The stable production version that users can acquire from Plugin Central in New Relic A development version that you are actively improving, testing, or otherwise have in a non-production state Plugins contain two versioned parts: The agent collects metrics from the source and transmits those metrics to the Plugin API. The dashboard is a collection of visualizations and configurations that you make in the Plugins user interface. Plugin users view this automatically from their own Plugins dashboards in New Relic. Versioning works differently for these two parts. Agent versioning There are two types of plugin agents, with two different versioning situations: SaaS agents are agents that you, the SaaS application developer, deploy and run on behalf of your SaaS users. On-premises agents are agents that your users install into their systems. Plugin agents Versioning SaaS agents There is only one copy of this agent running anywhere (the one you developed and deployed on behalf of your users), so whatever version you are running will inherently be the latest version. Whatever metrics the latest version is sending to New Relic will be the metrics available to (but not necessarily charted for) your users in their Plugins dashboards. On-premises agents When you publish a new version of your agent, all of your plugin users' dashboards will note that a new agent version is available. They will be directed to your Plugin Central listing, where they can download and install the new version of your agent. Recommendation: Provide a streamlined agent update procedure in your own documentation. Update a SaaS agent This procedure assumes: You are starting with a plugin published to the Plugin Central (the production version). Your plugin has a SaaS agent running inside your app, and you want to make improvements to the SaaS agent portion of your plugin. As part of your normal development process you have a second dev version of your agent running, which is not published in Plugin Central. Your plugin's dev version uses a different GUID (for example, com.company.service.plugin.dev). Both your dev and your production plugins have the same plugin dashboards. To update your plugin's SaaS agent: Make changes to your dev agent. Do not change the version number or GUID of your dev agent in the agent config file. When you are ready to make your latest dev agent the production agent for your customers, follow your standard procedures to deploy your dev code to production. If applicable, make any necessary changes to your plugin's dashboards. Your users will receive no notification, and they do not need to take any action. You didn't change the version number, so your agent changes are transparent to your users. Update an on-premises agent This procedure assumes you are starting with a plugin published in Plugin Central, and you want to make improvements to the on-premises agent portion of your plugin. Make a copy of your agent code. Change the version number in the agent config file. To ensure that New Relic knows two different versions of your agent exist now, run the agent so that it reports metrics to the Plugin API. Continue working on your agent and making improvements, but do not change the version number again. When you are ready to make this new agent version the latest version for your plugin users, save it to the location where you distribute your agent code (for example, GitHub). From the New Relic UI, select your published plugin, select Edit, and then select Save. Select Publish, and then select the new agent version you are publishing. At this point, all of your plugin users will see a notice in the Plugins UI that a new version is available. They will be directed to your listing in Plugin Central, which points to your download location. From there your users can acquire your new agent version. Update plugin dashboards If you add metrics to your agent, be sure to add them to charts on your dashboard, and then save your dashboard and re-publish. All your users will see the new dashboard, and the new metrics will either be populated immediately (if you are running a SaaS agent on their behalf) or as soon as they update their agent (if you are offering an on-premises agent). If you need to migrate dashboards between GUIDs, get help at support.newrelic.com. Otherwise, to update your dashboard, follow this workflow. These steps assume you are starting with a plugin already published in Plugin Central, and you want to make improvements to the dashboard portion of your plugin. Go to one.newrelic.com > More > Plugins, and select your plugin's name. From your plugin's summary page, select Edit > Dashboards, then add, edit, or delete dashboards. When you are ready to publish: From your plugin's summary page, select Publish. At this point, all of your plugin users will see your new dashboard version the next time they select your plugin's dashboard in the New Relic UI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.24713,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Maintain <em>plugin</em> versions",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603e956fe7b9d28f062a07b5"
    },
    {
      "sections": [
        "Checklist for developing plugins",
        "Important",
        "Limited access to legacy plugins",
        "Plan your plugin",
        "Create your plugin",
        "Publish your plugin",
        "Documentation",
        "\"About us\" URL",
        "Branding image URL",
        "Developer terms of service",
        "Publication",
        "Versions",
        "Plugin support",
        "Support for your plugin users",
        "Escalated plugin support"
      ],
      "title": "Checklist for developing plugins",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "c60d87c25a2c835d2b7e44340bddb678117ddd07",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/checklist-developing-plugins/",
      "published_at": "2021-05-03T06:33:12Z",
      "updated_at": "2021-03-16T11:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Plan your plugin When planning your plugin for Plugin Central: Sketch the types of metrics you want to collect and how you want to present them on dashboards. Include any necessary mathematical calculations. Sketch the types of summary metrics you want to collect and how you want to present them on the plugin's summary page. Include any necessary mathematical calculations. Optional: Define alert conditions for your metrics. Optional: If you want to receive alert notifications for your plugin, verify the email address to be used and confirm any other notification options as necessary. Decide whether to develop the plugin with one of the plugin SDKs or to use the Plugin API. Create your plugin When creating your plugin for Plugin Central: Select a unique, meaningful GUID name. Write the plugin agent. Test your plugin, including summary metrics, customized dashboards, alert conditions, and your process to disable or uninstall your plugin. Consider writing Chef and Puppet installation scripts to make plugin installation easier. Publish your plugin The following items are required for plugins published through New Relic's Plugin Central. If you do not plan to make your plugin publicly accessible to users, some of these items are not applicable. Documentation When documenting your plugin, include requirements and procedures to install, configure, use, troubleshoot, uninstall, and contact your support resources. Documentation requirements Guidelines Title Descriptive title; for example, \"Wikipedia plugin for New Relic.\" Table of contents List of main topics with anchors to each section. Description Explanation of how the plugin can be used in New Relic to monitor and improve the associated software's performance. What systems does it monitor (for example, memcache, versions X-Y, on the local host, sets and gets)? What problem does it solve? Plugin requirements Requirements or dependencies; for example: Internet access via SSL (HTTPS) Supported operating systems Minimum environment requirements (Java, Ruby, glibc, etc.) Supported monitored systems Any known limitations Metrics source documentation Plugin users may not be familiar with all the metrics displayed, their source, what the metrics mean, etc. If you have documentation that provides these details, be sure to include links to that information. For example: Description of data expected from source, frequency, mechanism, etc.; for example, \"Data is read from a file socket and exported from the source once per second.\") Description of data itself; for example, a well-formatted JSON such as {X: {y: z}} Description of data being sent; for example, average response time in milliseconds, of a set or get, taken over a minute, recorded from the specified data Installation Step-by-step procedures to obtain and install the plugin. Do not require su or sudo permission in order to install your agent or support software unless absolutely required. These requirements must be limited in scope and well documented. Configuration Instructions to configure the plugin, expected format, and how to set them. Include how to find the user's New Relic license key. Troubleshooting Include instructions as applicable; for example: How to resolve common problems: Unable to connect to New Relic, unable to connect to the monitored server, incorrect license key How to enable logging or verbose logging How to restart the plugin How to test connectivity to New Relic How to handle errors; for example, failure to read, aggregate, or send data Disabling and uninstalling Questions to consider: Are there other dependencies before disabling or uninstalling the plugin? For example, are there any special procedures your plugin users need to know in order to have their operating system stop the process from running, so that they can remove components (instances) from their installed plugin? Can you temporarily disable and then re-enable the plugin (for example, for troubleshooting or updating it), or must you completely uninstall and reinstall? Can the uninstall procedure be done from a command line? Support resources Make a plan for supporting your plugin and identifying a support URL for users. In your plugin's support information, describe how users can contact you for support in whatever way works best for you: documentation website, phone, email, forum, Twitter, ticketing system, etc. \"About us\" URL Identify the About Us URL for your plugin. Branding image URL Identify a URL to a branding image for when you publish your plugin. Follow these formatting guidelines: Set the image size to 64 x 64px. Save as a .png or .gif file. Use transparency for the background unless it is a square icon. Design the image to display well on both white and black backgrounds. Developer terms of service Review the Developer Terms of Service for New Relic Plugins. A link to this document appears on your plugin's Publish page in the UI. Publication Plugin Central is the repository of plugins available in New Relic. If you want to distribute your plugin through Plugin Central, make sure your documentation and support plans are in place, then select your plugin's Publish option in the New Relic UI. The Publish page in the UI prompts you to verify all requirements. As soon as your plugin is published, all of its dashboards and summary metrics are available for your plugin users. The Distribution method identifies how users can obtain your plugin from Plugin Central. File download: Most developers typically select this option for plugin setup and installation. Webpage link: SaaS providers typically select this option for plugin configuration and identify their website's landing page URL. Platform Installer (NPI): If you use the New Relic Platform Installer (NPI) command line utility to package your plugin, select this option. You can also publish a plugin without listing it in Plugin Central; for example, if you want to beta test it first, or if you only want specific users to be able to use it. When publishing an unlisted plugin, make sure the checkbox option in the UI for List this plugin in Plugin Central is not selected. You will need to communicate directly with your users when your unlisted plugin is added, updated, or removed. Versions You can update and re-publish your plugin as often as you want. Every time you publish changes to your plugin and list them in Plugin Central, the changes are immediately visible in Plugin Central. In addition, your published plugin changes typically appear in New Relic's website within five minutes. Recommendation: To avoid development and testing impacts on your users, maintain dev and production versions when updating your plugin. Plugin support Plugin publishers are responsible for providing first-line support if users have problems using their plugin. This includes verifying correct data acquisition and transmission. If problems continue with getting the expected data into New Relic's user interface after you complete your troubleshooting procedures, then you (not your users) can escalate the problem to New Relic. We will work with you to resolve the problem, and then you can communicate the solution to your users. Support for your plugin users Follow these guidelines for supporting your plugin's users by confirming data collection and transmission. Check that the plugin configuration is correct, including: Necessary credentials for the target system IP addresses or DNS names for the target system Any settings that might affect data acquisition Review transmission logs for errors, including: Authentication errors Connection errors Error responses from the target system Review transaction logs for useful data. How much data is being collected? Does the data make sense? Verify if the plugin is converting acquired data into useful metrics. Do the metrics make sense? Would the metrics make a good chart? Are the metrics being aggregated into valid JSON? Is the JSON size within limits? Confirm transmission of the plugin data. If you are using an SDK for New Relic Plugins and the Plugin API, does your data transmission conform to New Relic's rate limits? Are the 50X codes sporadic or continuous? Do your transaction logs indicate any data transmission problems? Escalated plugin support If you have verified good data acquisition and transmission, but there still is trouble getting the expected data in New Relic's user interface, escalate the support request to New Relic on behalf of your users. Do not have your users contact us. Include as much of the following information as possible: Plugin support requests Notes User affected by the problem Information such as: Permalink to the plugin page where you see the problem, so that we can view the endpoint. Recommendation: Ask the user if you can add your user ID to the New Relic account so that you can obtain a permalink yourself. User's New Relic account ID. If you do not have the user's permalink or account ID, include the user's email address they used to sign up for their New Relic account. (This may be a different email than the one they used to contact you.) User's name and New Relic account name. Detailed description of the problem For example: The user can see data, but it's not the data they are expecting. The user can see no data at all. The user configured and started the plugin correctly, but it does not appear in the user interface for New Relic Plugins. Any other specific details about the problem. Other evidence This includes: Explain the troubleshooting you have done so far and what you expected to happen in contrast to the actual results. Provide any available permalinks, screenshots, and log files. Summarize your understanding of the problem. We will work with you to characterize and resolve the problem. Keep the user updated with progress. After we provide you with a resolution, ask the user to verify the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.24713,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Checklist for <em>developing</em> <em>plugins</em>",
        "sections": "Checklist for <em>developing</em> <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": " white and black backgrounds. <em>Developer</em> terms of service Review the <em>Developer</em> Terms of Service for New Relic <em>Plugins</em>. A link to this document appears on your <em>plugin</em>&#x27;s Publish page in the UI. Publication <em>Plugin</em> Central is the repository of <em>plugins</em> available in New Relic. If you want to distribute your"
      },
      "id": "603ec26f64441fe6484e885f"
    },
    {
      "sections": [
        "Create a plugin",
        "Important",
        "Limited access to legacy plugins",
        "Plugin SDKs",
        "Chef and Puppet installation templates",
        "Multiple agents example",
        "Define hosts and ports in YAML",
        "Edit the plugin code",
        "Create summary metrics",
        "SaaS developer plugins",
        "New Relic license key",
        "Metric reporting",
        "Example: Multiple accounts",
        "Example: Single account",
        "Additional publisher details",
        "View plugin usage"
      ],
      "title": "Create a plugin",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Develop plugins"
      ],
      "external_id": "7700a7def38cbe3fc9a77293305519d73c747f41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/develop-plugins/create-plugin/",
      "published_at": "2021-05-04T22:23:25Z",
      "updated_at": "2021-03-16T11:00:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Plugin SDKs To get started with writing a plugin agent that generates example metric data, refer to the README files in GitHub for the Plugin agent SDK, including: Java .NET Ruby Chef and Puppet installation templates After developing a plugin with a plugin SDK, you can use Chef and Puppet installation scripts. This makes plugin installation easier from Plugin Central in New Relic, especially when your plugin has required runtime dependencies, such as Java or Ruby. Managing plugins with user permissions and startup scripts also is easier. Several Chef and Puppet installation scripts have been written for supported plugins. You can use these Chef recipes and Puppet manifests as templates for other plugins. For more information about installation scripts for plugins in Plugin Central, see: Chef cookbook for New Relic Puppet module for New Relic Multiple agents example This is an example of how to configure your plugin to create multiple agents with different configurations. In this example: The plugin is called Wikipedia. Wikipedia has 3 hosts: English, Spanish, and German. Each host uses a different port in New Relic Plugins. Define hosts and ports in YAML Edit your YAML configuration file to include a list of entries for the component (instance) as a collection of block sequences. For example: agents: wikipedia - hostname: en.wikipedia.org port: 80 - hostname: sp.wikipedia.org port: 81 - hostname: de.wikipedia.org port: 82 Copy Edit the plugin code Edit your plugin code to identify specific options; for example, names, hostnames, ports, etc.: agent_human_labels(\"Wikipedia\") { \"Wikipedia on #{hostname} on port # {port}\" } agent_config_options :hostname, :port Copy Create summary metrics Within your plugin's setup_metrics method, the symbols referenced in the agent_config_options are available as local variables. You can view the summary metrics in the user interface, create one or more dashboards, and continue editing your plugin. SaaS developer plugins The Plugin API is useful when you need to: Use a programming language not supported by the plugin SDKs. Write plugins to in-house standards or as part of a larger running application. Report metrics for a large number of individual accounts. The Plugin API can be used by plugin developers to POST metrics for multiple components (instances) directly to the New Relic collectors using JSON. Each POST typically is consumed by the collector in under 3ms, so this is a very fast way to send large amounts of metric data. New Relic license key In order to provide your customers with New Relic metrics via your plugin, you must have access to the New Relic license key for each individual account. You can capture this information when provisioning new customers via the New Relic Partner API, or you can provide a mechanism whereby customers can share their existing New Relic license key with you. Metric reporting Once you have access to the New Relic license key, your plugin can use the Plugin API to POST metrics for multiple components (instances) using JSON. You should POST metrics for each of your accounts to New Relic no more frequently than every 60 seconds and no less than every 300 seconds. Multiple components (instances) can include multiple metrics within a single POST, corresponding to a particular New Relic account. You can provide metrics for your SaaS users that cover many database components, web server components, cache components, message queue components, etc. Example: Multiple accounts Here is an example of the steps to follow in order to report plugin metrics for a collection of accounts: # Ruby language example # Define the Plugin API endpoint URL url = URI.parse(\"https://platform-api.newrelic.com/platform/v1/metrics\") # Assuming the Account model has a scope that provides all accounts # having a New Relic license key, fetch those accounts and iterate # over them to POST the metrics to New Relic Plugins Account.with_new_relic_license.each do |account| # Prepare an HTTP POST request request = Net::HTTP::Post.new(url.request_uri) # Set the BODY to the JSON structure containing the metrics request.body = account.gather_new_relic_metrics.as_json # Set the required headers request.add_field('X-License-Key', account.new_relic_license_key) request.add_field('Content-Type', 'application/json') request.delete('accept') # Need to remove the default 'Accept: */*' request.add_field('Accept', 'application/json') # Post the metric data to the New Relic Servers response = Net::HTTP.new(url.host, url.port).start do |http| http.request(request) end # Test for success success = JSON.parse(response.body)['status'] == 'ok' end Copy Example: Single account Here is a large JSON data example showing what could be sent to New Relic Plugins via HTTP POST for a single licensee. This example contains multiple metrics for multiple components or instances for a single plugin. This example represents a sample size of 60 seconds. { \"agent\": { \"host\" : \"host.service_name.com\", \"pid\" : 1234, \"version\" : \"1.0.0\" }, \"components\": [ { \"name\": \"Database Server\", \"guid\": \"com.saas_company_name.postgresql\", \"duration\" : 60, \"metrics\" : { \"Component/Connections/Bytes received[bytes/sec]\" : 200, \"Component/Connections/Bytes sent[bytes/sec]\" : 30, \"Component/Queries/Query rate[Queries/sec]\" : 10 } }, { \"name\": \"Cache Server\", \"guid\": \"com.saas_company_name.memcached\", \"duration\" : 60, \"metrics\" : { \"Component/Cache/Writes[count]\" : 220, \"Component/Cache/Hits[count]\" : 300, \"Component/Cache/Misses[count]\" : 100, \"Component/Cache/Memory/Used[bytes]\" : 1000, \"Component/Cache/Memory/Free[bytes]\" : 10 } }, { \"name\": \"Message Queue\", \"guid\": \"com.saas_company_name.sidekiq\", \"duration\" : 60, \"metrics\" : { \"Component/Jobs/Queued[count]\" : 2000, \"Component/Jobs/Running[count]\" : 100, \"Component/Jobs/Failed[count]\" : 10, \"Component/Jobs/Processed[count]\" : 1000000 } } ] } Copy Additional publisher details Once your plugin has reported some data, you can edit it to include: Your publisher (organization) name Link to your website landing page Link to your support page URL to a branding image Detailed description of the plugin When publishing your plugin, the Type of download field offers options for a file download or website URL. SaaS providers can enter their website landing page URL. View plugin usage After you publish your plugin, New Relic will update usage data about accounts and components or instances every 24 hours, including: Number of accounts using your plugin Components or instances that are reporting data Review comments Ratings Plugins that are publicly published in Plugin Central will have more details in the Usage dashboard than unlisted (privately published) ones. In addition to providing a central location to examine review comments and ratings, the Usage dashboard is useful for verifying public information about the plugin, including the download link and a shortcut link to Plugin Central. Anyone on the authoring account can view the published plugin's Usage dashboard. Go to one.newrelic.com > More > Plugins, and select the plugin's name or icon. From the plugin's Summary page, select Usage.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.23782,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create a <em>plugin</em>",
        "sections": "SaaS <em>developer</em> <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": " <em>plugin</em>&#x27;s setup_metrics method, the symbols referenced in the agent_config_options are available as local variables. You can view the summary metrics in the user interface, create one or more dashboards, and continue editing your <em>plugin</em>. SaaS <em>developer</em> <em>plugins</em> The <em>Plugin</em> API is useful when you need"
      },
      "id": "603e9450196a67c29ca83d9a"
    }
  ],
  "/docs/plugins/plugin-developer-resources/developer-reference/get-plugin-data-rest-api": [
    {
      "sections": [
        "Metric data for the Plugin API",
        "Important",
        "Limited access to legacy plugins",
        "URI",
        "GUID",
        "Time periods for metrics",
        "Metric data details",
        "Timeslice metric values",
        "Calculations",
        "Examples",
        "Metrics",
        "cURL example",
        "Metric references",
        "Metric naming guidelines",
        "Metric segments",
        "Caution",
        "Metric attributes",
        "Metric values",
        "Units"
      ],
      "title": "Metric data for the Plugin API",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "2e9d0553b7277c73fe8a2147519d9943fca440fc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/metric-data-plugin-api/",
      "published_at": "2021-05-06T09:48:09Z",
      "updated_at": "2021-03-16T11:20:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. URI Metric timeslice data is sent with the Plugin API as an HTTP POST of JSON data using this URI: https://platform-api.newrelic.com/platform/v1/metrics Copy The Plugin API does not support New Relic's REST API, and vice versa. However, you can use the REST API (v2) to extract plugin data. For a list with links to procedures and examples, see Plugin examples (v2). GUID The plugin needs a Globally Unique Identifier (GUID), which is a character string limited to no less than 4 and no more than 255 characters. The GUID for a published plugin must be unique for each plugin. When creating a plugin, you are responsible for managing your own GUIDs to avoid naming conflicts. Time periods for metrics Metrics that appear in dashboards are reported with a duration. The end time is implied by the time New Relic receives the metric(s). Thus, you cannot define metric values that both start and end in the future, or start and end in the past. The Plugin API is designed for live metrics only, not historical metric collection. Metrics may only be reported for a period starting in the past (no more than a few hours) and ending upon reporting. The charts on your plugin's dashboards can show any time period you want; for example, 30 minutes, 30 days, etc. You can also deliver data at 1-hour intervals. New Relic does not extrapolate data values between the data points delivered. For example, data will aggregate when there is too much, but data will not be extrapolated if there is not enough data. In order for data to appear on a 30 minute chart, make sure at least one data point is within the range, or no data will appear. Use a 60-second polling interval, because the default dashboard shows 30 minutes of data, which gives 30 data points for the chart. Or, if you want to show 3 days of data, use a 1-hour polling interval, which provides 24 * 3=72 data points for your chart. Metric data details The JSON data is a hash with two required keys at the top level: components: An array of components, each consisting of a hash of attributes for the individual component, including the metric data. agent: A hash describing the agent that is reporting metrics data to New Relic Plugins on behalf of the component(s). Of these values, only host and version are required. When graphing metrics, be aware that null = zero. Metric data POST Description Component data One of two required keys at the top level. This is an array of hashes describing the components that report metrics in this request. Each hash contains the following values: name A name ( < =32 characters) that uniquely identifies the monitored entity and appears as the display name for this agent. Note: Metric names are case sensitive. guid A \"reverse domain name\" styled identifier; for example, com.newrelic.mysql. This is a unique identity defined in the plugin's user interface, which ties the agent data to the corresponding plugin user interface in New Relic. duration The duration in seconds over which the metric data was collected. The end time is implied as the time the data is received by the API. metrics Timeslice data for each metric being reported. The hash keys are metric names, and the values are the timeslice data value for the named metric. Agent data One of two required keys at the top level. A hash specifying information about the agent that is reporting data on behalf of the components. host (required) The hostname of the agent monitoring the specified components. This is the hostname where the monitoring agent is running, not the hostname of the component being monitored. pid (optional) The process identifier of the agent monitoring the specified components. This is the process identifier of the monitoring agent itself, not a process identifier that may be associated with the monitored components. version (required) The version of the agent monitoring the specified components, using the format A.B.C where A, B, and C are integers. The version number must conform to the rules specified in standard Semantic Versioning scheme v2.0.0. Timeslice metric values Metrics are sent inside the component hash with the key metrics and a hash as a value. The hash keys are metric names, and the values are the timeslice data values for the named metric. The timeslice hash value uses one of three formats: Timeslice hash value Description A single scalar value with a floating point number or integer This is the simplest format, and this number is required. The reported value is used as the total, minimum, and maximum data value. The count value is assumed to be 1. The Plugin API does not support reporting of arbitrary string metrics, only scalar values that are aggregated. Array of five required values in specific order An array of five required integers or floating point numbers that represent, in order: Total value over the time period Count of the number of events this value represents over the time period; the average is calculated by dividing total by count Minimum value over the time period Maximum value over the time period Sum of squares for the samples over the time period Hash with five required key/value pairs in any order A hash with value names as the keys, and integers or floating point values as the values. All five key/value pairs are required. The keys of the hash are the type of timeslice data, and the value is the data value. These has key/value pairs can be in any order: total: Total value over the time period count: Count of the number of events this value represents over the time period; the average is calculated by dividing total by count min: Minimum value over the time period max: Maximum value over the time period sum_of_squares: Sum of squares for the samples over the time period Calculations Limited mathematical calculations are available with the key/value pairs, such as computing total, count, minimum, maximum, averages, and standard deviations. However, to do more extensive calculations, you need to do the math in the agent, and then send the results as a new metric. For example, send Metric1, Metric2, and Metric3 (which equals Metric1 divided by Metric2). If you submit negative metric values, the charts on your plugin's dashboards will not show them. However, the summary metrics for your plugin will show negative values. Examples Here are some examples. Metrics \"metrics\" : { \"Component/Database/Primary[Queries/Second]\" : { \"total\" : 25, \"count\" : 2, \"min\" : 10, \"max\" : 15, \"sum_of_squares\" : 325 }, \"Component/Database/Secondary[Queries/Second]\" : [25, 2, 10, 15, 325], \"Component/Database/Backup[Queries/Second]\" : 10 } Copy cURL example curl -vi https://platform-api.newrelic.com/platform/v1/metrics \\ -H \"X-License-Key: YOUR_LICENSE_KEY_HERE\" \\ -H \"Content-Type: application/json\" \\ -H \"Accept: application/json\" \\ -X POST -d '{ \"agent\": { \"host\" : \"db.internal.your_company.com\", \"pid\" : 1234, \"version\" : \"1.0.0\" }, \"components\": [ { \"name\": \"Primary MySQL Database\", \"guid\": \"com.your_company_name.plugin_name\", \"duration\" : 60, \"metrics\" : { \"Component/ProductionDatabase[Queries/Second]\": 100, \"Component/AnalyticsDatabase[Queries/Second]\": { \"min\" : 2, \"max\" : 10, \"total\": 12, \"count\" : 2, \"sum_of_squares\" : 104 } } } ] }' Copy Metric references Refer to these references as you develop your own plugins. Metric naming guidelines Metric timeslice data uses a unique case-sensitive identifier, referred to as the metric name. In order for the metric to be rendered usefully in the user interface, the metric name must contain a prefix, category name, label, and optional units indicator. Here are some recommended guidelines for the text in metric names to make them more readable in the user interface. Metric naming guidelines Guidelines UI display Use case and whitespace characters appropriate for display in the user interface, because segments are rendered as-is in the UI. Category and label segments Metric names are case sensitive. Capitalize the first word in the category and label segments. Keep category and label segments as short as possible. Length There is a limit of 255 characters for metric names. Characters to avoid using Avoid using the following characters in names. These characters have special meaning and should not be used except where specifically required for their purpose. / ] [ | * Also avoid multi-byte characters. Units Use abbreviated names for units when possible. Metric segments Each of these segments is divided by the forward slash / character. Each segment is interpreted for a specific purpose in the UI and roughly follows this pattern: prefix/category/label[units] Copy For example, the metric representing the latency of cache hits reported by a plugin collecting data for a cache appliance might look like this: Component/Cache/Hits[sec|hit] Copy Metric segment order Notes Prefix: Component/ or Custom/ The first segment of a custom metric is Component/ (if it comes from a plugin agent) or Custom/ (if it is a custom metric collected by a New Relic agent. For example, Custom/MyMetric). Caution If you use the Plugin API only, and if the metrics do not start with Component/, they may not be available or may not appear correctly in charts and dashboards. Category name The second part of a custom metric is a category name, used to group metrics into different categories. For example, the metrics reported by a database plugin may fall into categories such as schema, tables, or connections. Label The third part of the metric name is used for labeling the data when it appears in tables and charts. If it contains multiple segments, each slash separating the segments of the label will be rendered as part of the label. Units The fourth segment of the metric consists of a units specification. Metric attributes Most metrics are defined statically and represent some global state; for example, cache size. Other metrics are dynamic and include some contextual attribute like the name of a host or a file. These metrics need to be structured so you can easily show them as a group in a table stacked in a chart. To add attribute names to a metric, put them in trailing segments separated by a forward slash / character. For example: Component/Disk/Bytes In/dev001 Component/Network/External services/ae592c3.aws.com Copy You can specify more than one attribute as long as they occupy the same position for a given metric category and label: Component/Tables/Row count/DB001/BLOG_POSTS[rows] Copy Caution Avoid overloading the metric space by putting in segment values that have a large range of values. While something like a customer's region in an attribute is a reasonable thing to track in the metric, the customer name would not be if you have more than a few hundred customers. If your agent starts sending an excessive amount of metrics, your metrics may be automatically collapsed into groups with wildcards: Component/Users/*[visits] Copy Metric values You can report a metric value in one of two ways: Single value: This typically is the value being reported for that time slice. If you use an SDK, you report the single value to the SDK. It handles tracking the rest of these values. Set of aggregate value: This includes the min, max, and sum of squares values for the value being reported. If you use the Plugin API, the preferred method is to report all of the values. When aggregating a series of timeslice data into a single timeslice data entry for a given period, all fields are summed except for the min and max value. If you are using an SDK plugins, this is done automatically. If you are using the Plugin API to develop plugins, you need to code for this. A metric value contains several fields, but it is represented primarily by the count and value. The count is a 32-bit integer field, and the value is a 32-bit float. Metric values can represent more than one data point or sample as an aggregation of measures. Typically the count is the number of samples, and the value is the total value of all samples. Here are the fields in a metric value: Metric value Description count The number of things being measured. If data is collected at the time the event occurs, like with some kind of injection, then the count in the timeslice data will be 1. Required if it is not 1 (0 generally represents an absent value). value Required: The total value measured across all things being counted. When averages are calculated later, we divide the value by the count. In some cases, the value field is irrelevant. min, max The minimum and maximum values when the count is greater than 1. When the count is 1, these are the same as the value. Optional depending on whether they are available or relevant for a given metric. sum of squares This is the sum of squares of each value and is useful when the values follow a standard distribution. You can only capture this value when you are collecting data each time the event happens. You store the value of the event in the value field and the square of the value in the sum of squares. This is used to calculate a standard deviation later on. The sum of squares is optional. It is used to calculate a standard deviation for a selection of data. If standard deviation for the value is not meaningful, such as when the values are not part of a normal distribution, then the sum of squares is omitted. Units When a metric value is collected by periodically sampling an interface, the count units are implicitly samples, and the value units are whatever is being sampled. For data it might be bytes. For throughput it might be something like kilobytes/second. For utilization (like CPU) it might be percent. When the count units are samples, they can be omitted in the metric name. Units of time, bytes, and bits may get special treatment, allowing additional conversion in the user interface between magnitudes. For example, if you specify a metric with units of kilobytes, then in the UI you may be presented the option of displaying a chart of Mb. Metrics units describe what the value field and count represent. Units are specified inside brackets and consist of units for the value, followed by a pipe (|) and then the units for the count. For example: Component/metric_id[value_unit|count_unit] Copy Exception: The pipe and count units (|[count_unit]) are not required after the value unit for samples. Rate metrics are commonly defined as sample per interval. This is defined as units/interval in the metric, with a forward slash to separate units from interval. For example: Component/metric_id[value_unit/interval] Copy In rare cases there will only be a unit value for count. The value will be interpreted as unitless. Value units are omitted, and the vertical bar appears in front of the count units. For example: Component/metric_id[|count_unit] Copy Units for plugin metrics Notes Naming conventions You can have mixed-case unit names. They.can consist strictly of alphabetical characters as well as the _, %, or / symbols. Case is preserved. Punctuation markers, dashes, spaces and any other symbols are not allowed. Recommendation: Use uncapitalized words, spelled out in full. For example, use second not sec. Rate metrics When a metric value represents a rate, such as bytes/second, then the value is assumed to be a sample for the given interval. The units specifier looks like [ bytes/second] since the count units are implicitly samples. For example: Component/metric_id[bytes/second] Copy The count units are samples (default) and the value units are bytes/second. The forward slash separates the units from the interval. Count with units A common case for declaring units is when measuring response times. If the custom metric represents the average latency of a call to a cache, then the units for the metric value are seconds per call. For example: Component/metric_id[seconds|call] Copy Count units are calls and value units are seconds. The default count metric is not being used, so you need to specify it. The bar separates the value units from the count units. Units in charts The units specified in a metric have several implications for the way the values are interpreted by generic charts and tables: Units display in labels and tooltips in charts to indicate what the values represent. Units imply a set of different values available from a single metric value. When creating a chart in a dashboard, the dashboard author selects one of the available value methods for that metric to plot in the chart.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.26836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data for the <em>Plugin</em> API",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "&quot; : 2, &quot;max&quot; : 10, &quot;total&quot;: 12, &quot;count&quot; : 2, &quot;sum_of_squares&quot; : 104 } } } ] }&#x27; Copy Metric references <em>Refer</em> to these references as you <em>develop</em> your own <em>plugins</em>. Metric naming guidelines Metric timeslice data uses a unique case-sensitive identifier, referred to as the metric name. In order"
      },
      "id": "603e80db64441f0def4e8863"
    },
    {
      "sections": [
        "Plugin data",
        "Important",
        "Limited access to legacy plugins",
        "Use integers and floats",
        "Define the time period (duration)",
        "Follow unit conversion guidelines",
        "Select value methods for display in the UI"
      ],
      "title": "Plugin data",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "e5fd09ba8dd9c63a140479fbc2032254d1cf8c4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/plugin-data/",
      "published_at": "2021-05-03T06:33:26Z",
      "updated_at": "2021-03-16T11:02:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Use integers and floats All plugin metrics must be an integer or float, and they must be reported along with a duration. You can also report the type of metric so it can be converted from one unit type into another. You can display the metrics you collect in a variety of value methods, including throughput, averages, min/max, and rate. The metrics appear in charts and tables you create for your plugin's user interface. Plugins in Plugin Central are designed to report on frequency metrics using non-negative integers or floating-point numbers: Non-negative integers: Supported. Floating-point numbers: Supported. Negative values: Not supported, except for summary metrics on the plugin's Summary page. Otherwise, the UI shows negative values as zero. String values: Not supported; the UI shows strings as zero. However, parts of your metric name (the key) can be displayed in the UI. Define the time period (duration) All metrics must include a duration period that starts no more than a few hours in the past. The end time is set automatically to the time New Relic Plugins receives the metrics. You cannot report a duration that starts or ends in the future, or a duration that ends in the past. For best results, use one of the plugin SDKs to create your plugin. Otherwise, some POST attempts may fail because the actual recorded duration could vary in increments of the plugin's scheduled reporting frequency. Follow unit conversion guidelines Plugins automatically converts some units (such as rate units) to more natural forms. For example, [bytes/second] is converted to Bps. Follow these guidelines for unit conversions: Long format: Always specify the long format (for example, [bytes/second]) in the metric name. The long or short version will be used as appropriate. (Unit designations are not case sensitive.) Consistency: Use modifiers consistently in the metric name. If you use a different modifier with the same metric name, it will be treated as a different metric. Optional: Standard modifiers: Provide standard modifiers to the first metric in a value unit. For example, rather than specifying [bytes/second], you can specify [kiloBytes/second]. Plugins accepts these standard modifiers: Modifier Multiplier Modifier Multiplier Kilo 1000 - -- - -- Mega 1000^2 - -- - -- Giga 1000^3 Gibi 1024^3 Tera 1000^4 Tebi 1024^4 Peta 1000^5 Pebi 1024^5 Select value methods for display in the UI When you define a metric value for reporting, Plugins also captures a count, min, max, and sum of squares. Depending on whether you report single or aggregate values, you may report these numbers directly, or Plugins may calculate them automatically. You can then choose a value method for rendering these metrics in your plugin UI. In general, to configure value methods in the user interface: Select the metric you want to use. Review the list of value methods to select how to present the data in a column or plotted in a chart. Available value methods depend on the format of the units part of the metric name: Value method Count | Value Value Rate Count: The total of the count field over the entire timeslice data interval. When aggregating timeslice data, the count is summed. Total value: The total value over the entire time slice data interval. When aggregating timeslice data, the value field is summed Time rates only Average value: The total value divided by the total count, calculated only when units for both count and value are available. Throughput: The total count divided by the time interval of the time slice. By default New Relic Plugins measures the throughput in minutes according to the count units, such as calls per minute or bytes per minute. When the count units are specified in time (seconds), then the throughput appears as a percentage. Min/Max: The statistical values for minimum and maximum values when recorded in the metric value along with Count and Value. Standard deviation: The standard deviation of the entire set of measures recorded over the time interval. This is available only if the sum of squares field was populated in the metric value. The sum of squares and mean are used to calculate the standard deviation. In practice, this is meaningful only for populations that resemble a normal distribution. Rate: The rate is the total value divided by the time interval. When units of the value are in time, then the rate value is a percentage value. Units that are themselves rates will not have an explicit rate value method. The rate is simply the average value. Percentage: If you want the metric to appear as a percentage in the user interface, then you must define it as a percentage in the JSON.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.26048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Plugin</em> data",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603e91e3196a67c11ea83d9d"
    },
    {
      "sections": [
        "Plan plugin metrics",
        "Important",
        "Limited access to legacy plugins",
        "Collect plugin metrics",
        "Present plugin metrics"
      ],
      "title": "Plan plugin metrics",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "08974b731c810af2b6b037e8b761834c6e1ce7a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/plan-plugin-metrics/",
      "published_at": "2021-05-03T06:33:03Z",
      "updated_at": "2021-03-16T11:01:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Collect plugin metrics If you are running one of our APM agents to receive information about your applications, you can also receive arbitrary custom metrics. Using custom dashboards with your plugins, you can visualize custom metrics in a variety of useful ways. You can write plugins agents that can be run anywhere to collect metrics from any available system and report them to New Relic for dashboard display. Plugins also allow for summary metrics and one or more dashboards to visualize metrics that can be shared with every user of the plugin. This allows you to create a consistent user interface for the metrics you collect. The data that plugins report is in the form of a key/value pair. Values are numerical, either integers or floating point non-negative numbers. Negative numbers can be included in your summary metrics and tables; however, visualization in charts is limited to numbers greater than or equal to zero. Keys are strings which include the concept of name spaces and units. While values cannot be strings, parts of your metric name (the key) can be displayed in plugin dashboards. Your plugin agent can run anywhere with internet access to Plugins. You can write an agent using the agent SDKs. You can also write your agent to connect via HTTP POST using the API for Plugins in any language with HTTP support. Using the Plugin API might be the most appropriate solution when one agent is reporting metrics for more than one New Relic account. This is common for service providers to report specialized metrics for each of their customers using Plugins. This can be done with a small number of agents monitoring a large number of users. Present plugin metrics When creating a plugin agent, good metric name planning is critical to your success. Poorly chosen metrics names can make it difficult or impossible to display the information you intend. Plan ahead for how you want to visualize your information and to record metrics in a way that will facilitate this. You may even want to record the same metrics with more than one name in order to visualize different aspects of your data. Plugin dashboards do not have the ability to do mathematical calculations, so make sure your plugin agent handles any necessary calculations (sum, average, total, count, etc.) before recording metrics. Once you have collected metrics with your plugin agent, you will need to create dashboards to visualize the information in your metrics. All plugins will have a default dashboard. You can add as many dashboards as necessary to visualize your metric data (maximum 15). In addition to dashboards, you can choose up to five metrics to represent the summary of each instance. Summary metrics convey the health status of each instance and are used to trigger Caution events and Critical alerts for your plugins. The summary metrics appear on your plugin's Summary page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.26012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Plan <em>plugin</em> metrics",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603eb01228ccbc6fa6eba790"
    }
  ],
  "/docs/plugins/plugin-developer-resources/developer-reference/licenses-plugin-developers": [
    {
      "sections": [
        "Metric data for the Plugin API",
        "Important",
        "Limited access to legacy plugins",
        "URI",
        "GUID",
        "Time periods for metrics",
        "Metric data details",
        "Timeslice metric values",
        "Calculations",
        "Examples",
        "Metrics",
        "cURL example",
        "Metric references",
        "Metric naming guidelines",
        "Metric segments",
        "Caution",
        "Metric attributes",
        "Metric values",
        "Units"
      ],
      "title": "Metric data for the Plugin API",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "2e9d0553b7277c73fe8a2147519d9943fca440fc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/metric-data-plugin-api/",
      "published_at": "2021-05-06T09:48:09Z",
      "updated_at": "2021-03-16T11:20:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. URI Metric timeslice data is sent with the Plugin API as an HTTP POST of JSON data using this URI: https://platform-api.newrelic.com/platform/v1/metrics Copy The Plugin API does not support New Relic's REST API, and vice versa. However, you can use the REST API (v2) to extract plugin data. For a list with links to procedures and examples, see Plugin examples (v2). GUID The plugin needs a Globally Unique Identifier (GUID), which is a character string limited to no less than 4 and no more than 255 characters. The GUID for a published plugin must be unique for each plugin. When creating a plugin, you are responsible for managing your own GUIDs to avoid naming conflicts. Time periods for metrics Metrics that appear in dashboards are reported with a duration. The end time is implied by the time New Relic receives the metric(s). Thus, you cannot define metric values that both start and end in the future, or start and end in the past. The Plugin API is designed for live metrics only, not historical metric collection. Metrics may only be reported for a period starting in the past (no more than a few hours) and ending upon reporting. The charts on your plugin's dashboards can show any time period you want; for example, 30 minutes, 30 days, etc. You can also deliver data at 1-hour intervals. New Relic does not extrapolate data values between the data points delivered. For example, data will aggregate when there is too much, but data will not be extrapolated if there is not enough data. In order for data to appear on a 30 minute chart, make sure at least one data point is within the range, or no data will appear. Use a 60-second polling interval, because the default dashboard shows 30 minutes of data, which gives 30 data points for the chart. Or, if you want to show 3 days of data, use a 1-hour polling interval, which provides 24 * 3=72 data points for your chart. Metric data details The JSON data is a hash with two required keys at the top level: components: An array of components, each consisting of a hash of attributes for the individual component, including the metric data. agent: A hash describing the agent that is reporting metrics data to New Relic Plugins on behalf of the component(s). Of these values, only host and version are required. When graphing metrics, be aware that null = zero. Metric data POST Description Component data One of two required keys at the top level. This is an array of hashes describing the components that report metrics in this request. Each hash contains the following values: name A name ( < =32 characters) that uniquely identifies the monitored entity and appears as the display name for this agent. Note: Metric names are case sensitive. guid A \"reverse domain name\" styled identifier; for example, com.newrelic.mysql. This is a unique identity defined in the plugin's user interface, which ties the agent data to the corresponding plugin user interface in New Relic. duration The duration in seconds over which the metric data was collected. The end time is implied as the time the data is received by the API. metrics Timeslice data for each metric being reported. The hash keys are metric names, and the values are the timeslice data value for the named metric. Agent data One of two required keys at the top level. A hash specifying information about the agent that is reporting data on behalf of the components. host (required) The hostname of the agent monitoring the specified components. This is the hostname where the monitoring agent is running, not the hostname of the component being monitored. pid (optional) The process identifier of the agent monitoring the specified components. This is the process identifier of the monitoring agent itself, not a process identifier that may be associated with the monitored components. version (required) The version of the agent monitoring the specified components, using the format A.B.C where A, B, and C are integers. The version number must conform to the rules specified in standard Semantic Versioning scheme v2.0.0. Timeslice metric values Metrics are sent inside the component hash with the key metrics and a hash as a value. The hash keys are metric names, and the values are the timeslice data values for the named metric. The timeslice hash value uses one of three formats: Timeslice hash value Description A single scalar value with a floating point number or integer This is the simplest format, and this number is required. The reported value is used as the total, minimum, and maximum data value. The count value is assumed to be 1. The Plugin API does not support reporting of arbitrary string metrics, only scalar values that are aggregated. Array of five required values in specific order An array of five required integers or floating point numbers that represent, in order: Total value over the time period Count of the number of events this value represents over the time period; the average is calculated by dividing total by count Minimum value over the time period Maximum value over the time period Sum of squares for the samples over the time period Hash with five required key/value pairs in any order A hash with value names as the keys, and integers or floating point values as the values. All five key/value pairs are required. The keys of the hash are the type of timeslice data, and the value is the data value. These has key/value pairs can be in any order: total: Total value over the time period count: Count of the number of events this value represents over the time period; the average is calculated by dividing total by count min: Minimum value over the time period max: Maximum value over the time period sum_of_squares: Sum of squares for the samples over the time period Calculations Limited mathematical calculations are available with the key/value pairs, such as computing total, count, minimum, maximum, averages, and standard deviations. However, to do more extensive calculations, you need to do the math in the agent, and then send the results as a new metric. For example, send Metric1, Metric2, and Metric3 (which equals Metric1 divided by Metric2). If you submit negative metric values, the charts on your plugin's dashboards will not show them. However, the summary metrics for your plugin will show negative values. Examples Here are some examples. Metrics \"metrics\" : { \"Component/Database/Primary[Queries/Second]\" : { \"total\" : 25, \"count\" : 2, \"min\" : 10, \"max\" : 15, \"sum_of_squares\" : 325 }, \"Component/Database/Secondary[Queries/Second]\" : [25, 2, 10, 15, 325], \"Component/Database/Backup[Queries/Second]\" : 10 } Copy cURL example curl -vi https://platform-api.newrelic.com/platform/v1/metrics \\ -H \"X-License-Key: YOUR_LICENSE_KEY_HERE\" \\ -H \"Content-Type: application/json\" \\ -H \"Accept: application/json\" \\ -X POST -d '{ \"agent\": { \"host\" : \"db.internal.your_company.com\", \"pid\" : 1234, \"version\" : \"1.0.0\" }, \"components\": [ { \"name\": \"Primary MySQL Database\", \"guid\": \"com.your_company_name.plugin_name\", \"duration\" : 60, \"metrics\" : { \"Component/ProductionDatabase[Queries/Second]\": 100, \"Component/AnalyticsDatabase[Queries/Second]\": { \"min\" : 2, \"max\" : 10, \"total\": 12, \"count\" : 2, \"sum_of_squares\" : 104 } } } ] }' Copy Metric references Refer to these references as you develop your own plugins. Metric naming guidelines Metric timeslice data uses a unique case-sensitive identifier, referred to as the metric name. In order for the metric to be rendered usefully in the user interface, the metric name must contain a prefix, category name, label, and optional units indicator. Here are some recommended guidelines for the text in metric names to make them more readable in the user interface. Metric naming guidelines Guidelines UI display Use case and whitespace characters appropriate for display in the user interface, because segments are rendered as-is in the UI. Category and label segments Metric names are case sensitive. Capitalize the first word in the category and label segments. Keep category and label segments as short as possible. Length There is a limit of 255 characters for metric names. Characters to avoid using Avoid using the following characters in names. These characters have special meaning and should not be used except where specifically required for their purpose. / ] [ | * Also avoid multi-byte characters. Units Use abbreviated names for units when possible. Metric segments Each of these segments is divided by the forward slash / character. Each segment is interpreted for a specific purpose in the UI and roughly follows this pattern: prefix/category/label[units] Copy For example, the metric representing the latency of cache hits reported by a plugin collecting data for a cache appliance might look like this: Component/Cache/Hits[sec|hit] Copy Metric segment order Notes Prefix: Component/ or Custom/ The first segment of a custom metric is Component/ (if it comes from a plugin agent) or Custom/ (if it is a custom metric collected by a New Relic agent. For example, Custom/MyMetric). Caution If you use the Plugin API only, and if the metrics do not start with Component/, they may not be available or may not appear correctly in charts and dashboards. Category name The second part of a custom metric is a category name, used to group metrics into different categories. For example, the metrics reported by a database plugin may fall into categories such as schema, tables, or connections. Label The third part of the metric name is used for labeling the data when it appears in tables and charts. If it contains multiple segments, each slash separating the segments of the label will be rendered as part of the label. Units The fourth segment of the metric consists of a units specification. Metric attributes Most metrics are defined statically and represent some global state; for example, cache size. Other metrics are dynamic and include some contextual attribute like the name of a host or a file. These metrics need to be structured so you can easily show them as a group in a table stacked in a chart. To add attribute names to a metric, put them in trailing segments separated by a forward slash / character. For example: Component/Disk/Bytes In/dev001 Component/Network/External services/ae592c3.aws.com Copy You can specify more than one attribute as long as they occupy the same position for a given metric category and label: Component/Tables/Row count/DB001/BLOG_POSTS[rows] Copy Caution Avoid overloading the metric space by putting in segment values that have a large range of values. While something like a customer's region in an attribute is a reasonable thing to track in the metric, the customer name would not be if you have more than a few hundred customers. If your agent starts sending an excessive amount of metrics, your metrics may be automatically collapsed into groups with wildcards: Component/Users/*[visits] Copy Metric values You can report a metric value in one of two ways: Single value: This typically is the value being reported for that time slice. If you use an SDK, you report the single value to the SDK. It handles tracking the rest of these values. Set of aggregate value: This includes the min, max, and sum of squares values for the value being reported. If you use the Plugin API, the preferred method is to report all of the values. When aggregating a series of timeslice data into a single timeslice data entry for a given period, all fields are summed except for the min and max value. If you are using an SDK plugins, this is done automatically. If you are using the Plugin API to develop plugins, you need to code for this. A metric value contains several fields, but it is represented primarily by the count and value. The count is a 32-bit integer field, and the value is a 32-bit float. Metric values can represent more than one data point or sample as an aggregation of measures. Typically the count is the number of samples, and the value is the total value of all samples. Here are the fields in a metric value: Metric value Description count The number of things being measured. If data is collected at the time the event occurs, like with some kind of injection, then the count in the timeslice data will be 1. Required if it is not 1 (0 generally represents an absent value). value Required: The total value measured across all things being counted. When averages are calculated later, we divide the value by the count. In some cases, the value field is irrelevant. min, max The minimum and maximum values when the count is greater than 1. When the count is 1, these are the same as the value. Optional depending on whether they are available or relevant for a given metric. sum of squares This is the sum of squares of each value and is useful when the values follow a standard distribution. You can only capture this value when you are collecting data each time the event happens. You store the value of the event in the value field and the square of the value in the sum of squares. This is used to calculate a standard deviation later on. The sum of squares is optional. It is used to calculate a standard deviation for a selection of data. If standard deviation for the value is not meaningful, such as when the values are not part of a normal distribution, then the sum of squares is omitted. Units When a metric value is collected by periodically sampling an interface, the count units are implicitly samples, and the value units are whatever is being sampled. For data it might be bytes. For throughput it might be something like kilobytes/second. For utilization (like CPU) it might be percent. When the count units are samples, they can be omitted in the metric name. Units of time, bytes, and bits may get special treatment, allowing additional conversion in the user interface between magnitudes. For example, if you specify a metric with units of kilobytes, then in the UI you may be presented the option of displaying a chart of Mb. Metrics units describe what the value field and count represent. Units are specified inside brackets and consist of units for the value, followed by a pipe (|) and then the units for the count. For example: Component/metric_id[value_unit|count_unit] Copy Exception: The pipe and count units (|[count_unit]) are not required after the value unit for samples. Rate metrics are commonly defined as sample per interval. This is defined as units/interval in the metric, with a forward slash to separate units from interval. For example: Component/metric_id[value_unit/interval] Copy In rare cases there will only be a unit value for count. The value will be interpreted as unitless. Value units are omitted, and the vertical bar appears in front of the count units. For example: Component/metric_id[|count_unit] Copy Units for plugin metrics Notes Naming conventions You can have mixed-case unit names. They.can consist strictly of alphabetical characters as well as the _, %, or / symbols. Case is preserved. Punctuation markers, dashes, spaces and any other symbols are not allowed. Recommendation: Use uncapitalized words, spelled out in full. For example, use second not sec. Rate metrics When a metric value represents a rate, such as bytes/second, then the value is assumed to be a sample for the given interval. The units specifier looks like [ bytes/second] since the count units are implicitly samples. For example: Component/metric_id[bytes/second] Copy The count units are samples (default) and the value units are bytes/second. The forward slash separates the units from the interval. Count with units A common case for declaring units is when measuring response times. If the custom metric represents the average latency of a call to a cache, then the units for the metric value are seconds per call. For example: Component/metric_id[seconds|call] Copy Count units are calls and value units are seconds. The default count metric is not being used, so you need to specify it. The bar separates the value units from the count units. Units in charts The units specified in a metric have several implications for the way the values are interpreted by generic charts and tables: Units display in labels and tooltips in charts to indicate what the values represent. Units imply a set of different values available from a single metric value. When creating a chart in a dashboard, the dashboard author selects one of the available value methods for that metric to plot in the chart.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.26836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data for the <em>Plugin</em> API",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "&quot; : 2, &quot;max&quot; : 10, &quot;total&quot;: 12, &quot;count&quot; : 2, &quot;sum_of_squares&quot; : 104 } } } ] }&#x27; Copy Metric references <em>Refer</em> to these references as you <em>develop</em> your own <em>plugins</em>. Metric naming guidelines Metric timeslice data uses a unique case-sensitive identifier, referred to as the metric name. In order"
      },
      "id": "603e80db64441f0def4e8863"
    },
    {
      "sections": [
        "Plugin data",
        "Important",
        "Limited access to legacy plugins",
        "Use integers and floats",
        "Define the time period (duration)",
        "Follow unit conversion guidelines",
        "Select value methods for display in the UI"
      ],
      "title": "Plugin data",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "e5fd09ba8dd9c63a140479fbc2032254d1cf8c4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/plugin-data/",
      "published_at": "2021-05-03T06:33:26Z",
      "updated_at": "2021-03-16T11:02:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Use integers and floats All plugin metrics must be an integer or float, and they must be reported along with a duration. You can also report the type of metric so it can be converted from one unit type into another. You can display the metrics you collect in a variety of value methods, including throughput, averages, min/max, and rate. The metrics appear in charts and tables you create for your plugin's user interface. Plugins in Plugin Central are designed to report on frequency metrics using non-negative integers or floating-point numbers: Non-negative integers: Supported. Floating-point numbers: Supported. Negative values: Not supported, except for summary metrics on the plugin's Summary page. Otherwise, the UI shows negative values as zero. String values: Not supported; the UI shows strings as zero. However, parts of your metric name (the key) can be displayed in the UI. Define the time period (duration) All metrics must include a duration period that starts no more than a few hours in the past. The end time is set automatically to the time New Relic Plugins receives the metrics. You cannot report a duration that starts or ends in the future, or a duration that ends in the past. For best results, use one of the plugin SDKs to create your plugin. Otherwise, some POST attempts may fail because the actual recorded duration could vary in increments of the plugin's scheduled reporting frequency. Follow unit conversion guidelines Plugins automatically converts some units (such as rate units) to more natural forms. For example, [bytes/second] is converted to Bps. Follow these guidelines for unit conversions: Long format: Always specify the long format (for example, [bytes/second]) in the metric name. The long or short version will be used as appropriate. (Unit designations are not case sensitive.) Consistency: Use modifiers consistently in the metric name. If you use a different modifier with the same metric name, it will be treated as a different metric. Optional: Standard modifiers: Provide standard modifiers to the first metric in a value unit. For example, rather than specifying [bytes/second], you can specify [kiloBytes/second]. Plugins accepts these standard modifiers: Modifier Multiplier Modifier Multiplier Kilo 1000 - -- - -- Mega 1000^2 - -- - -- Giga 1000^3 Gibi 1024^3 Tera 1000^4 Tebi 1024^4 Peta 1000^5 Pebi 1024^5 Select value methods for display in the UI When you define a metric value for reporting, Plugins also captures a count, min, max, and sum of squares. Depending on whether you report single or aggregate values, you may report these numbers directly, or Plugins may calculate them automatically. You can then choose a value method for rendering these metrics in your plugin UI. In general, to configure value methods in the user interface: Select the metric you want to use. Review the list of value methods to select how to present the data in a column or plotted in a chart. Available value methods depend on the format of the units part of the metric name: Value method Count | Value Value Rate Count: The total of the count field over the entire timeslice data interval. When aggregating timeslice data, the count is summed. Total value: The total value over the entire time slice data interval. When aggregating timeslice data, the value field is summed Time rates only Average value: The total value divided by the total count, calculated only when units for both count and value are available. Throughput: The total count divided by the time interval of the time slice. By default New Relic Plugins measures the throughput in minutes according to the count units, such as calls per minute or bytes per minute. When the count units are specified in time (seconds), then the throughput appears as a percentage. Min/Max: The statistical values for minimum and maximum values when recorded in the metric value along with Count and Value. Standard deviation: The standard deviation of the entire set of measures recorded over the time interval. This is available only if the sum of squares field was populated in the metric value. The sum of squares and mean are used to calculate the standard deviation. In practice, this is meaningful only for populations that resemble a normal distribution. Rate: The rate is the total value divided by the time interval. When units of the value are in time, then the rate value is a percentage value. Units that are themselves rates will not have an explicit rate value method. The rate is simply the average value. Percentage: If you want the metric to appear as a percentage in the user interface, then you must define it as a percentage in the JSON.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.26048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Plugin</em> data",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603e91e3196a67c11ea83d9d"
    },
    {
      "sections": [
        "Plan plugin metrics",
        "Important",
        "Limited access to legacy plugins",
        "Collect plugin metrics",
        "Present plugin metrics"
      ],
      "title": "Plan plugin metrics",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "08974b731c810af2b6b037e8b761834c6e1ce7a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/plan-plugin-metrics/",
      "published_at": "2021-05-03T06:33:03Z",
      "updated_at": "2021-03-16T11:01:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Collect plugin metrics If you are running one of our APM agents to receive information about your applications, you can also receive arbitrary custom metrics. Using custom dashboards with your plugins, you can visualize custom metrics in a variety of useful ways. You can write plugins agents that can be run anywhere to collect metrics from any available system and report them to New Relic for dashboard display. Plugins also allow for summary metrics and one or more dashboards to visualize metrics that can be shared with every user of the plugin. This allows you to create a consistent user interface for the metrics you collect. The data that plugins report is in the form of a key/value pair. Values are numerical, either integers or floating point non-negative numbers. Negative numbers can be included in your summary metrics and tables; however, visualization in charts is limited to numbers greater than or equal to zero. Keys are strings which include the concept of name spaces and units. While values cannot be strings, parts of your metric name (the key) can be displayed in plugin dashboards. Your plugin agent can run anywhere with internet access to Plugins. You can write an agent using the agent SDKs. You can also write your agent to connect via HTTP POST using the API for Plugins in any language with HTTP support. Using the Plugin API might be the most appropriate solution when one agent is reporting metrics for more than one New Relic account. This is common for service providers to report specialized metrics for each of their customers using Plugins. This can be done with a small number of agents monitoring a large number of users. Present plugin metrics When creating a plugin agent, good metric name planning is critical to your success. Poorly chosen metrics names can make it difficult or impossible to display the information you intend. Plan ahead for how you want to visualize your information and to record metrics in a way that will facilitate this. You may even want to record the same metrics with more than one name in order to visualize different aspects of your data. Plugin dashboards do not have the ability to do mathematical calculations, so make sure your plugin agent handles any necessary calculations (sum, average, total, count, etc.) before recording metrics. Once you have collected metrics with your plugin agent, you will need to create dashboards to visualize the information in your metrics. All plugins will have a default dashboard. You can add as many dashboards as necessary to visualize your metric data (maximum 15). In addition to dashboards, you can choose up to five metrics to represent the summary of each instance. Summary metrics convey the health status of each instance and are used to trigger Caution events and Critical alerts for your plugins. The summary metrics appear on your plugin's Summary page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.2601,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Plan <em>plugin</em> metrics",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603eb01228ccbc6fa6eba790"
    }
  ],
  "/docs/plugins/plugin-developer-resources/developer-reference/metric-data-plugin-api": [
    {
      "sections": [
        "Plugin data",
        "Important",
        "Limited access to legacy plugins",
        "Use integers and floats",
        "Define the time period (duration)",
        "Follow unit conversion guidelines",
        "Select value methods for display in the UI"
      ],
      "title": "Plugin data",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "e5fd09ba8dd9c63a140479fbc2032254d1cf8c4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/plugin-data/",
      "published_at": "2021-05-03T06:33:26Z",
      "updated_at": "2021-03-16T11:02:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Use integers and floats All plugin metrics must be an integer or float, and they must be reported along with a duration. You can also report the type of metric so it can be converted from one unit type into another. You can display the metrics you collect in a variety of value methods, including throughput, averages, min/max, and rate. The metrics appear in charts and tables you create for your plugin's user interface. Plugins in Plugin Central are designed to report on frequency metrics using non-negative integers or floating-point numbers: Non-negative integers: Supported. Floating-point numbers: Supported. Negative values: Not supported, except for summary metrics on the plugin's Summary page. Otherwise, the UI shows negative values as zero. String values: Not supported; the UI shows strings as zero. However, parts of your metric name (the key) can be displayed in the UI. Define the time period (duration) All metrics must include a duration period that starts no more than a few hours in the past. The end time is set automatically to the time New Relic Plugins receives the metrics. You cannot report a duration that starts or ends in the future, or a duration that ends in the past. For best results, use one of the plugin SDKs to create your plugin. Otherwise, some POST attempts may fail because the actual recorded duration could vary in increments of the plugin's scheduled reporting frequency. Follow unit conversion guidelines Plugins automatically converts some units (such as rate units) to more natural forms. For example, [bytes/second] is converted to Bps. Follow these guidelines for unit conversions: Long format: Always specify the long format (for example, [bytes/second]) in the metric name. The long or short version will be used as appropriate. (Unit designations are not case sensitive.) Consistency: Use modifiers consistently in the metric name. If you use a different modifier with the same metric name, it will be treated as a different metric. Optional: Standard modifiers: Provide standard modifiers to the first metric in a value unit. For example, rather than specifying [bytes/second], you can specify [kiloBytes/second]. Plugins accepts these standard modifiers: Modifier Multiplier Modifier Multiplier Kilo 1000 - -- - -- Mega 1000^2 - -- - -- Giga 1000^3 Gibi 1024^3 Tera 1000^4 Tebi 1024^4 Peta 1000^5 Pebi 1024^5 Select value methods for display in the UI When you define a metric value for reporting, Plugins also captures a count, min, max, and sum of squares. Depending on whether you report single or aggregate values, you may report these numbers directly, or Plugins may calculate them automatically. You can then choose a value method for rendering these metrics in your plugin UI. In general, to configure value methods in the user interface: Select the metric you want to use. Review the list of value methods to select how to present the data in a column or plotted in a chart. Available value methods depend on the format of the units part of the metric name: Value method Count | Value Value Rate Count: The total of the count field over the entire timeslice data interval. When aggregating timeslice data, the count is summed. Total value: The total value over the entire time slice data interval. When aggregating timeslice data, the value field is summed Time rates only Average value: The total value divided by the total count, calculated only when units for both count and value are available. Throughput: The total count divided by the time interval of the time slice. By default New Relic Plugins measures the throughput in minutes according to the count units, such as calls per minute or bytes per minute. When the count units are specified in time (seconds), then the throughput appears as a percentage. Min/Max: The statistical values for minimum and maximum values when recorded in the metric value along with Count and Value. Standard deviation: The standard deviation of the entire set of measures recorded over the time interval. This is available only if the sum of squares field was populated in the metric value. The sum of squares and mean are used to calculate the standard deviation. In practice, this is meaningful only for populations that resemble a normal distribution. Rate: The rate is the total value divided by the time interval. When units of the value are in time, then the rate value is a percentage value. Units that are themselves rates will not have an explicit rate value method. The rate is simply the average value. Percentage: If you want the metric to appear as a percentage in the user interface, then you must define it as a percentage in the JSON.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.26048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Plugin</em> data",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603e91e3196a67c11ea83d9d"
    },
    {
      "sections": [
        "Plan plugin metrics",
        "Important",
        "Limited access to legacy plugins",
        "Collect plugin metrics",
        "Present plugin metrics"
      ],
      "title": "Plan plugin metrics",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "08974b731c810af2b6b037e8b761834c6e1ce7a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/plan-plugin-metrics/",
      "published_at": "2021-05-03T06:33:03Z",
      "updated_at": "2021-03-16T11:01:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Collect plugin metrics If you are running one of our APM agents to receive information about your applications, you can also receive arbitrary custom metrics. Using custom dashboards with your plugins, you can visualize custom metrics in a variety of useful ways. You can write plugins agents that can be run anywhere to collect metrics from any available system and report them to New Relic for dashboard display. Plugins also allow for summary metrics and one or more dashboards to visualize metrics that can be shared with every user of the plugin. This allows you to create a consistent user interface for the metrics you collect. The data that plugins report is in the form of a key/value pair. Values are numerical, either integers or floating point non-negative numbers. Negative numbers can be included in your summary metrics and tables; however, visualization in charts is limited to numbers greater than or equal to zero. Keys are strings which include the concept of name spaces and units. While values cannot be strings, parts of your metric name (the key) can be displayed in plugin dashboards. Your plugin agent can run anywhere with internet access to Plugins. You can write an agent using the agent SDKs. You can also write your agent to connect via HTTP POST using the API for Plugins in any language with HTTP support. Using the Plugin API might be the most appropriate solution when one agent is reporting metrics for more than one New Relic account. This is common for service providers to report specialized metrics for each of their customers using Plugins. This can be done with a small number of agents monitoring a large number of users. Present plugin metrics When creating a plugin agent, good metric name planning is critical to your success. Poorly chosen metrics names can make it difficult or impossible to display the information you intend. Plan ahead for how you want to visualize your information and to record metrics in a way that will facilitate this. You may even want to record the same metrics with more than one name in order to visualize different aspects of your data. Plugin dashboards do not have the ability to do mathematical calculations, so make sure your plugin agent handles any necessary calculations (sum, average, total, count, etc.) before recording metrics. Once you have collected metrics with your plugin agent, you will need to create dashboards to visualize the information in your metrics. All plugins will have a default dashboard. You can add as many dashboards as necessary to visualize your metric data (maximum 15). In addition to dashboards, you can choose up to five metrics to represent the summary of each instance. Summary metrics convey the health status of each instance and are used to trigger Caution events and Critical alerts for your plugins. The summary metrics appear on your plugin's Summary page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.2601,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Plan <em>plugin</em> metrics",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603eb01228ccbc6fa6eba790"
    },
    {
      "sections": [
        "Use the Plugin API",
        "Important",
        "Limited access to legacy plugins",
        "Before you begin",
        "Metric data POST",
        "Data aggregation",
        "Compression",
        "Examples",
        "Example JSON",
        "Pseudo-code template",
        "API responses and error codes",
        "Debugging logs",
        "Error codes"
      ],
      "title": "Use the Plugin API",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "f30a9a37241be1a13263e2bc8892f411d6fa618b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/use-plugin-api/",
      "published_at": "2021-05-06T04:03:41Z",
      "updated_at": "2021-03-13T03:44:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Before you begin Using a development language other than Ruby, .NET, or Java for a plugin agent means you do not have an SDK to work with, but you do have some benefits. This is a guide for plugin developers to get started with writing an agent in any language that can work directly with the Plugin API for Plugin Central. You can use any language you want, as long as it supports sending JSON through HTTP POST. This allows for better integration with your systems. For the same reason, it is the best option for SaaS-based plugin agents. However, if you are not using the Plugins SDK for Java. .NET, or Ruby, you have some additional setup and planning to do in developing a plugin agent. This includes: Error tracking on POST calls A method for tracking and aggregating data when a POST fails Your own support plans if a New Relic SDK for your language or development tools is not available Any publicly available plugins in the Plugin Central should come bundled with their source code if the executable code is not plain text. This allows you to both try out plugins and to review the code. Recommendation: Before authoring a plugin, install some existing plugins using the Java SDK, .NET SDK, or Ruby SDK to see how they are written. Metric data POST Metric data is sent as an HTTP POST of JSON data using this URI: https://platform-api.newrelic.com/platform/v1/metrics Copy The MIME-type for the POST is application/json. The Plugins feature is designed to receive a continuous stream of metrics at a certain maximum speed, and to present this information on useful charts. The recommended frequency for sending data to Plugins is to send 60 seconds worth of data once a minute. Agents sending data more frequently than twice a minute on average may be subject to enforced limits on the number of metrics being saved. The following are recommended soft limits. Requests smaller than this will work; requests larger than this are subject to rejection or automatic data aggregation. As a hard cap, the total size of the POST payload should be no larger than 1MB (10^6 bytes). If the metric is \"expensive\" to calculate and does not change quickly, consider writing your plugin agent so that it skips some polling cycles to retrieve data and then sends the last value. This produces better results for your plugin users' dashboards. Type Limit Description Components 500 Number of distinct components currently tracked. Please note this is a per POST limit only. More than 500 components are able to report to an account simultaneously. Metrics per component 10,000 Total number of unique metrics per component. Take precautions to ensure metric names are not generated too dynamically. Even if the number of metrics being sent in each individual post is small, over time they may add up to a large number of unique metrics. When the number of metrics for a given component exceeds this limit, the server may start aggregating metrics together by globbing segments of the metric name with an asterisk (*). Metrics per post 20,000 Number of metrics sent per post. A post may send data for multiple components in a single request as long as the total number of metrics in the request does not exceed this limit. Frequency of post 2 per minute Frequency of update. Agents are expected to send data no more frequently than 1 per minute. Data aggregation The SDKs manage data aggregation in the event of a failed POST. If you are not using an SDK, you need to manage this yourself. Include all five metric values in a POST: min, max, total, count, and sum or squares. (Exception: This may not be necessary for monotonic metrics where short term variation is not an issue.) Recompute these values for the accumulating metric data as required by what is being measured, incrementing the duration accordingly, until a successful POST is sent. Compression Data can be sent in the following encoding formats: identity deflate gzip If data is sent compressed, make sure the Content-Encoding header specifies the type of encoding. Examples Here are some examples for developing plugins. Example JSON This is an example of the JSON that would be used to POST data to Plugins. The JSON data is a hash with two required keys at the top level: agent: A hash describing the agent that is reporting metrics data to Plugins. A POST can contain information for only one agent. Host and version are required. components: An array of components, each consisting of a hash of attributes for the individual component. Multiple components can be sent with a single. Each component has its own name, GUID, duration, and metrics. { \"agent\": { \"host\" : \"db.internal.your_company.com\", \"pid\" : 1234, \"version\" : \"1.0.0\" }, \"components\": [ { \"name\": \"Primary MySQL Database\", \"guid\": \"com.your_company_name.plugin_name\", \"duration\" : 60, \"metrics\" : { \"Component/ProductionDatabase[Queries/Second]\": 100, \"Component/AnalyticsDatabase[Queries/Second]\": { \"min\" : 2, \"max\" : 10, \"total\": 12, \"count\" : 2, \"sum_of_squares\" : 104 } } } ] } Copy Pseudo-code template This is a pseudo-code example that works with the Plugin API. It can be used as a template for developing plugin agents. Initialization: // globals string platform_api_uri = \"https://platform-api.newrelic.com/platform/v1/metrics\" int poll_cycle = 60 // time in seconds string version = \"1.0.0\" // major_version.minor_version.patch_level string agent_host = get_host_name_where_this_process_is_running() string agent_pid = get_process_id_of_this_process() time last_poll_time // initialize if necessary initialize once create agent_hash with: agent_host agent_pid version for each newrelic_account do // just handling one account? then \"for each\" is unnecessary complexity for each monitored_component do create component_hash with: string guid = \"com.your_company.component_name_in_snake_case\" string name =\"Human Readable Component Name\" int duration = 0 // this will get updated each poll_cycle hash metrics_hash // this will be updated by populate_component_metrics_hash() end end end Copy Loop: every poll_cycle seconds do for each newrelic_account do // just handling one account? then \"for each\" is unnecessary complexity clear hash_to_send add agent_hash to hash_to_send for each component do populate_component_metrics_hash() this component.metrics_hash(\"duration\") = time.now() - last_poll_time in seconds add component.metrics_hash to hash_to_send end json_to_send = serialize_to_json(hash_to_send) connection = open http_connection(platform_api_uri) add header(\"X-License-Key\",this newrelic_account.license_key) to connection add header(\"Content-Type\",\"application/json\") to connection add header(\"Accept\",\"application/json\") to connection set http_verb to \"POST\" for connection response = send(json_to_send) to connection case response.code when response_code = 200 clear component.metrics_hash last_poll_time = time.now() when response_code = 400 // your request was malformed // consider reporting a \"supportability\" metric which counts the number of 400 responses you get // for example \"Component/Supportability/http_error_codes/400\" // you can use this on a \"Supportability\" Dashboard that helps diagnose your agent when response_code = 403 // forbidden probably due to a bad license key // log error and shutdown the agent when response_code = 404 // invalid URL // you should never get this error for https://platform-api.newrelic.com/platform/v1/metrics when response_code = 405 // invalid method // HTTP verb should be \"POST\" when response_code = 413 // POST body too large // try splitting at component boundaries // split along metric name spaces // fail gracefully - consider reporting a supportability metric (see 400) when response_code = 500 // error on New Relic's collector // could be due to malformed data or system trouble // fail gracefully - consider reporting a supportability metric (see 400) when response_code = 503 or 504 // New Relic collector busy //- this happens by design from time-to-time // keep collecting metrics // do NOT reset last_poll_time // log error if the problem persists for several minutes end case end end Copy Metric population: function populate_component_metrics_hash() // collect metrics from monitored component at any interval // if this is the first time collecting metrics, set last_poll_time to // time.now - metric duration, the time duration for which these metrics // were collected // // if you collect 2 or more metrics from the monitored component before data // is reported to Plugins either because your metric collection interval is // faster than poll_cycle or because your agent was unable to report metrics to // Plugins (for example a 503 http response), aggregate your data by storing: // total_value, max, min, count, sum_of_squares for each metric // // if the interval is longer than poll_cycle, retain the metrics and // report them each poll_cycle until they are updated end Copy API responses and error codes Depending on whether you are using the Plugin API or an agent SDK for plugins, the HTTP responses and logging techniques may be different. For example, responses for the Plugin API are uncompressed JSON. Successful posts return this JSON: {\"status\":\"ok\"} Copy The API does not support Accept-Encoding. Debugging logs To debug information, use either of these options: public static Logger getLogger(); Copy OR public static void Logger setLogger(Logger logger) { LOGGER = logger; } Copy Error codes If an error occurs, an appropriate status code is returned. The JSON returned is the hash key error with a detailed description of the error that occurred. For example: {\"error\":\"Failed to create agent with parameters=[...]\"} {\"error\":\"Missing metric data\"} {\"error\":\"Unable to parse body: Unexpected token RIGHT BRACE(}) at position 228.\"} Copy Code Name Description 400 Bad request The request or headers are in the wrong format, or the URL is incorrect, or the GUID does not meet the validation requirements. 403 Unauthorized Authentication error (no license key header, or invalid license key). 404 Not found Invalid URL. 405 Method not allowed Returned if the method is an invalid or unexpected type (GET/POST/PUT/etc.). 413 Request entity too large Too many metrics were sent in one request, or too many components (instances) were specified in one request, or other single-request limits were reached. 500 Internal server error Unexpected server error. 502 Bad gateway All 50X errors mean there is a transient problem in the server completing requests, and no data has been retained. Clients are expected to resend the data after waiting one minute. The data should be aggregated appropriately, combining multiple timeslice data values for the same metric into a single aggregate timeslice data value. 503 Service unavailable See 502 description. 504 Gateway timeout See 502 description.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.28523,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use the <em>Plugin</em> API",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "604436cf28ccbcf2332c60a8"
    }
  ],
  "/docs/plugins/plugin-developer-resources/developer-reference/parts-plugin": [
    {
      "sections": [
        "Metric data for the Plugin API",
        "Important",
        "Limited access to legacy plugins",
        "URI",
        "GUID",
        "Time periods for metrics",
        "Metric data details",
        "Timeslice metric values",
        "Calculations",
        "Examples",
        "Metrics",
        "cURL example",
        "Metric references",
        "Metric naming guidelines",
        "Metric segments",
        "Caution",
        "Metric attributes",
        "Metric values",
        "Units"
      ],
      "title": "Metric data for the Plugin API",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "2e9d0553b7277c73fe8a2147519d9943fca440fc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/metric-data-plugin-api/",
      "published_at": "2021-05-06T09:48:09Z",
      "updated_at": "2021-03-16T11:20:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. URI Metric timeslice data is sent with the Plugin API as an HTTP POST of JSON data using this URI: https://platform-api.newrelic.com/platform/v1/metrics Copy The Plugin API does not support New Relic's REST API, and vice versa. However, you can use the REST API (v2) to extract plugin data. For a list with links to procedures and examples, see Plugin examples (v2). GUID The plugin needs a Globally Unique Identifier (GUID), which is a character string limited to no less than 4 and no more than 255 characters. The GUID for a published plugin must be unique for each plugin. When creating a plugin, you are responsible for managing your own GUIDs to avoid naming conflicts. Time periods for metrics Metrics that appear in dashboards are reported with a duration. The end time is implied by the time New Relic receives the metric(s). Thus, you cannot define metric values that both start and end in the future, or start and end in the past. The Plugin API is designed for live metrics only, not historical metric collection. Metrics may only be reported for a period starting in the past (no more than a few hours) and ending upon reporting. The charts on your plugin's dashboards can show any time period you want; for example, 30 minutes, 30 days, etc. You can also deliver data at 1-hour intervals. New Relic does not extrapolate data values between the data points delivered. For example, data will aggregate when there is too much, but data will not be extrapolated if there is not enough data. In order for data to appear on a 30 minute chart, make sure at least one data point is within the range, or no data will appear. Use a 60-second polling interval, because the default dashboard shows 30 minutes of data, which gives 30 data points for the chart. Or, if you want to show 3 days of data, use a 1-hour polling interval, which provides 24 * 3=72 data points for your chart. Metric data details The JSON data is a hash with two required keys at the top level: components: An array of components, each consisting of a hash of attributes for the individual component, including the metric data. agent: A hash describing the agent that is reporting metrics data to New Relic Plugins on behalf of the component(s). Of these values, only host and version are required. When graphing metrics, be aware that null = zero. Metric data POST Description Component data One of two required keys at the top level. This is an array of hashes describing the components that report metrics in this request. Each hash contains the following values: name A name ( < =32 characters) that uniquely identifies the monitored entity and appears as the display name for this agent. Note: Metric names are case sensitive. guid A \"reverse domain name\" styled identifier; for example, com.newrelic.mysql. This is a unique identity defined in the plugin's user interface, which ties the agent data to the corresponding plugin user interface in New Relic. duration The duration in seconds over which the metric data was collected. The end time is implied as the time the data is received by the API. metrics Timeslice data for each metric being reported. The hash keys are metric names, and the values are the timeslice data value for the named metric. Agent data One of two required keys at the top level. A hash specifying information about the agent that is reporting data on behalf of the components. host (required) The hostname of the agent monitoring the specified components. This is the hostname where the monitoring agent is running, not the hostname of the component being monitored. pid (optional) The process identifier of the agent monitoring the specified components. This is the process identifier of the monitoring agent itself, not a process identifier that may be associated with the monitored components. version (required) The version of the agent monitoring the specified components, using the format A.B.C where A, B, and C are integers. The version number must conform to the rules specified in standard Semantic Versioning scheme v2.0.0. Timeslice metric values Metrics are sent inside the component hash with the key metrics and a hash as a value. The hash keys are metric names, and the values are the timeslice data values for the named metric. The timeslice hash value uses one of three formats: Timeslice hash value Description A single scalar value with a floating point number or integer This is the simplest format, and this number is required. The reported value is used as the total, minimum, and maximum data value. The count value is assumed to be 1. The Plugin API does not support reporting of arbitrary string metrics, only scalar values that are aggregated. Array of five required values in specific order An array of five required integers or floating point numbers that represent, in order: Total value over the time period Count of the number of events this value represents over the time period; the average is calculated by dividing total by count Minimum value over the time period Maximum value over the time period Sum of squares for the samples over the time period Hash with five required key/value pairs in any order A hash with value names as the keys, and integers or floating point values as the values. All five key/value pairs are required. The keys of the hash are the type of timeslice data, and the value is the data value. These has key/value pairs can be in any order: total: Total value over the time period count: Count of the number of events this value represents over the time period; the average is calculated by dividing total by count min: Minimum value over the time period max: Maximum value over the time period sum_of_squares: Sum of squares for the samples over the time period Calculations Limited mathematical calculations are available with the key/value pairs, such as computing total, count, minimum, maximum, averages, and standard deviations. However, to do more extensive calculations, you need to do the math in the agent, and then send the results as a new metric. For example, send Metric1, Metric2, and Metric3 (which equals Metric1 divided by Metric2). If you submit negative metric values, the charts on your plugin's dashboards will not show them. However, the summary metrics for your plugin will show negative values. Examples Here are some examples. Metrics \"metrics\" : { \"Component/Database/Primary[Queries/Second]\" : { \"total\" : 25, \"count\" : 2, \"min\" : 10, \"max\" : 15, \"sum_of_squares\" : 325 }, \"Component/Database/Secondary[Queries/Second]\" : [25, 2, 10, 15, 325], \"Component/Database/Backup[Queries/Second]\" : 10 } Copy cURL example curl -vi https://platform-api.newrelic.com/platform/v1/metrics \\ -H \"X-License-Key: YOUR_LICENSE_KEY_HERE\" \\ -H \"Content-Type: application/json\" \\ -H \"Accept: application/json\" \\ -X POST -d '{ \"agent\": { \"host\" : \"db.internal.your_company.com\", \"pid\" : 1234, \"version\" : \"1.0.0\" }, \"components\": [ { \"name\": \"Primary MySQL Database\", \"guid\": \"com.your_company_name.plugin_name\", \"duration\" : 60, \"metrics\" : { \"Component/ProductionDatabase[Queries/Second]\": 100, \"Component/AnalyticsDatabase[Queries/Second]\": { \"min\" : 2, \"max\" : 10, \"total\": 12, \"count\" : 2, \"sum_of_squares\" : 104 } } } ] }' Copy Metric references Refer to these references as you develop your own plugins. Metric naming guidelines Metric timeslice data uses a unique case-sensitive identifier, referred to as the metric name. In order for the metric to be rendered usefully in the user interface, the metric name must contain a prefix, category name, label, and optional units indicator. Here are some recommended guidelines for the text in metric names to make them more readable in the user interface. Metric naming guidelines Guidelines UI display Use case and whitespace characters appropriate for display in the user interface, because segments are rendered as-is in the UI. Category and label segments Metric names are case sensitive. Capitalize the first word in the category and label segments. Keep category and label segments as short as possible. Length There is a limit of 255 characters for metric names. Characters to avoid using Avoid using the following characters in names. These characters have special meaning and should not be used except where specifically required for their purpose. / ] [ | * Also avoid multi-byte characters. Units Use abbreviated names for units when possible. Metric segments Each of these segments is divided by the forward slash / character. Each segment is interpreted for a specific purpose in the UI and roughly follows this pattern: prefix/category/label[units] Copy For example, the metric representing the latency of cache hits reported by a plugin collecting data for a cache appliance might look like this: Component/Cache/Hits[sec|hit] Copy Metric segment order Notes Prefix: Component/ or Custom/ The first segment of a custom metric is Component/ (if it comes from a plugin agent) or Custom/ (if it is a custom metric collected by a New Relic agent. For example, Custom/MyMetric). Caution If you use the Plugin API only, and if the metrics do not start with Component/, they may not be available or may not appear correctly in charts and dashboards. Category name The second part of a custom metric is a category name, used to group metrics into different categories. For example, the metrics reported by a database plugin may fall into categories such as schema, tables, or connections. Label The third part of the metric name is used for labeling the data when it appears in tables and charts. If it contains multiple segments, each slash separating the segments of the label will be rendered as part of the label. Units The fourth segment of the metric consists of a units specification. Metric attributes Most metrics are defined statically and represent some global state; for example, cache size. Other metrics are dynamic and include some contextual attribute like the name of a host or a file. These metrics need to be structured so you can easily show them as a group in a table stacked in a chart. To add attribute names to a metric, put them in trailing segments separated by a forward slash / character. For example: Component/Disk/Bytes In/dev001 Component/Network/External services/ae592c3.aws.com Copy You can specify more than one attribute as long as they occupy the same position for a given metric category and label: Component/Tables/Row count/DB001/BLOG_POSTS[rows] Copy Caution Avoid overloading the metric space by putting in segment values that have a large range of values. While something like a customer's region in an attribute is a reasonable thing to track in the metric, the customer name would not be if you have more than a few hundred customers. If your agent starts sending an excessive amount of metrics, your metrics may be automatically collapsed into groups with wildcards: Component/Users/*[visits] Copy Metric values You can report a metric value in one of two ways: Single value: This typically is the value being reported for that time slice. If you use an SDK, you report the single value to the SDK. It handles tracking the rest of these values. Set of aggregate value: This includes the min, max, and sum of squares values for the value being reported. If you use the Plugin API, the preferred method is to report all of the values. When aggregating a series of timeslice data into a single timeslice data entry for a given period, all fields are summed except for the min and max value. If you are using an SDK plugins, this is done automatically. If you are using the Plugin API to develop plugins, you need to code for this. A metric value contains several fields, but it is represented primarily by the count and value. The count is a 32-bit integer field, and the value is a 32-bit float. Metric values can represent more than one data point or sample as an aggregation of measures. Typically the count is the number of samples, and the value is the total value of all samples. Here are the fields in a metric value: Metric value Description count The number of things being measured. If data is collected at the time the event occurs, like with some kind of injection, then the count in the timeslice data will be 1. Required if it is not 1 (0 generally represents an absent value). value Required: The total value measured across all things being counted. When averages are calculated later, we divide the value by the count. In some cases, the value field is irrelevant. min, max The minimum and maximum values when the count is greater than 1. When the count is 1, these are the same as the value. Optional depending on whether they are available or relevant for a given metric. sum of squares This is the sum of squares of each value and is useful when the values follow a standard distribution. You can only capture this value when you are collecting data each time the event happens. You store the value of the event in the value field and the square of the value in the sum of squares. This is used to calculate a standard deviation later on. The sum of squares is optional. It is used to calculate a standard deviation for a selection of data. If standard deviation for the value is not meaningful, such as when the values are not part of a normal distribution, then the sum of squares is omitted. Units When a metric value is collected by periodically sampling an interface, the count units are implicitly samples, and the value units are whatever is being sampled. For data it might be bytes. For throughput it might be something like kilobytes/second. For utilization (like CPU) it might be percent. When the count units are samples, they can be omitted in the metric name. Units of time, bytes, and bits may get special treatment, allowing additional conversion in the user interface between magnitudes. For example, if you specify a metric with units of kilobytes, then in the UI you may be presented the option of displaying a chart of Mb. Metrics units describe what the value field and count represent. Units are specified inside brackets and consist of units for the value, followed by a pipe (|) and then the units for the count. For example: Component/metric_id[value_unit|count_unit] Copy Exception: The pipe and count units (|[count_unit]) are not required after the value unit for samples. Rate metrics are commonly defined as sample per interval. This is defined as units/interval in the metric, with a forward slash to separate units from interval. For example: Component/metric_id[value_unit/interval] Copy In rare cases there will only be a unit value for count. The value will be interpreted as unitless. Value units are omitted, and the vertical bar appears in front of the count units. For example: Component/metric_id[|count_unit] Copy Units for plugin metrics Notes Naming conventions You can have mixed-case unit names. They.can consist strictly of alphabetical characters as well as the _, %, or / symbols. Case is preserved. Punctuation markers, dashes, spaces and any other symbols are not allowed. Recommendation: Use uncapitalized words, spelled out in full. For example, use second not sec. Rate metrics When a metric value represents a rate, such as bytes/second, then the value is assumed to be a sample for the given interval. The units specifier looks like [ bytes/second] since the count units are implicitly samples. For example: Component/metric_id[bytes/second] Copy The count units are samples (default) and the value units are bytes/second. The forward slash separates the units from the interval. Count with units A common case for declaring units is when measuring response times. If the custom metric represents the average latency of a call to a cache, then the units for the metric value are seconds per call. For example: Component/metric_id[seconds|call] Copy Count units are calls and value units are seconds. The default count metric is not being used, so you need to specify it. The bar separates the value units from the count units. Units in charts The units specified in a metric have several implications for the way the values are interpreted by generic charts and tables: Units display in labels and tooltips in charts to indicate what the values represent. Units imply a set of different values available from a single metric value. When creating a chart in a dashboard, the dashboard author selects one of the available value methods for that metric to plot in the chart.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.26834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data for the <em>Plugin</em> API",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "&quot; : 2, &quot;max&quot; : 10, &quot;total&quot;: 12, &quot;count&quot; : 2, &quot;sum_of_squares&quot; : 104 } } } ] }&#x27; Copy Metric references <em>Refer</em> to these references as you <em>develop</em> your own <em>plugins</em>. Metric naming guidelines Metric timeslice data uses a unique case-sensitive identifier, referred to as the metric name. In order"
      },
      "id": "603e80db64441f0def4e8863"
    },
    {
      "sections": [
        "Plugin data",
        "Important",
        "Limited access to legacy plugins",
        "Use integers and floats",
        "Define the time period (duration)",
        "Follow unit conversion guidelines",
        "Select value methods for display in the UI"
      ],
      "title": "Plugin data",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "e5fd09ba8dd9c63a140479fbc2032254d1cf8c4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/plugin-data/",
      "published_at": "2021-05-03T06:33:26Z",
      "updated_at": "2021-03-16T11:02:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Use integers and floats All plugin metrics must be an integer or float, and they must be reported along with a duration. You can also report the type of metric so it can be converted from one unit type into another. You can display the metrics you collect in a variety of value methods, including throughput, averages, min/max, and rate. The metrics appear in charts and tables you create for your plugin's user interface. Plugins in Plugin Central are designed to report on frequency metrics using non-negative integers or floating-point numbers: Non-negative integers: Supported. Floating-point numbers: Supported. Negative values: Not supported, except for summary metrics on the plugin's Summary page. Otherwise, the UI shows negative values as zero. String values: Not supported; the UI shows strings as zero. However, parts of your metric name (the key) can be displayed in the UI. Define the time period (duration) All metrics must include a duration period that starts no more than a few hours in the past. The end time is set automatically to the time New Relic Plugins receives the metrics. You cannot report a duration that starts or ends in the future, or a duration that ends in the past. For best results, use one of the plugin SDKs to create your plugin. Otherwise, some POST attempts may fail because the actual recorded duration could vary in increments of the plugin's scheduled reporting frequency. Follow unit conversion guidelines Plugins automatically converts some units (such as rate units) to more natural forms. For example, [bytes/second] is converted to Bps. Follow these guidelines for unit conversions: Long format: Always specify the long format (for example, [bytes/second]) in the metric name. The long or short version will be used as appropriate. (Unit designations are not case sensitive.) Consistency: Use modifiers consistently in the metric name. If you use a different modifier with the same metric name, it will be treated as a different metric. Optional: Standard modifiers: Provide standard modifiers to the first metric in a value unit. For example, rather than specifying [bytes/second], you can specify [kiloBytes/second]. Plugins accepts these standard modifiers: Modifier Multiplier Modifier Multiplier Kilo 1000 - -- - -- Mega 1000^2 - -- - -- Giga 1000^3 Gibi 1024^3 Tera 1000^4 Tebi 1024^4 Peta 1000^5 Pebi 1024^5 Select value methods for display in the UI When you define a metric value for reporting, Plugins also captures a count, min, max, and sum of squares. Depending on whether you report single or aggregate values, you may report these numbers directly, or Plugins may calculate them automatically. You can then choose a value method for rendering these metrics in your plugin UI. In general, to configure value methods in the user interface: Select the metric you want to use. Review the list of value methods to select how to present the data in a column or plotted in a chart. Available value methods depend on the format of the units part of the metric name: Value method Count | Value Value Rate Count: The total of the count field over the entire timeslice data interval. When aggregating timeslice data, the count is summed. Total value: The total value over the entire time slice data interval. When aggregating timeslice data, the value field is summed Time rates only Average value: The total value divided by the total count, calculated only when units for both count and value are available. Throughput: The total count divided by the time interval of the time slice. By default New Relic Plugins measures the throughput in minutes according to the count units, such as calls per minute or bytes per minute. When the count units are specified in time (seconds), then the throughput appears as a percentage. Min/Max: The statistical values for minimum and maximum values when recorded in the metric value along with Count and Value. Standard deviation: The standard deviation of the entire set of measures recorded over the time interval. This is available only if the sum of squares field was populated in the metric value. The sum of squares and mean are used to calculate the standard deviation. In practice, this is meaningful only for populations that resemble a normal distribution. Rate: The rate is the total value divided by the time interval. When units of the value are in time, then the rate value is a percentage value. Units that are themselves rates will not have an explicit rate value method. The rate is simply the average value. Percentage: If you want the metric to appear as a percentage in the user interface, then you must define it as a percentage in the JSON.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.26047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Plugin</em> data",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603e91e3196a67c11ea83d9d"
    },
    {
      "sections": [
        "Plan plugin metrics",
        "Important",
        "Limited access to legacy plugins",
        "Collect plugin metrics",
        "Present plugin metrics"
      ],
      "title": "Plan plugin metrics",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "08974b731c810af2b6b037e8b761834c6e1ce7a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/plan-plugin-metrics/",
      "published_at": "2021-05-03T06:33:03Z",
      "updated_at": "2021-03-16T11:01:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Collect plugin metrics If you are running one of our APM agents to receive information about your applications, you can also receive arbitrary custom metrics. Using custom dashboards with your plugins, you can visualize custom metrics in a variety of useful ways. You can write plugins agents that can be run anywhere to collect metrics from any available system and report them to New Relic for dashboard display. Plugins also allow for summary metrics and one or more dashboards to visualize metrics that can be shared with every user of the plugin. This allows you to create a consistent user interface for the metrics you collect. The data that plugins report is in the form of a key/value pair. Values are numerical, either integers or floating point non-negative numbers. Negative numbers can be included in your summary metrics and tables; however, visualization in charts is limited to numbers greater than or equal to zero. Keys are strings which include the concept of name spaces and units. While values cannot be strings, parts of your metric name (the key) can be displayed in plugin dashboards. Your plugin agent can run anywhere with internet access to Plugins. You can write an agent using the agent SDKs. You can also write your agent to connect via HTTP POST using the API for Plugins in any language with HTTP support. Using the Plugin API might be the most appropriate solution when one agent is reporting metrics for more than one New Relic account. This is common for service providers to report specialized metrics for each of their customers using Plugins. This can be done with a small number of agents monitoring a large number of users. Present plugin metrics When creating a plugin agent, good metric name planning is critical to your success. Poorly chosen metrics names can make it difficult or impossible to display the information you intend. Plan ahead for how you want to visualize your information and to record metrics in a way that will facilitate this. You may even want to record the same metrics with more than one name in order to visualize different aspects of your data. Plugin dashboards do not have the ability to do mathematical calculations, so make sure your plugin agent handles any necessary calculations (sum, average, total, count, etc.) before recording metrics. Once you have collected metrics with your plugin agent, you will need to create dashboards to visualize the information in your metrics. All plugins will have a default dashboard. You can add as many dashboards as necessary to visualize your metric data (maximum 15). In addition to dashboards, you can choose up to five metrics to represent the summary of each instance. Summary metrics convey the health status of each instance and are used to trigger Caution events and Critical alerts for your plugins. The summary metrics appear on your plugin's Summary page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.2601,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Plan <em>plugin</em> metrics",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603eb01228ccbc6fa6eba790"
    }
  ],
  "/docs/plugins/plugin-developer-resources/developer-reference/plan-plugin-metrics": [
    {
      "sections": [
        "Metric data for the Plugin API",
        "Important",
        "Limited access to legacy plugins",
        "URI",
        "GUID",
        "Time periods for metrics",
        "Metric data details",
        "Timeslice metric values",
        "Calculations",
        "Examples",
        "Metrics",
        "cURL example",
        "Metric references",
        "Metric naming guidelines",
        "Metric segments",
        "Caution",
        "Metric attributes",
        "Metric values",
        "Units"
      ],
      "title": "Metric data for the Plugin API",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "2e9d0553b7277c73fe8a2147519d9943fca440fc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/metric-data-plugin-api/",
      "published_at": "2021-05-06T09:48:09Z",
      "updated_at": "2021-03-16T11:20:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. URI Metric timeslice data is sent with the Plugin API as an HTTP POST of JSON data using this URI: https://platform-api.newrelic.com/platform/v1/metrics Copy The Plugin API does not support New Relic's REST API, and vice versa. However, you can use the REST API (v2) to extract plugin data. For a list with links to procedures and examples, see Plugin examples (v2). GUID The plugin needs a Globally Unique Identifier (GUID), which is a character string limited to no less than 4 and no more than 255 characters. The GUID for a published plugin must be unique for each plugin. When creating a plugin, you are responsible for managing your own GUIDs to avoid naming conflicts. Time periods for metrics Metrics that appear in dashboards are reported with a duration. The end time is implied by the time New Relic receives the metric(s). Thus, you cannot define metric values that both start and end in the future, or start and end in the past. The Plugin API is designed for live metrics only, not historical metric collection. Metrics may only be reported for a period starting in the past (no more than a few hours) and ending upon reporting. The charts on your plugin's dashboards can show any time period you want; for example, 30 minutes, 30 days, etc. You can also deliver data at 1-hour intervals. New Relic does not extrapolate data values between the data points delivered. For example, data will aggregate when there is too much, but data will not be extrapolated if there is not enough data. In order for data to appear on a 30 minute chart, make sure at least one data point is within the range, or no data will appear. Use a 60-second polling interval, because the default dashboard shows 30 minutes of data, which gives 30 data points for the chart. Or, if you want to show 3 days of data, use a 1-hour polling interval, which provides 24 * 3=72 data points for your chart. Metric data details The JSON data is a hash with two required keys at the top level: components: An array of components, each consisting of a hash of attributes for the individual component, including the metric data. agent: A hash describing the agent that is reporting metrics data to New Relic Plugins on behalf of the component(s). Of these values, only host and version are required. When graphing metrics, be aware that null = zero. Metric data POST Description Component data One of two required keys at the top level. This is an array of hashes describing the components that report metrics in this request. Each hash contains the following values: name A name ( < =32 characters) that uniquely identifies the monitored entity and appears as the display name for this agent. Note: Metric names are case sensitive. guid A \"reverse domain name\" styled identifier; for example, com.newrelic.mysql. This is a unique identity defined in the plugin's user interface, which ties the agent data to the corresponding plugin user interface in New Relic. duration The duration in seconds over which the metric data was collected. The end time is implied as the time the data is received by the API. metrics Timeslice data for each metric being reported. The hash keys are metric names, and the values are the timeslice data value for the named metric. Agent data One of two required keys at the top level. A hash specifying information about the agent that is reporting data on behalf of the components. host (required) The hostname of the agent monitoring the specified components. This is the hostname where the monitoring agent is running, not the hostname of the component being monitored. pid (optional) The process identifier of the agent monitoring the specified components. This is the process identifier of the monitoring agent itself, not a process identifier that may be associated with the monitored components. version (required) The version of the agent monitoring the specified components, using the format A.B.C where A, B, and C are integers. The version number must conform to the rules specified in standard Semantic Versioning scheme v2.0.0. Timeslice metric values Metrics are sent inside the component hash with the key metrics and a hash as a value. The hash keys are metric names, and the values are the timeslice data values for the named metric. The timeslice hash value uses one of three formats: Timeslice hash value Description A single scalar value with a floating point number or integer This is the simplest format, and this number is required. The reported value is used as the total, minimum, and maximum data value. The count value is assumed to be 1. The Plugin API does not support reporting of arbitrary string metrics, only scalar values that are aggregated. Array of five required values in specific order An array of five required integers or floating point numbers that represent, in order: Total value over the time period Count of the number of events this value represents over the time period; the average is calculated by dividing total by count Minimum value over the time period Maximum value over the time period Sum of squares for the samples over the time period Hash with five required key/value pairs in any order A hash with value names as the keys, and integers or floating point values as the values. All five key/value pairs are required. The keys of the hash are the type of timeslice data, and the value is the data value. These has key/value pairs can be in any order: total: Total value over the time period count: Count of the number of events this value represents over the time period; the average is calculated by dividing total by count min: Minimum value over the time period max: Maximum value over the time period sum_of_squares: Sum of squares for the samples over the time period Calculations Limited mathematical calculations are available with the key/value pairs, such as computing total, count, minimum, maximum, averages, and standard deviations. However, to do more extensive calculations, you need to do the math in the agent, and then send the results as a new metric. For example, send Metric1, Metric2, and Metric3 (which equals Metric1 divided by Metric2). If you submit negative metric values, the charts on your plugin's dashboards will not show them. However, the summary metrics for your plugin will show negative values. Examples Here are some examples. Metrics \"metrics\" : { \"Component/Database/Primary[Queries/Second]\" : { \"total\" : 25, \"count\" : 2, \"min\" : 10, \"max\" : 15, \"sum_of_squares\" : 325 }, \"Component/Database/Secondary[Queries/Second]\" : [25, 2, 10, 15, 325], \"Component/Database/Backup[Queries/Second]\" : 10 } Copy cURL example curl -vi https://platform-api.newrelic.com/platform/v1/metrics \\ -H \"X-License-Key: YOUR_LICENSE_KEY_HERE\" \\ -H \"Content-Type: application/json\" \\ -H \"Accept: application/json\" \\ -X POST -d '{ \"agent\": { \"host\" : \"db.internal.your_company.com\", \"pid\" : 1234, \"version\" : \"1.0.0\" }, \"components\": [ { \"name\": \"Primary MySQL Database\", \"guid\": \"com.your_company_name.plugin_name\", \"duration\" : 60, \"metrics\" : { \"Component/ProductionDatabase[Queries/Second]\": 100, \"Component/AnalyticsDatabase[Queries/Second]\": { \"min\" : 2, \"max\" : 10, \"total\": 12, \"count\" : 2, \"sum_of_squares\" : 104 } } } ] }' Copy Metric references Refer to these references as you develop your own plugins. Metric naming guidelines Metric timeslice data uses a unique case-sensitive identifier, referred to as the metric name. In order for the metric to be rendered usefully in the user interface, the metric name must contain a prefix, category name, label, and optional units indicator. Here are some recommended guidelines for the text in metric names to make them more readable in the user interface. Metric naming guidelines Guidelines UI display Use case and whitespace characters appropriate for display in the user interface, because segments are rendered as-is in the UI. Category and label segments Metric names are case sensitive. Capitalize the first word in the category and label segments. Keep category and label segments as short as possible. Length There is a limit of 255 characters for metric names. Characters to avoid using Avoid using the following characters in names. These characters have special meaning and should not be used except where specifically required for their purpose. / ] [ | * Also avoid multi-byte characters. Units Use abbreviated names for units when possible. Metric segments Each of these segments is divided by the forward slash / character. Each segment is interpreted for a specific purpose in the UI and roughly follows this pattern: prefix/category/label[units] Copy For example, the metric representing the latency of cache hits reported by a plugin collecting data for a cache appliance might look like this: Component/Cache/Hits[sec|hit] Copy Metric segment order Notes Prefix: Component/ or Custom/ The first segment of a custom metric is Component/ (if it comes from a plugin agent) or Custom/ (if it is a custom metric collected by a New Relic agent. For example, Custom/MyMetric). Caution If you use the Plugin API only, and if the metrics do not start with Component/, they may not be available or may not appear correctly in charts and dashboards. Category name The second part of a custom metric is a category name, used to group metrics into different categories. For example, the metrics reported by a database plugin may fall into categories such as schema, tables, or connections. Label The third part of the metric name is used for labeling the data when it appears in tables and charts. If it contains multiple segments, each slash separating the segments of the label will be rendered as part of the label. Units The fourth segment of the metric consists of a units specification. Metric attributes Most metrics are defined statically and represent some global state; for example, cache size. Other metrics are dynamic and include some contextual attribute like the name of a host or a file. These metrics need to be structured so you can easily show them as a group in a table stacked in a chart. To add attribute names to a metric, put them in trailing segments separated by a forward slash / character. For example: Component/Disk/Bytes In/dev001 Component/Network/External services/ae592c3.aws.com Copy You can specify more than one attribute as long as they occupy the same position for a given metric category and label: Component/Tables/Row count/DB001/BLOG_POSTS[rows] Copy Caution Avoid overloading the metric space by putting in segment values that have a large range of values. While something like a customer's region in an attribute is a reasonable thing to track in the metric, the customer name would not be if you have more than a few hundred customers. If your agent starts sending an excessive amount of metrics, your metrics may be automatically collapsed into groups with wildcards: Component/Users/*[visits] Copy Metric values You can report a metric value in one of two ways: Single value: This typically is the value being reported for that time slice. If you use an SDK, you report the single value to the SDK. It handles tracking the rest of these values. Set of aggregate value: This includes the min, max, and sum of squares values for the value being reported. If you use the Plugin API, the preferred method is to report all of the values. When aggregating a series of timeslice data into a single timeslice data entry for a given period, all fields are summed except for the min and max value. If you are using an SDK plugins, this is done automatically. If you are using the Plugin API to develop plugins, you need to code for this. A metric value contains several fields, but it is represented primarily by the count and value. The count is a 32-bit integer field, and the value is a 32-bit float. Metric values can represent more than one data point or sample as an aggregation of measures. Typically the count is the number of samples, and the value is the total value of all samples. Here are the fields in a metric value: Metric value Description count The number of things being measured. If data is collected at the time the event occurs, like with some kind of injection, then the count in the timeslice data will be 1. Required if it is not 1 (0 generally represents an absent value). value Required: The total value measured across all things being counted. When averages are calculated later, we divide the value by the count. In some cases, the value field is irrelevant. min, max The minimum and maximum values when the count is greater than 1. When the count is 1, these are the same as the value. Optional depending on whether they are available or relevant for a given metric. sum of squares This is the sum of squares of each value and is useful when the values follow a standard distribution. You can only capture this value when you are collecting data each time the event happens. You store the value of the event in the value field and the square of the value in the sum of squares. This is used to calculate a standard deviation later on. The sum of squares is optional. It is used to calculate a standard deviation for a selection of data. If standard deviation for the value is not meaningful, such as when the values are not part of a normal distribution, then the sum of squares is omitted. Units When a metric value is collected by periodically sampling an interface, the count units are implicitly samples, and the value units are whatever is being sampled. For data it might be bytes. For throughput it might be something like kilobytes/second. For utilization (like CPU) it might be percent. When the count units are samples, they can be omitted in the metric name. Units of time, bytes, and bits may get special treatment, allowing additional conversion in the user interface between magnitudes. For example, if you specify a metric with units of kilobytes, then in the UI you may be presented the option of displaying a chart of Mb. Metrics units describe what the value field and count represent. Units are specified inside brackets and consist of units for the value, followed by a pipe (|) and then the units for the count. For example: Component/metric_id[value_unit|count_unit] Copy Exception: The pipe and count units (|[count_unit]) are not required after the value unit for samples. Rate metrics are commonly defined as sample per interval. This is defined as units/interval in the metric, with a forward slash to separate units from interval. For example: Component/metric_id[value_unit/interval] Copy In rare cases there will only be a unit value for count. The value will be interpreted as unitless. Value units are omitted, and the vertical bar appears in front of the count units. For example: Component/metric_id[|count_unit] Copy Units for plugin metrics Notes Naming conventions You can have mixed-case unit names. They.can consist strictly of alphabetical characters as well as the _, %, or / symbols. Case is preserved. Punctuation markers, dashes, spaces and any other symbols are not allowed. Recommendation: Use uncapitalized words, spelled out in full. For example, use second not sec. Rate metrics When a metric value represents a rate, such as bytes/second, then the value is assumed to be a sample for the given interval. The units specifier looks like [ bytes/second] since the count units are implicitly samples. For example: Component/metric_id[bytes/second] Copy The count units are samples (default) and the value units are bytes/second. The forward slash separates the units from the interval. Count with units A common case for declaring units is when measuring response times. If the custom metric represents the average latency of a call to a cache, then the units for the metric value are seconds per call. For example: Component/metric_id[seconds|call] Copy Count units are calls and value units are seconds. The default count metric is not being used, so you need to specify it. The bar separates the value units from the count units. Units in charts The units specified in a metric have several implications for the way the values are interpreted by generic charts and tables: Units display in labels and tooltips in charts to indicate what the values represent. Units imply a set of different values available from a single metric value. When creating a chart in a dashboard, the dashboard author selects one of the available value methods for that metric to plot in the chart.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.26834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data for the <em>Plugin</em> API",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "&quot; : 2, &quot;max&quot; : 10, &quot;total&quot;: 12, &quot;count&quot; : 2, &quot;sum_of_squares&quot; : 104 } } } ] }&#x27; Copy Metric references <em>Refer</em> to these references as you <em>develop</em> your own <em>plugins</em>. Metric naming guidelines Metric timeslice data uses a unique case-sensitive identifier, referred to as the metric name. In order"
      },
      "id": "603e80db64441f0def4e8863"
    },
    {
      "sections": [
        "Plugin data",
        "Important",
        "Limited access to legacy plugins",
        "Use integers and floats",
        "Define the time period (duration)",
        "Follow unit conversion guidelines",
        "Select value methods for display in the UI"
      ],
      "title": "Plugin data",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "e5fd09ba8dd9c63a140479fbc2032254d1cf8c4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/plugin-data/",
      "published_at": "2021-05-03T06:33:26Z",
      "updated_at": "2021-03-16T11:02:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Use integers and floats All plugin metrics must be an integer or float, and they must be reported along with a duration. You can also report the type of metric so it can be converted from one unit type into another. You can display the metrics you collect in a variety of value methods, including throughput, averages, min/max, and rate. The metrics appear in charts and tables you create for your plugin's user interface. Plugins in Plugin Central are designed to report on frequency metrics using non-negative integers or floating-point numbers: Non-negative integers: Supported. Floating-point numbers: Supported. Negative values: Not supported, except for summary metrics on the plugin's Summary page. Otherwise, the UI shows negative values as zero. String values: Not supported; the UI shows strings as zero. However, parts of your metric name (the key) can be displayed in the UI. Define the time period (duration) All metrics must include a duration period that starts no more than a few hours in the past. The end time is set automatically to the time New Relic Plugins receives the metrics. You cannot report a duration that starts or ends in the future, or a duration that ends in the past. For best results, use one of the plugin SDKs to create your plugin. Otherwise, some POST attempts may fail because the actual recorded duration could vary in increments of the plugin's scheduled reporting frequency. Follow unit conversion guidelines Plugins automatically converts some units (such as rate units) to more natural forms. For example, [bytes/second] is converted to Bps. Follow these guidelines for unit conversions: Long format: Always specify the long format (for example, [bytes/second]) in the metric name. The long or short version will be used as appropriate. (Unit designations are not case sensitive.) Consistency: Use modifiers consistently in the metric name. If you use a different modifier with the same metric name, it will be treated as a different metric. Optional: Standard modifiers: Provide standard modifiers to the first metric in a value unit. For example, rather than specifying [bytes/second], you can specify [kiloBytes/second]. Plugins accepts these standard modifiers: Modifier Multiplier Modifier Multiplier Kilo 1000 - -- - -- Mega 1000^2 - -- - -- Giga 1000^3 Gibi 1024^3 Tera 1000^4 Tebi 1024^4 Peta 1000^5 Pebi 1024^5 Select value methods for display in the UI When you define a metric value for reporting, Plugins also captures a count, min, max, and sum of squares. Depending on whether you report single or aggregate values, you may report these numbers directly, or Plugins may calculate them automatically. You can then choose a value method for rendering these metrics in your plugin UI. In general, to configure value methods in the user interface: Select the metric you want to use. Review the list of value methods to select how to present the data in a column or plotted in a chart. Available value methods depend on the format of the units part of the metric name: Value method Count | Value Value Rate Count: The total of the count field over the entire timeslice data interval. When aggregating timeslice data, the count is summed. Total value: The total value over the entire time slice data interval. When aggregating timeslice data, the value field is summed Time rates only Average value: The total value divided by the total count, calculated only when units for both count and value are available. Throughput: The total count divided by the time interval of the time slice. By default New Relic Plugins measures the throughput in minutes according to the count units, such as calls per minute or bytes per minute. When the count units are specified in time (seconds), then the throughput appears as a percentage. Min/Max: The statistical values for minimum and maximum values when recorded in the metric value along with Count and Value. Standard deviation: The standard deviation of the entire set of measures recorded over the time interval. This is available only if the sum of squares field was populated in the metric value. The sum of squares and mean are used to calculate the standard deviation. In practice, this is meaningful only for populations that resemble a normal distribution. Rate: The rate is the total value divided by the time interval. When units of the value are in time, then the rate value is a percentage value. Units that are themselves rates will not have an explicit rate value method. The rate is simply the average value. Percentage: If you want the metric to appear as a percentage in the user interface, then you must define it as a percentage in the JSON.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.26047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Plugin</em> data",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603e91e3196a67c11ea83d9d"
    },
    {
      "sections": [
        "Use the Plugin API",
        "Important",
        "Limited access to legacy plugins",
        "Before you begin",
        "Metric data POST",
        "Data aggregation",
        "Compression",
        "Examples",
        "Example JSON",
        "Pseudo-code template",
        "API responses and error codes",
        "Debugging logs",
        "Error codes"
      ],
      "title": "Use the Plugin API",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "f30a9a37241be1a13263e2bc8892f411d6fa618b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/use-plugin-api/",
      "published_at": "2021-05-06T04:03:41Z",
      "updated_at": "2021-03-13T03:44:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Before you begin Using a development language other than Ruby, .NET, or Java for a plugin agent means you do not have an SDK to work with, but you do have some benefits. This is a guide for plugin developers to get started with writing an agent in any language that can work directly with the Plugin API for Plugin Central. You can use any language you want, as long as it supports sending JSON through HTTP POST. This allows for better integration with your systems. For the same reason, it is the best option for SaaS-based plugin agents. However, if you are not using the Plugins SDK for Java. .NET, or Ruby, you have some additional setup and planning to do in developing a plugin agent. This includes: Error tracking on POST calls A method for tracking and aggregating data when a POST fails Your own support plans if a New Relic SDK for your language or development tools is not available Any publicly available plugins in the Plugin Central should come bundled with their source code if the executable code is not plain text. This allows you to both try out plugins and to review the code. Recommendation: Before authoring a plugin, install some existing plugins using the Java SDK, .NET SDK, or Ruby SDK to see how they are written. Metric data POST Metric data is sent as an HTTP POST of JSON data using this URI: https://platform-api.newrelic.com/platform/v1/metrics Copy The MIME-type for the POST is application/json. The Plugins feature is designed to receive a continuous stream of metrics at a certain maximum speed, and to present this information on useful charts. The recommended frequency for sending data to Plugins is to send 60 seconds worth of data once a minute. Agents sending data more frequently than twice a minute on average may be subject to enforced limits on the number of metrics being saved. The following are recommended soft limits. Requests smaller than this will work; requests larger than this are subject to rejection or automatic data aggregation. As a hard cap, the total size of the POST payload should be no larger than 1MB (10^6 bytes). If the metric is \"expensive\" to calculate and does not change quickly, consider writing your plugin agent so that it skips some polling cycles to retrieve data and then sends the last value. This produces better results for your plugin users' dashboards. Type Limit Description Components 500 Number of distinct components currently tracked. Please note this is a per POST limit only. More than 500 components are able to report to an account simultaneously. Metrics per component 10,000 Total number of unique metrics per component. Take precautions to ensure metric names are not generated too dynamically. Even if the number of metrics being sent in each individual post is small, over time they may add up to a large number of unique metrics. When the number of metrics for a given component exceeds this limit, the server may start aggregating metrics together by globbing segments of the metric name with an asterisk (*). Metrics per post 20,000 Number of metrics sent per post. A post may send data for multiple components in a single request as long as the total number of metrics in the request does not exceed this limit. Frequency of post 2 per minute Frequency of update. Agents are expected to send data no more frequently than 1 per minute. Data aggregation The SDKs manage data aggregation in the event of a failed POST. If you are not using an SDK, you need to manage this yourself. Include all five metric values in a POST: min, max, total, count, and sum or squares. (Exception: This may not be necessary for monotonic metrics where short term variation is not an issue.) Recompute these values for the accumulating metric data as required by what is being measured, incrementing the duration accordingly, until a successful POST is sent. Compression Data can be sent in the following encoding formats: identity deflate gzip If data is sent compressed, make sure the Content-Encoding header specifies the type of encoding. Examples Here are some examples for developing plugins. Example JSON This is an example of the JSON that would be used to POST data to Plugins. The JSON data is a hash with two required keys at the top level: agent: A hash describing the agent that is reporting metrics data to Plugins. A POST can contain information for only one agent. Host and version are required. components: An array of components, each consisting of a hash of attributes for the individual component. Multiple components can be sent with a single. Each component has its own name, GUID, duration, and metrics. { \"agent\": { \"host\" : \"db.internal.your_company.com\", \"pid\" : 1234, \"version\" : \"1.0.0\" }, \"components\": [ { \"name\": \"Primary MySQL Database\", \"guid\": \"com.your_company_name.plugin_name\", \"duration\" : 60, \"metrics\" : { \"Component/ProductionDatabase[Queries/Second]\": 100, \"Component/AnalyticsDatabase[Queries/Second]\": { \"min\" : 2, \"max\" : 10, \"total\": 12, \"count\" : 2, \"sum_of_squares\" : 104 } } } ] } Copy Pseudo-code template This is a pseudo-code example that works with the Plugin API. It can be used as a template for developing plugin agents. Initialization: // globals string platform_api_uri = \"https://platform-api.newrelic.com/platform/v1/metrics\" int poll_cycle = 60 // time in seconds string version = \"1.0.0\" // major_version.minor_version.patch_level string agent_host = get_host_name_where_this_process_is_running() string agent_pid = get_process_id_of_this_process() time last_poll_time // initialize if necessary initialize once create agent_hash with: agent_host agent_pid version for each newrelic_account do // just handling one account? then \"for each\" is unnecessary complexity for each monitored_component do create component_hash with: string guid = \"com.your_company.component_name_in_snake_case\" string name =\"Human Readable Component Name\" int duration = 0 // this will get updated each poll_cycle hash metrics_hash // this will be updated by populate_component_metrics_hash() end end end Copy Loop: every poll_cycle seconds do for each newrelic_account do // just handling one account? then \"for each\" is unnecessary complexity clear hash_to_send add agent_hash to hash_to_send for each component do populate_component_metrics_hash() this component.metrics_hash(\"duration\") = time.now() - last_poll_time in seconds add component.metrics_hash to hash_to_send end json_to_send = serialize_to_json(hash_to_send) connection = open http_connection(platform_api_uri) add header(\"X-License-Key\",this newrelic_account.license_key) to connection add header(\"Content-Type\",\"application/json\") to connection add header(\"Accept\",\"application/json\") to connection set http_verb to \"POST\" for connection response = send(json_to_send) to connection case response.code when response_code = 200 clear component.metrics_hash last_poll_time = time.now() when response_code = 400 // your request was malformed // consider reporting a \"supportability\" metric which counts the number of 400 responses you get // for example \"Component/Supportability/http_error_codes/400\" // you can use this on a \"Supportability\" Dashboard that helps diagnose your agent when response_code = 403 // forbidden probably due to a bad license key // log error and shutdown the agent when response_code = 404 // invalid URL // you should never get this error for https://platform-api.newrelic.com/platform/v1/metrics when response_code = 405 // invalid method // HTTP verb should be \"POST\" when response_code = 413 // POST body too large // try splitting at component boundaries // split along metric name spaces // fail gracefully - consider reporting a supportability metric (see 400) when response_code = 500 // error on New Relic's collector // could be due to malformed data or system trouble // fail gracefully - consider reporting a supportability metric (see 400) when response_code = 503 or 504 // New Relic collector busy //- this happens by design from time-to-time // keep collecting metrics // do NOT reset last_poll_time // log error if the problem persists for several minutes end case end end Copy Metric population: function populate_component_metrics_hash() // collect metrics from monitored component at any interval // if this is the first time collecting metrics, set last_poll_time to // time.now - metric duration, the time duration for which these metrics // were collected // // if you collect 2 or more metrics from the monitored component before data // is reported to Plugins either because your metric collection interval is // faster than poll_cycle or because your agent was unable to report metrics to // Plugins (for example a 503 http response), aggregate your data by storing: // total_value, max, min, count, sum_of_squares for each metric // // if the interval is longer than poll_cycle, retain the metrics and // report them each poll_cycle until they are updated end Copy API responses and error codes Depending on whether you are using the Plugin API or an agent SDK for plugins, the HTTP responses and logging techniques may be different. For example, responses for the Plugin API are uncompressed JSON. Successful posts return this JSON: {\"status\":\"ok\"} Copy The API does not support Accept-Encoding. Debugging logs To debug information, use either of these options: public static Logger getLogger(); Copy OR public static void Logger setLogger(Logger logger) { LOGGER = logger; } Copy Error codes If an error occurs, an appropriate status code is returned. The JSON returned is the hash key error with a detailed description of the error that occurred. For example: {\"error\":\"Failed to create agent with parameters=[...]\"} {\"error\":\"Missing metric data\"} {\"error\":\"Unable to parse body: Unexpected token RIGHT BRACE(}) at position 228.\"} Copy Code Name Description 400 Bad request The request or headers are in the wrong format, or the URL is incorrect, or the GUID does not meet the validation requirements. 403 Unauthorized Authentication error (no license key header, or invalid license key). 404 Not found Invalid URL. 405 Method not allowed Returned if the method is an invalid or unexpected type (GET/POST/PUT/etc.). 413 Request entity too large Too many metrics were sent in one request, or too many components (instances) were specified in one request, or other single-request limits were reached. 500 Internal server error Unexpected server error. 502 Bad gateway All 50X errors mean there is a transient problem in the server completing requests, and no data has been retained. Clients are expected to resend the data after waiting one minute. The data should be aggregated appropriately, combining multiple timeslice data values for the same metric into a single aggregate timeslice data value. 503 Service unavailable See 502 description. 504 Gateway timeout See 502 description.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.28523,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use the <em>Plugin</em> API",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "604436cf28ccbcf2332c60a8"
    }
  ],
  "/docs/plugins/plugin-developer-resources/developer-reference/plugin-data": [
    {
      "sections": [
        "Metric data for the Plugin API",
        "Important",
        "Limited access to legacy plugins",
        "URI",
        "GUID",
        "Time periods for metrics",
        "Metric data details",
        "Timeslice metric values",
        "Calculations",
        "Examples",
        "Metrics",
        "cURL example",
        "Metric references",
        "Metric naming guidelines",
        "Metric segments",
        "Caution",
        "Metric attributes",
        "Metric values",
        "Units"
      ],
      "title": "Metric data for the Plugin API",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "2e9d0553b7277c73fe8a2147519d9943fca440fc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/metric-data-plugin-api/",
      "published_at": "2021-05-06T09:48:09Z",
      "updated_at": "2021-03-16T11:20:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. URI Metric timeslice data is sent with the Plugin API as an HTTP POST of JSON data using this URI: https://platform-api.newrelic.com/platform/v1/metrics Copy The Plugin API does not support New Relic's REST API, and vice versa. However, you can use the REST API (v2) to extract plugin data. For a list with links to procedures and examples, see Plugin examples (v2). GUID The plugin needs a Globally Unique Identifier (GUID), which is a character string limited to no less than 4 and no more than 255 characters. The GUID for a published plugin must be unique for each plugin. When creating a plugin, you are responsible for managing your own GUIDs to avoid naming conflicts. Time periods for metrics Metrics that appear in dashboards are reported with a duration. The end time is implied by the time New Relic receives the metric(s). Thus, you cannot define metric values that both start and end in the future, or start and end in the past. The Plugin API is designed for live metrics only, not historical metric collection. Metrics may only be reported for a period starting in the past (no more than a few hours) and ending upon reporting. The charts on your plugin's dashboards can show any time period you want; for example, 30 minutes, 30 days, etc. You can also deliver data at 1-hour intervals. New Relic does not extrapolate data values between the data points delivered. For example, data will aggregate when there is too much, but data will not be extrapolated if there is not enough data. In order for data to appear on a 30 minute chart, make sure at least one data point is within the range, or no data will appear. Use a 60-second polling interval, because the default dashboard shows 30 minutes of data, which gives 30 data points for the chart. Or, if you want to show 3 days of data, use a 1-hour polling interval, which provides 24 * 3=72 data points for your chart. Metric data details The JSON data is a hash with two required keys at the top level: components: An array of components, each consisting of a hash of attributes for the individual component, including the metric data. agent: A hash describing the agent that is reporting metrics data to New Relic Plugins on behalf of the component(s). Of these values, only host and version are required. When graphing metrics, be aware that null = zero. Metric data POST Description Component data One of two required keys at the top level. This is an array of hashes describing the components that report metrics in this request. Each hash contains the following values: name A name ( < =32 characters) that uniquely identifies the monitored entity and appears as the display name for this agent. Note: Metric names are case sensitive. guid A \"reverse domain name\" styled identifier; for example, com.newrelic.mysql. This is a unique identity defined in the plugin's user interface, which ties the agent data to the corresponding plugin user interface in New Relic. duration The duration in seconds over which the metric data was collected. The end time is implied as the time the data is received by the API. metrics Timeslice data for each metric being reported. The hash keys are metric names, and the values are the timeslice data value for the named metric. Agent data One of two required keys at the top level. A hash specifying information about the agent that is reporting data on behalf of the components. host (required) The hostname of the agent monitoring the specified components. This is the hostname where the monitoring agent is running, not the hostname of the component being monitored. pid (optional) The process identifier of the agent monitoring the specified components. This is the process identifier of the monitoring agent itself, not a process identifier that may be associated with the monitored components. version (required) The version of the agent monitoring the specified components, using the format A.B.C where A, B, and C are integers. The version number must conform to the rules specified in standard Semantic Versioning scheme v2.0.0. Timeslice metric values Metrics are sent inside the component hash with the key metrics and a hash as a value. The hash keys are metric names, and the values are the timeslice data values for the named metric. The timeslice hash value uses one of three formats: Timeslice hash value Description A single scalar value with a floating point number or integer This is the simplest format, and this number is required. The reported value is used as the total, minimum, and maximum data value. The count value is assumed to be 1. The Plugin API does not support reporting of arbitrary string metrics, only scalar values that are aggregated. Array of five required values in specific order An array of five required integers or floating point numbers that represent, in order: Total value over the time period Count of the number of events this value represents over the time period; the average is calculated by dividing total by count Minimum value over the time period Maximum value over the time period Sum of squares for the samples over the time period Hash with five required key/value pairs in any order A hash with value names as the keys, and integers or floating point values as the values. All five key/value pairs are required. The keys of the hash are the type of timeslice data, and the value is the data value. These has key/value pairs can be in any order: total: Total value over the time period count: Count of the number of events this value represents over the time period; the average is calculated by dividing total by count min: Minimum value over the time period max: Maximum value over the time period sum_of_squares: Sum of squares for the samples over the time period Calculations Limited mathematical calculations are available with the key/value pairs, such as computing total, count, minimum, maximum, averages, and standard deviations. However, to do more extensive calculations, you need to do the math in the agent, and then send the results as a new metric. For example, send Metric1, Metric2, and Metric3 (which equals Metric1 divided by Metric2). If you submit negative metric values, the charts on your plugin's dashboards will not show them. However, the summary metrics for your plugin will show negative values. Examples Here are some examples. Metrics \"metrics\" : { \"Component/Database/Primary[Queries/Second]\" : { \"total\" : 25, \"count\" : 2, \"min\" : 10, \"max\" : 15, \"sum_of_squares\" : 325 }, \"Component/Database/Secondary[Queries/Second]\" : [25, 2, 10, 15, 325], \"Component/Database/Backup[Queries/Second]\" : 10 } Copy cURL example curl -vi https://platform-api.newrelic.com/platform/v1/metrics \\ -H \"X-License-Key: YOUR_LICENSE_KEY_HERE\" \\ -H \"Content-Type: application/json\" \\ -H \"Accept: application/json\" \\ -X POST -d '{ \"agent\": { \"host\" : \"db.internal.your_company.com\", \"pid\" : 1234, \"version\" : \"1.0.0\" }, \"components\": [ { \"name\": \"Primary MySQL Database\", \"guid\": \"com.your_company_name.plugin_name\", \"duration\" : 60, \"metrics\" : { \"Component/ProductionDatabase[Queries/Second]\": 100, \"Component/AnalyticsDatabase[Queries/Second]\": { \"min\" : 2, \"max\" : 10, \"total\": 12, \"count\" : 2, \"sum_of_squares\" : 104 } } } ] }' Copy Metric references Refer to these references as you develop your own plugins. Metric naming guidelines Metric timeslice data uses a unique case-sensitive identifier, referred to as the metric name. In order for the metric to be rendered usefully in the user interface, the metric name must contain a prefix, category name, label, and optional units indicator. Here are some recommended guidelines for the text in metric names to make them more readable in the user interface. Metric naming guidelines Guidelines UI display Use case and whitespace characters appropriate for display in the user interface, because segments are rendered as-is in the UI. Category and label segments Metric names are case sensitive. Capitalize the first word in the category and label segments. Keep category and label segments as short as possible. Length There is a limit of 255 characters for metric names. Characters to avoid using Avoid using the following characters in names. These characters have special meaning and should not be used except where specifically required for their purpose. / ] [ | * Also avoid multi-byte characters. Units Use abbreviated names for units when possible. Metric segments Each of these segments is divided by the forward slash / character. Each segment is interpreted for a specific purpose in the UI and roughly follows this pattern: prefix/category/label[units] Copy For example, the metric representing the latency of cache hits reported by a plugin collecting data for a cache appliance might look like this: Component/Cache/Hits[sec|hit] Copy Metric segment order Notes Prefix: Component/ or Custom/ The first segment of a custom metric is Component/ (if it comes from a plugin agent) or Custom/ (if it is a custom metric collected by a New Relic agent. For example, Custom/MyMetric). Caution If you use the Plugin API only, and if the metrics do not start with Component/, they may not be available or may not appear correctly in charts and dashboards. Category name The second part of a custom metric is a category name, used to group metrics into different categories. For example, the metrics reported by a database plugin may fall into categories such as schema, tables, or connections. Label The third part of the metric name is used for labeling the data when it appears in tables and charts. If it contains multiple segments, each slash separating the segments of the label will be rendered as part of the label. Units The fourth segment of the metric consists of a units specification. Metric attributes Most metrics are defined statically and represent some global state; for example, cache size. Other metrics are dynamic and include some contextual attribute like the name of a host or a file. These metrics need to be structured so you can easily show them as a group in a table stacked in a chart. To add attribute names to a metric, put them in trailing segments separated by a forward slash / character. For example: Component/Disk/Bytes In/dev001 Component/Network/External services/ae592c3.aws.com Copy You can specify more than one attribute as long as they occupy the same position for a given metric category and label: Component/Tables/Row count/DB001/BLOG_POSTS[rows] Copy Caution Avoid overloading the metric space by putting in segment values that have a large range of values. While something like a customer's region in an attribute is a reasonable thing to track in the metric, the customer name would not be if you have more than a few hundred customers. If your agent starts sending an excessive amount of metrics, your metrics may be automatically collapsed into groups with wildcards: Component/Users/*[visits] Copy Metric values You can report a metric value in one of two ways: Single value: This typically is the value being reported for that time slice. If you use an SDK, you report the single value to the SDK. It handles tracking the rest of these values. Set of aggregate value: This includes the min, max, and sum of squares values for the value being reported. If you use the Plugin API, the preferred method is to report all of the values. When aggregating a series of timeslice data into a single timeslice data entry for a given period, all fields are summed except for the min and max value. If you are using an SDK plugins, this is done automatically. If you are using the Plugin API to develop plugins, you need to code for this. A metric value contains several fields, but it is represented primarily by the count and value. The count is a 32-bit integer field, and the value is a 32-bit float. Metric values can represent more than one data point or sample as an aggregation of measures. Typically the count is the number of samples, and the value is the total value of all samples. Here are the fields in a metric value: Metric value Description count The number of things being measured. If data is collected at the time the event occurs, like with some kind of injection, then the count in the timeslice data will be 1. Required if it is not 1 (0 generally represents an absent value). value Required: The total value measured across all things being counted. When averages are calculated later, we divide the value by the count. In some cases, the value field is irrelevant. min, max The minimum and maximum values when the count is greater than 1. When the count is 1, these are the same as the value. Optional depending on whether they are available or relevant for a given metric. sum of squares This is the sum of squares of each value and is useful when the values follow a standard distribution. You can only capture this value when you are collecting data each time the event happens. You store the value of the event in the value field and the square of the value in the sum of squares. This is used to calculate a standard deviation later on. The sum of squares is optional. It is used to calculate a standard deviation for a selection of data. If standard deviation for the value is not meaningful, such as when the values are not part of a normal distribution, then the sum of squares is omitted. Units When a metric value is collected by periodically sampling an interface, the count units are implicitly samples, and the value units are whatever is being sampled. For data it might be bytes. For throughput it might be something like kilobytes/second. For utilization (like CPU) it might be percent. When the count units are samples, they can be omitted in the metric name. Units of time, bytes, and bits may get special treatment, allowing additional conversion in the user interface between magnitudes. For example, if you specify a metric with units of kilobytes, then in the UI you may be presented the option of displaying a chart of Mb. Metrics units describe what the value field and count represent. Units are specified inside brackets and consist of units for the value, followed by a pipe (|) and then the units for the count. For example: Component/metric_id[value_unit|count_unit] Copy Exception: The pipe and count units (|[count_unit]) are not required after the value unit for samples. Rate metrics are commonly defined as sample per interval. This is defined as units/interval in the metric, with a forward slash to separate units from interval. For example: Component/metric_id[value_unit/interval] Copy In rare cases there will only be a unit value for count. The value will be interpreted as unitless. Value units are omitted, and the vertical bar appears in front of the count units. For example: Component/metric_id[|count_unit] Copy Units for plugin metrics Notes Naming conventions You can have mixed-case unit names. They.can consist strictly of alphabetical characters as well as the _, %, or / symbols. Case is preserved. Punctuation markers, dashes, spaces and any other symbols are not allowed. Recommendation: Use uncapitalized words, spelled out in full. For example, use second not sec. Rate metrics When a metric value represents a rate, such as bytes/second, then the value is assumed to be a sample for the given interval. The units specifier looks like [ bytes/second] since the count units are implicitly samples. For example: Component/metric_id[bytes/second] Copy The count units are samples (default) and the value units are bytes/second. The forward slash separates the units from the interval. Count with units A common case for declaring units is when measuring response times. If the custom metric represents the average latency of a call to a cache, then the units for the metric value are seconds per call. For example: Component/metric_id[seconds|call] Copy Count units are calls and value units are seconds. The default count metric is not being used, so you need to specify it. The bar separates the value units from the count units. Units in charts The units specified in a metric have several implications for the way the values are interpreted by generic charts and tables: Units display in labels and tooltips in charts to indicate what the values represent. Units imply a set of different values available from a single metric value. When creating a chart in a dashboard, the dashboard author selects one of the available value methods for that metric to plot in the chart.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.26834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data for the <em>Plugin</em> API",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "&quot; : 2, &quot;max&quot; : 10, &quot;total&quot;: 12, &quot;count&quot; : 2, &quot;sum_of_squares&quot; : 104 } } } ] }&#x27; Copy Metric references <em>Refer</em> to these references as you <em>develop</em> your own <em>plugins</em>. Metric naming guidelines Metric timeslice data uses a unique case-sensitive identifier, referred to as the metric name. In order"
      },
      "id": "603e80db64441f0def4e8863"
    },
    {
      "sections": [
        "Plan plugin metrics",
        "Important",
        "Limited access to legacy plugins",
        "Collect plugin metrics",
        "Present plugin metrics"
      ],
      "title": "Plan plugin metrics",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "08974b731c810af2b6b037e8b761834c6e1ce7a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/plan-plugin-metrics/",
      "published_at": "2021-05-03T06:33:03Z",
      "updated_at": "2021-03-16T11:01:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Collect plugin metrics If you are running one of our APM agents to receive information about your applications, you can also receive arbitrary custom metrics. Using custom dashboards with your plugins, you can visualize custom metrics in a variety of useful ways. You can write plugins agents that can be run anywhere to collect metrics from any available system and report them to New Relic for dashboard display. Plugins also allow for summary metrics and one or more dashboards to visualize metrics that can be shared with every user of the plugin. This allows you to create a consistent user interface for the metrics you collect. The data that plugins report is in the form of a key/value pair. Values are numerical, either integers or floating point non-negative numbers. Negative numbers can be included in your summary metrics and tables; however, visualization in charts is limited to numbers greater than or equal to zero. Keys are strings which include the concept of name spaces and units. While values cannot be strings, parts of your metric name (the key) can be displayed in plugin dashboards. Your plugin agent can run anywhere with internet access to Plugins. You can write an agent using the agent SDKs. You can also write your agent to connect via HTTP POST using the API for Plugins in any language with HTTP support. Using the Plugin API might be the most appropriate solution when one agent is reporting metrics for more than one New Relic account. This is common for service providers to report specialized metrics for each of their customers using Plugins. This can be done with a small number of agents monitoring a large number of users. Present plugin metrics When creating a plugin agent, good metric name planning is critical to your success. Poorly chosen metrics names can make it difficult or impossible to display the information you intend. Plan ahead for how you want to visualize your information and to record metrics in a way that will facilitate this. You may even want to record the same metrics with more than one name in order to visualize different aspects of your data. Plugin dashboards do not have the ability to do mathematical calculations, so make sure your plugin agent handles any necessary calculations (sum, average, total, count, etc.) before recording metrics. Once you have collected metrics with your plugin agent, you will need to create dashboards to visualize the information in your metrics. All plugins will have a default dashboard. You can add as many dashboards as necessary to visualize your metric data (maximum 15). In addition to dashboards, you can choose up to five metrics to represent the summary of each instance. Summary metrics convey the health status of each instance and are used to trigger Caution events and Critical alerts for your plugins. The summary metrics appear on your plugin's Summary page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.2601,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Plan <em>plugin</em> metrics",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603eb01228ccbc6fa6eba790"
    },
    {
      "sections": [
        "Use the Plugin API",
        "Important",
        "Limited access to legacy plugins",
        "Before you begin",
        "Metric data POST",
        "Data aggregation",
        "Compression",
        "Examples",
        "Example JSON",
        "Pseudo-code template",
        "API responses and error codes",
        "Debugging logs",
        "Error codes"
      ],
      "title": "Use the Plugin API",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "f30a9a37241be1a13263e2bc8892f411d6fa618b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/use-plugin-api/",
      "published_at": "2021-05-06T04:03:41Z",
      "updated_at": "2021-03-13T03:44:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Before you begin Using a development language other than Ruby, .NET, or Java for a plugin agent means you do not have an SDK to work with, but you do have some benefits. This is a guide for plugin developers to get started with writing an agent in any language that can work directly with the Plugin API for Plugin Central. You can use any language you want, as long as it supports sending JSON through HTTP POST. This allows for better integration with your systems. For the same reason, it is the best option for SaaS-based plugin agents. However, if you are not using the Plugins SDK for Java. .NET, or Ruby, you have some additional setup and planning to do in developing a plugin agent. This includes: Error tracking on POST calls A method for tracking and aggregating data when a POST fails Your own support plans if a New Relic SDK for your language or development tools is not available Any publicly available plugins in the Plugin Central should come bundled with their source code if the executable code is not plain text. This allows you to both try out plugins and to review the code. Recommendation: Before authoring a plugin, install some existing plugins using the Java SDK, .NET SDK, or Ruby SDK to see how they are written. Metric data POST Metric data is sent as an HTTP POST of JSON data using this URI: https://platform-api.newrelic.com/platform/v1/metrics Copy The MIME-type for the POST is application/json. The Plugins feature is designed to receive a continuous stream of metrics at a certain maximum speed, and to present this information on useful charts. The recommended frequency for sending data to Plugins is to send 60 seconds worth of data once a minute. Agents sending data more frequently than twice a minute on average may be subject to enforced limits on the number of metrics being saved. The following are recommended soft limits. Requests smaller than this will work; requests larger than this are subject to rejection or automatic data aggregation. As a hard cap, the total size of the POST payload should be no larger than 1MB (10^6 bytes). If the metric is \"expensive\" to calculate and does not change quickly, consider writing your plugin agent so that it skips some polling cycles to retrieve data and then sends the last value. This produces better results for your plugin users' dashboards. Type Limit Description Components 500 Number of distinct components currently tracked. Please note this is a per POST limit only. More than 500 components are able to report to an account simultaneously. Metrics per component 10,000 Total number of unique metrics per component. Take precautions to ensure metric names are not generated too dynamically. Even if the number of metrics being sent in each individual post is small, over time they may add up to a large number of unique metrics. When the number of metrics for a given component exceeds this limit, the server may start aggregating metrics together by globbing segments of the metric name with an asterisk (*). Metrics per post 20,000 Number of metrics sent per post. A post may send data for multiple components in a single request as long as the total number of metrics in the request does not exceed this limit. Frequency of post 2 per minute Frequency of update. Agents are expected to send data no more frequently than 1 per minute. Data aggregation The SDKs manage data aggregation in the event of a failed POST. If you are not using an SDK, you need to manage this yourself. Include all five metric values in a POST: min, max, total, count, and sum or squares. (Exception: This may not be necessary for monotonic metrics where short term variation is not an issue.) Recompute these values for the accumulating metric data as required by what is being measured, incrementing the duration accordingly, until a successful POST is sent. Compression Data can be sent in the following encoding formats: identity deflate gzip If data is sent compressed, make sure the Content-Encoding header specifies the type of encoding. Examples Here are some examples for developing plugins. Example JSON This is an example of the JSON that would be used to POST data to Plugins. The JSON data is a hash with two required keys at the top level: agent: A hash describing the agent that is reporting metrics data to Plugins. A POST can contain information for only one agent. Host and version are required. components: An array of components, each consisting of a hash of attributes for the individual component. Multiple components can be sent with a single. Each component has its own name, GUID, duration, and metrics. { \"agent\": { \"host\" : \"db.internal.your_company.com\", \"pid\" : 1234, \"version\" : \"1.0.0\" }, \"components\": [ { \"name\": \"Primary MySQL Database\", \"guid\": \"com.your_company_name.plugin_name\", \"duration\" : 60, \"metrics\" : { \"Component/ProductionDatabase[Queries/Second]\": 100, \"Component/AnalyticsDatabase[Queries/Second]\": { \"min\" : 2, \"max\" : 10, \"total\": 12, \"count\" : 2, \"sum_of_squares\" : 104 } } } ] } Copy Pseudo-code template This is a pseudo-code example that works with the Plugin API. It can be used as a template for developing plugin agents. Initialization: // globals string platform_api_uri = \"https://platform-api.newrelic.com/platform/v1/metrics\" int poll_cycle = 60 // time in seconds string version = \"1.0.0\" // major_version.minor_version.patch_level string agent_host = get_host_name_where_this_process_is_running() string agent_pid = get_process_id_of_this_process() time last_poll_time // initialize if necessary initialize once create agent_hash with: agent_host agent_pid version for each newrelic_account do // just handling one account? then \"for each\" is unnecessary complexity for each monitored_component do create component_hash with: string guid = \"com.your_company.component_name_in_snake_case\" string name =\"Human Readable Component Name\" int duration = 0 // this will get updated each poll_cycle hash metrics_hash // this will be updated by populate_component_metrics_hash() end end end Copy Loop: every poll_cycle seconds do for each newrelic_account do // just handling one account? then \"for each\" is unnecessary complexity clear hash_to_send add agent_hash to hash_to_send for each component do populate_component_metrics_hash() this component.metrics_hash(\"duration\") = time.now() - last_poll_time in seconds add component.metrics_hash to hash_to_send end json_to_send = serialize_to_json(hash_to_send) connection = open http_connection(platform_api_uri) add header(\"X-License-Key\",this newrelic_account.license_key) to connection add header(\"Content-Type\",\"application/json\") to connection add header(\"Accept\",\"application/json\") to connection set http_verb to \"POST\" for connection response = send(json_to_send) to connection case response.code when response_code = 200 clear component.metrics_hash last_poll_time = time.now() when response_code = 400 // your request was malformed // consider reporting a \"supportability\" metric which counts the number of 400 responses you get // for example \"Component/Supportability/http_error_codes/400\" // you can use this on a \"Supportability\" Dashboard that helps diagnose your agent when response_code = 403 // forbidden probably due to a bad license key // log error and shutdown the agent when response_code = 404 // invalid URL // you should never get this error for https://platform-api.newrelic.com/platform/v1/metrics when response_code = 405 // invalid method // HTTP verb should be \"POST\" when response_code = 413 // POST body too large // try splitting at component boundaries // split along metric name spaces // fail gracefully - consider reporting a supportability metric (see 400) when response_code = 500 // error on New Relic's collector // could be due to malformed data or system trouble // fail gracefully - consider reporting a supportability metric (see 400) when response_code = 503 or 504 // New Relic collector busy //- this happens by design from time-to-time // keep collecting metrics // do NOT reset last_poll_time // log error if the problem persists for several minutes end case end end Copy Metric population: function populate_component_metrics_hash() // collect metrics from monitored component at any interval // if this is the first time collecting metrics, set last_poll_time to // time.now - metric duration, the time duration for which these metrics // were collected // // if you collect 2 or more metrics from the monitored component before data // is reported to Plugins either because your metric collection interval is // faster than poll_cycle or because your agent was unable to report metrics to // Plugins (for example a 503 http response), aggregate your data by storing: // total_value, max, min, count, sum_of_squares for each metric // // if the interval is longer than poll_cycle, retain the metrics and // report them each poll_cycle until they are updated end Copy API responses and error codes Depending on whether you are using the Plugin API or an agent SDK for plugins, the HTTP responses and logging techniques may be different. For example, responses for the Plugin API are uncompressed JSON. Successful posts return this JSON: {\"status\":\"ok\"} Copy The API does not support Accept-Encoding. Debugging logs To debug information, use either of these options: public static Logger getLogger(); Copy OR public static void Logger setLogger(Logger logger) { LOGGER = logger; } Copy Error codes If an error occurs, an appropriate status code is returned. The JSON returned is the hash key error with a detailed description of the error that occurred. For example: {\"error\":\"Failed to create agent with parameters=[...]\"} {\"error\":\"Missing metric data\"} {\"error\":\"Unable to parse body: Unexpected token RIGHT BRACE(}) at position 228.\"} Copy Code Name Description 400 Bad request The request or headers are in the wrong format, or the URL is incorrect, or the GUID does not meet the validation requirements. 403 Unauthorized Authentication error (no license key header, or invalid license key). 404 Not found Invalid URL. 405 Method not allowed Returned if the method is an invalid or unexpected type (GET/POST/PUT/etc.). 413 Request entity too large Too many metrics were sent in one request, or too many components (instances) were specified in one request, or other single-request limits were reached. 500 Internal server error Unexpected server error. 502 Bad gateway All 50X errors mean there is a transient problem in the server completing requests, and no data has been retained. Clients are expected to resend the data after waiting one minute. The data should be aggregated appropriately, combining multiple timeslice data values for the same metric into a single aggregate timeslice data value. 503 Service unavailable See 502 description. 504 Gateway timeout See 502 description.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.28522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use the <em>Plugin</em> API",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "604436cf28ccbcf2332c60a8"
    }
  ],
  "/docs/plugins/plugin-developer-resources/developer-reference/use-plugin-api": [
    {
      "sections": [
        "Metric data for the Plugin API",
        "Important",
        "Limited access to legacy plugins",
        "URI",
        "GUID",
        "Time periods for metrics",
        "Metric data details",
        "Timeslice metric values",
        "Calculations",
        "Examples",
        "Metrics",
        "cURL example",
        "Metric references",
        "Metric naming guidelines",
        "Metric segments",
        "Caution",
        "Metric attributes",
        "Metric values",
        "Units"
      ],
      "title": "Metric data for the Plugin API",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "2e9d0553b7277c73fe8a2147519d9943fca440fc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/metric-data-plugin-api/",
      "published_at": "2021-05-06T09:48:09Z",
      "updated_at": "2021-03-16T11:20:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. URI Metric timeslice data is sent with the Plugin API as an HTTP POST of JSON data using this URI: https://platform-api.newrelic.com/platform/v1/metrics Copy The Plugin API does not support New Relic's REST API, and vice versa. However, you can use the REST API (v2) to extract plugin data. For a list with links to procedures and examples, see Plugin examples (v2). GUID The plugin needs a Globally Unique Identifier (GUID), which is a character string limited to no less than 4 and no more than 255 characters. The GUID for a published plugin must be unique for each plugin. When creating a plugin, you are responsible for managing your own GUIDs to avoid naming conflicts. Time periods for metrics Metrics that appear in dashboards are reported with a duration. The end time is implied by the time New Relic receives the metric(s). Thus, you cannot define metric values that both start and end in the future, or start and end in the past. The Plugin API is designed for live metrics only, not historical metric collection. Metrics may only be reported for a period starting in the past (no more than a few hours) and ending upon reporting. The charts on your plugin's dashboards can show any time period you want; for example, 30 minutes, 30 days, etc. You can also deliver data at 1-hour intervals. New Relic does not extrapolate data values between the data points delivered. For example, data will aggregate when there is too much, but data will not be extrapolated if there is not enough data. In order for data to appear on a 30 minute chart, make sure at least one data point is within the range, or no data will appear. Use a 60-second polling interval, because the default dashboard shows 30 minutes of data, which gives 30 data points for the chart. Or, if you want to show 3 days of data, use a 1-hour polling interval, which provides 24 * 3=72 data points for your chart. Metric data details The JSON data is a hash with two required keys at the top level: components: An array of components, each consisting of a hash of attributes for the individual component, including the metric data. agent: A hash describing the agent that is reporting metrics data to New Relic Plugins on behalf of the component(s). Of these values, only host and version are required. When graphing metrics, be aware that null = zero. Metric data POST Description Component data One of two required keys at the top level. This is an array of hashes describing the components that report metrics in this request. Each hash contains the following values: name A name ( < =32 characters) that uniquely identifies the monitored entity and appears as the display name for this agent. Note: Metric names are case sensitive. guid A \"reverse domain name\" styled identifier; for example, com.newrelic.mysql. This is a unique identity defined in the plugin's user interface, which ties the agent data to the corresponding plugin user interface in New Relic. duration The duration in seconds over which the metric data was collected. The end time is implied as the time the data is received by the API. metrics Timeslice data for each metric being reported. The hash keys are metric names, and the values are the timeslice data value for the named metric. Agent data One of two required keys at the top level. A hash specifying information about the agent that is reporting data on behalf of the components. host (required) The hostname of the agent monitoring the specified components. This is the hostname where the monitoring agent is running, not the hostname of the component being monitored. pid (optional) The process identifier of the agent monitoring the specified components. This is the process identifier of the monitoring agent itself, not a process identifier that may be associated with the monitored components. version (required) The version of the agent monitoring the specified components, using the format A.B.C where A, B, and C are integers. The version number must conform to the rules specified in standard Semantic Versioning scheme v2.0.0. Timeslice metric values Metrics are sent inside the component hash with the key metrics and a hash as a value. The hash keys are metric names, and the values are the timeslice data values for the named metric. The timeslice hash value uses one of three formats: Timeslice hash value Description A single scalar value with a floating point number or integer This is the simplest format, and this number is required. The reported value is used as the total, minimum, and maximum data value. The count value is assumed to be 1. The Plugin API does not support reporting of arbitrary string metrics, only scalar values that are aggregated. Array of five required values in specific order An array of five required integers or floating point numbers that represent, in order: Total value over the time period Count of the number of events this value represents over the time period; the average is calculated by dividing total by count Minimum value over the time period Maximum value over the time period Sum of squares for the samples over the time period Hash with five required key/value pairs in any order A hash with value names as the keys, and integers or floating point values as the values. All five key/value pairs are required. The keys of the hash are the type of timeslice data, and the value is the data value. These has key/value pairs can be in any order: total: Total value over the time period count: Count of the number of events this value represents over the time period; the average is calculated by dividing total by count min: Minimum value over the time period max: Maximum value over the time period sum_of_squares: Sum of squares for the samples over the time period Calculations Limited mathematical calculations are available with the key/value pairs, such as computing total, count, minimum, maximum, averages, and standard deviations. However, to do more extensive calculations, you need to do the math in the agent, and then send the results as a new metric. For example, send Metric1, Metric2, and Metric3 (which equals Metric1 divided by Metric2). If you submit negative metric values, the charts on your plugin's dashboards will not show them. However, the summary metrics for your plugin will show negative values. Examples Here are some examples. Metrics \"metrics\" : { \"Component/Database/Primary[Queries/Second]\" : { \"total\" : 25, \"count\" : 2, \"min\" : 10, \"max\" : 15, \"sum_of_squares\" : 325 }, \"Component/Database/Secondary[Queries/Second]\" : [25, 2, 10, 15, 325], \"Component/Database/Backup[Queries/Second]\" : 10 } Copy cURL example curl -vi https://platform-api.newrelic.com/platform/v1/metrics \\ -H \"X-License-Key: YOUR_LICENSE_KEY_HERE\" \\ -H \"Content-Type: application/json\" \\ -H \"Accept: application/json\" \\ -X POST -d '{ \"agent\": { \"host\" : \"db.internal.your_company.com\", \"pid\" : 1234, \"version\" : \"1.0.0\" }, \"components\": [ { \"name\": \"Primary MySQL Database\", \"guid\": \"com.your_company_name.plugin_name\", \"duration\" : 60, \"metrics\" : { \"Component/ProductionDatabase[Queries/Second]\": 100, \"Component/AnalyticsDatabase[Queries/Second]\": { \"min\" : 2, \"max\" : 10, \"total\": 12, \"count\" : 2, \"sum_of_squares\" : 104 } } } ] }' Copy Metric references Refer to these references as you develop your own plugins. Metric naming guidelines Metric timeslice data uses a unique case-sensitive identifier, referred to as the metric name. In order for the metric to be rendered usefully in the user interface, the metric name must contain a prefix, category name, label, and optional units indicator. Here are some recommended guidelines for the text in metric names to make them more readable in the user interface. Metric naming guidelines Guidelines UI display Use case and whitespace characters appropriate for display in the user interface, because segments are rendered as-is in the UI. Category and label segments Metric names are case sensitive. Capitalize the first word in the category and label segments. Keep category and label segments as short as possible. Length There is a limit of 255 characters for metric names. Characters to avoid using Avoid using the following characters in names. These characters have special meaning and should not be used except where specifically required for their purpose. / ] [ | * Also avoid multi-byte characters. Units Use abbreviated names for units when possible. Metric segments Each of these segments is divided by the forward slash / character. Each segment is interpreted for a specific purpose in the UI and roughly follows this pattern: prefix/category/label[units] Copy For example, the metric representing the latency of cache hits reported by a plugin collecting data for a cache appliance might look like this: Component/Cache/Hits[sec|hit] Copy Metric segment order Notes Prefix: Component/ or Custom/ The first segment of a custom metric is Component/ (if it comes from a plugin agent) or Custom/ (if it is a custom metric collected by a New Relic agent. For example, Custom/MyMetric). Caution If you use the Plugin API only, and if the metrics do not start with Component/, they may not be available or may not appear correctly in charts and dashboards. Category name The second part of a custom metric is a category name, used to group metrics into different categories. For example, the metrics reported by a database plugin may fall into categories such as schema, tables, or connections. Label The third part of the metric name is used for labeling the data when it appears in tables and charts. If it contains multiple segments, each slash separating the segments of the label will be rendered as part of the label. Units The fourth segment of the metric consists of a units specification. Metric attributes Most metrics are defined statically and represent some global state; for example, cache size. Other metrics are dynamic and include some contextual attribute like the name of a host or a file. These metrics need to be structured so you can easily show them as a group in a table stacked in a chart. To add attribute names to a metric, put them in trailing segments separated by a forward slash / character. For example: Component/Disk/Bytes In/dev001 Component/Network/External services/ae592c3.aws.com Copy You can specify more than one attribute as long as they occupy the same position for a given metric category and label: Component/Tables/Row count/DB001/BLOG_POSTS[rows] Copy Caution Avoid overloading the metric space by putting in segment values that have a large range of values. While something like a customer's region in an attribute is a reasonable thing to track in the metric, the customer name would not be if you have more than a few hundred customers. If your agent starts sending an excessive amount of metrics, your metrics may be automatically collapsed into groups with wildcards: Component/Users/*[visits] Copy Metric values You can report a metric value in one of two ways: Single value: This typically is the value being reported for that time slice. If you use an SDK, you report the single value to the SDK. It handles tracking the rest of these values. Set of aggregate value: This includes the min, max, and sum of squares values for the value being reported. If you use the Plugin API, the preferred method is to report all of the values. When aggregating a series of timeslice data into a single timeslice data entry for a given period, all fields are summed except for the min and max value. If you are using an SDK plugins, this is done automatically. If you are using the Plugin API to develop plugins, you need to code for this. A metric value contains several fields, but it is represented primarily by the count and value. The count is a 32-bit integer field, and the value is a 32-bit float. Metric values can represent more than one data point or sample as an aggregation of measures. Typically the count is the number of samples, and the value is the total value of all samples. Here are the fields in a metric value: Metric value Description count The number of things being measured. If data is collected at the time the event occurs, like with some kind of injection, then the count in the timeslice data will be 1. Required if it is not 1 (0 generally represents an absent value). value Required: The total value measured across all things being counted. When averages are calculated later, we divide the value by the count. In some cases, the value field is irrelevant. min, max The minimum and maximum values when the count is greater than 1. When the count is 1, these are the same as the value. Optional depending on whether they are available or relevant for a given metric. sum of squares This is the sum of squares of each value and is useful when the values follow a standard distribution. You can only capture this value when you are collecting data each time the event happens. You store the value of the event in the value field and the square of the value in the sum of squares. This is used to calculate a standard deviation later on. The sum of squares is optional. It is used to calculate a standard deviation for a selection of data. If standard deviation for the value is not meaningful, such as when the values are not part of a normal distribution, then the sum of squares is omitted. Units When a metric value is collected by periodically sampling an interface, the count units are implicitly samples, and the value units are whatever is being sampled. For data it might be bytes. For throughput it might be something like kilobytes/second. For utilization (like CPU) it might be percent. When the count units are samples, they can be omitted in the metric name. Units of time, bytes, and bits may get special treatment, allowing additional conversion in the user interface between magnitudes. For example, if you specify a metric with units of kilobytes, then in the UI you may be presented the option of displaying a chart of Mb. Metrics units describe what the value field and count represent. Units are specified inside brackets and consist of units for the value, followed by a pipe (|) and then the units for the count. For example: Component/metric_id[value_unit|count_unit] Copy Exception: The pipe and count units (|[count_unit]) are not required after the value unit for samples. Rate metrics are commonly defined as sample per interval. This is defined as units/interval in the metric, with a forward slash to separate units from interval. For example: Component/metric_id[value_unit/interval] Copy In rare cases there will only be a unit value for count. The value will be interpreted as unitless. Value units are omitted, and the vertical bar appears in front of the count units. For example: Component/metric_id[|count_unit] Copy Units for plugin metrics Notes Naming conventions You can have mixed-case unit names. They.can consist strictly of alphabetical characters as well as the _, %, or / symbols. Case is preserved. Punctuation markers, dashes, spaces and any other symbols are not allowed. Recommendation: Use uncapitalized words, spelled out in full. For example, use second not sec. Rate metrics When a metric value represents a rate, such as bytes/second, then the value is assumed to be a sample for the given interval. The units specifier looks like [ bytes/second] since the count units are implicitly samples. For example: Component/metric_id[bytes/second] Copy The count units are samples (default) and the value units are bytes/second. The forward slash separates the units from the interval. Count with units A common case for declaring units is when measuring response times. If the custom metric represents the average latency of a call to a cache, then the units for the metric value are seconds per call. For example: Component/metric_id[seconds|call] Copy Count units are calls and value units are seconds. The default count metric is not being used, so you need to specify it. The bar separates the value units from the count units. Units in charts The units specified in a metric have several implications for the way the values are interpreted by generic charts and tables: Units display in labels and tooltips in charts to indicate what the values represent. Units imply a set of different values available from a single metric value. When creating a chart in a dashboard, the dashboard author selects one of the available value methods for that metric to plot in the chart.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.26834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data for the <em>Plugin</em> API",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "&quot; : 2, &quot;max&quot; : 10, &quot;total&quot;: 12, &quot;count&quot; : 2, &quot;sum_of_squares&quot; : 104 } } } ] }&#x27; Copy Metric references <em>Refer</em> to these references as you <em>develop</em> your own <em>plugins</em>. Metric naming guidelines Metric timeslice data uses a unique case-sensitive identifier, referred to as the metric name. In order"
      },
      "id": "603e80db64441f0def4e8863"
    },
    {
      "sections": [
        "Plugin data",
        "Important",
        "Limited access to legacy plugins",
        "Use integers and floats",
        "Define the time period (duration)",
        "Follow unit conversion guidelines",
        "Select value methods for display in the UI"
      ],
      "title": "Plugin data",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "e5fd09ba8dd9c63a140479fbc2032254d1cf8c4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/plugin-data/",
      "published_at": "2021-05-03T06:33:26Z",
      "updated_at": "2021-03-16T11:02:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Use integers and floats All plugin metrics must be an integer or float, and they must be reported along with a duration. You can also report the type of metric so it can be converted from one unit type into another. You can display the metrics you collect in a variety of value methods, including throughput, averages, min/max, and rate. The metrics appear in charts and tables you create for your plugin's user interface. Plugins in Plugin Central are designed to report on frequency metrics using non-negative integers or floating-point numbers: Non-negative integers: Supported. Floating-point numbers: Supported. Negative values: Not supported, except for summary metrics on the plugin's Summary page. Otherwise, the UI shows negative values as zero. String values: Not supported; the UI shows strings as zero. However, parts of your metric name (the key) can be displayed in the UI. Define the time period (duration) All metrics must include a duration period that starts no more than a few hours in the past. The end time is set automatically to the time New Relic Plugins receives the metrics. You cannot report a duration that starts or ends in the future, or a duration that ends in the past. For best results, use one of the plugin SDKs to create your plugin. Otherwise, some POST attempts may fail because the actual recorded duration could vary in increments of the plugin's scheduled reporting frequency. Follow unit conversion guidelines Plugins automatically converts some units (such as rate units) to more natural forms. For example, [bytes/second] is converted to Bps. Follow these guidelines for unit conversions: Long format: Always specify the long format (for example, [bytes/second]) in the metric name. The long or short version will be used as appropriate. (Unit designations are not case sensitive.) Consistency: Use modifiers consistently in the metric name. If you use a different modifier with the same metric name, it will be treated as a different metric. Optional: Standard modifiers: Provide standard modifiers to the first metric in a value unit. For example, rather than specifying [bytes/second], you can specify [kiloBytes/second]. Plugins accepts these standard modifiers: Modifier Multiplier Modifier Multiplier Kilo 1000 - -- - -- Mega 1000^2 - -- - -- Giga 1000^3 Gibi 1024^3 Tera 1000^4 Tebi 1024^4 Peta 1000^5 Pebi 1024^5 Select value methods for display in the UI When you define a metric value for reporting, Plugins also captures a count, min, max, and sum of squares. Depending on whether you report single or aggregate values, you may report these numbers directly, or Plugins may calculate them automatically. You can then choose a value method for rendering these metrics in your plugin UI. In general, to configure value methods in the user interface: Select the metric you want to use. Review the list of value methods to select how to present the data in a column or plotted in a chart. Available value methods depend on the format of the units part of the metric name: Value method Count | Value Value Rate Count: The total of the count field over the entire timeslice data interval. When aggregating timeslice data, the count is summed. Total value: The total value over the entire time slice data interval. When aggregating timeslice data, the value field is summed Time rates only Average value: The total value divided by the total count, calculated only when units for both count and value are available. Throughput: The total count divided by the time interval of the time slice. By default New Relic Plugins measures the throughput in minutes according to the count units, such as calls per minute or bytes per minute. When the count units are specified in time (seconds), then the throughput appears as a percentage. Min/Max: The statistical values for minimum and maximum values when recorded in the metric value along with Count and Value. Standard deviation: The standard deviation of the entire set of measures recorded over the time interval. This is available only if the sum of squares field was populated in the metric value. The sum of squares and mean are used to calculate the standard deviation. In practice, this is meaningful only for populations that resemble a normal distribution. Rate: The rate is the total value divided by the time interval. When units of the value are in time, then the rate value is a percentage value. Units that are themselves rates will not have an explicit rate value method. The rate is simply the average value. Percentage: If you want the metric to appear as a percentage in the user interface, then you must define it as a percentage in the JSON.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.26047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Plugin</em> data",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603e91e3196a67c11ea83d9d"
    },
    {
      "sections": [
        "Plan plugin metrics",
        "Important",
        "Limited access to legacy plugins",
        "Collect plugin metrics",
        "Present plugin metrics"
      ],
      "title": "Plan plugin metrics",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "08974b731c810af2b6b037e8b761834c6e1ce7a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/plan-plugin-metrics/",
      "published_at": "2021-05-03T06:33:03Z",
      "updated_at": "2021-03-16T11:01:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Collect plugin metrics If you are running one of our APM agents to receive information about your applications, you can also receive arbitrary custom metrics. Using custom dashboards with your plugins, you can visualize custom metrics in a variety of useful ways. You can write plugins agents that can be run anywhere to collect metrics from any available system and report them to New Relic for dashboard display. Plugins also allow for summary metrics and one or more dashboards to visualize metrics that can be shared with every user of the plugin. This allows you to create a consistent user interface for the metrics you collect. The data that plugins report is in the form of a key/value pair. Values are numerical, either integers or floating point non-negative numbers. Negative numbers can be included in your summary metrics and tables; however, visualization in charts is limited to numbers greater than or equal to zero. Keys are strings which include the concept of name spaces and units. While values cannot be strings, parts of your metric name (the key) can be displayed in plugin dashboards. Your plugin agent can run anywhere with internet access to Plugins. You can write an agent using the agent SDKs. You can also write your agent to connect via HTTP POST using the API for Plugins in any language with HTTP support. Using the Plugin API might be the most appropriate solution when one agent is reporting metrics for more than one New Relic account. This is common for service providers to report specialized metrics for each of their customers using Plugins. This can be done with a small number of agents monitoring a large number of users. Present plugin metrics When creating a plugin agent, good metric name planning is critical to your success. Poorly chosen metrics names can make it difficult or impossible to display the information you intend. Plan ahead for how you want to visualize your information and to record metrics in a way that will facilitate this. You may even want to record the same metrics with more than one name in order to visualize different aspects of your data. Plugin dashboards do not have the ability to do mathematical calculations, so make sure your plugin agent handles any necessary calculations (sum, average, total, count, etc.) before recording metrics. Once you have collected metrics with your plugin agent, you will need to create dashboards to visualize the information in your metrics. All plugins will have a default dashboard. You can add as many dashboards as necessary to visualize your metric data (maximum 15). In addition to dashboards, you can choose up to five metrics to represent the summary of each instance. Summary metrics convey the health status of each instance and are used to trigger Caution events and Critical alerts for your plugins. The summary metrics appear on your plugin's Summary page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.2601,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Plan <em>plugin</em> metrics",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugin</em> <em>developer</em> <em>resources</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. <em>developer</em>.newrelic.com: Use <em>developer</em> tools"
      },
      "id": "603eb01228ccbc6fa6eba790"
    }
  ],
  "/docs/plugins/plugins-new-relic/custom-dashboards-custom-views/custom-dashboards-v2-legacy": [
    {
      "sections": [
        "Custom views (deprecated)",
        "Important",
        "Custom views in Liquid",
        "Account drops",
        "Methods",
        "Application drops",
        "Application metric drops",
        "Examples",
        "Value methods",
        "Filters",
        "Arithmetic filters",
        "Tags",
        "Chart tags",
        "Referencing metrics",
        "Blocks"
      ],
      "title": "Custom views (deprecated)",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Custom dashboards and custom views"
      ],
      "external_id": "f463c45abafd9dfd5c6ff8f62d834d6125cc4ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/custom-dashboards-custom-views/custom-views-deprecated/",
      "published_at": "2021-05-03T06:36:07Z",
      "updated_at": "2021-03-13T02:57:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In 2012, custom dashboards (v1) replaced the deprecated custom views feature. Then, in February 2014, custom dashboards (v2) replaced our original custom dashboards feature (v1). Custom dashboards (v2) are part of a legacy feature and are being retained only for use with our legacy plugins tool. In addition, plugins in Plugin Central are not supported with accounts that host data in the EU region data center. Important For an even better experience than plugins, custom dashboards, and custom views, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Custom views in Liquid New Relic custom views allow users to visualize custom metric data in charts and HTML tables. Custom Views are written using a custom version of Liquid, a templating language created for Shopify. Custom view code looks like normal HTML interspersed with small blocks of code. The Liquid Wiki has additional information about how to write templates. Every Liquid custom view has access to four context variables, account, application, metrics, and applications. The account variable is an Account drop for the current account, and the application variable points to the current application selection. The metrics variable allows access to metrics for the current application and the applications variable can be used to access the applications belonging to the current account. Drops are secure wrappers around New Relic objects and methods accessible from Liquid templates. Drops expose a limited number of method calls available on each object in a Liquid template, as specified below. Account drops Methods id: The integer id of the account name: The name of the account applications: A collection proxy for the account applications. Applications can be looked up using this syntax: app = account.applications['The app name'] Copy The return value of the lookup is an Application drop. Application drops An application drop represents an application. Methods id: The integer id of the application name: The name of the application health_status: Returns a 1, 2 or 3 which indicates the overall health of the application. The traffic_light filter can be used to render a traffic light from the health_status integer value. metrics: An ApplicationMetrics drop which can be used to look up metrics. Application metric drops An application metrics drop is a collection proxy that can be used to find metrics. {{ application.metrics['metric name'] }} Copy You can also access the metrics for the current account selection with just the metrics variable. {{ metrics['metric name'] }} Copy You can use the application metrics drop to look up a specific metric like in the above sample. You can also use it to retrieve multiple metrics using a regular expression match: {% assign metrics = application.metrics.find_by_regexp['account'] %} Copy The return value of a single metric lookup is an application metric drop. The return value of a find_by_regexp invocation is an array of application metric drops. You can use the metric selector to browse all available metrics and insert metric names or regexp values into your custom view for use in chart tags or filters. If you have added custom metrics via custom metrics, you will see them in the metric selector. An ApplicationMetric drop represents a single application metric and can be used to fetch metric values. Metric value functions like call_count, time_percentage_by_host, and average_value_by_host can be directly invoked on this drop. Metric value functions are also used as a parameter for chart tags to specify the value to display in the chart. The return value of a value function invocation is a MetricValue. Methods id: The integer id of the metric name: The name of the metric Examples {{ application.metrics['Memory/Physical'].average_value_by_host.value }} Copy {{ metrics['CPU/User Time'].time_percentage_by_host.value }} Copy Value methods Some of the value methods return the same data for a given metric, but with different units. Units, if any, are listed in parentheses after the value method. total_value (ms): The total value of the metric for each period within the time window. Use the value_suffix attribute to set the suffix average_value, average_response_time (ms): The average value of the metric for each period within the time window. count, call_count: The number of data points for the metric value (e.g. # of method invocations) requests_per_minute (rpm), calls_per_minute (cpm), errors_per_minute (epm): The number of requests per minute min_value, min_call_time (ms): The smallest metric value collected during the period. max_value, max_call_time (ms): The largest metric value collected during the period. time_percentage (%): Useful for DB and CPU percentage utilization, added across all applicable hosts. time_percentage_by_host (%): Time percentage averaged across the # of hosts. average_value_by_host: The raw value averaged across the # of hosts. score: The value of a scoring method, currently used with Apdex metrics. Filters Filters are methods in Liquid. They always take their first parameter as the output of the left side of the filter (before the '|'). For more information about using filters, see the Liquid Wiki on Filters. Examples traffic_light(input, caution_threshold = 1, danger_threshold = 2) This filter renders a traffic light image by comparing the input value against upper and lower thresholds. If the danger threshold is exceeded, the light will be red. If the caution threshold is exceeded, the light will be yellow. Otherwise it will be green. {{ application.health_status | traffic_light }} {{ application.metrics['Memory/Physical'].average_value_by_host.value | traffic_light:800,1300 }} link_to_application(input, application) This filter generates a link to an application. The input value is the link text. {{ 'current application' | link_to_application:application }} link_to_custom_view(input, custom view name or id) This filter generates a link to a custom view. The input value is the link text. {{ 'For more detail see this custom view' | link_to_custom_view:'My Custom View' }} round(input, places = 0) This filter rounds a value. {{ 109.45 | round:1 }} percentage(input) This filter turns a value to a percentage by multiplying it by 100 and rounding to two places. {{ 0.87 | percentage }} Arithmetic filters These filters are core features of Liquid: # addition plus(input, operand) # subtraction minus(input, operand) # multiplication times(input, operand) # division divided_by(input, operand) Copy sort_table(table_id, column, order = 'asc') This filter sorts a table identified by DOM id \"tableid\", with a default sort on the column numbered \"column\" in the order specified. The order is an optional parameter. Once invoked, the table can be re-sorted dynamically by clicking on the table headers. Here is an example: { % assign metrics = application.metrics.find_by_regexp [ '._Controller/.'] %} <table id=\"metrics_table\"> <thead> <tr> <th></th> <th>Resp. time (300,1000)</th> <th></th> <th>RPM(10,50)</th> <th>Action</th> </tr> </thead> <tbody> {% for metric in metrics %} <tr> <td>{{metric.average_response_time.value | traffic_light:300, 1000}}</td> <td>{{metric.average_response_time.value}}</td> <td>{{metric.requests_per_minute.value | traffic_light:10, 50}}</td> <td>{{metric.requests_per_minute.value}}</td> <td>{{metric.name}}</td> </tr> {% endfor %} </tbody> </table> {{ 'metrics_table' | sort_table:2, 'desc' }} Copy The last line calls the table sort, sorting on the second column in descending order. For more information, see Liquid Filters. Tags Tags in Liquid are used to create logic and other custom behavior in your custom views. For more information about built-in tags, see The Liquid Wiki page on Tags. The New Relic custom tags listed below are used to display charts and alter the time window. Chart tags New Relic custom views support chart rendering using a set of custom tags. Common chart attributes include: title: The chart title subtitle: The subtitle value: A metric value function label: A function on the metric name that returns the label for each metric's timeseries. Possible values are ui_name (default), long_ui_name, last_segment (returns the last '/'-separated segment of the metric name), or segment_N (returns the Nth segment of the metric name). application: Either an application id or a name. This can be used to override the selected application. since: Changes the time window used for the metric data query. See the since block. hide_legend: Hides the graph legend when set to true limit: Limits the number of metrics matched by a regular expression metric match link_to: A url that will become the drilldown link for the chart link_to_custom_view: A custom view name or id. The chart will hyperlink to the given custom view. caution_threshold: A number value representing a caution threshold. A yellow horizontal line will be drawn on the graph at this value. danger_threshold: A number value representing a danger threshold. A red horizontal line will be drawn on the graph at this value. value_suffix: A suffix to be appended to all metric values simple_tooltip: when true, the tooltip is just the value and suffix Referencing metrics Metric data can be referenced in two ways: either by using the name of a specific metric, or by providing a regular expression that matches multiple metrics. Use either the metric or the regexp attribute (but not both) in each chart tag to set the metric source. metric: A string that matches a single metric. The value should be in single quotes and it should not be escaped. regexp: A regular expression that matches metrics. This expression should be wrapped in quotes and it should not be escaped. The following values are provided for informational purposes, for customers who created custom views using these values prior to June 2012. You can access your old custom views and create new custom dashboards from the New Relic Custom dashboards menu. line_chart {% line_chart value:time_percentage metric:'CPU/User Time' title:'CPU' %} pie_chart {% pie_chart regexp:'ActiveRecord/(save|find|destroy)' title:'Active Record' value:time_percentage %} horizontal_bar_chart {% horizontal_bar_chart value:call_count title:'Active Record' regexp:'ActiveRecord/(save|find|destroy)' %} compare_with_last_week_chart {% compare_with_last_week_chart metric:'ActiveRecord/all' title:'Week to Week Comparison' value:time_percentage %} compare_with_yesterday_chart {% compare_with_yesterday_chart metric:'ActiveRecord/all' title:'ActiveRecord' value:time_percentage %} Similar to the compare_with_last_week_chart but uses a 24 hour time period for comparison rather than 7 day. compare_with_yesterday_and_last_week_chart {% compare_with_yesterday_and_last_week_chart metric:'ActiveRecord/all' title:'ActiveRecord' value:time_percentage %} A combination of compare_with_yesterday_chart and compare_with_last_week_chart. daily_summary_chart {% daily_summary_chart metric:'Controller' title:'Daily Summary Chart' value:call_count %} weekly_summary_chart {% weekly_summary_chart metric:'Controller' title:'Weekly Summary Chart' value:call_count %} Blocks Blocks in Liquid are tags that are used to create logic in your custom view. There are many blocks built into Liquid, as well as the custom New Relic 'since' block. since New Relic's since block tag is used to specify a time window for a set of queries. This tag must be followed by a matching endsince tag. All metric data value and chart data queries occurring within a since tag will be scoped to the given time range. Charts will override this time window if the since attribute is specified, but this tag is useful for scoping an entire custom view to a particular time window. It is also the only way to change the time window scope of a metric value query. Examples {% since midnight %} {{ application.metrics['Memory/Physical'].average_value_by_host.value }} {% endsince %} {% since 3.hours.ago %} {% line_chart value:time_percentage metric:'CPU/User Time' title:'CPU Last 3 hours' %} {% endsince %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 277.37787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Custom</em> <em>views</em> (deprecated)",
        "sections": "<em>Custom</em> <em>views</em> (deprecated)",
        "tags": "<em>Custom</em> <em>dashboards</em> <em>and</em> <em>custom</em> <em>views</em>",
        "body": ". In addition, <em>plugins</em> in <em>Plugin</em> Central are not supported with accounts that host data in the EU region data center. Important For an even better experience than <em>plugins</em>, <em>custom</em> <em>dashboards</em>, and <em>custom</em> <em>views</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use"
      },
      "id": "60445cdb196a678ea2960f21"
    },
    {
      "sections": [
        "Use a Plugin Central plugin",
        "Important",
        "Limited access to legacy plugins",
        "View plugin dashboard details",
        "Plugin summary",
        "Plugin dashboards",
        "Plugin alerts",
        "Delete a plugin",
        "Remove plugin components (instances)",
        "Delete the plugin"
      ],
      "title": "Use a Plugin Central plugin",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Install plugins"
      ],
      "external_id": "feae68c2e9d870f7c02fff5ffb69f2c262a0cd6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/install-plugins/use-plugin-central-plugin/",
      "published_at": "2021-05-04T18:26:10Z",
      "updated_at": "2021-03-16T11:03:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. View plugin dashboard details Each plugin in Plugin Central includes procedures for how to install, use, troubleshoot, and uninstall it. Plugins in Plugin Central are not supported with accounts that host data in the EU region data center. After you install a plugin, it starts to receive data, usually within five minutes. The plugin automatically appears with a short name and icon on your Plugins menu in New Relic One. You do not need to select it from Plugin Central. The amount and types of information on the plugin's summary page and dashboards depend on the specific plugin. For example, a plugin may have one or more components (instances) and one or more dashboards. To view summary and dashboard details about the plugin: Go to one.newrelic.com > More > Plugins, and select your plugin. From the plugin's summary page, review the list of components or instances, summary metrics, and list of Recent Events. To view dashboard details about any component or instance, select its name. Plugin summary Depending on the plugin, the summary includes: One or more components or instances (what the plugin agent is monitoring, typically a host/port pair) Zero to five summary metrics for the past three minutes (values such as average, total, minimum, maximum, standard deviation, rate, or count) with optional alerts Recent events list, including deployments, notifications, and alerts Other information about alert violations, events, and activity If your plugin has 100 or more components or instances, you can search for a specific component instance. Here is a summary of additional standard features. If you want to... Do this... View version information for a component's or instance's agent Mouse over the component's name. Change the sort order On the title row of the plugin's summary page, select the up or down arrow for a component (instance) or a summary metric's label. Show or hide items on the events and activity list Select an event icon, or select All. View details about an event On the events and activity list, select the link. View page details for a component or instance Select the name or a summary metric for the component (instance). Plugin dashboards Depending on the plugin, it may have one or more dashboards, and each dashboard may present data as a chart or a table. You can use any of New Relic's standard dashboard features to drill down into detailed information. The customized dashboards that show plugin data are part of the plugin. Users cannot add or remove these dashboards. This must be done by the author or publisher as part of a plugin update. Plugin alerts If the plugin publisher set Critical (red) or Caution (yellow) alert conditions for your plugin's components or instances, you can view details direct in the user interface. For example, you can: Select and view alert details. Change the existing thresholds. Set your alert notification options; for example, to receive email notifications for Critical events. Delete a plugin Each plugin in Plugin Central includes procedures for how to uninstall it. When you select the plugin's Download or Continue button, the plugin should include a README file or refer to other documentation resources. Remove plugin components (instances) At a minimum, your plugin must stop reporting data before you start uninstalling it. Make sure the health status for your plugin's components (instances) are gray. Depending on the plugin, there may be other dependencies before disabling or uninstalling it. For example, plugins from SaaS providers may have different requirements. Be sure to review the instructions that the plugin's publisher provides. Then, to remove individual components from your plugin, click the settings icon for each component (instance). Delete the plugin After you remove each component (instance) for the plugin, the plugin icon will automatically disappear from your Plugins menu in the New Relic UI. You do not need to do anything else to delete the plugin. If you are the plugin's publisher and need to delete the plugin from Plugin Central, go to support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.479706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use a <em>Plugin</em> Central <em>plugin</em>",
        "sections": "<em>View</em> <em>plugin</em> <em>dashboard</em> details",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": "&#x27;s summary page and <em>dashboards</em> depend on the specific <em>plugin</em>. For example, a <em>plugin</em> may have one or more components (instances) and one or more <em>dashboards</em>. To <em>view</em> summary and <em>dashboard</em> details about the <em>plugin</em>: Go to one.newrelic.com &gt; More &gt; <em>Plugins</em>, and select your <em>plugin</em>. From the <em>plugin</em>&#x27;s summary page"
      },
      "id": "603ebf0928ccbcf8d0eba762"
    },
    {
      "sections": [
        "Install from Plugin Central",
        "Important",
        "Limited access to legacy plugins",
        "Requirements",
        "Access rights",
        "License key",
        "Typical plugin installation procedures",
        "Install an NPI-compatible plugin",
        "Install the plugin",
        "Manage plugins with the NPI tool",
        "Troubleshoot NPI-compatible plugins",
        "Duplicate plugins",
        "Error message ./npi: line 1: bin/node: No such file or directory",
        "Error message -bash: ./npi: No such file or directory",
        "Insufficient privileges to run background processes",
        "Install with Chef or Puppet",
        "Chef cookbooks",
        "Puppet modules"
      ],
      "title": "Install from Plugin Central",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Install plugins"
      ],
      "external_id": "a19bd4cb7582a8653cd83b18e431b23cb4270876",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/install-plugins/install-plugin-central/",
      "published_at": "2021-05-03T06:36:26Z",
      "updated_at": "2021-03-13T01:16:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Requirements Each plugin in Plugin Central includes its own procedures for how to install, use, troubleshoot, and uninstall it. In order to use a plugin, first verify that your environment meets the plugin's documented requirements. Then follow the plugin's procedures to install the plugin agent on one or more hosts in your monitored environment, or to configure a SaaS plugin as directed by your SaaS provider. As a standard security measure for data collection, your application server must support SHA-2 (256-bit). We do not support SHA-1. Also, plugins in Plugin Central are not supported with accounts that host data in the EU region data center. Access rights When using an agent from Plugin Central, deploy the agent giving the fewest possible permissions in order for the plugin agent to function successfully. Unless the plugin publisher gives specific instructions, you should run the plugin agent as a non-privileged user; do not use su or sudo privileges. This applies to both installing and using the agent. If the plugin agent needs credentials for the component (instance) that it is monitoring, create a custom set of credentials just for the monitoring agent to use. These should be separate from any other production credentials. The custom credentials should grant the fewest possible permissions while still allowing the agent to gather the data it needs. For example, for most plugin agents, you should only need to grant read-only access to your components or instances so the plugin agent cannot modify your system in any way. Also, with many agents, you should only need to grant access to read performance and administration data, not necessarily end customer or other sensitive data. For more information, see Plugin security. License key As part of any plugin installation process, you need your New Relic license key. When you are logged into the Plugins UI, the plugin's installation page in Plugin Central also shows your license key so you can easily copy it to your clipboard. If plugins have been published by SaaS providers, they must have access to the New Relic license key for each individual account. They can capture this information when provisioning new customers via the New Relic Partner API, or they can provide a mechanism for customers to share their existing New Relic license key. Typical plugin installation procedures Installation requirements depend on the type of plugin. For example, a Java plugin agent has different requirements than a Ruby plugin agent. Before you use a plugin, review the documentation that the plugin's publisher provides about the agent's installation requirements. To install any plugin from Plugin Central: Go to one.newrelic.com > More > Plugins. From the Plugin Central directory, select the plugin's title or its Get started button. From the plugin's details page, select the Download or Continue button. Follow the plugin's specific instructions to get your plugin installed and running. After you start running a plugin, it collects and sends data to New Relic, usually within five minutes. The plugin name will automatically appear in the Plugins UI, where you can select and view its summary metrics and dashboards. Install an NPI-compatible plugin The New Relic Platform Installer (NPI) is a command line utility that helps you easily download, configure, and manage a plugin by installing it with a single command. After you install the NPI tool, you can use it to install any plugins that are compatible with it. Install the plugin Plugins that are compatible with the New Relic Platform Installer include an NPI compatible label. If you have not already installed the NPI tool: Go to one.newrelic.com > More > Plugins, then select any plugin listed as NPI compatible. From the selected plugin's Installation page in the UI, click the link that says * Requires New Relic Platform Installer (NPI) - Get it here. From the dropdown that opens, select your operating system. Copy the command that appears, then run it in your terminal to install the NPI tool. Unix-based systems: If you need to set a default user, in your terminal, run: ./npi set user <USER NAME> Copy Once you have installed the NPI tool, you can install any NPI compatible plugin. Go to one.newrelic.com > More > Plugins, then select any plugin listed as NPI compatible. From the selected plugin's Installation page in the UI, follow the procedures to copy the specific plugin's installation command. In your terminal, change to the directory ~/newrelic-npi, then paste and run the install command. Manage plugins with the NPI tool To view information that helps you manage NPI-compatible plugins: For usage and commands, help and version flags, and setup examples, run the command --help from the directory ~/newrelic-npi. For a list of plugins that are NPI-compatible, run the command ./npi available. If you need to include proxy settings in your configuration (for both the NPI tool and the plugin's newrelic.json file), use these commands: ./npi config set proxy_host <HOST> ./npi config set proxy_port <PORT> ./npi config set proxy_username <USER NAME> ./npi config set proxy_password <PASSWORD> Copy To view the full path for a plugin, run a where command. This is useful for viewing log files or locating a plugin on your filesystem so you can manually configure it. Troubleshoot NPI-compatible plugins In addition to the troubleshooting procedures provided by the plugin publisher, follow these troubleshooting guidelines when installing NPI-compatible plugins. Duplicate plugins Problem: If you install a plugin and then install the same plugin again through the NPI tool, you will have two versions of the plugin installed. Solution: Delete the older version of the plugin, and then install the NPI-compatible version using the NPI tool. Procedures to delete plugins typically appear in the README file or in other documentation that the plugin publisher provides. Error message ./npi: line 1: bin/node: No such file or directory Problem: The architecture script that you selected when you installed the NPI tool does not match your operating system (for example, x86 instead of x64). Solution: Install the NPI tool using the correct script for your operating system. Error message -bash: ./npi: No such file or directory Problem: You cannot run NPI commands. Solution: You can only access the NPI tool from the location where it was installed. To solve this problem, navigate to the directory ~/newrelic-npi, and run the command again. Insufficient privileges to run background processes Problem: If you try to set a plugin to run as a background process, you might see a message that you have insufficient privileges. Solution: The plugin creates an /etc/init.d script on Linux and a Windows service on Windows, both of which require escalated privileges to run. To solve this problem: Linux: Run the command with sudo in front of it. Windows: Run the command as an administrator. Install with Chef or Puppet In addition to standard installation procedures, you can install plugins with Chef and Puppet configuration management tools. These tools automate plugin installation and make it easier to manage plugins with the rest of your server software. Chef cookbooks Plugins in Plugin Central may come bundled with a Chef script, or you can write your own. If a Chef script is provided, this does not mean you are required to use it to install the plugin. Before installing a plugin using Chef, add the Chef cookbook for New Relic Plugins: Procedures: See Chef's cookbook documentation. New Relic Plugins cookbook: See Chef's community site for newrelic_plugins. Requirements and dependencies: See New Relic's GitHub repo for installing plugins with Chef. Then, to install a plugin using Chef: Configure Chef with the plugin details. Run Chef to install the plugin. Chef cookbooks and recipes define roles for specific server configurations. For example, a web server can have the role web_server which includes all of the software and configuration needed for a web server. Here is an example of creating a Chef role for a server running the Wikipedia Java example plugin: name \"newrelic_wikipedia_example_java_plugin\" description \"Server running the New Relic Plugins Wikipedia Example Java Plugin\" run_list( \"recipe[newrelic_plugins::wikipedia_example_java]\" ) default_attributes( \"newrelic\" => { \"license_key\" => \"NEW_RELIC_LICENSE_KEY\", \"wikipedia_example_java\" => { \"install_path\" => \"/path/to/plugin\", \"user\" => \"newrelic\" } } ) Copy Puppet modules Plugins in Plugin Central may come bundled with a Puppet script, or you can write your own. If a Puppet script is provided, this does not mean you are required to use it to install the plugin. Before installing a plugin using Puppet, add New Relic's Puppet module for plugins: Procedures: See Puppet's module documentation. New Relic plugin modules: See the Puppet Forge community site. Requirements and dependencies: See New Relic's GitHub repo for installing plugins with Puppet. Then, to install a plugin using Puppet: Configure Puppet with the plugin details. Run Puppet to install the plugin. Puppet modules contain manifest files that are a collection of classes for configuring a server. For example, a web server can be assigned several classes for the necessary software for a web server. Here is an example of using a Puppet class for a server running the Wikipedia Java example plugin: class { 'newrelic_plugins::wikipedia_example_java': license_key => 'NEW_RELIC_LICENSE_KEY', install_path => '/path/to/plugin', user => 'newrelic' } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.438965,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install from <em>Plugin</em> Central",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": " to get your <em>plugin</em> installed and running. After you start running a <em>plugin</em>, it collects and sends data to <em>New</em> <em>Relic</em>, usually within five minutes. The <em>plugin</em> name will automatically appear in the <em>Plugins</em> UI, where you can select and <em>view</em> its summary metrics and <em>dashboards</em>. Install an NPI-compatible"
      },
      "id": "60445cdd196a6788d9960f28"
    }
  ],
  "/docs/plugins/plugins-new-relic/custom-dashboards-custom-views/custom-views-deprecated": [
    {
      "sections": [
        "Custom dashboards v2 (legacy)",
        "Important",
        "Limited access to legacy plugins"
      ],
      "title": "Custom dashboards v2 (legacy)",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Custom dashboards and custom views"
      ],
      "external_id": "f122ddf1c7bcc4c1efb449838eafa63d79d5753c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/custom-dashboards-custom-views/custom-dashboards-v2-legacy/",
      "published_at": "2021-05-07T14:03:27Z",
      "updated_at": "2021-03-13T01:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In February 2014, custom dashboards (v2) replaced our original custom dashboards feature (v1). Custom dashboards (v2) are part of a legacy feature and are being retained only for use with our legacy plugins tool. In addition, plugins in Plugin Central are not supported with accounts that host data in the EU region data center. Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 277.33835,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Custom</em> <em>dashboards</em> v2 (legacy)",
        "sections": "<em>Custom</em> <em>dashboards</em> v2 (legacy)",
        "tags": "<em>Custom</em> <em>dashboards</em> <em>and</em> <em>custom</em> <em>views</em>",
        "body": "In February 2014, <em>custom</em> <em>dashboards</em> (v2) replaced our original <em>custom</em> <em>dashboards</em> feature (v1). <em>Custom</em> <em>dashboards</em> (v2) are part of a legacy feature and are being retained only for use with our legacy <em>plugins</em> tool. In addition, <em>plugins</em> in <em>Plugin</em> Central are not supported with accounts that host data"
      },
      "id": "60445cde28ccbc04a2311239"
    },
    {
      "sections": [
        "Use a Plugin Central plugin",
        "Important",
        "Limited access to legacy plugins",
        "View plugin dashboard details",
        "Plugin summary",
        "Plugin dashboards",
        "Plugin alerts",
        "Delete a plugin",
        "Remove plugin components (instances)",
        "Delete the plugin"
      ],
      "title": "Use a Plugin Central plugin",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Install plugins"
      ],
      "external_id": "feae68c2e9d870f7c02fff5ffb69f2c262a0cd6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/install-plugins/use-plugin-central-plugin/",
      "published_at": "2021-05-04T18:26:10Z",
      "updated_at": "2021-03-16T11:03:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. View plugin dashboard details Each plugin in Plugin Central includes procedures for how to install, use, troubleshoot, and uninstall it. Plugins in Plugin Central are not supported with accounts that host data in the EU region data center. After you install a plugin, it starts to receive data, usually within five minutes. The plugin automatically appears with a short name and icon on your Plugins menu in New Relic One. You do not need to select it from Plugin Central. The amount and types of information on the plugin's summary page and dashboards depend on the specific plugin. For example, a plugin may have one or more components (instances) and one or more dashboards. To view summary and dashboard details about the plugin: Go to one.newrelic.com > More > Plugins, and select your plugin. From the plugin's summary page, review the list of components or instances, summary metrics, and list of Recent Events. To view dashboard details about any component or instance, select its name. Plugin summary Depending on the plugin, the summary includes: One or more components or instances (what the plugin agent is monitoring, typically a host/port pair) Zero to five summary metrics for the past three minutes (values such as average, total, minimum, maximum, standard deviation, rate, or count) with optional alerts Recent events list, including deployments, notifications, and alerts Other information about alert violations, events, and activity If your plugin has 100 or more components or instances, you can search for a specific component instance. Here is a summary of additional standard features. If you want to... Do this... View version information for a component's or instance's agent Mouse over the component's name. Change the sort order On the title row of the plugin's summary page, select the up or down arrow for a component (instance) or a summary metric's label. Show or hide items on the events and activity list Select an event icon, or select All. View details about an event On the events and activity list, select the link. View page details for a component or instance Select the name or a summary metric for the component (instance). Plugin dashboards Depending on the plugin, it may have one or more dashboards, and each dashboard may present data as a chart or a table. You can use any of New Relic's standard dashboard features to drill down into detailed information. The customized dashboards that show plugin data are part of the plugin. Users cannot add or remove these dashboards. This must be done by the author or publisher as part of a plugin update. Plugin alerts If the plugin publisher set Critical (red) or Caution (yellow) alert conditions for your plugin's components or instances, you can view details direct in the user interface. For example, you can: Select and view alert details. Change the existing thresholds. Set your alert notification options; for example, to receive email notifications for Critical events. Delete a plugin Each plugin in Plugin Central includes procedures for how to uninstall it. When you select the plugin's Download or Continue button, the plugin should include a README file or refer to other documentation resources. Remove plugin components (instances) At a minimum, your plugin must stop reporting data before you start uninstalling it. Make sure the health status for your plugin's components (instances) are gray. Depending on the plugin, there may be other dependencies before disabling or uninstalling it. For example, plugins from SaaS providers may have different requirements. Be sure to review the instructions that the plugin's publisher provides. Then, to remove individual components from your plugin, click the settings icon for each component (instance). Delete the plugin After you remove each component (instance) for the plugin, the plugin icon will automatically disappear from your Plugins menu in the New Relic UI. You do not need to do anything else to delete the plugin. If you are the plugin's publisher and need to delete the plugin from Plugin Central, go to support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.4797,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use a <em>Plugin</em> Central <em>plugin</em>",
        "sections": "<em>View</em> <em>plugin</em> <em>dashboard</em> details",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": "&#x27;s summary page and <em>dashboards</em> depend on the specific <em>plugin</em>. For example, a <em>plugin</em> may have one or more components (instances) and one or more <em>dashboards</em>. To <em>view</em> summary and <em>dashboard</em> details about the <em>plugin</em>: Go to one.newrelic.com &gt; More &gt; <em>Plugins</em>, and select your <em>plugin</em>. From the <em>plugin</em>&#x27;s summary page"
      },
      "id": "603ebf0928ccbcf8d0eba762"
    },
    {
      "sections": [
        "Install from Plugin Central",
        "Important",
        "Limited access to legacy plugins",
        "Requirements",
        "Access rights",
        "License key",
        "Typical plugin installation procedures",
        "Install an NPI-compatible plugin",
        "Install the plugin",
        "Manage plugins with the NPI tool",
        "Troubleshoot NPI-compatible plugins",
        "Duplicate plugins",
        "Error message ./npi: line 1: bin/node: No such file or directory",
        "Error message -bash: ./npi: No such file or directory",
        "Insufficient privileges to run background processes",
        "Install with Chef or Puppet",
        "Chef cookbooks",
        "Puppet modules"
      ],
      "title": "Install from Plugin Central",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Install plugins"
      ],
      "external_id": "a19bd4cb7582a8653cd83b18e431b23cb4270876",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/install-plugins/install-plugin-central/",
      "published_at": "2021-05-03T06:36:26Z",
      "updated_at": "2021-03-13T01:16:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Requirements Each plugin in Plugin Central includes its own procedures for how to install, use, troubleshoot, and uninstall it. In order to use a plugin, first verify that your environment meets the plugin's documented requirements. Then follow the plugin's procedures to install the plugin agent on one or more hosts in your monitored environment, or to configure a SaaS plugin as directed by your SaaS provider. As a standard security measure for data collection, your application server must support SHA-2 (256-bit). We do not support SHA-1. Also, plugins in Plugin Central are not supported with accounts that host data in the EU region data center. Access rights When using an agent from Plugin Central, deploy the agent giving the fewest possible permissions in order for the plugin agent to function successfully. Unless the plugin publisher gives specific instructions, you should run the plugin agent as a non-privileged user; do not use su or sudo privileges. This applies to both installing and using the agent. If the plugin agent needs credentials for the component (instance) that it is monitoring, create a custom set of credentials just for the monitoring agent to use. These should be separate from any other production credentials. The custom credentials should grant the fewest possible permissions while still allowing the agent to gather the data it needs. For example, for most plugin agents, you should only need to grant read-only access to your components or instances so the plugin agent cannot modify your system in any way. Also, with many agents, you should only need to grant access to read performance and administration data, not necessarily end customer or other sensitive data. For more information, see Plugin security. License key As part of any plugin installation process, you need your New Relic license key. When you are logged into the Plugins UI, the plugin's installation page in Plugin Central also shows your license key so you can easily copy it to your clipboard. If plugins have been published by SaaS providers, they must have access to the New Relic license key for each individual account. They can capture this information when provisioning new customers via the New Relic Partner API, or they can provide a mechanism for customers to share their existing New Relic license key. Typical plugin installation procedures Installation requirements depend on the type of plugin. For example, a Java plugin agent has different requirements than a Ruby plugin agent. Before you use a plugin, review the documentation that the plugin's publisher provides about the agent's installation requirements. To install any plugin from Plugin Central: Go to one.newrelic.com > More > Plugins. From the Plugin Central directory, select the plugin's title or its Get started button. From the plugin's details page, select the Download or Continue button. Follow the plugin's specific instructions to get your plugin installed and running. After you start running a plugin, it collects and sends data to New Relic, usually within five minutes. The plugin name will automatically appear in the Plugins UI, where you can select and view its summary metrics and dashboards. Install an NPI-compatible plugin The New Relic Platform Installer (NPI) is a command line utility that helps you easily download, configure, and manage a plugin by installing it with a single command. After you install the NPI tool, you can use it to install any plugins that are compatible with it. Install the plugin Plugins that are compatible with the New Relic Platform Installer include an NPI compatible label. If you have not already installed the NPI tool: Go to one.newrelic.com > More > Plugins, then select any plugin listed as NPI compatible. From the selected plugin's Installation page in the UI, click the link that says * Requires New Relic Platform Installer (NPI) - Get it here. From the dropdown that opens, select your operating system. Copy the command that appears, then run it in your terminal to install the NPI tool. Unix-based systems: If you need to set a default user, in your terminal, run: ./npi set user <USER NAME> Copy Once you have installed the NPI tool, you can install any NPI compatible plugin. Go to one.newrelic.com > More > Plugins, then select any plugin listed as NPI compatible. From the selected plugin's Installation page in the UI, follow the procedures to copy the specific plugin's installation command. In your terminal, change to the directory ~/newrelic-npi, then paste and run the install command. Manage plugins with the NPI tool To view information that helps you manage NPI-compatible plugins: For usage and commands, help and version flags, and setup examples, run the command --help from the directory ~/newrelic-npi. For a list of plugins that are NPI-compatible, run the command ./npi available. If you need to include proxy settings in your configuration (for both the NPI tool and the plugin's newrelic.json file), use these commands: ./npi config set proxy_host <HOST> ./npi config set proxy_port <PORT> ./npi config set proxy_username <USER NAME> ./npi config set proxy_password <PASSWORD> Copy To view the full path for a plugin, run a where command. This is useful for viewing log files or locating a plugin on your filesystem so you can manually configure it. Troubleshoot NPI-compatible plugins In addition to the troubleshooting procedures provided by the plugin publisher, follow these troubleshooting guidelines when installing NPI-compatible plugins. Duplicate plugins Problem: If you install a plugin and then install the same plugin again through the NPI tool, you will have two versions of the plugin installed. Solution: Delete the older version of the plugin, and then install the NPI-compatible version using the NPI tool. Procedures to delete plugins typically appear in the README file or in other documentation that the plugin publisher provides. Error message ./npi: line 1: bin/node: No such file or directory Problem: The architecture script that you selected when you installed the NPI tool does not match your operating system (for example, x86 instead of x64). Solution: Install the NPI tool using the correct script for your operating system. Error message -bash: ./npi: No such file or directory Problem: You cannot run NPI commands. Solution: You can only access the NPI tool from the location where it was installed. To solve this problem, navigate to the directory ~/newrelic-npi, and run the command again. Insufficient privileges to run background processes Problem: If you try to set a plugin to run as a background process, you might see a message that you have insufficient privileges. Solution: The plugin creates an /etc/init.d script on Linux and a Windows service on Windows, both of which require escalated privileges to run. To solve this problem: Linux: Run the command with sudo in front of it. Windows: Run the command as an administrator. Install with Chef or Puppet In addition to standard installation procedures, you can install plugins with Chef and Puppet configuration management tools. These tools automate plugin installation and make it easier to manage plugins with the rest of your server software. Chef cookbooks Plugins in Plugin Central may come bundled with a Chef script, or you can write your own. If a Chef script is provided, this does not mean you are required to use it to install the plugin. Before installing a plugin using Chef, add the Chef cookbook for New Relic Plugins: Procedures: See Chef's cookbook documentation. New Relic Plugins cookbook: See Chef's community site for newrelic_plugins. Requirements and dependencies: See New Relic's GitHub repo for installing plugins with Chef. Then, to install a plugin using Chef: Configure Chef with the plugin details. Run Chef to install the plugin. Chef cookbooks and recipes define roles for specific server configurations. For example, a web server can have the role web_server which includes all of the software and configuration needed for a web server. Here is an example of creating a Chef role for a server running the Wikipedia Java example plugin: name \"newrelic_wikipedia_example_java_plugin\" description \"Server running the New Relic Plugins Wikipedia Example Java Plugin\" run_list( \"recipe[newrelic_plugins::wikipedia_example_java]\" ) default_attributes( \"newrelic\" => { \"license_key\" => \"NEW_RELIC_LICENSE_KEY\", \"wikipedia_example_java\" => { \"install_path\" => \"/path/to/plugin\", \"user\" => \"newrelic\" } } ) Copy Puppet modules Plugins in Plugin Central may come bundled with a Puppet script, or you can write your own. If a Puppet script is provided, this does not mean you are required to use it to install the plugin. Before installing a plugin using Puppet, add New Relic's Puppet module for plugins: Procedures: See Puppet's module documentation. New Relic plugin modules: See the Puppet Forge community site. Requirements and dependencies: See New Relic's GitHub repo for installing plugins with Puppet. Then, to install a plugin using Puppet: Configure Puppet with the plugin details. Run Puppet to install the plugin. Puppet modules contain manifest files that are a collection of classes for configuring a server. For example, a web server can be assigned several classes for the necessary software for a web server. Here is an example of using a Puppet class for a server running the Wikipedia Java example plugin: class { 'newrelic_plugins::wikipedia_example_java': license_key => 'NEW_RELIC_LICENSE_KEY', install_path => '/path/to/plugin', user => 'newrelic' } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.438965,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install from <em>Plugin</em> Central",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": " to get your <em>plugin</em> installed and running. After you start running a <em>plugin</em>, it collects and sends data to <em>New</em> <em>Relic</em>, usually within five minutes. The <em>plugin</em> name will automatically appear in the <em>Plugins</em> UI, where you can select and <em>view</em> its summary metrics and <em>dashboards</em>. Install an NPI-compatible"
      },
      "id": "60445cdd196a6788d9960f28"
    }
  ],
  "/docs/plugins/plugins-new-relic/get-started/get-plugin-help": [
    {
      "sections": [
        "Introduction to Plugin Central",
        "Important",
        "Limited access to legacy plugins",
        "Developers and SaaS providers",
        "Plugin Central directory",
        "View plugins in Plugin Central",
        "Get started with plugins",
        "Ratings",
        "Reviews",
        "Plugin feedback policy"
      ],
      "title": "Introduction to Plugin Central",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Get started"
      ],
      "external_id": "aa864c660f02e96be1c9cec897300ed96e5e33cb",
      "image": "https://docs.newrelic.com/static/916b76819340fbeb3becda03908ca2d2/c1b63/plugins-landing-page-prototype071720.png",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/get-started/introduction-plugin-central/",
      "published_at": "2021-05-03T06:36:07Z",
      "updated_at": "2021-03-16T11:02:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Developers and SaaS providers Plugin Central is where partners, third-party vendors, and users could publish plugin agents that collect selected data. This is also where you could install and view the plugin data on your Plugins dashboards as a set of summary metrics, charts, and tables. In most cases, the plugin's agent runs on the users' app server. SaaS or PaaS providers can also create plugin agents that run on their system and report metrics for customers who use New Relic to monitor their applications. For more information, see the specific plugin agent SDK documentation. Plugin Central directory Important Plugins in Plugin Central are not supported with accounts that host data in the EU region data center. The plugin agent collects, sends, and stores the metric data. Plugin Central provides a searchable directory for plugins that developers publish and make publicly available to users. From Plugin Central, you can select and download whatever plugins you want to use. After you install or configure a plugin, you can view the plugin's dashboard data securely from the plugins user interface in New Relic One. View plugins in Plugin Central To view information about available (published) plugins: Go to one.newrelic.com > More > Plugins. By default, available plugins appear in alphabetical order. From the Plugin Central directory in New Relic One, select any published plugin to view a description and install it. Depending on the selected plugin, installation and configuration instructions will vary. Refer to your plugin's documentation for specific details. After you install or configure a plugin, it automatically appears on your Plugins menu in New Relic One, where you can select and view it directly. You may need to wait a few minutes for data to appear. Get started with plugins Here are some tips for making the most of Plugin Central. Ratings Plugins listed in New Relic's Plugin Central include a 5-star rating system, ranging from 1 (lowest) to 5 (highest). This helps you make more informed choices when choosing among similar plugins. This also provides a way for you to share what you think of a plugin. You can rate as many plugins as you want. If you have not voted for a plugin, its current star rating (gold or gray) does not include an outline. You can have only one vote for a specific plugin, and you cannot delete your vote. However, you can change your rating level anytime. After you select the star level (1 to 5) to cast your vote, the stars change to gold with an outline at the rating level you selected. Reviews Plugin Central includes a simple review system to share what you think of a plugin and to provide tips for others about installation and usage. Existing reviews appear when you select an individual plugin's title or Get started link. You can write as many reviews for as many plugins as you want, following the feedback policy. You can also edit or delete your own reviews. When you write a review for a plugin, if you have not already rated the plugin, you must provide a rating. Subsequent reviews will use the rating you provided. You can change your rating at any time. Plugin administrators also reserve the right to delete reviews if necessary. For more information, see Plugin feedback policy. Plugin feedback policy Here are some types of reviews we welcome: Your experience using the plugin Suggestions for improvement Your thoughts or opinions about the plugin, even if you disagree with us or point out mistakes Constructive criticism Your review must not contain personal attacks, name calling, libel, defamation, hate speech, etc. And under no circumstances should you post anything that could be taken as threatening, harassing, bullying, obscene, pornographic, sexist, or racist. We reserve the right to moderate reviews to make sure the tone is civil and fair. We will delete a review or rating in these situations: Spam, such as off-topic or nonsense reviews Inappropriate reviews including profanity and links to offensive content Attacks, including personal attacks against the plugin author or other reviewers, as well as attacks against New Relic or other companies. This does not mean you can't disagree with us or with each other, just be polite about it. False reviews that contain misleading statements or claims Other; for example, reviews or ratings that appear to be gaming the system",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.3156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Plugin</em> Central",
        "sections": "<em>Get</em> <em>started</em> with <em>plugins</em>",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": ". You may need to wait a few minutes for data to appear. <em>Get</em> <em>started</em> with <em>plugins</em> Here are some tips for making the most of <em>Plugin</em> Central. Ratings <em>Plugins</em> listed in <em>New</em> <em>Relic</em>&#x27;s <em>Plugin</em> Central include a 5-star rating system, ranging from 1 (lowest) to 5 (highest). This helps you make more informed"
      },
      "id": "603e81b428ccbc63bdeba79e"
    },
    {
      "sections": [
        "Plugin security",
        "Important",
        "Limited access to legacy plugins",
        "Open community",
        "Third-party content",
        "Source code",
        "Access to license keys",
        "Access rights",
        "Plugin storage"
      ],
      "title": "Plugin security",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Get started"
      ],
      "external_id": "8476f9a0e63a7f58388b4a6e7fb8b089843033e3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/get-started/plugin-security/",
      "published_at": "2021-05-05T22:16:57Z",
      "updated_at": "2021-03-16T11:02:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Open community New Relic's Plugins tool been designed to be open and extensible, so that any New Relic user, developer, technology vendor, or partner may publish publicly accessible plugins within Plugin Central. Anyone who has a New Relic account can install and use these plugins through their New Relic user interface. Exception: Plugins in Plugin Central are not supported with accounts that host data in the EU region data center. Having an open community where users both create and consume plugins can raise questions surrounding security. This document intends to address any security considerations for using these plugins. For more information about New Relic's security measures, see our security and data privacy documentation, or visit the New Relic security website. Third-party content For some plugins, New Relic, Inc. is the publisher, and will be clearly identified as the publisher. However, as an open resource, many plugins are created by our partners and third-party developers. Every plugin in the Plugin Central directory clearly identifies whether it was published by a New Relic developer or by a third party. We require plugin publishers to provide an About link to their website, documentation about what the plugin is for and how to use it, and a link to obtain support when using the plugin. We also require plugin publishers to review and accept the Developer Terms of Service Agreement before they can make their plugin publicly accessible. You can review all information provided by the publisher before installing any plugin. Only those plugins that identify New Relic, Inc. as the publisher fall under New Relic's posted privacy policy. For more information, see the New Relic security website. For other plugins, refer to the publisher's security and compliance statements. Source code If you have any concerns about plugins developed with the SDKs for plugins, you can review the source code and verify that the plugin agents behave as expected. The plugin agent's code is light, and it can be reviewed in minutes. Access to license keys Always keep your New Relic license key private. Typically access to your license key is needed only to record metric data or deployments for your applications, hosts, or plugins that are monitored by New Relic, not to introduce new data or code. No other access is allowed. Access rights When developing a plugin agent, authors and publishers need to consider the environment in which they will be run. You should do everything possible to reduce the level of permissions your plugin users need to grant to the agent in order for it to run correctly. In particular: Unless it is absolutely necessary, do not require su or sudo permissions in order to install your agent or support software on your users' computers. In this situation, the requirements should be limited in scope and well-documented. For additional information about access rights for plugin users, see the documentation about installing a plugin. When running your agent on the users' computers, do not require su or sudo permissions. The components (instances) your plugin agent is monitoring should only need to grant read-only permissions in order for your agent to perform its actions. As much as possible, the components (instances) your plugin agent is monitoring should be able to reduce the levels of information and access needed. When documenting your plugin, describe what level of permissions your plugin agent requires from the components (instances) it is monitoring and why this is necessary. Following these steps will make it easier for your plugin users to install your agent and increase their confidence that your agent cannot harm their components or instances being monitored. This will also reduce the likelihood of user problems if your agent has any serious bugs or other defects. Plugin storage Plugins only need access to their monitored systems and New Relic simply to report metrics. You may want to consider running plugin agents in sequestered systems with limited network access that allow no more than the minimum required network access. Also, data retention for plugins follows New Relic's standard policies. If you have any concerns about deploying any plugin from Plugin Central, follow your organization's guidelines. If for any reason you do not trust the source of an existing plugin, try creating your own version.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.3156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Plugin</em> security",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": ") as of June 16, 2021. For more information, see our Explorers Hub post. Open community <em>New</em> <em>Relic</em>&#x27;s <em>Plugins</em> tool been designed to be open and extensible, so that any <em>New</em> <em>Relic</em> user, developer, technology vendor, or partner may publish publicly accessible <em>plugins</em> within <em>Plugin</em> Central. Anyone who has"
      },
      "id": "603ebeb9e7b9d25a642a07d4"
    },
    {
      "sections": [
        "Install from Plugin Central",
        "Important",
        "Limited access to legacy plugins",
        "Requirements",
        "Access rights",
        "License key",
        "Typical plugin installation procedures",
        "Install an NPI-compatible plugin",
        "Install the plugin",
        "Manage plugins with the NPI tool",
        "Troubleshoot NPI-compatible plugins",
        "Duplicate plugins",
        "Error message ./npi: line 1: bin/node: No such file or directory",
        "Error message -bash: ./npi: No such file or directory",
        "Insufficient privileges to run background processes",
        "Install with Chef or Puppet",
        "Chef cookbooks",
        "Puppet modules"
      ],
      "title": "Install from Plugin Central",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Install plugins"
      ],
      "external_id": "a19bd4cb7582a8653cd83b18e431b23cb4270876",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/install-plugins/install-plugin-central/",
      "published_at": "2021-05-03T06:36:26Z",
      "updated_at": "2021-03-13T01:16:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Requirements Each plugin in Plugin Central includes its own procedures for how to install, use, troubleshoot, and uninstall it. In order to use a plugin, first verify that your environment meets the plugin's documented requirements. Then follow the plugin's procedures to install the plugin agent on one or more hosts in your monitored environment, or to configure a SaaS plugin as directed by your SaaS provider. As a standard security measure for data collection, your application server must support SHA-2 (256-bit). We do not support SHA-1. Also, plugins in Plugin Central are not supported with accounts that host data in the EU region data center. Access rights When using an agent from Plugin Central, deploy the agent giving the fewest possible permissions in order for the plugin agent to function successfully. Unless the plugin publisher gives specific instructions, you should run the plugin agent as a non-privileged user; do not use su or sudo privileges. This applies to both installing and using the agent. If the plugin agent needs credentials for the component (instance) that it is monitoring, create a custom set of credentials just for the monitoring agent to use. These should be separate from any other production credentials. The custom credentials should grant the fewest possible permissions while still allowing the agent to gather the data it needs. For example, for most plugin agents, you should only need to grant read-only access to your components or instances so the plugin agent cannot modify your system in any way. Also, with many agents, you should only need to grant access to read performance and administration data, not necessarily end customer or other sensitive data. For more information, see Plugin security. License key As part of any plugin installation process, you need your New Relic license key. When you are logged into the Plugins UI, the plugin's installation page in Plugin Central also shows your license key so you can easily copy it to your clipboard. If plugins have been published by SaaS providers, they must have access to the New Relic license key for each individual account. They can capture this information when provisioning new customers via the New Relic Partner API, or they can provide a mechanism for customers to share their existing New Relic license key. Typical plugin installation procedures Installation requirements depend on the type of plugin. For example, a Java plugin agent has different requirements than a Ruby plugin agent. Before you use a plugin, review the documentation that the plugin's publisher provides about the agent's installation requirements. To install any plugin from Plugin Central: Go to one.newrelic.com > More > Plugins. From the Plugin Central directory, select the plugin's title or its Get started button. From the plugin's details page, select the Download or Continue button. Follow the plugin's specific instructions to get your plugin installed and running. After you start running a plugin, it collects and sends data to New Relic, usually within five minutes. The plugin name will automatically appear in the Plugins UI, where you can select and view its summary metrics and dashboards. Install an NPI-compatible plugin The New Relic Platform Installer (NPI) is a command line utility that helps you easily download, configure, and manage a plugin by installing it with a single command. After you install the NPI tool, you can use it to install any plugins that are compatible with it. Install the plugin Plugins that are compatible with the New Relic Platform Installer include an NPI compatible label. If you have not already installed the NPI tool: Go to one.newrelic.com > More > Plugins, then select any plugin listed as NPI compatible. From the selected plugin's Installation page in the UI, click the link that says * Requires New Relic Platform Installer (NPI) - Get it here. From the dropdown that opens, select your operating system. Copy the command that appears, then run it in your terminal to install the NPI tool. Unix-based systems: If you need to set a default user, in your terminal, run: ./npi set user <USER NAME> Copy Once you have installed the NPI tool, you can install any NPI compatible plugin. Go to one.newrelic.com > More > Plugins, then select any plugin listed as NPI compatible. From the selected plugin's Installation page in the UI, follow the procedures to copy the specific plugin's installation command. In your terminal, change to the directory ~/newrelic-npi, then paste and run the install command. Manage plugins with the NPI tool To view information that helps you manage NPI-compatible plugins: For usage and commands, help and version flags, and setup examples, run the command --help from the directory ~/newrelic-npi. For a list of plugins that are NPI-compatible, run the command ./npi available. If you need to include proxy settings in your configuration (for both the NPI tool and the plugin's newrelic.json file), use these commands: ./npi config set proxy_host <HOST> ./npi config set proxy_port <PORT> ./npi config set proxy_username <USER NAME> ./npi config set proxy_password <PASSWORD> Copy To view the full path for a plugin, run a where command. This is useful for viewing log files or locating a plugin on your filesystem so you can manually configure it. Troubleshoot NPI-compatible plugins In addition to the troubleshooting procedures provided by the plugin publisher, follow these troubleshooting guidelines when installing NPI-compatible plugins. Duplicate plugins Problem: If you install a plugin and then install the same plugin again through the NPI tool, you will have two versions of the plugin installed. Solution: Delete the older version of the plugin, and then install the NPI-compatible version using the NPI tool. Procedures to delete plugins typically appear in the README file or in other documentation that the plugin publisher provides. Error message ./npi: line 1: bin/node: No such file or directory Problem: The architecture script that you selected when you installed the NPI tool does not match your operating system (for example, x86 instead of x64). Solution: Install the NPI tool using the correct script for your operating system. Error message -bash: ./npi: No such file or directory Problem: You cannot run NPI commands. Solution: You can only access the NPI tool from the location where it was installed. To solve this problem, navigate to the directory ~/newrelic-npi, and run the command again. Insufficient privileges to run background processes Problem: If you try to set a plugin to run as a background process, you might see a message that you have insufficient privileges. Solution: The plugin creates an /etc/init.d script on Linux and a Windows service on Windows, both of which require escalated privileges to run. To solve this problem: Linux: Run the command with sudo in front of it. Windows: Run the command as an administrator. Install with Chef or Puppet In addition to standard installation procedures, you can install plugins with Chef and Puppet configuration management tools. These tools automate plugin installation and make it easier to manage plugins with the rest of your server software. Chef cookbooks Plugins in Plugin Central may come bundled with a Chef script, or you can write your own. If a Chef script is provided, this does not mean you are required to use it to install the plugin. Before installing a plugin using Chef, add the Chef cookbook for New Relic Plugins: Procedures: See Chef's cookbook documentation. New Relic Plugins cookbook: See Chef's community site for newrelic_plugins. Requirements and dependencies: See New Relic's GitHub repo for installing plugins with Chef. Then, to install a plugin using Chef: Configure Chef with the plugin details. Run Chef to install the plugin. Chef cookbooks and recipes define roles for specific server configurations. For example, a web server can have the role web_server which includes all of the software and configuration needed for a web server. Here is an example of creating a Chef role for a server running the Wikipedia Java example plugin: name \"newrelic_wikipedia_example_java_plugin\" description \"Server running the New Relic Plugins Wikipedia Example Java Plugin\" run_list( \"recipe[newrelic_plugins::wikipedia_example_java]\" ) default_attributes( \"newrelic\" => { \"license_key\" => \"NEW_RELIC_LICENSE_KEY\", \"wikipedia_example_java\" => { \"install_path\" => \"/path/to/plugin\", \"user\" => \"newrelic\" } } ) Copy Puppet modules Plugins in Plugin Central may come bundled with a Puppet script, or you can write your own. If a Puppet script is provided, this does not mean you are required to use it to install the plugin. Before installing a plugin using Puppet, add New Relic's Puppet module for plugins: Procedures: See Puppet's module documentation. New Relic plugin modules: See the Puppet Forge community site. Requirements and dependencies: See New Relic's GitHub repo for installing plugins with Puppet. Then, to install a plugin using Puppet: Configure Puppet with the plugin details. Run Puppet to install the plugin. Puppet modules contain manifest files that are a collection of classes for configuring a server. For example, a web server can be assigned several classes for the necessary software for a web server. Here is an example of using a Puppet class for a server running the Wikipedia Java example plugin: class { 'newrelic_plugins::wikipedia_example_java': license_key => 'NEW_RELIC_LICENSE_KEY', install_path => '/path/to/plugin', user => 'newrelic' } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.42331,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install from <em>Plugin</em> Central",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": " to <em>get</em> your <em>plugin</em> installed and running. After you <em>start</em> running a <em>plugin</em>, it collects and sends data to <em>New</em> <em>Relic</em>, usually within five minutes. The <em>plugin</em> name will automatically appear in the <em>Plugins</em> UI, where you can select and view its summary metrics and dashboards. Install an NPI-compatible"
      },
      "id": "60445cdd196a6788d9960f28"
    }
  ],
  "/docs/plugins/plugins-new-relic/get-started/introduction-plugin-central": [
    {
      "sections": [
        "Plugin security",
        "Important",
        "Limited access to legacy plugins",
        "Open community",
        "Third-party content",
        "Source code",
        "Access to license keys",
        "Access rights",
        "Plugin storage"
      ],
      "title": "Plugin security",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Get started"
      ],
      "external_id": "8476f9a0e63a7f58388b4a6e7fb8b089843033e3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/get-started/plugin-security/",
      "published_at": "2021-05-05T22:16:57Z",
      "updated_at": "2021-03-16T11:02:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Open community New Relic's Plugins tool been designed to be open and extensible, so that any New Relic user, developer, technology vendor, or partner may publish publicly accessible plugins within Plugin Central. Anyone who has a New Relic account can install and use these plugins through their New Relic user interface. Exception: Plugins in Plugin Central are not supported with accounts that host data in the EU region data center. Having an open community where users both create and consume plugins can raise questions surrounding security. This document intends to address any security considerations for using these plugins. For more information about New Relic's security measures, see our security and data privacy documentation, or visit the New Relic security website. Third-party content For some plugins, New Relic, Inc. is the publisher, and will be clearly identified as the publisher. However, as an open resource, many plugins are created by our partners and third-party developers. Every plugin in the Plugin Central directory clearly identifies whether it was published by a New Relic developer or by a third party. We require plugin publishers to provide an About link to their website, documentation about what the plugin is for and how to use it, and a link to obtain support when using the plugin. We also require plugin publishers to review and accept the Developer Terms of Service Agreement before they can make their plugin publicly accessible. You can review all information provided by the publisher before installing any plugin. Only those plugins that identify New Relic, Inc. as the publisher fall under New Relic's posted privacy policy. For more information, see the New Relic security website. For other plugins, refer to the publisher's security and compliance statements. Source code If you have any concerns about plugins developed with the SDKs for plugins, you can review the source code and verify that the plugin agents behave as expected. The plugin agent's code is light, and it can be reviewed in minutes. Access to license keys Always keep your New Relic license key private. Typically access to your license key is needed only to record metric data or deployments for your applications, hosts, or plugins that are monitored by New Relic, not to introduce new data or code. No other access is allowed. Access rights When developing a plugin agent, authors and publishers need to consider the environment in which they will be run. You should do everything possible to reduce the level of permissions your plugin users need to grant to the agent in order for it to run correctly. In particular: Unless it is absolutely necessary, do not require su or sudo permissions in order to install your agent or support software on your users' computers. In this situation, the requirements should be limited in scope and well-documented. For additional information about access rights for plugin users, see the documentation about installing a plugin. When running your agent on the users' computers, do not require su or sudo permissions. The components (instances) your plugin agent is monitoring should only need to grant read-only permissions in order for your agent to perform its actions. As much as possible, the components (instances) your plugin agent is monitoring should be able to reduce the levels of information and access needed. When documenting your plugin, describe what level of permissions your plugin agent requires from the components (instances) it is monitoring and why this is necessary. Following these steps will make it easier for your plugin users to install your agent and increase their confidence that your agent cannot harm their components or instances being monitored. This will also reduce the likelihood of user problems if your agent has any serious bugs or other defects. Plugin storage Plugins only need access to their monitored systems and New Relic simply to report metrics. You may want to consider running plugin agents in sequestered systems with limited network access that allow no more than the minimum required network access. Also, data retention for plugins follows New Relic's standard policies. If you have any concerns about deploying any plugin from Plugin Central, follow your organization's guidelines. If for any reason you do not trust the source of an existing plugin, try creating your own version.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.31558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Plugin</em> security",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": ") as of June 16, 2021. For more information, see our Explorers Hub post. Open community <em>New</em> <em>Relic</em>&#x27;s <em>Plugins</em> tool been designed to be open and extensible, so that any <em>New</em> <em>Relic</em> user, developer, technology vendor, or partner may publish publicly accessible <em>plugins</em> within <em>Plugin</em> Central. Anyone who has"
      },
      "id": "603ebeb9e7b9d25a642a07d4"
    },
    {
      "sections": [
        "Get plugin help",
        "Important",
        "Limited access to legacy plugins",
        "Plugin help resources"
      ],
      "title": "Get plugin help",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Get started"
      ],
      "external_id": "34d38b612d908d489b251716e2856b31644e03f5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/get-started/get-plugin-help/",
      "published_at": "2021-05-03T06:36:27Z",
      "updated_at": "2021-03-13T03:10:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Plugin help resources Each plugin in New Relic's Plugin Central typically includes troubleshooting information. When you select the plugin's Download or Continue button, the plugin should include a README file or refer to other documentation. If you experience problems that the plugin's documentation does not address, contact the plugin publisher's support resources identified in the plugin's Get support link. Be prepared to provide information such as: Are you able to connect to the plugins UI or able to connect to the monitored server? Do you have a New Relic license key or a message about an invalid license key? If you received a specific error, what was its error number or message? Can you provide a screenshot of the plugin's webpage where you are experiencing problems? Can you provide a log file? Can you provide your configuration file? Can you restart the plugin? Plugins in Plugin Central are not supported with accounts that host data in the EU region data center.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.03789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>plugin</em> help",
        "sections": "<em>Get</em> <em>plugin</em> help",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with <em>New</em> <em>Relic</em>, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools"
      },
      "id": "60445cdde7b9d2a2ef579a13"
    },
    {
      "sections": [
        "Install from Plugin Central",
        "Important",
        "Limited access to legacy plugins",
        "Requirements",
        "Access rights",
        "License key",
        "Typical plugin installation procedures",
        "Install an NPI-compatible plugin",
        "Install the plugin",
        "Manage plugins with the NPI tool",
        "Troubleshoot NPI-compatible plugins",
        "Duplicate plugins",
        "Error message ./npi: line 1: bin/node: No such file or directory",
        "Error message -bash: ./npi: No such file or directory",
        "Insufficient privileges to run background processes",
        "Install with Chef or Puppet",
        "Chef cookbooks",
        "Puppet modules"
      ],
      "title": "Install from Plugin Central",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Install plugins"
      ],
      "external_id": "a19bd4cb7582a8653cd83b18e431b23cb4270876",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/install-plugins/install-plugin-central/",
      "published_at": "2021-05-03T06:36:26Z",
      "updated_at": "2021-03-13T01:16:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Requirements Each plugin in Plugin Central includes its own procedures for how to install, use, troubleshoot, and uninstall it. In order to use a plugin, first verify that your environment meets the plugin's documented requirements. Then follow the plugin's procedures to install the plugin agent on one or more hosts in your monitored environment, or to configure a SaaS plugin as directed by your SaaS provider. As a standard security measure for data collection, your application server must support SHA-2 (256-bit). We do not support SHA-1. Also, plugins in Plugin Central are not supported with accounts that host data in the EU region data center. Access rights When using an agent from Plugin Central, deploy the agent giving the fewest possible permissions in order for the plugin agent to function successfully. Unless the plugin publisher gives specific instructions, you should run the plugin agent as a non-privileged user; do not use su or sudo privileges. This applies to both installing and using the agent. If the plugin agent needs credentials for the component (instance) that it is monitoring, create a custom set of credentials just for the monitoring agent to use. These should be separate from any other production credentials. The custom credentials should grant the fewest possible permissions while still allowing the agent to gather the data it needs. For example, for most plugin agents, you should only need to grant read-only access to your components or instances so the plugin agent cannot modify your system in any way. Also, with many agents, you should only need to grant access to read performance and administration data, not necessarily end customer or other sensitive data. For more information, see Plugin security. License key As part of any plugin installation process, you need your New Relic license key. When you are logged into the Plugins UI, the plugin's installation page in Plugin Central also shows your license key so you can easily copy it to your clipboard. If plugins have been published by SaaS providers, they must have access to the New Relic license key for each individual account. They can capture this information when provisioning new customers via the New Relic Partner API, or they can provide a mechanism for customers to share their existing New Relic license key. Typical plugin installation procedures Installation requirements depend on the type of plugin. For example, a Java plugin agent has different requirements than a Ruby plugin agent. Before you use a plugin, review the documentation that the plugin's publisher provides about the agent's installation requirements. To install any plugin from Plugin Central: Go to one.newrelic.com > More > Plugins. From the Plugin Central directory, select the plugin's title or its Get started button. From the plugin's details page, select the Download or Continue button. Follow the plugin's specific instructions to get your plugin installed and running. After you start running a plugin, it collects and sends data to New Relic, usually within five minutes. The plugin name will automatically appear in the Plugins UI, where you can select and view its summary metrics and dashboards. Install an NPI-compatible plugin The New Relic Platform Installer (NPI) is a command line utility that helps you easily download, configure, and manage a plugin by installing it with a single command. After you install the NPI tool, you can use it to install any plugins that are compatible with it. Install the plugin Plugins that are compatible with the New Relic Platform Installer include an NPI compatible label. If you have not already installed the NPI tool: Go to one.newrelic.com > More > Plugins, then select any plugin listed as NPI compatible. From the selected plugin's Installation page in the UI, click the link that says * Requires New Relic Platform Installer (NPI) - Get it here. From the dropdown that opens, select your operating system. Copy the command that appears, then run it in your terminal to install the NPI tool. Unix-based systems: If you need to set a default user, in your terminal, run: ./npi set user <USER NAME> Copy Once you have installed the NPI tool, you can install any NPI compatible plugin. Go to one.newrelic.com > More > Plugins, then select any plugin listed as NPI compatible. From the selected plugin's Installation page in the UI, follow the procedures to copy the specific plugin's installation command. In your terminal, change to the directory ~/newrelic-npi, then paste and run the install command. Manage plugins with the NPI tool To view information that helps you manage NPI-compatible plugins: For usage and commands, help and version flags, and setup examples, run the command --help from the directory ~/newrelic-npi. For a list of plugins that are NPI-compatible, run the command ./npi available. If you need to include proxy settings in your configuration (for both the NPI tool and the plugin's newrelic.json file), use these commands: ./npi config set proxy_host <HOST> ./npi config set proxy_port <PORT> ./npi config set proxy_username <USER NAME> ./npi config set proxy_password <PASSWORD> Copy To view the full path for a plugin, run a where command. This is useful for viewing log files or locating a plugin on your filesystem so you can manually configure it. Troubleshoot NPI-compatible plugins In addition to the troubleshooting procedures provided by the plugin publisher, follow these troubleshooting guidelines when installing NPI-compatible plugins. Duplicate plugins Problem: If you install a plugin and then install the same plugin again through the NPI tool, you will have two versions of the plugin installed. Solution: Delete the older version of the plugin, and then install the NPI-compatible version using the NPI tool. Procedures to delete plugins typically appear in the README file or in other documentation that the plugin publisher provides. Error message ./npi: line 1: bin/node: No such file or directory Problem: The architecture script that you selected when you installed the NPI tool does not match your operating system (for example, x86 instead of x64). Solution: Install the NPI tool using the correct script for your operating system. Error message -bash: ./npi: No such file or directory Problem: You cannot run NPI commands. Solution: You can only access the NPI tool from the location where it was installed. To solve this problem, navigate to the directory ~/newrelic-npi, and run the command again. Insufficient privileges to run background processes Problem: If you try to set a plugin to run as a background process, you might see a message that you have insufficient privileges. Solution: The plugin creates an /etc/init.d script on Linux and a Windows service on Windows, both of which require escalated privileges to run. To solve this problem: Linux: Run the command with sudo in front of it. Windows: Run the command as an administrator. Install with Chef or Puppet In addition to standard installation procedures, you can install plugins with Chef and Puppet configuration management tools. These tools automate plugin installation and make it easier to manage plugins with the rest of your server software. Chef cookbooks Plugins in Plugin Central may come bundled with a Chef script, or you can write your own. If a Chef script is provided, this does not mean you are required to use it to install the plugin. Before installing a plugin using Chef, add the Chef cookbook for New Relic Plugins: Procedures: See Chef's cookbook documentation. New Relic Plugins cookbook: See Chef's community site for newrelic_plugins. Requirements and dependencies: See New Relic's GitHub repo for installing plugins with Chef. Then, to install a plugin using Chef: Configure Chef with the plugin details. Run Chef to install the plugin. Chef cookbooks and recipes define roles for specific server configurations. For example, a web server can have the role web_server which includes all of the software and configuration needed for a web server. Here is an example of creating a Chef role for a server running the Wikipedia Java example plugin: name \"newrelic_wikipedia_example_java_plugin\" description \"Server running the New Relic Plugins Wikipedia Example Java Plugin\" run_list( \"recipe[newrelic_plugins::wikipedia_example_java]\" ) default_attributes( \"newrelic\" => { \"license_key\" => \"NEW_RELIC_LICENSE_KEY\", \"wikipedia_example_java\" => { \"install_path\" => \"/path/to/plugin\", \"user\" => \"newrelic\" } } ) Copy Puppet modules Plugins in Plugin Central may come bundled with a Puppet script, or you can write your own. If a Puppet script is provided, this does not mean you are required to use it to install the plugin. Before installing a plugin using Puppet, add New Relic's Puppet module for plugins: Procedures: See Puppet's module documentation. New Relic plugin modules: See the Puppet Forge community site. Requirements and dependencies: See New Relic's GitHub repo for installing plugins with Puppet. Then, to install a plugin using Puppet: Configure Puppet with the plugin details. Run Puppet to install the plugin. Puppet modules contain manifest files that are a collection of classes for configuring a server. For example, a web server can be assigned several classes for the necessary software for a web server. Here is an example of using a Puppet class for a server running the Wikipedia Java example plugin: class { 'newrelic_plugins::wikipedia_example_java': license_key => 'NEW_RELIC_LICENSE_KEY', install_path => '/path/to/plugin', user => 'newrelic' } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.42331,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install from <em>Plugin</em> Central",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": " to <em>get</em> your <em>plugin</em> installed and running. After you <em>start</em> running a <em>plugin</em>, it collects and sends data to <em>New</em> <em>Relic</em>, usually within five minutes. The <em>plugin</em> name will automatically appear in the <em>Plugins</em> UI, where you can select and view its summary metrics and dashboards. Install an NPI-compatible"
      },
      "id": "60445cdd196a6788d9960f28"
    }
  ],
  "/docs/plugins/plugins-new-relic/get-started/plugin-security": [
    {
      "sections": [
        "Introduction to Plugin Central",
        "Important",
        "Limited access to legacy plugins",
        "Developers and SaaS providers",
        "Plugin Central directory",
        "View plugins in Plugin Central",
        "Get started with plugins",
        "Ratings",
        "Reviews",
        "Plugin feedback policy"
      ],
      "title": "Introduction to Plugin Central",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Get started"
      ],
      "external_id": "aa864c660f02e96be1c9cec897300ed96e5e33cb",
      "image": "https://docs.newrelic.com/static/916b76819340fbeb3becda03908ca2d2/c1b63/plugins-landing-page-prototype071720.png",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/get-started/introduction-plugin-central/",
      "published_at": "2021-05-03T06:36:07Z",
      "updated_at": "2021-03-16T11:02:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Developers and SaaS providers Plugin Central is where partners, third-party vendors, and users could publish plugin agents that collect selected data. This is also where you could install and view the plugin data on your Plugins dashboards as a set of summary metrics, charts, and tables. In most cases, the plugin's agent runs on the users' app server. SaaS or PaaS providers can also create plugin agents that run on their system and report metrics for customers who use New Relic to monitor their applications. For more information, see the specific plugin agent SDK documentation. Plugin Central directory Important Plugins in Plugin Central are not supported with accounts that host data in the EU region data center. The plugin agent collects, sends, and stores the metric data. Plugin Central provides a searchable directory for plugins that developers publish and make publicly available to users. From Plugin Central, you can select and download whatever plugins you want to use. After you install or configure a plugin, you can view the plugin's dashboard data securely from the plugins user interface in New Relic One. View plugins in Plugin Central To view information about available (published) plugins: Go to one.newrelic.com > More > Plugins. By default, available plugins appear in alphabetical order. From the Plugin Central directory in New Relic One, select any published plugin to view a description and install it. Depending on the selected plugin, installation and configuration instructions will vary. Refer to your plugin's documentation for specific details. After you install or configure a plugin, it automatically appears on your Plugins menu in New Relic One, where you can select and view it directly. You may need to wait a few minutes for data to appear. Get started with plugins Here are some tips for making the most of Plugin Central. Ratings Plugins listed in New Relic's Plugin Central include a 5-star rating system, ranging from 1 (lowest) to 5 (highest). This helps you make more informed choices when choosing among similar plugins. This also provides a way for you to share what you think of a plugin. You can rate as many plugins as you want. If you have not voted for a plugin, its current star rating (gold or gray) does not include an outline. You can have only one vote for a specific plugin, and you cannot delete your vote. However, you can change your rating level anytime. After you select the star level (1 to 5) to cast your vote, the stars change to gold with an outline at the rating level you selected. Reviews Plugin Central includes a simple review system to share what you think of a plugin and to provide tips for others about installation and usage. Existing reviews appear when you select an individual plugin's title or Get started link. You can write as many reviews for as many plugins as you want, following the feedback policy. You can also edit or delete your own reviews. When you write a review for a plugin, if you have not already rated the plugin, you must provide a rating. Subsequent reviews will use the rating you provided. You can change your rating at any time. Plugin administrators also reserve the right to delete reviews if necessary. For more information, see Plugin feedback policy. Plugin feedback policy Here are some types of reviews we welcome: Your experience using the plugin Suggestions for improvement Your thoughts or opinions about the plugin, even if you disagree with us or point out mistakes Constructive criticism Your review must not contain personal attacks, name calling, libel, defamation, hate speech, etc. And under no circumstances should you post anything that could be taken as threatening, harassing, bullying, obscene, pornographic, sexist, or racist. We reserve the right to moderate reviews to make sure the tone is civil and fair. We will delete a review or rating in these situations: Spam, such as off-topic or nonsense reviews Inappropriate reviews including profanity and links to offensive content Attacks, including personal attacks against the plugin author or other reviewers, as well as attacks against New Relic or other companies. This does not mean you can't disagree with us or with each other, just be polite about it. False reviews that contain misleading statements or claims Other; for example, reviews or ratings that appear to be gaming the system",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.31558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Plugin</em> Central",
        "sections": "<em>Get</em> <em>started</em> with <em>plugins</em>",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": ". You may need to wait a few minutes for data to appear. <em>Get</em> <em>started</em> with <em>plugins</em> Here are some tips for making the most of <em>Plugin</em> Central. Ratings <em>Plugins</em> listed in <em>New</em> <em>Relic</em>&#x27;s <em>Plugin</em> Central include a 5-star rating system, ranging from 1 (lowest) to 5 (highest). This helps you make more informed"
      },
      "id": "603e81b428ccbc63bdeba79e"
    },
    {
      "sections": [
        "Get plugin help",
        "Important",
        "Limited access to legacy plugins",
        "Plugin help resources"
      ],
      "title": "Get plugin help",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Get started"
      ],
      "external_id": "34d38b612d908d489b251716e2856b31644e03f5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/get-started/get-plugin-help/",
      "published_at": "2021-05-03T06:36:27Z",
      "updated_at": "2021-03-13T03:10:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Plugin help resources Each plugin in New Relic's Plugin Central typically includes troubleshooting information. When you select the plugin's Download or Continue button, the plugin should include a README file or refer to other documentation. If you experience problems that the plugin's documentation does not address, contact the plugin publisher's support resources identified in the plugin's Get support link. Be prepared to provide information such as: Are you able to connect to the plugins UI or able to connect to the monitored server? Do you have a New Relic license key or a message about an invalid license key? If you received a specific error, what was its error number or message? Can you provide a screenshot of the plugin's webpage where you are experiencing problems? Can you provide a log file? Can you provide your configuration file? Can you restart the plugin? Plugins in Plugin Central are not supported with accounts that host data in the EU region data center.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.03789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>plugin</em> help",
        "sections": "<em>Get</em> <em>plugin</em> help",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": "Important For an even better experience than <em>plugins</em>, go to: newrelic.com&#x2F;integrations: Integrate the on-host and cloud systems you already use with <em>New</em> <em>Relic</em>, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools"
      },
      "id": "60445cdde7b9d2a2ef579a13"
    },
    {
      "sections": [
        "Install from Plugin Central",
        "Important",
        "Limited access to legacy plugins",
        "Requirements",
        "Access rights",
        "License key",
        "Typical plugin installation procedures",
        "Install an NPI-compatible plugin",
        "Install the plugin",
        "Manage plugins with the NPI tool",
        "Troubleshoot NPI-compatible plugins",
        "Duplicate plugins",
        "Error message ./npi: line 1: bin/node: No such file or directory",
        "Error message -bash: ./npi: No such file or directory",
        "Insufficient privileges to run background processes",
        "Install with Chef or Puppet",
        "Chef cookbooks",
        "Puppet modules"
      ],
      "title": "Install from Plugin Central",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Install plugins"
      ],
      "external_id": "a19bd4cb7582a8653cd83b18e431b23cb4270876",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/install-plugins/install-plugin-central/",
      "published_at": "2021-05-03T06:36:26Z",
      "updated_at": "2021-03-13T01:16:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Requirements Each plugin in Plugin Central includes its own procedures for how to install, use, troubleshoot, and uninstall it. In order to use a plugin, first verify that your environment meets the plugin's documented requirements. Then follow the plugin's procedures to install the plugin agent on one or more hosts in your monitored environment, or to configure a SaaS plugin as directed by your SaaS provider. As a standard security measure for data collection, your application server must support SHA-2 (256-bit). We do not support SHA-1. Also, plugins in Plugin Central are not supported with accounts that host data in the EU region data center. Access rights When using an agent from Plugin Central, deploy the agent giving the fewest possible permissions in order for the plugin agent to function successfully. Unless the plugin publisher gives specific instructions, you should run the plugin agent as a non-privileged user; do not use su or sudo privileges. This applies to both installing and using the agent. If the plugin agent needs credentials for the component (instance) that it is monitoring, create a custom set of credentials just for the monitoring agent to use. These should be separate from any other production credentials. The custom credentials should grant the fewest possible permissions while still allowing the agent to gather the data it needs. For example, for most plugin agents, you should only need to grant read-only access to your components or instances so the plugin agent cannot modify your system in any way. Also, with many agents, you should only need to grant access to read performance and administration data, not necessarily end customer or other sensitive data. For more information, see Plugin security. License key As part of any plugin installation process, you need your New Relic license key. When you are logged into the Plugins UI, the plugin's installation page in Plugin Central also shows your license key so you can easily copy it to your clipboard. If plugins have been published by SaaS providers, they must have access to the New Relic license key for each individual account. They can capture this information when provisioning new customers via the New Relic Partner API, or they can provide a mechanism for customers to share their existing New Relic license key. Typical plugin installation procedures Installation requirements depend on the type of plugin. For example, a Java plugin agent has different requirements than a Ruby plugin agent. Before you use a plugin, review the documentation that the plugin's publisher provides about the agent's installation requirements. To install any plugin from Plugin Central: Go to one.newrelic.com > More > Plugins. From the Plugin Central directory, select the plugin's title or its Get started button. From the plugin's details page, select the Download or Continue button. Follow the plugin's specific instructions to get your plugin installed and running. After you start running a plugin, it collects and sends data to New Relic, usually within five minutes. The plugin name will automatically appear in the Plugins UI, where you can select and view its summary metrics and dashboards. Install an NPI-compatible plugin The New Relic Platform Installer (NPI) is a command line utility that helps you easily download, configure, and manage a plugin by installing it with a single command. After you install the NPI tool, you can use it to install any plugins that are compatible with it. Install the plugin Plugins that are compatible with the New Relic Platform Installer include an NPI compatible label. If you have not already installed the NPI tool: Go to one.newrelic.com > More > Plugins, then select any plugin listed as NPI compatible. From the selected plugin's Installation page in the UI, click the link that says * Requires New Relic Platform Installer (NPI) - Get it here. From the dropdown that opens, select your operating system. Copy the command that appears, then run it in your terminal to install the NPI tool. Unix-based systems: If you need to set a default user, in your terminal, run: ./npi set user <USER NAME> Copy Once you have installed the NPI tool, you can install any NPI compatible plugin. Go to one.newrelic.com > More > Plugins, then select any plugin listed as NPI compatible. From the selected plugin's Installation page in the UI, follow the procedures to copy the specific plugin's installation command. In your terminal, change to the directory ~/newrelic-npi, then paste and run the install command. Manage plugins with the NPI tool To view information that helps you manage NPI-compatible plugins: For usage and commands, help and version flags, and setup examples, run the command --help from the directory ~/newrelic-npi. For a list of plugins that are NPI-compatible, run the command ./npi available. If you need to include proxy settings in your configuration (for both the NPI tool and the plugin's newrelic.json file), use these commands: ./npi config set proxy_host <HOST> ./npi config set proxy_port <PORT> ./npi config set proxy_username <USER NAME> ./npi config set proxy_password <PASSWORD> Copy To view the full path for a plugin, run a where command. This is useful for viewing log files or locating a plugin on your filesystem so you can manually configure it. Troubleshoot NPI-compatible plugins In addition to the troubleshooting procedures provided by the plugin publisher, follow these troubleshooting guidelines when installing NPI-compatible plugins. Duplicate plugins Problem: If you install a plugin and then install the same plugin again through the NPI tool, you will have two versions of the plugin installed. Solution: Delete the older version of the plugin, and then install the NPI-compatible version using the NPI tool. Procedures to delete plugins typically appear in the README file or in other documentation that the plugin publisher provides. Error message ./npi: line 1: bin/node: No such file or directory Problem: The architecture script that you selected when you installed the NPI tool does not match your operating system (for example, x86 instead of x64). Solution: Install the NPI tool using the correct script for your operating system. Error message -bash: ./npi: No such file or directory Problem: You cannot run NPI commands. Solution: You can only access the NPI tool from the location where it was installed. To solve this problem, navigate to the directory ~/newrelic-npi, and run the command again. Insufficient privileges to run background processes Problem: If you try to set a plugin to run as a background process, you might see a message that you have insufficient privileges. Solution: The plugin creates an /etc/init.d script on Linux and a Windows service on Windows, both of which require escalated privileges to run. To solve this problem: Linux: Run the command with sudo in front of it. Windows: Run the command as an administrator. Install with Chef or Puppet In addition to standard installation procedures, you can install plugins with Chef and Puppet configuration management tools. These tools automate plugin installation and make it easier to manage plugins with the rest of your server software. Chef cookbooks Plugins in Plugin Central may come bundled with a Chef script, or you can write your own. If a Chef script is provided, this does not mean you are required to use it to install the plugin. Before installing a plugin using Chef, add the Chef cookbook for New Relic Plugins: Procedures: See Chef's cookbook documentation. New Relic Plugins cookbook: See Chef's community site for newrelic_plugins. Requirements and dependencies: See New Relic's GitHub repo for installing plugins with Chef. Then, to install a plugin using Chef: Configure Chef with the plugin details. Run Chef to install the plugin. Chef cookbooks and recipes define roles for specific server configurations. For example, a web server can have the role web_server which includes all of the software and configuration needed for a web server. Here is an example of creating a Chef role for a server running the Wikipedia Java example plugin: name \"newrelic_wikipedia_example_java_plugin\" description \"Server running the New Relic Plugins Wikipedia Example Java Plugin\" run_list( \"recipe[newrelic_plugins::wikipedia_example_java]\" ) default_attributes( \"newrelic\" => { \"license_key\" => \"NEW_RELIC_LICENSE_KEY\", \"wikipedia_example_java\" => { \"install_path\" => \"/path/to/plugin\", \"user\" => \"newrelic\" } } ) Copy Puppet modules Plugins in Plugin Central may come bundled with a Puppet script, or you can write your own. If a Puppet script is provided, this does not mean you are required to use it to install the plugin. Before installing a plugin using Puppet, add New Relic's Puppet module for plugins: Procedures: See Puppet's module documentation. New Relic plugin modules: See the Puppet Forge community site. Requirements and dependencies: See New Relic's GitHub repo for installing plugins with Puppet. Then, to install a plugin using Puppet: Configure Puppet with the plugin details. Run Puppet to install the plugin. Puppet modules contain manifest files that are a collection of classes for configuring a server. For example, a web server can be assigned several classes for the necessary software for a web server. Here is an example of using a Puppet class for a server running the Wikipedia Java example plugin: class { 'newrelic_plugins::wikipedia_example_java': license_key => 'NEW_RELIC_LICENSE_KEY', install_path => '/path/to/plugin', user => 'newrelic' } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.42331,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install from <em>Plugin</em> Central",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": " to <em>get</em> your <em>plugin</em> installed and running. After you <em>start</em> running a <em>plugin</em>, it collects and sends data to <em>New</em> <em>Relic</em>, usually within five minutes. The <em>plugin</em> name will automatically appear in the <em>Plugins</em> UI, where you can select and view its summary metrics and dashboards. Install an NPI-compatible"
      },
      "id": "60445cdd196a6788d9960f28"
    }
  ],
  "/docs/plugins/plugins-new-relic/install-plugins/install-plugin-central": [
    {
      "sections": [
        "Use a Plugin Central plugin",
        "Important",
        "Limited access to legacy plugins",
        "View plugin dashboard details",
        "Plugin summary",
        "Plugin dashboards",
        "Plugin alerts",
        "Delete a plugin",
        "Remove plugin components (instances)",
        "Delete the plugin"
      ],
      "title": "Use a Plugin Central plugin",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Install plugins"
      ],
      "external_id": "feae68c2e9d870f7c02fff5ffb69f2c262a0cd6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/install-plugins/use-plugin-central-plugin/",
      "published_at": "2021-05-04T18:26:10Z",
      "updated_at": "2021-03-16T11:03:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. View plugin dashboard details Each plugin in Plugin Central includes procedures for how to install, use, troubleshoot, and uninstall it. Plugins in Plugin Central are not supported with accounts that host data in the EU region data center. After you install a plugin, it starts to receive data, usually within five minutes. The plugin automatically appears with a short name and icon on your Plugins menu in New Relic One. You do not need to select it from Plugin Central. The amount and types of information on the plugin's summary page and dashboards depend on the specific plugin. For example, a plugin may have one or more components (instances) and one or more dashboards. To view summary and dashboard details about the plugin: Go to one.newrelic.com > More > Plugins, and select your plugin. From the plugin's summary page, review the list of components or instances, summary metrics, and list of Recent Events. To view dashboard details about any component or instance, select its name. Plugin summary Depending on the plugin, the summary includes: One or more components or instances (what the plugin agent is monitoring, typically a host/port pair) Zero to five summary metrics for the past three minutes (values such as average, total, minimum, maximum, standard deviation, rate, or count) with optional alerts Recent events list, including deployments, notifications, and alerts Other information about alert violations, events, and activity If your plugin has 100 or more components or instances, you can search for a specific component instance. Here is a summary of additional standard features. If you want to... Do this... View version information for a component's or instance's agent Mouse over the component's name. Change the sort order On the title row of the plugin's summary page, select the up or down arrow for a component (instance) or a summary metric's label. Show or hide items on the events and activity list Select an event icon, or select All. View details about an event On the events and activity list, select the link. View page details for a component or instance Select the name or a summary metric for the component (instance). Plugin dashboards Depending on the plugin, it may have one or more dashboards, and each dashboard may present data as a chart or a table. You can use any of New Relic's standard dashboard features to drill down into detailed information. The customized dashboards that show plugin data are part of the plugin. Users cannot add or remove these dashboards. This must be done by the author or publisher as part of a plugin update. Plugin alerts If the plugin publisher set Critical (red) or Caution (yellow) alert conditions for your plugin's components or instances, you can view details direct in the user interface. For example, you can: Select and view alert details. Change the existing thresholds. Set your alert notification options; for example, to receive email notifications for Critical events. Delete a plugin Each plugin in Plugin Central includes procedures for how to uninstall it. When you select the plugin's Download or Continue button, the plugin should include a README file or refer to other documentation resources. Remove plugin components (instances) At a minimum, your plugin must stop reporting data before you start uninstalling it. Make sure the health status for your plugin's components (instances) are gray. Depending on the plugin, there may be other dependencies before disabling or uninstalling it. For example, plugins from SaaS providers may have different requirements. Be sure to review the instructions that the plugin's publisher provides. Then, to remove individual components from your plugin, click the settings icon for each component (instance). Delete the plugin After you remove each component (instance) for the plugin, the plugin icon will automatically disappear from your Plugins menu in the New Relic UI. You do not need to do anything else to delete the plugin. If you are the plugin's publisher and need to delete the plugin from Plugin Central, go to support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.75818,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use a <em>Plugin</em> Central <em>plugin</em>",
        "sections": "Use a <em>Plugin</em> Central <em>plugin</em>",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": " center. After you <em>install</em> a <em>plugin</em>, it starts to receive data, usually within five minutes. The <em>plugin</em> automatically appears with a short name and icon on your <em>Plugins</em> menu in <em>New</em> <em>Relic</em> One. You do not need to select it from <em>Plugin</em> Central. The amount and types of information on the <em>plugin</em>"
      },
      "id": "603ebf0928ccbcf8d0eba762"
    },
    {
      "sections": [
        "New Relic One CLI reference",
        "Installing the New Relic One CLI",
        "Tip",
        "New Relic One CLI Commands",
        "Get started",
        "Configure your CLI preferences",
        "Set up your Nerdpacks",
        "Manage your Nerdpack subscriptions",
        "Install and manage plugins",
        "Manage catalog information"
      ],
      "title": "New Relic One CLI reference",
      "type": "developer",
      "tags": [
        "New Relic One app",
        "nerdpack commands"
      ],
      "external_id": "858339a44ead21c83257778ce60b4c352cd30d3b",
      "image": "https://developer.newrelic.com/static/2c6d337608b38a3312b4fc740afe6167/7272b/developercenter.png",
      "url": "https://developer.newrelic.com/explore-docs/nr1-cli/",
      "published_at": "2021-05-07T01:42:20Z",
      "updated_at": "2021-05-05T01:53:28Z",
      "document_type": "page",
      "popularity": 1,
      "info": "An overview of the CLI to help you build, deploy, and manage New Relic apps.",
      "body": "To build a New Relic One app, you must install the New Relic One CLI. The CLI helps you build, publish, and manage your New Relic app. We provide a variety of tools for building apps, including the New Relic One CLI (command line interface). This page explains how to use CLI commands to: Generate Nerdpack/Nerdlet templates Locally serve Nerdpacks (when developing) Publish and deploy Subscribe to Nerdpacks Add screenshots and metadata to the catalog Installing the New Relic One CLI In New Relic, click Apps and then in the New Relic One catalog area, click the Build your own application launcher and follow the quick start instructions. The quick start automatically generates an API key for the account you select, and gives you the pre-populated commands to create a profile, generate your first \"Hello World\" app, and serve it locally. Tip Use the NR1 VS Code extension to build your apps. New Relic One CLI Commands This table provides descriptions for the New Relic One commands. For more context, including usage and option details, click any individual command or the command category. For details on user permissions, see Permissions. For more on how to serve and publish your application, see our guide on Deploying your New Relic One app. Get started nr1 help Shows all nr1 commands or details about each command. nr1 update Updates to the latest version of the CLI. nr1 create Creates a new component from a template (Nerdpack, Nerdlet, launcher, or catalog). nr1 profiles Manages the profiles you use to run CLI commands. nr1 autocomplete Displays autocomplete installation instructions. nr1 nrql Fetches data using NRQL (New Relic query language). Configure your CLI preferences nr1 config:set Sets a specific configuration value. nr1 config:get Shows a specific configuration. nr1 config:list Lists your configuration choices. nr1 config:delete Removes the value of a specific configuration. Set up your Nerdpacks nr1 nerdpack:build Assembles your Nerdpack into bundles. nr1 nerdpack:clone Clones an open source Nerdpack from our GitHub repository. nr1 nerdpack:serve Serves your Nerdpack for testing and development purposes. nr1 nerdpack:uuid Shows or regenerates the UUID of a Nerdpack. nr1 nerdpack:publish Publishes your Nerdpack to New Relic. nr1 nerdpack:deploy Deploys a Nerdpack version to a specific channel. nr1 nerdpack:undeploy Undeploys a Nerdpack version from a specific channel. nr1 nerdpack:clean Cleans your developtment folders. nr1 nerdpack:validate Validates the contents of your Nerdpack. nr1 nerdpack:info Shows the state of your Nerdpack in the New Relic's registry. Manage your Nerdpack subscriptions nr1 subscription:set Subscribes your account to a Nerdpack and channel. nr1 subscription:list Lists all the Nerdpacks your account is subscribed to. nr1 subscription:unset Unsubscribes your account from a Nerdpack. Install and manage plugins nr1 plugins:install Installs a plugin into the CLI. nr1 plugins:link Links a plugin into the CLI for development. nr1 plugins:update Updates your installed plugins. nr1 plugins:uninstall Removes a plugin from the CLI. Manage catalog information nr1 catalog:info Shows the Nerdpack info stored in the catalog. nr1 catalog:submit Gathers and submits the catalog info on the current folder.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.83777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> One CLI reference",
        "sections": "<em>Installing</em> the <em>New</em> <em>Relic</em> One CLI",
        "info": "An overview of the CLI to help you build, deploy, and manage <em>New</em> <em>Relic</em> apps.",
        "tags": "<em>New</em> <em>Relic</em> One app",
        "body": "To build a <em>New</em> <em>Relic</em> One app, you must <em>install</em> the <em>New</em> <em>Relic</em> One CLI. The CLI helps you build, publish, and manage your <em>New</em> <em>Relic</em> app. We provide a variety of tools for building apps, including the <em>New</em> <em>Relic</em> One CLI (command line interface). This page explains how to use CLI commands to: Generate"
      },
      "id": "6091fa9864441feb412f36d4"
    },
    {
      "sections": [
        "Introduction to Plugin Central",
        "Important",
        "Limited access to legacy plugins",
        "Developers and SaaS providers",
        "Plugin Central directory",
        "View plugins in Plugin Central",
        "Get started with plugins",
        "Ratings",
        "Reviews",
        "Plugin feedback policy"
      ],
      "title": "Introduction to Plugin Central",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Get started"
      ],
      "external_id": "aa864c660f02e96be1c9cec897300ed96e5e33cb",
      "image": "https://docs.newrelic.com/static/916b76819340fbeb3becda03908ca2d2/c1b63/plugins-landing-page-prototype071720.png",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/get-started/introduction-plugin-central/",
      "published_at": "2021-05-03T06:36:07Z",
      "updated_at": "2021-03-16T11:02:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Developers and SaaS providers Plugin Central is where partners, third-party vendors, and users could publish plugin agents that collect selected data. This is also where you could install and view the plugin data on your Plugins dashboards as a set of summary metrics, charts, and tables. In most cases, the plugin's agent runs on the users' app server. SaaS or PaaS providers can also create plugin agents that run on their system and report metrics for customers who use New Relic to monitor their applications. For more information, see the specific plugin agent SDK documentation. Plugin Central directory Important Plugins in Plugin Central are not supported with accounts that host data in the EU region data center. The plugin agent collects, sends, and stores the metric data. Plugin Central provides a searchable directory for plugins that developers publish and make publicly available to users. From Plugin Central, you can select and download whatever plugins you want to use. After you install or configure a plugin, you can view the plugin's dashboard data securely from the plugins user interface in New Relic One. View plugins in Plugin Central To view information about available (published) plugins: Go to one.newrelic.com > More > Plugins. By default, available plugins appear in alphabetical order. From the Plugin Central directory in New Relic One, select any published plugin to view a description and install it. Depending on the selected plugin, installation and configuration instructions will vary. Refer to your plugin's documentation for specific details. After you install or configure a plugin, it automatically appears on your Plugins menu in New Relic One, where you can select and view it directly. You may need to wait a few minutes for data to appear. Get started with plugins Here are some tips for making the most of Plugin Central. Ratings Plugins listed in New Relic's Plugin Central include a 5-star rating system, ranging from 1 (lowest) to 5 (highest). This helps you make more informed choices when choosing among similar plugins. This also provides a way for you to share what you think of a plugin. You can rate as many plugins as you want. If you have not voted for a plugin, its current star rating (gold or gray) does not include an outline. You can have only one vote for a specific plugin, and you cannot delete your vote. However, you can change your rating level anytime. After you select the star level (1 to 5) to cast your vote, the stars change to gold with an outline at the rating level you selected. Reviews Plugin Central includes a simple review system to share what you think of a plugin and to provide tips for others about installation and usage. Existing reviews appear when you select an individual plugin's title or Get started link. You can write as many reviews for as many plugins as you want, following the feedback policy. You can also edit or delete your own reviews. When you write a review for a plugin, if you have not already rated the plugin, you must provide a rating. Subsequent reviews will use the rating you provided. You can change your rating at any time. Plugin administrators also reserve the right to delete reviews if necessary. For more information, see Plugin feedback policy. Plugin feedback policy Here are some types of reviews we welcome: Your experience using the plugin Suggestions for improvement Your thoughts or opinions about the plugin, even if you disagree with us or point out mistakes Constructive criticism Your review must not contain personal attacks, name calling, libel, defamation, hate speech, etc. And under no circumstances should you post anything that could be taken as threatening, harassing, bullying, obscene, pornographic, sexist, or racist. We reserve the right to moderate reviews to make sure the tone is civil and fair. We will delete a review or rating in these situations: Spam, such as off-topic or nonsense reviews Inappropriate reviews including profanity and links to offensive content Attacks, including personal attacks against the plugin author or other reviewers, as well as attacks against New Relic or other companies. This does not mean you can't disagree with us or with each other, just be polite about it. False reviews that contain misleading statements or claims Other; for example, reviews or ratings that appear to be gaming the system",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.55476,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Plugin</em> Central",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": " for <em>plugins</em> that developers publish and make publicly available to users. From <em>Plugin</em> Central, you can select and download whatever <em>plugins</em> you want to use. After you <em>install</em> or configure a <em>plugin</em>, you can view the <em>plugin</em>&#x27;s dashboard data securely from the <em>plugins</em> user interface in <em>New</em> <em>Relic</em> One"
      },
      "id": "603e81b428ccbc63bdeba79e"
    }
  ],
  "/docs/plugins/plugins-new-relic/install-plugins/use-plugin-central-plugin": [
    {
      "sections": [
        "Install from Plugin Central",
        "Important",
        "Limited access to legacy plugins",
        "Requirements",
        "Access rights",
        "License key",
        "Typical plugin installation procedures",
        "Install an NPI-compatible plugin",
        "Install the plugin",
        "Manage plugins with the NPI tool",
        "Troubleshoot NPI-compatible plugins",
        "Duplicate plugins",
        "Error message ./npi: line 1: bin/node: No such file or directory",
        "Error message -bash: ./npi: No such file or directory",
        "Insufficient privileges to run background processes",
        "Install with Chef or Puppet",
        "Chef cookbooks",
        "Puppet modules"
      ],
      "title": "Install from Plugin Central",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Install plugins"
      ],
      "external_id": "a19bd4cb7582a8653cd83b18e431b23cb4270876",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/install-plugins/install-plugin-central/",
      "published_at": "2021-05-03T06:36:26Z",
      "updated_at": "2021-03-13T01:16:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Requirements Each plugin in Plugin Central includes its own procedures for how to install, use, troubleshoot, and uninstall it. In order to use a plugin, first verify that your environment meets the plugin's documented requirements. Then follow the plugin's procedures to install the plugin agent on one or more hosts in your monitored environment, or to configure a SaaS plugin as directed by your SaaS provider. As a standard security measure for data collection, your application server must support SHA-2 (256-bit). We do not support SHA-1. Also, plugins in Plugin Central are not supported with accounts that host data in the EU region data center. Access rights When using an agent from Plugin Central, deploy the agent giving the fewest possible permissions in order for the plugin agent to function successfully. Unless the plugin publisher gives specific instructions, you should run the plugin agent as a non-privileged user; do not use su or sudo privileges. This applies to both installing and using the agent. If the plugin agent needs credentials for the component (instance) that it is monitoring, create a custom set of credentials just for the monitoring agent to use. These should be separate from any other production credentials. The custom credentials should grant the fewest possible permissions while still allowing the agent to gather the data it needs. For example, for most plugin agents, you should only need to grant read-only access to your components or instances so the plugin agent cannot modify your system in any way. Also, with many agents, you should only need to grant access to read performance and administration data, not necessarily end customer or other sensitive data. For more information, see Plugin security. License key As part of any plugin installation process, you need your New Relic license key. When you are logged into the Plugins UI, the plugin's installation page in Plugin Central also shows your license key so you can easily copy it to your clipboard. If plugins have been published by SaaS providers, they must have access to the New Relic license key for each individual account. They can capture this information when provisioning new customers via the New Relic Partner API, or they can provide a mechanism for customers to share their existing New Relic license key. Typical plugin installation procedures Installation requirements depend on the type of plugin. For example, a Java plugin agent has different requirements than a Ruby plugin agent. Before you use a plugin, review the documentation that the plugin's publisher provides about the agent's installation requirements. To install any plugin from Plugin Central: Go to one.newrelic.com > More > Plugins. From the Plugin Central directory, select the plugin's title or its Get started button. From the plugin's details page, select the Download or Continue button. Follow the plugin's specific instructions to get your plugin installed and running. After you start running a plugin, it collects and sends data to New Relic, usually within five minutes. The plugin name will automatically appear in the Plugins UI, where you can select and view its summary metrics and dashboards. Install an NPI-compatible plugin The New Relic Platform Installer (NPI) is a command line utility that helps you easily download, configure, and manage a plugin by installing it with a single command. After you install the NPI tool, you can use it to install any plugins that are compatible with it. Install the plugin Plugins that are compatible with the New Relic Platform Installer include an NPI compatible label. If you have not already installed the NPI tool: Go to one.newrelic.com > More > Plugins, then select any plugin listed as NPI compatible. From the selected plugin's Installation page in the UI, click the link that says * Requires New Relic Platform Installer (NPI) - Get it here. From the dropdown that opens, select your operating system. Copy the command that appears, then run it in your terminal to install the NPI tool. Unix-based systems: If you need to set a default user, in your terminal, run: ./npi set user <USER NAME> Copy Once you have installed the NPI tool, you can install any NPI compatible plugin. Go to one.newrelic.com > More > Plugins, then select any plugin listed as NPI compatible. From the selected plugin's Installation page in the UI, follow the procedures to copy the specific plugin's installation command. In your terminal, change to the directory ~/newrelic-npi, then paste and run the install command. Manage plugins with the NPI tool To view information that helps you manage NPI-compatible plugins: For usage and commands, help and version flags, and setup examples, run the command --help from the directory ~/newrelic-npi. For a list of plugins that are NPI-compatible, run the command ./npi available. If you need to include proxy settings in your configuration (for both the NPI tool and the plugin's newrelic.json file), use these commands: ./npi config set proxy_host <HOST> ./npi config set proxy_port <PORT> ./npi config set proxy_username <USER NAME> ./npi config set proxy_password <PASSWORD> Copy To view the full path for a plugin, run a where command. This is useful for viewing log files or locating a plugin on your filesystem so you can manually configure it. Troubleshoot NPI-compatible plugins In addition to the troubleshooting procedures provided by the plugin publisher, follow these troubleshooting guidelines when installing NPI-compatible plugins. Duplicate plugins Problem: If you install a plugin and then install the same plugin again through the NPI tool, you will have two versions of the plugin installed. Solution: Delete the older version of the plugin, and then install the NPI-compatible version using the NPI tool. Procedures to delete plugins typically appear in the README file or in other documentation that the plugin publisher provides. Error message ./npi: line 1: bin/node: No such file or directory Problem: The architecture script that you selected when you installed the NPI tool does not match your operating system (for example, x86 instead of x64). Solution: Install the NPI tool using the correct script for your operating system. Error message -bash: ./npi: No such file or directory Problem: You cannot run NPI commands. Solution: You can only access the NPI tool from the location where it was installed. To solve this problem, navigate to the directory ~/newrelic-npi, and run the command again. Insufficient privileges to run background processes Problem: If you try to set a plugin to run as a background process, you might see a message that you have insufficient privileges. Solution: The plugin creates an /etc/init.d script on Linux and a Windows service on Windows, both of which require escalated privileges to run. To solve this problem: Linux: Run the command with sudo in front of it. Windows: Run the command as an administrator. Install with Chef or Puppet In addition to standard installation procedures, you can install plugins with Chef and Puppet configuration management tools. These tools automate plugin installation and make it easier to manage plugins with the rest of your server software. Chef cookbooks Plugins in Plugin Central may come bundled with a Chef script, or you can write your own. If a Chef script is provided, this does not mean you are required to use it to install the plugin. Before installing a plugin using Chef, add the Chef cookbook for New Relic Plugins: Procedures: See Chef's cookbook documentation. New Relic Plugins cookbook: See Chef's community site for newrelic_plugins. Requirements and dependencies: See New Relic's GitHub repo for installing plugins with Chef. Then, to install a plugin using Chef: Configure Chef with the plugin details. Run Chef to install the plugin. Chef cookbooks and recipes define roles for specific server configurations. For example, a web server can have the role web_server which includes all of the software and configuration needed for a web server. Here is an example of creating a Chef role for a server running the Wikipedia Java example plugin: name \"newrelic_wikipedia_example_java_plugin\" description \"Server running the New Relic Plugins Wikipedia Example Java Plugin\" run_list( \"recipe[newrelic_plugins::wikipedia_example_java]\" ) default_attributes( \"newrelic\" => { \"license_key\" => \"NEW_RELIC_LICENSE_KEY\", \"wikipedia_example_java\" => { \"install_path\" => \"/path/to/plugin\", \"user\" => \"newrelic\" } } ) Copy Puppet modules Plugins in Plugin Central may come bundled with a Puppet script, or you can write your own. If a Puppet script is provided, this does not mean you are required to use it to install the plugin. Before installing a plugin using Puppet, add New Relic's Puppet module for plugins: Procedures: See Puppet's module documentation. New Relic plugin modules: See the Puppet Forge community site. Requirements and dependencies: See New Relic's GitHub repo for installing plugins with Puppet. Then, to install a plugin using Puppet: Configure Puppet with the plugin details. Run Puppet to install the plugin. Puppet modules contain manifest files that are a collection of classes for configuring a server. For example, a web server can be assigned several classes for the necessary software for a web server. Here is an example of using a Puppet class for a server running the Wikipedia Java example plugin: class { 'newrelic_plugins::wikipedia_example_java': license_key => 'NEW_RELIC_LICENSE_KEY', install_path => '/path/to/plugin', user => 'newrelic' } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.19676,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> from <em>Plugin</em> Central",
        "sections": "<em>Install</em> from <em>Plugin</em> Central",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": " to get your <em>plugin</em> installed and running. After you start running a <em>plugin</em>, it collects and sends data to <em>New</em> <em>Relic</em>, usually within five minutes. The <em>plugin</em> name will automatically appear in the <em>Plugins</em> UI, where you can select and view its summary metrics and dashboards. <em>Install</em> an NPI-compatible"
      },
      "id": "60445cdd196a6788d9960f28"
    },
    {
      "sections": [
        "New Relic One CLI reference",
        "Installing the New Relic One CLI",
        "Tip",
        "New Relic One CLI Commands",
        "Get started",
        "Configure your CLI preferences",
        "Set up your Nerdpacks",
        "Manage your Nerdpack subscriptions",
        "Install and manage plugins",
        "Manage catalog information"
      ],
      "title": "New Relic One CLI reference",
      "type": "developer",
      "tags": [
        "New Relic One app",
        "nerdpack commands"
      ],
      "external_id": "858339a44ead21c83257778ce60b4c352cd30d3b",
      "image": "https://developer.newrelic.com/static/2c6d337608b38a3312b4fc740afe6167/7272b/developercenter.png",
      "url": "https://developer.newrelic.com/explore-docs/nr1-cli/",
      "published_at": "2021-05-07T01:42:20Z",
      "updated_at": "2021-05-05T01:53:28Z",
      "document_type": "page",
      "popularity": 1,
      "info": "An overview of the CLI to help you build, deploy, and manage New Relic apps.",
      "body": "To build a New Relic One app, you must install the New Relic One CLI. The CLI helps you build, publish, and manage your New Relic app. We provide a variety of tools for building apps, including the New Relic One CLI (command line interface). This page explains how to use CLI commands to: Generate Nerdpack/Nerdlet templates Locally serve Nerdpacks (when developing) Publish and deploy Subscribe to Nerdpacks Add screenshots and metadata to the catalog Installing the New Relic One CLI In New Relic, click Apps and then in the New Relic One catalog area, click the Build your own application launcher and follow the quick start instructions. The quick start automatically generates an API key for the account you select, and gives you the pre-populated commands to create a profile, generate your first \"Hello World\" app, and serve it locally. Tip Use the NR1 VS Code extension to build your apps. New Relic One CLI Commands This table provides descriptions for the New Relic One commands. For more context, including usage and option details, click any individual command or the command category. For details on user permissions, see Permissions. For more on how to serve and publish your application, see our guide on Deploying your New Relic One app. Get started nr1 help Shows all nr1 commands or details about each command. nr1 update Updates to the latest version of the CLI. nr1 create Creates a new component from a template (Nerdpack, Nerdlet, launcher, or catalog). nr1 profiles Manages the profiles you use to run CLI commands. nr1 autocomplete Displays autocomplete installation instructions. nr1 nrql Fetches data using NRQL (New Relic query language). Configure your CLI preferences nr1 config:set Sets a specific configuration value. nr1 config:get Shows a specific configuration. nr1 config:list Lists your configuration choices. nr1 config:delete Removes the value of a specific configuration. Set up your Nerdpacks nr1 nerdpack:build Assembles your Nerdpack into bundles. nr1 nerdpack:clone Clones an open source Nerdpack from our GitHub repository. nr1 nerdpack:serve Serves your Nerdpack for testing and development purposes. nr1 nerdpack:uuid Shows or regenerates the UUID of a Nerdpack. nr1 nerdpack:publish Publishes your Nerdpack to New Relic. nr1 nerdpack:deploy Deploys a Nerdpack version to a specific channel. nr1 nerdpack:undeploy Undeploys a Nerdpack version from a specific channel. nr1 nerdpack:clean Cleans your developtment folders. nr1 nerdpack:validate Validates the contents of your Nerdpack. nr1 nerdpack:info Shows the state of your Nerdpack in the New Relic's registry. Manage your Nerdpack subscriptions nr1 subscription:set Subscribes your account to a Nerdpack and channel. nr1 subscription:list Lists all the Nerdpacks your account is subscribed to. nr1 subscription:unset Unsubscribes your account from a Nerdpack. Install and manage plugins nr1 plugins:install Installs a plugin into the CLI. nr1 plugins:link Links a plugin into the CLI for development. nr1 plugins:update Updates your installed plugins. nr1 plugins:uninstall Removes a plugin from the CLI. Manage catalog information nr1 catalog:info Shows the Nerdpack info stored in the catalog. nr1 catalog:submit Gathers and submits the catalog info on the current folder.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.8377,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> One CLI reference",
        "sections": "<em>Installing</em> the <em>New</em> <em>Relic</em> One CLI",
        "info": "An overview of the CLI to help you build, deploy, and manage <em>New</em> <em>Relic</em> apps.",
        "tags": "<em>New</em> <em>Relic</em> One app",
        "body": "To build a <em>New</em> <em>Relic</em> One app, you must <em>install</em> the <em>New</em> <em>Relic</em> One CLI. The CLI helps you build, publish, and manage your <em>New</em> <em>Relic</em> app. We provide a variety of tools for building apps, including the <em>New</em> <em>Relic</em> One CLI (command line interface). This page explains how to use CLI commands to: Generate"
      },
      "id": "6091fa9864441feb412f36d4"
    },
    {
      "sections": [
        "Introduction to Plugin Central",
        "Important",
        "Limited access to legacy plugins",
        "Developers and SaaS providers",
        "Plugin Central directory",
        "View plugins in Plugin Central",
        "Get started with plugins",
        "Ratings",
        "Reviews",
        "Plugin feedback policy"
      ],
      "title": "Introduction to Plugin Central",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugins New Relic",
        "Get started"
      ],
      "external_id": "aa864c660f02e96be1c9cec897300ed96e5e33cb",
      "image": "https://docs.newrelic.com/static/916b76819340fbeb3becda03908ca2d2/c1b63/plugins-landing-page-prototype071720.png",
      "url": "https://docs.newrelic.com/docs/plugins/plugins-new-relic/get-started/introduction-plugin-central/",
      "published_at": "2021-05-03T06:36:07Z",
      "updated_at": "2021-03-16T11:02:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Developers and SaaS providers Plugin Central is where partners, third-party vendors, and users could publish plugin agents that collect selected data. This is also where you could install and view the plugin data on your Plugins dashboards as a set of summary metrics, charts, and tables. In most cases, the plugin's agent runs on the users' app server. SaaS or PaaS providers can also create plugin agents that run on their system and report metrics for customers who use New Relic to monitor their applications. For more information, see the specific plugin agent SDK documentation. Plugin Central directory Important Plugins in Plugin Central are not supported with accounts that host data in the EU region data center. The plugin agent collects, sends, and stores the metric data. Plugin Central provides a searchable directory for plugins that developers publish and make publicly available to users. From Plugin Central, you can select and download whatever plugins you want to use. After you install or configure a plugin, you can view the plugin's dashboard data securely from the plugins user interface in New Relic One. View plugins in Plugin Central To view information about available (published) plugins: Go to one.newrelic.com > More > Plugins. By default, available plugins appear in alphabetical order. From the Plugin Central directory in New Relic One, select any published plugin to view a description and install it. Depending on the selected plugin, installation and configuration instructions will vary. Refer to your plugin's documentation for specific details. After you install or configure a plugin, it automatically appears on your Plugins menu in New Relic One, where you can select and view it directly. You may need to wait a few minutes for data to appear. Get started with plugins Here are some tips for making the most of Plugin Central. Ratings Plugins listed in New Relic's Plugin Central include a 5-star rating system, ranging from 1 (lowest) to 5 (highest). This helps you make more informed choices when choosing among similar plugins. This also provides a way for you to share what you think of a plugin. You can rate as many plugins as you want. If you have not voted for a plugin, its current star rating (gold or gray) does not include an outline. You can have only one vote for a specific plugin, and you cannot delete your vote. However, you can change your rating level anytime. After you select the star level (1 to 5) to cast your vote, the stars change to gold with an outline at the rating level you selected. Reviews Plugin Central includes a simple review system to share what you think of a plugin and to provide tips for others about installation and usage. Existing reviews appear when you select an individual plugin's title or Get started link. You can write as many reviews for as many plugins as you want, following the feedback policy. You can also edit or delete your own reviews. When you write a review for a plugin, if you have not already rated the plugin, you must provide a rating. Subsequent reviews will use the rating you provided. You can change your rating at any time. Plugin administrators also reserve the right to delete reviews if necessary. For more information, see Plugin feedback policy. Plugin feedback policy Here are some types of reviews we welcome: Your experience using the plugin Suggestions for improvement Your thoughts or opinions about the plugin, even if you disagree with us or point out mistakes Constructive criticism Your review must not contain personal attacks, name calling, libel, defamation, hate speech, etc. And under no circumstances should you post anything that could be taken as threatening, harassing, bullying, obscene, pornographic, sexist, or racist. We reserve the right to moderate reviews to make sure the tone is civil and fair. We will delete a review or rating in these situations: Spam, such as off-topic or nonsense reviews Inappropriate reviews including profanity and links to offensive content Attacks, including personal attacks against the plugin author or other reviewers, as well as attacks against New Relic or other companies. This does not mean you can't disagree with us or with each other, just be polite about it. False reviews that contain misleading statements or claims Other; for example, reviews or ratings that appear to be gaming the system",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.554756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Plugin</em> Central",
        "sections": "Limited access to legacy <em>plugins</em>",
        "tags": "<em>Plugins</em> <em>New</em> <em>Relic</em>",
        "body": " for <em>plugins</em> that developers publish and make publicly available to users. From <em>Plugin</em> Central, you can select and download whatever <em>plugins</em> you want to use. After you <em>install</em> or configure a <em>plugin</em>, you can view the <em>plugin</em>&#x27;s dashboard data securely from the <em>plugins</em> user interface in <em>New</em> <em>Relic</em> One"
      },
      "id": "603e81b428ccbc63bdeba79e"
    }
  ],
  "/docs/prometheus-remote-write-integration": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "c43eafc49c9c82cbf8642897c868c9602cecc6b9",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-05-05T18:22:42Z",
      "updated_at": "2021-03-16T06:16:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Prometheus remote write integration Prometheus OpenMetrics for Kubernetes or Docker Benefits Use this if you currently have Prometheus servers and want an easy way to access your combined metrics from New Relic. It only takes one line of yaml in your Prometheus configuration. You'll be able to access your metrics through both New Relic and Prometheus. You don't need to make any additional adjustments for data to remain available in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Use this if you’re looking for an alternative or replacement to a Prometheus server that stores all your metrics directly in New Relic. You won’t have to manage any Prometheus servers yourself. You don't need local storage. Keep in mind You will still need to manage your Prometheus servers, although you should be able to reduce your storage retention, and there’ll be fewer query loads to the server. Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Recommendations Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more new relic accounts or sub-accounts to manage rate limits. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. The New Relic Telemetry Data Platform can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Learn about Grafana support options. Explore the range of other options available as part of the Telemetry Data Platform.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2081.6055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send <em>Prometheus</em> metric data to New Relic",
        "sections": "<em>Prometheus</em> OpenMetrics or <em>remote</em> <em>write</em> <em>integration</em>?",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "This page provides an overview of New Relic&#x27;s <em>Prometheus</em> <em>integration</em> options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. <em>Prometheus</em> OpenMetrics or <em>remote</em> <em>write</em> <em>integration</em>? We currently offer two"
      },
      "id": "603ea41964441f0d824e8874"
    },
    {
      "sections": [
        "Prometheus High Availability (HA)",
        "Tip",
        "External labels",
        "Prometheus Operator",
        "Standalone Prometheus"
      ],
      "title": "Prometheus High Availability (HA)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "3c0fddd6e878f30f8ba4c132f537b88cd47f2eba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure/prometheus-high-availability-ha/",
      "published_at": "2021-05-05T18:18:51Z",
      "updated_at": "2021-03-13T02:41:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are using our Prometheus remote write integration in a high-availability (HA) configuration, you need to make sure your Prometheus servers aren't sending multiple copies of the same metrics to New Relic. This document describes how you can configure your remote write integration so that New Relic does not keep duplicated metrics. Tip For information on standard Prometheus remote write integration without using a high-availability configuration, see Set up your Prometheus remote write integration. External labels New Relic requires two external labels to deduplicate data from replicas in a high-availability configuration: Label name Description Example value prometheus A label whose value identifies the name of a high-availability cluster or group of Prometheus servers. monitoring-cluster prometheus_replica A label whose value identifies the unique replica sending this data. replica-1 The remaining sections explain how labels work with Prometheus Operator and standalone Prometheus. Prometheus Operator These external labels are added by default if you use Prometheus Operator version 0.19.0 (or higher). This applies whether you use Prometheus Operator directly or via the helm chart. The operator sets the value of the prometheus label (the one identifying a cluster) as <prometheus deployment namespace>/<prometheus deployment name>. For example, if your namespace for the Prometheus deployment is monitoring and the name of the deployment is prometheus-cluster1, the value is monitoring/prometheus-cluster1. The operator sets the value of the prometheus_replica label as the name of the pod for each replica. This follows the format replica-<replica number>, where the number is the ordinal of that replica (for example, the first replica is named replica-1). Tip If you still see duplicate copies of replica data, make sure you do not have replicaExternalLabelName or prometheusExternalLabelName in your Prometheus spec or chart configuration because these overrides change the label name. Standalone Prometheus When deploying a Prometheus server directly, you need to add the external labels to the configuration file. Here are two different example configurations for replicas within the same high-availability cluster: Replica 1 (prometheus.yml) global: external_labels: prometheus: monitoring-cluster prometheus_replica: replica-1 Copy Replica 2 (prometheus.yml) global: external_labels: prometheus: monitoring-cluster prometheus_replica: replica-2 Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2060.4297,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Prometheus</em> High Availability (HA)",
        "sections": "<em>Prometheus</em> High Availability (HA)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "If you are using our <em>Prometheus</em> <em>remote</em> <em>write</em> <em>integration</em> in a high-availability (HA) configuration, you need to make sure your <em>Prometheus</em> servers aren&#x27;t sending multiple copies of the same metrics to New Relic. This document describes how you can configure your <em>remote</em> <em>write</em> <em>integration</em> so that New"
      },
      "id": "6044e621196a67b846960f6b"
    },
    {
      "image": "https://docs.newrelic.com/static/d2a9c929c7541b67b6fe4c87844fc01b/ae694/prometheus_grafana_dashboard.png",
      "url": "https://docs.newrelic.com/whats-new/2020/08/create-grafana-dashboards-prometheus-data-stored-new-relic/",
      "sections": [
        "Create Grafana dashboards with Prometheus data stored in New Relic",
        "Step 1: Get data flowing into New Relic with the Prometheus remote write integration",
        "Step 2: Configure your Grafana dashboards to use Prometheus data stored in New Relic"
      ],
      "published_at": "2021-05-04T17:14:55Z",
      "title": "Create Grafana dashboards with Prometheus data stored in New Relic",
      "updated_at": "2021-03-11T00:16:19Z",
      "type": "docs",
      "external_id": "da09ab47a2ac806ad3ed1fa67e3a02dd54394383",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "We’ve teamed up with Grafana Labs so you can use our Telemetry Data Platform as a data source for Prometheus metrics and see them in your existing dashboards, seamlessly tapping into the reliability, scale, and security provided by New Relic. Follow the steps below or use this more detailed walkthrough to send Prometheus data to New Relic, so that Grafana can populate your existing Prometheus-specific dashboards with that data. This process requires Prometheus version 2.15.0 or higher and Grafana version 6.7.0 or higher. You’ll also need to sign up for New Relic. Here's an example of how these Grafana dashboards with Prometheus data look in our new dark mode. Step 1: Get data flowing into New Relic with the Prometheus remote write integration Go to Instrument Everything – US or Instrument Everything – EU, then click the Prometheus tile. You can also go to the Prometheus remote write setup page to get your remote_write URL. For more information on how to set up the Prometheus remote write integration, check out our docs. Step 2: Configure your Grafana dashboards to use Prometheus data stored in New Relic For more information on how to configure New Relic as a Prometheus data source for Grafana, check out our docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2059.8188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create Grafana dashboards with <em>Prometheus</em> data stored in New Relic",
        "sections": "Step 1: Get data flowing into New Relic with the <em>Prometheus</em> <em>remote</em> <em>write</em> <em>integration</em>",
        "body": " these Grafana dashboards with <em>Prometheus</em> data look in our new dark mode. Step 1: Get data flowing into New Relic with the <em>Prometheus</em> <em>remote</em> <em>write</em> <em>integration</em> Go to Instrument Everything – US or Instrument Everything – EU, then click the <em>Prometheus</em> tile. You can also go to the <em>Prometheus</em> <em>remote</em> <em>write</em>"
      },
      "id": "60445821e7b9d23b585799e4"
    }
  ],
  "/docs/python-agent-api-different-call-forms": [
    {
      "sections": [
        "APM agent data security",
        "Disclosure and audit",
        "Data collection",
        "Security settings",
        "Default security settings",
        "High security mode",
        "Custom security settings",
        "Data received by New Relic",
        "Important",
        "TLS and SSL",
        "Data transmission",
        "Proxies"
      ],
      "title": "APM agent data security",
      "type": "docs",
      "tags": [
        "APM",
        "New Relic APM",
        "Getting started"
      ],
      "external_id": "13a81c4a9a04e42bd4493768be3bfc42f769e1e5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/new-relic-apm/getting-started/apm-agent-data-security/",
      "published_at": "2021-05-05T01:45:09Z",
      "updated_at": "2021-05-05T01:45:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The APM agent that you installed receives data from your applications. The default data retention is based on your pricing edition. New Relic's default security settings automatically work to ensure data privacy and to limit the kind of information New Relic receives. You can also change these settings. Disclosure and audit Our APM agent is a publicly accessible plugin for web applications. The agent does not do any dynamic code generation while communicating with your app, so using the agent will not introduce any code into your application without your knowledge. Most of our agents are open source, so you can see what our code does: C SDK Go .NET Node.js Python Ruby Data collection Using a JSON message format, data the agent receives from your app is posted once a minute to the New Relic user interface. The website returns a JSON response to the agent, indicating if the data was correctly received or if there was an error. New Relic collects the following aggregate metric data: Database activity External web service calls Controller and dispatch activity View activity Uncaught exceptions and counts Process memory and CPU usage This aggregate metric data summarizes calls to specific methods in your application: how many times each one was called and various response time statistics (average, minimum, maximum, and standard deviation). In New Relic, you will see the class and method names along with their aggregate numbers. New Relic optionally collects: Data collection Comments Uncaught errors New Relic captures the error as well as a runtime stack trace of the offending code. Transaction traces These are snapshots of a single transaction. As an option, the agent can also collect the query statements called within the transaction. The default collection uses obfuscation to hide any strings or numbers from the query. For transactions slower than a threshold you set, New Relic also collects data from SQL EXPLAIN. For database calls slower than a configured threshold, New Relic optionally collects runtime stack traces, which are helpful to pinpoint where in the code a database call is made. Custom parameters You can add custom parameters to your application code and record them with transaction traces to provide additional context while you are examining profiling information. Optional: For both errors and transaction traces, the HTTP request parameters can also be recorded. Security settings If you want to restrict the information that New Relic receives, you can enable high security mode. If high security mode or the default settings do not work for your business needs, you can apply custom settings. Default security settings Depending on the agent, the default settings provide security for request parameters, HTTPS usage, and SQL: C SDK default security settings Go default security settings Java default security settings .NET default security settings Node.js default security settings PHP default security settings Python default security settings Ruby default security settings High security mode When the agent is in high security mode, default settings are locked so that users cannot change them. In addition, high security mode applies restrictions to custom events, custom instrumentation, user attributes, exception messages, or message queue parameters, depending on the agent: C SDK: n/a Go high security mode settings Java high security mode settings .NET high security mode settings Node.js high security mode settings PHP high security mode settings Python high security mode settings Ruby high security mode settings Custom security settings If you want custom security settings, you can customize the configuration file, change custom attribute settings, or use the API, depending on your agent: C SDK custom security settings Go custom security settings Java custom security settings .NET custom security mode settings Node.js custom security settings PHP custom security settings Python custom security settings Ruby custom security settings Data received by New Relic This information applies to all APM agents no matter what security settings you have applied. Important Other data that New Relic receives is specific to the security settings for each agent. Data Captured? APM agent language version OS type and version System properties Average response time of transactions in your app URL hits Client IP address Not captured TLS and SSL Our preferred protocol for all domains is TLS 1.2. APM agents enable SSL by default. To verify which release includes SSL by default and to ensure that you have the most up-to-date version, refer to your agent's release notes: C SDK Go Java .NET Node.js PHP Python Ruby The configuration file also includes an optional flag (ssl) to enable or disable SSL using HTTPS. New Relic does not do host authentication with HTTPS, just communication encryption. Exception: You cannot disable SSL for the C SDK. The C SDK daemon can only connect with SSL. New Relic requires HTTPS for all traffic to APM and the REST API. This includes both inbound and outbound traffic. If your REST API call uses HTTP, or if you have disabled SSL in your configuration file, change your script or program to HTTPS. Data transmission Under Java, .NET and PHP, New Relic uses JSON to serialize data. The Ruby agent uses either Ruby marshaling or JSON serialization to send data to New Relic, depending on whether a native JSON encoder is available in under the Ruby version the agent is running on. For required changes when you want to create firewall rules to allow the agent to communicate, see Networks. For more information about security measures for your data in transit to New Relic or at rest in our storage, see Data encryption. Proxies Optional settings are available so that you can configure the agent to communicate through a proxy. To define proxy settings for host, port, domain, user, or password, refer to your agent's configuration file documentation: Agent Proxy settings C SDK -proxy at daemon startup Go transport Java Use proxy settings, including: proxy_host proxy_password proxy_port proxy_user .NET proxy element Node.js proxy PHP newrelic.daemon.proxy or the daemon's proxy setting Python proxy settings Ruby Use proxy settings, including: proxy_host proxy_port proxy_user proxy_pass",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.51326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>agent</em> data security",
        "sections": "APM <em>agent</em> data security",
        "body": " source, so you can see what our code does: C SDK Go .NET Node.js <em>Python</em> Ruby Data collection Using a JSON message format, data the <em>agent</em> receives from your app is posted once a minute to the New Relic user interface. The website returns a JSON response to the <em>agent</em>, indicating if the data"
      },
      "id": "6043ffe7196a67cdd1960f67"
    },
    {
      "sections": [
        "OneLogin SCIM/SSO application configuration",
        "Requirements",
        "Add SCIM/SSO application",
        "Set up authentication domain",
        "Configure SCIM/SSO application",
        "Step 1. Fill in the configuration form",
        "Step 2. Fill in the rules form",
        "A rule that only uses actions",
        "Step 3. Fill in the Parameters form",
        "Step 4. Fill in the provisioning form",
        "Tip",
        "Step 5. Save your changes",
        "Assign users",
        "What's next?"
      ],
      "title": "OneLogin SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "d298162c055490c99117f564c3ea9c2ea5dfd8d1",
      "image": "https://docs.newrelic.com/static/8f585557ea58f70d94a746e6439bf1ad/c1b63/onelogin_rules_conditions_actions.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/onelogin-scimsso-application-configuration/",
      "published_at": "2021-05-06T04:52:58Z",
      "updated_at": "2021-05-06T04:52:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides OneLogin-specific details on how to configure the New Relic OneLogin SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Add SCIM/SSO application Add the New Relic SCIM/SSO application to your OneLogin applications. Go to the OneLogin web site and sign in with an account that has administrator permissions. From the OneLogin home page, click on Administration. From the OneLogin Administration page, choose the Applications menu. From the OneLogin Applications page, click on Add App. In the search field on the OneLogin Find Applications page, enter \"New Relic by Organization\" and then click on the application when it shows in the search results. From the Add New Relic by Organization page, click on Save. Set up authentication domain In New Relic's authentication domain UI, set up a new domain with SCIM enabled. You will use values from this UI in later steps. Configure SCIM/SSO application Configuration for the New Relic SCIM/SSO application is split across several forms. This section describes the different forms that need to be configured. From the New Relic by organization application page, fill in the following forms: Step 1. Fill in the configuration form In the left pane, select Configuration and complete the following: Take the authentication domain ID and SCIM bearer token values from New Relic's authentication domain UI and input them into the appropriate app fields. Leave the API Connection disabled until all the configuration described in the following sections is completed. After completing all the configuration, enable the connection. Step 2. Fill in the rules form Configure the user groups to send to New Relic using rules. OneLogin provides this documentation which describes how to use rules to provision groups for users. Decide what type of groups to send along with your users to New Relic. If your organization is using Active Directory or LDAP, you might choose to use security groups to define your users capabilities at New Relic. Another reasonable group choice is OneLogin role. On the New Relic side, your user's groups define their capabilities. The groups that are sent with users will be mapped to New Relic capability groups. Note that at the moment, there is no way to delete a group from the OneLogin side. This is a known limitation from OneLogin. Removing or changing rules does not delete groups already sent to New Relic. If you wish to no longer use a group, removing all the users from the group will prevent it from being used at New Relic. A rule that only uses actions Here's an example rule configuration does not use any conditions. The conditions are left empty to avoid applying any filtering logic to the users. All users will be sent in this example. If you want to send only a subset of users, you need to specify conditions to select the subset. The actions describe where to retrieve the value for the group name and how to parse the value. In this example, we retrieve the group name from the OneLogin role field. The OneLogin role field only has a single value, but sometimes the source for the group name contains other fields besides group name. In other words, some sources give you a list of fields and values and only one of those fields has the value you want to use. In this case, you can insert a regular expression in with value that matches field to find and extract the value for the group name. This example uses the entire value of the For each field for the group name. Step 3. Fill in the Parameters form In the left pane, select Parameters and complete the following: Click Groups field. Check Include in User Provisioning. Click Save. Step 4. Fill in the provisioning form In the left pane, select Provisioning and complete the following: Check Enable provisioning. Under Require admin approval before this action is performed, uncheck these options: Create user Delete user Update user Tip If you do not uncheck these options, SCIM provisioning requests will not be sent until an administrator approves them. Set When users are deleted in OneLogin, or the user's app access is removed, perform the below action to Delete. Set When user accounts are suspended in OneLogin, perform the following action to Suspend. Step 5. Save your changes After you complete the above forms, click Save. Then, return to the Configuration form and enable the API connection. Assign users After New Relic SCIM/SSO application configuration is finished and New Relic side configuration is finished, you can begin to assign users to the application. Assign the New Relic SCIM/SSO application to a user. Go to the OneLogin web site and sign in with an account that has administrator permissions. From the OneLogin home page, click Administration. From the OneLogin Administration page, choose the Users menu Users item. From the OneLogin Users page, click the user you want to assign the application to. From the user's page, click Applications. From the user's application page, click the plus sign and select the \"New Relic by Organization\" application. From the Edit New Relic by Organization login for user page, enter the user's time zone in IANA Time Zone database format (also known as the Olson time zone database format) and click Save. If you're using Roles to define your New Relic capability groups, from the user's application page, click the proper role(s) for the user and then click Save User. OneLogin provisions users in near real time so almost the moment you save the user in OneLogin, the user should be ready to use at New Relic. What's next? When you're done importing users, here are some potential next steps: Users created via your identity provider start out as full users. If your organization is on New Relic One pricing, these users are billable. To convert users to free basic users, use the User management UI. After adding users, you'll want to grant them access to specific New Relic accounts, specific groups, and specific roles. To learn how to do this, see Manage users.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.15659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 1. Fill in the configuration <em>form</em>",
        "body": " the <em>different</em> <em>forms</em> that need to be configured. From the New Relic by organization application page, fill in the following <em>forms</em>: Step 1. Fill in the configuration <em>form</em> In the left pane, select Configuration and complete the following: Take the authentication domain ID and SCIM bearer token values"
      },
      "id": "6043f34228ccbccafb2c606a"
    },
    {
      "sections": [
        "Instrument your own functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "title": "Instrument your own functions",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "published_at": "2021-05-05T14:58:54Z",
      "updated_at": "2021-05-05T14:58:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node and Python functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS and Python. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go, Java, and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python and NodeJS, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.15483,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For <em>Python</em> and NodeJS, we also include: The New Relic <em>Agent</em> The AWS SDK instrumentation package for the New Relic <em>Agent</em> A handler wrapper, which"
      },
      "id": "605aa8a064441f453b868bb9"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards": [
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "See your dashboards across all New Relic",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-04T18:29:22Z",
      "updated_at": "2021-03-30T02:06:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. Chart all the events and attributes from everywhere across our platform. For more information, see our documentation on default data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. See your dashboards across all New Relic New Relic One dashboards have full backwards compatibility with the original New Relic platform, so any dashboard you have created in Insights will be automatically available in dashboards from day one. Reciprocally, when you add a new dashboard, it is also created in Insights. No further action is needed. With New Relic One you can also view dashboards across your organization using cross-account search. Tip Switching to New Relic One from Insights? See our transition guide. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.01562,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>dashboards</em>",
        "sections": "See <em>your</em> <em>dashboards</em> across all New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " and understand the <em>data</em> you collect. <em>Explore</em> <em>your</em> <em>data</em> and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of <em>your</em> system and applications for faster, more efficient troubleshooting. Use <em>dashboards</em> to: Drive insight with custom, high-density interactive"
      },
      "id": "603ec16028ccbc8d07eba78d"
    },
    {
      "sections": [
        "Explore the Public API Performance dashboard",
        "Important",
        "Add the dashboard in New Relic",
        "Explore the dashboard",
        "More about dashboards and data"
      ],
      "title": "Explore the Public API Performance dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "71646dd30d63a0c7e343f4d81061bbb27eceeb86",
      "image": "https://docs.newrelic.com/static/2c9a2621107e0114a2c345fcbb22356f/8c557/Public-API-Performance-Dash-for-GPD.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/explore-public-api-performance-dashboard/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-03-16T04:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Public API Performance dashboard is a dashboard supported by New Relic’s Global Performance data sets. It’s an out-of-the-box dashboard included as part of your New Relic account. It provides both actionable general insights about the performance of public APIs and an opportunity for new customers to test-drive New Relic’s dashboarding capabilities before adding their own data. The dashboard works by showing real latencies experienced by an anonymized sampling of New Relic customers when accessing popular public APIs. Important Global Performance data sets are presented as-is. Global Performance data sets represent an aggregate of samples across a range of sources, and New Relic makes no effort to attempt to confirm the correctness, completeness, or veracity of the data. This data should not be relied on as the sole source of information for any purpose you may use it, and New Relic is not responsible for decisions made in reliance on this data. Global Performance data sets should not be viewed as either an endorsement or a recommendation by New Relic of the technologies represented in the data sets. Add the dashboard in New Relic If the Public API Performance dashboard isn't already visible in your UI, you can add it easily. Enable the dashboard from https://one.newrelic.com/: New customers: The dashboard is enabled by default and added to the favorites list for all new accounts. Existing customers: If the dashboard hasn't already been enabled, you can add it by clicking your avatar and selecting Add your data. Click the Public API Performance tile to open the account selector, then click Add and view pre-built dashboard On the Public API Performance dashboard page, start exploring! Click the ... at the corner of any pane to expand charts, view queries, and more. Public API Performance dashboard Explore the dashboard Below are some suggestions for how to explore the Public API Performance dashboard. Click … in the corner of any of the charts and select View query to view the NRQL query used to create the chart. Click … in the corner of any of the charts and select Get as image to view or download any chart as an image. Select specific domains from the bar chart or add a filter by clicking the text field along the at the top of the page. If you’ve already added your own data, experiment with copying queries and modifying them for your own use. Important The Public API Performance dashboard is not currently available to EU customers. Important The Public API Performance dashboard does not currently support alerts. More about dashboards and data For more information about the Global Performance data sets that power the Public Performance API dashboard, see New Relic Global Performance data sets. For more information about New Relic dashboards, see our dashboards introduction. Customers can also dive into this data set in greater depth using our new data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.50076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Explore</em> the Public API Performance <em>dashboard</em>",
        "sections": "More about <em>dashboards</em> <em>and</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "The Public API Performance <em>dashboard</em> is a <em>dashboard</em> supported by New Relic’s Global Performance <em>data</em> sets. It’s an out-of-the-box <em>dashboard</em> included as part of <em>your</em> New Relic account. It provides both actionable general insights about the performance of public APIs and an opportunity for new"
      },
      "id": "603e97fa28ccbc013ceba7c1"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/129e7a553450c47847a969c79a2f7f89/c1b63/Dashboards_conf.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-05-04T18:45:04Z",
      "updated_at": "2021-03-16T02:53:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's guid, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Add a new page. Pages allow you to better organize your dashboards. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Access the query builder to see or edit the query associated to the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.47098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> <em>dashboard</em>",
        "sections": "Organize <em>your</em> <em>dashboards</em> with pages",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One <em>dashboards</em> to create or manage <em>your</em> charts directly from the chart menu, customize <em>your</em> <em>dashboard</em>&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> <em>dashboard</em> and built <em>your</em> charts, use our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/explore-public-api-performance-dashboard": [
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "See your dashboards across all New Relic",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-04T18:29:22Z",
      "updated_at": "2021-03-30T02:06:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. Chart all the events and attributes from everywhere across our platform. For more information, see our documentation on default data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. See your dashboards across all New Relic New Relic One dashboards have full backwards compatibility with the original New Relic platform, so any dashboard you have created in Insights will be automatically available in dashboards from day one. Reciprocally, when you add a new dashboard, it is also created in Insights. No further action is needed. With New Relic One you can also view dashboards across your organization using cross-account search. Tip Switching to New Relic One from Insights? See our transition guide. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.01562,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>dashboards</em>",
        "sections": "See <em>your</em> <em>dashboards</em> across all New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " and understand the <em>data</em> you collect. <em>Explore</em> <em>your</em> <em>data</em> and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of <em>your</em> system and applications for faster, more efficient troubleshooting. Use <em>dashboards</em> to: Drive insight with custom, high-density interactive"
      },
      "id": "603ec16028ccbc8d07eba78d"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-05-04T18:29:23Z",
      "updated_at": "2021-03-16T11:03:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click delete. Editing: If your visualization needs some tweaking, delete the visualization, then follow the steps above to re-add the visualization, making any updates in Custom Visualizations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.65067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "sections": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a <em>dashboard</em>. This gives you great flexibility around what you display on <em>dashboards</em>, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/129e7a553450c47847a969c79a2f7f89/c1b63/Dashboards_conf.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-05-04T18:45:04Z",
      "updated_at": "2021-03-16T02:53:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's guid, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Add a new page. Pages allow you to better organize your dashboards. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Access the query builder to see or edit the query associated to the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.47098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> <em>dashboard</em>",
        "sections": "Organize <em>your</em> <em>dashboards</em> with pages",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One <em>dashboards</em> to create or manage <em>your</em> charts directly from the chart menu, customize <em>your</em> <em>dashboard</em>&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> <em>dashboard</em> and built <em>your</em> charts, use our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets": [
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "See your dashboards across all New Relic",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-04T18:29:22Z",
      "updated_at": "2021-03-30T02:06:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. Chart all the events and attributes from everywhere across our platform. For more information, see our documentation on default data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. See your dashboards across all New Relic New Relic One dashboards have full backwards compatibility with the original New Relic platform, so any dashboard you have created in Insights will be automatically available in dashboards from day one. Reciprocally, when you add a new dashboard, it is also created in Insights. No further action is needed. With New Relic One you can also view dashboards across your organization using cross-account search. Tip Switching to New Relic One from Insights? See our transition guide. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.01562,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>dashboards</em>",
        "sections": "See <em>your</em> <em>dashboards</em> across all New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " and understand the <em>data</em> you collect. <em>Explore</em> <em>your</em> <em>data</em> and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of <em>your</em> system and applications for faster, more efficient troubleshooting. Use <em>dashboards</em> to: Drive insight with custom, high-density interactive"
      },
      "id": "603ec16028ccbc8d07eba78d"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-05-04T18:29:23Z",
      "updated_at": "2021-03-16T11:03:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click delete. Editing: If your visualization needs some tweaking, delete the visualization, then follow the steps above to re-add the visualization, making any updates in Custom Visualizations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.65067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "sections": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a <em>dashboard</em>. This gives you great flexibility around what you display on <em>dashboards</em>, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "Explore the Public API Performance dashboard",
        "Important",
        "Add the dashboard in New Relic",
        "Explore the dashboard",
        "More about dashboards and data"
      ],
      "title": "Explore the Public API Performance dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "71646dd30d63a0c7e343f4d81061bbb27eceeb86",
      "image": "https://docs.newrelic.com/static/2c9a2621107e0114a2c345fcbb22356f/8c557/Public-API-Performance-Dash-for-GPD.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/explore-public-api-performance-dashboard/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-03-16T04:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Public API Performance dashboard is a dashboard supported by New Relic’s Global Performance data sets. It’s an out-of-the-box dashboard included as part of your New Relic account. It provides both actionable general insights about the performance of public APIs and an opportunity for new customers to test-drive New Relic’s dashboarding capabilities before adding their own data. The dashboard works by showing real latencies experienced by an anonymized sampling of New Relic customers when accessing popular public APIs. Important Global Performance data sets are presented as-is. Global Performance data sets represent an aggregate of samples across a range of sources, and New Relic makes no effort to attempt to confirm the correctness, completeness, or veracity of the data. This data should not be relied on as the sole source of information for any purpose you may use it, and New Relic is not responsible for decisions made in reliance on this data. Global Performance data sets should not be viewed as either an endorsement or a recommendation by New Relic of the technologies represented in the data sets. Add the dashboard in New Relic If the Public API Performance dashboard isn't already visible in your UI, you can add it easily. Enable the dashboard from https://one.newrelic.com/: New customers: The dashboard is enabled by default and added to the favorites list for all new accounts. Existing customers: If the dashboard hasn't already been enabled, you can add it by clicking your avatar and selecting Add your data. Click the Public API Performance tile to open the account selector, then click Add and view pre-built dashboard On the Public API Performance dashboard page, start exploring! Click the ... at the corner of any pane to expand charts, view queries, and more. Public API Performance dashboard Explore the dashboard Below are some suggestions for how to explore the Public API Performance dashboard. Click … in the corner of any of the charts and select View query to view the NRQL query used to create the chart. Click … in the corner of any of the charts and select Get as image to view or download any chart as an image. Select specific domains from the bar chart or add a filter by clicking the text field along the at the top of the page. If you’ve already added your own data, experiment with copying queries and modifying them for your own use. Important The Public API Performance dashboard is not currently available to EU customers. Important The Public API Performance dashboard does not currently support alerts. More about dashboards and data For more information about the Global Performance data sets that power the Public Performance API dashboard, see New Relic Global Performance data sets. For more information about New Relic dashboards, see our dashboards introduction. Customers can also dive into this data set in greater depth using our new data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.50075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Explore</em> the Public API Performance <em>dashboard</em>",
        "sections": "More about <em>dashboards</em> <em>and</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "The Public API Performance <em>dashboard</em> is a <em>dashboard</em> supported by New Relic’s Global Performance <em>data</em> sets. It’s an out-of-the-box <em>dashboard</em> included as part of <em>your</em> New Relic account. It provides both actionable general insights about the performance of public APIs and an opportunity for new"
      },
      "id": "603e97fa28ccbc013ceba7c1"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards": [
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-05-04T18:29:23Z",
      "updated_at": "2021-03-16T11:03:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click delete. Editing: If your visualization needs some tweaking, delete the visualization, then follow the steps above to re-add the visualization, making any updates in Custom Visualizations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.65065,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "sections": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a <em>dashboard</em>. This gives you great flexibility around what you display on <em>dashboards</em>, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "Explore the Public API Performance dashboard",
        "Important",
        "Add the dashboard in New Relic",
        "Explore the dashboard",
        "More about dashboards and data"
      ],
      "title": "Explore the Public API Performance dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "71646dd30d63a0c7e343f4d81061bbb27eceeb86",
      "image": "https://docs.newrelic.com/static/2c9a2621107e0114a2c345fcbb22356f/8c557/Public-API-Performance-Dash-for-GPD.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/explore-public-api-performance-dashboard/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-03-16T04:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Public API Performance dashboard is a dashboard supported by New Relic’s Global Performance data sets. It’s an out-of-the-box dashboard included as part of your New Relic account. It provides both actionable general insights about the performance of public APIs and an opportunity for new customers to test-drive New Relic’s dashboarding capabilities before adding their own data. The dashboard works by showing real latencies experienced by an anonymized sampling of New Relic customers when accessing popular public APIs. Important Global Performance data sets are presented as-is. Global Performance data sets represent an aggregate of samples across a range of sources, and New Relic makes no effort to attempt to confirm the correctness, completeness, or veracity of the data. This data should not be relied on as the sole source of information for any purpose you may use it, and New Relic is not responsible for decisions made in reliance on this data. Global Performance data sets should not be viewed as either an endorsement or a recommendation by New Relic of the technologies represented in the data sets. Add the dashboard in New Relic If the Public API Performance dashboard isn't already visible in your UI, you can add it easily. Enable the dashboard from https://one.newrelic.com/: New customers: The dashboard is enabled by default and added to the favorites list for all new accounts. Existing customers: If the dashboard hasn't already been enabled, you can add it by clicking your avatar and selecting Add your data. Click the Public API Performance tile to open the account selector, then click Add and view pre-built dashboard On the Public API Performance dashboard page, start exploring! Click the ... at the corner of any pane to expand charts, view queries, and more. Public API Performance dashboard Explore the dashboard Below are some suggestions for how to explore the Public API Performance dashboard. Click … in the corner of any of the charts and select View query to view the NRQL query used to create the chart. Click … in the corner of any of the charts and select Get as image to view or download any chart as an image. Select specific domains from the bar chart or add a filter by clicking the text field along the at the top of the page. If you’ve already added your own data, experiment with copying queries and modifying them for your own use. Important The Public API Performance dashboard is not currently available to EU customers. Important The Public API Performance dashboard does not currently support alerts. More about dashboards and data For more information about the Global Performance data sets that power the Public Performance API dashboard, see New Relic Global Performance data sets. For more information about New Relic dashboards, see our dashboards introduction. Customers can also dive into this data set in greater depth using our new data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.50075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Explore</em> the Public API Performance <em>dashboard</em>",
        "sections": "More about <em>dashboards</em> <em>and</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "The Public API Performance <em>dashboard</em> is a <em>dashboard</em> supported by New Relic’s Global Performance <em>data</em> sets. It’s an out-of-the-box <em>dashboard</em> included as part of <em>your</em> New Relic account. It provides both actionable general insights about the performance of public APIs and an opportunity for new"
      },
      "id": "603e97fa28ccbc013ceba7c1"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/129e7a553450c47847a969c79a2f7f89/c1b63/Dashboards_conf.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-05-04T18:45:04Z",
      "updated_at": "2021-03-16T02:53:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's guid, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Add a new page. Pages allow you to better organize your dashboards. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Access the query builder to see or edit the query associated to the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.47098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> <em>dashboard</em>",
        "sections": "Organize <em>your</em> <em>dashboards</em> with pages",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One <em>dashboards</em> to create or manage <em>your</em> charts directly from the chart menu, customize <em>your</em> <em>dashboard</em>&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> <em>dashboard</em> and built <em>your</em> charts, use our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard": [
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "See your dashboards across all New Relic",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-04T18:29:22Z",
      "updated_at": "2021-03-30T02:06:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. Chart all the events and attributes from everywhere across our platform. For more information, see our documentation on default data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. See your dashboards across all New Relic New Relic One dashboards have full backwards compatibility with the original New Relic platform, so any dashboard you have created in Insights will be automatically available in dashboards from day one. Reciprocally, when you add a new dashboard, it is also created in Insights. No further action is needed. With New Relic One you can also view dashboards across your organization using cross-account search. Tip Switching to New Relic One from Insights? See our transition guide. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.01561,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>dashboards</em>",
        "sections": "See <em>your</em> <em>dashboards</em> across all New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " and understand the <em>data</em> you collect. <em>Explore</em> <em>your</em> <em>data</em> and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of <em>your</em> system and applications for faster, more efficient troubleshooting. Use <em>dashboards</em> to: Drive insight with custom, high-density interactive"
      },
      "id": "603ec16028ccbc8d07eba78d"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-05-04T18:29:23Z",
      "updated_at": "2021-03-16T11:03:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click delete. Editing: If your visualization needs some tweaking, delete the visualization, then follow the steps above to re-add the visualization, making any updates in Custom Visualizations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.65065,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "sections": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a <em>dashboard</em>. This gives you great flexibility around what you display on <em>dashboards</em>, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "Explore the Public API Performance dashboard",
        "Important",
        "Add the dashboard in New Relic",
        "Explore the dashboard",
        "More about dashboards and data"
      ],
      "title": "Explore the Public API Performance dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "71646dd30d63a0c7e343f4d81061bbb27eceeb86",
      "image": "https://docs.newrelic.com/static/2c9a2621107e0114a2c345fcbb22356f/8c557/Public-API-Performance-Dash-for-GPD.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/explore-public-api-performance-dashboard/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-03-16T04:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Public API Performance dashboard is a dashboard supported by New Relic’s Global Performance data sets. It’s an out-of-the-box dashboard included as part of your New Relic account. It provides both actionable general insights about the performance of public APIs and an opportunity for new customers to test-drive New Relic’s dashboarding capabilities before adding their own data. The dashboard works by showing real latencies experienced by an anonymized sampling of New Relic customers when accessing popular public APIs. Important Global Performance data sets are presented as-is. Global Performance data sets represent an aggregate of samples across a range of sources, and New Relic makes no effort to attempt to confirm the correctness, completeness, or veracity of the data. This data should not be relied on as the sole source of information for any purpose you may use it, and New Relic is not responsible for decisions made in reliance on this data. Global Performance data sets should not be viewed as either an endorsement or a recommendation by New Relic of the technologies represented in the data sets. Add the dashboard in New Relic If the Public API Performance dashboard isn't already visible in your UI, you can add it easily. Enable the dashboard from https://one.newrelic.com/: New customers: The dashboard is enabled by default and added to the favorites list for all new accounts. Existing customers: If the dashboard hasn't already been enabled, you can add it by clicking your avatar and selecting Add your data. Click the Public API Performance tile to open the account selector, then click Add and view pre-built dashboard On the Public API Performance dashboard page, start exploring! Click the ... at the corner of any pane to expand charts, view queries, and more. Public API Performance dashboard Explore the dashboard Below are some suggestions for how to explore the Public API Performance dashboard. Click … in the corner of any of the charts and select View query to view the NRQL query used to create the chart. Click … in the corner of any of the charts and select Get as image to view or download any chart as an image. Select specific domains from the bar chart or add a filter by clicking the text field along the at the top of the page. If you’ve already added your own data, experiment with copying queries and modifying them for your own use. Important The Public API Performance dashboard is not currently available to EU customers. Important The Public API Performance dashboard does not currently support alerts. More about dashboards and data For more information about the Global Performance data sets that power the Public Performance API dashboard, see New Relic Global Performance data sets. For more information about New Relic dashboards, see our dashboards introduction. Customers can also dive into this data set in greater depth using our new data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.50075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Explore</em> the Public API Performance <em>dashboard</em>",
        "sections": "More about <em>dashboards</em> <em>and</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "The Public API Performance <em>dashboard</em> is a <em>dashboard</em> supported by New Relic’s Global Performance <em>data</em> sets. It’s an out-of-the-box <em>dashboard</em> included as part of <em>your</em> New Relic account. It provides both actionable general insights about the performance of public APIs and an opportunity for new"
      },
      "id": "603e97fa28ccbc013ceba7c1"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/new-relic-global-performance-data-sets": [
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "See your dashboards across all New Relic",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-04T18:29:22Z",
      "updated_at": "2021-03-30T02:06:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. Chart all the events and attributes from everywhere across our platform. For more information, see our documentation on default data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. See your dashboards across all New Relic New Relic One dashboards have full backwards compatibility with the original New Relic platform, so any dashboard you have created in Insights will be automatically available in dashboards from day one. Reciprocally, when you add a new dashboard, it is also created in Insights. No further action is needed. With New Relic One you can also view dashboards across your organization using cross-account search. Tip Switching to New Relic One from Insights? See our transition guide. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.0156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>dashboards</em>",
        "sections": "See <em>your</em> <em>dashboards</em> across all New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " and understand the <em>data</em> you collect. <em>Explore</em> <em>your</em> <em>data</em> and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of <em>your</em> system and applications for faster, more efficient troubleshooting. Use <em>dashboards</em> to: Drive insight with custom, high-density interactive"
      },
      "id": "603ec16028ccbc8d07eba78d"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-05-04T18:29:23Z",
      "updated_at": "2021-03-16T11:03:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click delete. Editing: If your visualization needs some tweaking, delete the visualization, then follow the steps above to re-add the visualization, making any updates in Custom Visualizations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.65065,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "sections": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a <em>dashboard</em>. This gives you great flexibility around what you display on <em>dashboards</em>, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "Explore the Public API Performance dashboard",
        "Important",
        "Add the dashboard in New Relic",
        "Explore the dashboard",
        "More about dashboards and data"
      ],
      "title": "Explore the Public API Performance dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "71646dd30d63a0c7e343f4d81061bbb27eceeb86",
      "image": "https://docs.newrelic.com/static/2c9a2621107e0114a2c345fcbb22356f/8c557/Public-API-Performance-Dash-for-GPD.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/explore-public-api-performance-dashboard/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-03-16T04:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Public API Performance dashboard is a dashboard supported by New Relic’s Global Performance data sets. It’s an out-of-the-box dashboard included as part of your New Relic account. It provides both actionable general insights about the performance of public APIs and an opportunity for new customers to test-drive New Relic’s dashboarding capabilities before adding their own data. The dashboard works by showing real latencies experienced by an anonymized sampling of New Relic customers when accessing popular public APIs. Important Global Performance data sets are presented as-is. Global Performance data sets represent an aggregate of samples across a range of sources, and New Relic makes no effort to attempt to confirm the correctness, completeness, or veracity of the data. This data should not be relied on as the sole source of information for any purpose you may use it, and New Relic is not responsible for decisions made in reliance on this data. Global Performance data sets should not be viewed as either an endorsement or a recommendation by New Relic of the technologies represented in the data sets. Add the dashboard in New Relic If the Public API Performance dashboard isn't already visible in your UI, you can add it easily. Enable the dashboard from https://one.newrelic.com/: New customers: The dashboard is enabled by default and added to the favorites list for all new accounts. Existing customers: If the dashboard hasn't already been enabled, you can add it by clicking your avatar and selecting Add your data. Click the Public API Performance tile to open the account selector, then click Add and view pre-built dashboard On the Public API Performance dashboard page, start exploring! Click the ... at the corner of any pane to expand charts, view queries, and more. Public API Performance dashboard Explore the dashboard Below are some suggestions for how to explore the Public API Performance dashboard. Click … in the corner of any of the charts and select View query to view the NRQL query used to create the chart. Click … in the corner of any of the charts and select Get as image to view or download any chart as an image. Select specific domains from the bar chart or add a filter by clicking the text field along the at the top of the page. If you’ve already added your own data, experiment with copying queries and modifying them for your own use. Important The Public API Performance dashboard is not currently available to EU customers. Important The Public API Performance dashboard does not currently support alerts. More about dashboards and data For more information about the Global Performance data sets that power the Public Performance API dashboard, see New Relic Global Performance data sets. For more information about New Relic dashboards, see our dashboards introduction. Customers can also dive into this data set in greater depth using our new data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.50073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Explore</em> the Public API Performance <em>dashboard</em>",
        "sections": "More about <em>dashboards</em> <em>and</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "The Public API Performance <em>dashboard</em> is a <em>dashboard</em> supported by New Relic’s Global Performance <em>data</em> sets. It’s an out-of-the-box <em>dashboard</em> included as part of <em>your</em> New Relic account. It provides both actionable general insights about the performance of public APIs and an opportunity for new"
      },
      "id": "603e97fa28ccbc013ceba7c1"
    }
  ],
  "/docs/query-your-data/explore-query-data/explore-data/introduction-data-explorer": [
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "See your dashboards across all New Relic",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-04T18:29:22Z",
      "updated_at": "2021-03-30T02:06:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. Chart all the events and attributes from everywhere across our platform. For more information, see our documentation on default data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. See your dashboards across all New Relic New Relic One dashboards have full backwards compatibility with the original New Relic platform, so any dashboard you have created in Insights will be automatically available in dashboards from day one. Reciprocally, when you add a new dashboard, it is also created in Insights. No further action is needed. With New Relic One you can also view dashboards across your organization using cross-account search. Tip Switching to New Relic One from Insights? See our transition guide. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.3636,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "See <em>your</em> dashboards across all New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " and understand the <em>data</em> you collect. <em>Explore</em> <em>your</em> <em>data</em> and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of <em>your</em> system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive"
      },
      "id": "603ec16028ccbc8d07eba78d"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-05-04T18:29:23Z",
      "updated_at": "2021-03-16T11:03:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click delete. Editing: If your visualization needs some tweaking, delete the visualization, then follow the steps above to re-add the visualization, making any updates in Custom Visualizations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.59604,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> dashboards",
        "sections": "Add custom visualizations to <em>your</em> dashboards",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "Explore the Public API Performance dashboard",
        "Important",
        "Add the dashboard in New Relic",
        "Explore the dashboard",
        "More about dashboards and data"
      ],
      "title": "Explore the Public API Performance dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "71646dd30d63a0c7e343f4d81061bbb27eceeb86",
      "image": "https://docs.newrelic.com/static/2c9a2621107e0114a2c345fcbb22356f/8c557/Public-API-Performance-Dash-for-GPD.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/explore-public-api-performance-dashboard/",
      "published_at": "2021-05-04T18:29:57Z",
      "updated_at": "2021-03-16T04:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Public API Performance dashboard is a dashboard supported by New Relic’s Global Performance data sets. It’s an out-of-the-box dashboard included as part of your New Relic account. It provides both actionable general insights about the performance of public APIs and an opportunity for new customers to test-drive New Relic’s dashboarding capabilities before adding their own data. The dashboard works by showing real latencies experienced by an anonymized sampling of New Relic customers when accessing popular public APIs. Important Global Performance data sets are presented as-is. Global Performance data sets represent an aggregate of samples across a range of sources, and New Relic makes no effort to attempt to confirm the correctness, completeness, or veracity of the data. This data should not be relied on as the sole source of information for any purpose you may use it, and New Relic is not responsible for decisions made in reliance on this data. Global Performance data sets should not be viewed as either an endorsement or a recommendation by New Relic of the technologies represented in the data sets. Add the dashboard in New Relic If the Public API Performance dashboard isn't already visible in your UI, you can add it easily. Enable the dashboard from https://one.newrelic.com/: New customers: The dashboard is enabled by default and added to the favorites list for all new accounts. Existing customers: If the dashboard hasn't already been enabled, you can add it by clicking your avatar and selecting Add your data. Click the Public API Performance tile to open the account selector, then click Add and view pre-built dashboard On the Public API Performance dashboard page, start exploring! Click the ... at the corner of any pane to expand charts, view queries, and more. Public API Performance dashboard Explore the dashboard Below are some suggestions for how to explore the Public API Performance dashboard. Click … in the corner of any of the charts and select View query to view the NRQL query used to create the chart. Click … in the corner of any of the charts and select Get as image to view or download any chart as an image. Select specific domains from the bar chart or add a filter by clicking the text field along the at the top of the page. If you’ve already added your own data, experiment with copying queries and modifying them for your own use. Important The Public API Performance dashboard is not currently available to EU customers. Important The Public API Performance dashboard does not currently support alerts. More about dashboards and data For more information about the Global Performance data sets that power the Public Performance API dashboard, see New Relic Global Performance data sets. For more information about New Relic dashboards, see our dashboards introduction. Customers can also dive into this data set in greater depth using our new data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.45569,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Explore</em> the Public API Performance dashboard",
        "sections": "<em>Explore</em> the Public API Performance dashboard",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "The Public API Performance dashboard is a dashboard supported by New Relic’s Global Performance <em>data</em> sets. It’s an out-of-the-box dashboard included as part of <em>your</em> New Relic account. It provides both actionable general insights about the performance of public APIs and an opportunity for new"
      },
      "id": "603e97fa28ccbc013ceba7c1"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/introduction-query-builder": [
    {
      "sections": [
        "Use advanced PromQL-style mode to query data",
        "Use the query builder in PromQL-style mode",
        "Tip",
        "PromQL-style and the query builder"
      ],
      "title": "Use advanced PromQL-style mode to query data",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "5df9e170e9b362362c674baddac1189ed281bbf0",
      "image": "https://docs.newrelic.com/static/e1280f23afa0475b4025564d56027f13/c1b63/PromQL-after.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/use-advanced-promql-style-mode-query-data/",
      "published_at": "2021-05-05T01:39:14Z",
      "updated_at": "2021-03-16T02:54:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the query builder you can run queries of your data to create custom charts and other visualizations. The query builder comes with three working modes: basic query-less mode, advanced (NRQL) mode, and advanced PromQL-style mode, which takes PromQL queries as an input for accessing metrics and building charts. Use the query builder in PromQL-style mode You can access the query builder advanced PromQL-style mode by going to one.newrelic.com and clicking on Query your data at the top right corner. Go to the query builder tab on the left, then click PromQL-style on the right. Tip We support the Prometheus query language (PromQL) through our PromQL-style query mode. We do our best to automatically translate PromQL syntax queries into the closest NRQL approximation. For more information on how this works and differences you may observe between Prometheus and New Relic, see Supported PromQL features. Go to one.newrelic.com, press CTRL+E to open our Query Builder, then click PromQL-style to write a PromQL-style query. Build your PromQL-style query with the following parameters: Account: Select the account you want to query. PromQL-style prompt: Write you query here. You can view the list of valid options of the metrics and functions in the account. Step and range: Select the step and range for the query, or click on instant. Run the query to obtain the chart with the results. You can name the chart, change the type of chart, or add it to a dashboard. Tip Click NRQL to see how your PromQL-style query is translated into NRQL. PromQL-style and the query builder The query builder in advanced PromQL-style mode translates your PromQL query to NRQL before running the query. The results may be different from how Prometheus executes the query. If you would like to learn more about New Relic's PromQL-style query language and how it behaves, including troubleshooting information for translated queries, see Supported PromQL features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.15329,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use advanced PromQL-style mode to <em>query</em> <em>data</em>",
        "sections": "PromQL-style <em>and</em> the <em>query</em> <em>builder</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "With the <em>query</em> <em>builder</em> you can run queries of <em>your</em> <em>data</em> to create custom charts and other visualizations. The <em>query</em> <em>builder</em> comes with three working modes: basic <em>query</em>-less mode, advanced (NRQL) mode, and advanced PromQL-style mode, which takes PromQL queries as an input for accessing metrics"
      },
      "id": "603e821e196a67a042a83df6"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/129e7a553450c47847a969c79a2f7f89/c1b63/Dashboards_conf.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-05-04T18:45:04Z",
      "updated_at": "2021-03-16T02:53:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's guid, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Add a new page. Pages allow you to better organize your dashboards. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Access the query builder to see or edit the query associated to the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.6548,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> <em>builder</em> features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard page or in the edit mode) to access the <em>query</em> <em>builder</em>, or to add"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Query builder: Basic mode",
        "Data type",
        "Example of using basic mode",
        "Step 1: Select the source of the data for a chart",
        "Step 2: Filter the data",
        "Step 3: Adjust time range and limits",
        "Step 4: Customize the chart",
        "Important"
      ],
      "title": "Query builder: Basic mode",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "7f076b3909c9462829453bc59f0dae0f5d5501fd",
      "image": "https://docs.newrelic.com/static/6be4a8d2af5e02259c01e180d7f43326/58213/crop-basic-example-chart_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/query-builder-basic-mode/",
      "published_at": "2021-05-06T06:52:10Z",
      "updated_at": "2021-03-16T02:54:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the New Relic One query builder in basic mode to create a chart without having to use NRQL, our querying language. The basic mode helps guides you through a query-creation process. You can choose the source of the raw data, apply filters, and use other techniques to narrow the scope of the data in the chart. Data type The query builder basic mode has a Data type selector with two options: Events: In this context, this refers to all our non-Metric-type data, including events, logs, and trace data. Metrics: This refers to our dimensional Metric data type. You can also use this to query some types of metric timeslice data. For more on other types of metrics, see Data types. Example of using basic mode This example shows how to create a chart in basic mode. Step 1: Select the source of the data for a chart Begin by specifying what data you want to view in your chart. Click in the View a chart with box to select the event type, an attribute, and a function to perform on the attribute. You can use the event data dictionary to view information about an event type and its attributes on a single page. To see a tooltip with information about an event or attribute, hover over any term that has a dotted line underneath it. Here are the results of using the event data dictionary to specify the data: Event type. The Transaction event type measures a variety of data that describes what happens while a user is on a website, such as that user clicking on a button on a page. Attribute. The name attribute stores information on all transactions. Function. Select the unique_count function to get a count of all the transactions that occurred during the time frame. Basic mode now shows the selection: one.newrelic.com > Query builder > Basic > (event and attribute specified) As you specify data, the chart updates to show you the results from the data you specified. Based on the information specified so far, you can see a chart that shows the total number of transactions during the default time frame of 30 minutes. This total includes all transactions, whether the transaction was completed successfully or had errors. one.newrelic.com > Query builder > Basic > (event and attribute specified) Step 2: Filter the data Your next step is to determine which of those transactions got a 404 page not found error. If you look in the event data dictionary for the Transaction event type, you'll find this event also includes an attribute called httpResponseCode. Narrow the results to show only those transactions where a page not found error occurred. Use the Narrow results to box to create this filter: httpResponseCode = 404 . Because you want to be able to see the names of the apps that are resulting in the 404 errors, you use the Facet by box to see the results by appName (which is also an attribute for the Transaction event type). Faceting by appName updates the chart to break down the total number of 404 errors by the application names. This lets you know which apps are experiencing 404 errors. Your chart now shows the line chart with a line for each app, each with its own color. one.newrelic.com > Query builder > Basic > (event and attribute specified) > (filters and facets applied) Step 3: Adjust time range and limits You decide to focus on the five apps with the most page not found errors. The default value for the Limit field is 10, meaning that your chart will show the ten most relevant returns. You change that value to 5. Customer support told you that they had been getting calls about these errors for a little over two hours. You decide to change the time range from the last 30 minutes to the last three hours so that you can view the errors during the time when the customers were calling support. Now that you have the data set so that you are seeing exactly what you need, you can turn your attention to the appearance of the chart. Step 4: Customize the chart Because you are more interested in the total number of errors than a timeline view, you change the chart type to a bar chart. one.newrelic.com > Query builder > Basic > (event and attribute specified) > (filters and facets applied) > (time range and limit customized) > (chart type customized) When you're finished with your chart, you can add it to a dashboard or share it. This table contains notes about using basic mode. Item Description Prompts You can start typing directly in an empty box; a list of items that match the information you type will display. You can also click on an empty box to view a list of all of the items that are appropriate for the field, based on your earlier choices. Saving a basic mode data specification Every time you run a query, that query is saved in the My recent queries dropdown in advanced (NRQL) mode. Events Basic mode only supports data for one event and attribute. If you want to use more than one event and/or attribute, use the SELECT statement in advanced (NRQL) mode. Shortcuts Basic mode contains shortcuts that can display more complex events and attributes that aren't generally supported, as in this example (which shows the tooltip for the shortcut). Example of the Response time histogram shortcut, showing a tooltip. Tooltips Any time you see a dotted line under a term, you can hover over that term to see a tooltip with an explanation of the term. Narrow by You can use more than one Narrow by definition in basic mode filter; the conditions will be joined by AND. The WHERE clause in advanced (NRQL) allows OR in addition to AND. Important If your query was started using basic mode and if you make changes to that query using advanced (NRQL) mode, you cannot return to basic mode to edit that query. Any additional changes may only be made in advanced (NRQL) mode.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.92169,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> <em>builder</em>: Basic mode",
        "sections": "<em>Query</em> <em>builder</em>: Basic mode",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " was completed successfully or had errors. one.newrelic.com &gt; <em>Query</em> <em>builder</em> &gt; Basic &gt; (event and attribute specified) Step 2: Filter the <em>data</em> <em>Your</em> next step is to determine which of those transactions got a 404 page not found error. If you look in the event <em>data</em> dictionary for the Transaction event type"
      },
      "id": "603ec319e7b9d2008c2a07e0"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/query-builder-basic-mode": [
    {
      "sections": [
        "Use advanced PromQL-style mode to query data",
        "Use the query builder in PromQL-style mode",
        "Tip",
        "PromQL-style and the query builder"
      ],
      "title": "Use advanced PromQL-style mode to query data",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "5df9e170e9b362362c674baddac1189ed281bbf0",
      "image": "https://docs.newrelic.com/static/e1280f23afa0475b4025564d56027f13/c1b63/PromQL-after.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/use-advanced-promql-style-mode-query-data/",
      "published_at": "2021-05-05T01:39:14Z",
      "updated_at": "2021-03-16T02:54:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the query builder you can run queries of your data to create custom charts and other visualizations. The query builder comes with three working modes: basic query-less mode, advanced (NRQL) mode, and advanced PromQL-style mode, which takes PromQL queries as an input for accessing metrics and building charts. Use the query builder in PromQL-style mode You can access the query builder advanced PromQL-style mode by going to one.newrelic.com and clicking on Query your data at the top right corner. Go to the query builder tab on the left, then click PromQL-style on the right. Tip We support the Prometheus query language (PromQL) through our PromQL-style query mode. We do our best to automatically translate PromQL syntax queries into the closest NRQL approximation. For more information on how this works and differences you may observe between Prometheus and New Relic, see Supported PromQL features. Go to one.newrelic.com, press CTRL+E to open our Query Builder, then click PromQL-style to write a PromQL-style query. Build your PromQL-style query with the following parameters: Account: Select the account you want to query. PromQL-style prompt: Write you query here. You can view the list of valid options of the metrics and functions in the account. Step and range: Select the step and range for the query, or click on instant. Run the query to obtain the chart with the results. You can name the chart, change the type of chart, or add it to a dashboard. Tip Click NRQL to see how your PromQL-style query is translated into NRQL. PromQL-style and the query builder The query builder in advanced PromQL-style mode translates your PromQL query to NRQL before running the query. The results may be different from how Prometheus executes the query. If you would like to learn more about New Relic's PromQL-style query language and how it behaves, including troubleshooting information for translated queries, see Supported PromQL features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.15327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use advanced PromQL-style mode to <em>query</em> <em>data</em>",
        "sections": "PromQL-style <em>and</em> the <em>query</em> <em>builder</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "With the <em>query</em> <em>builder</em> you can run queries of <em>your</em> <em>data</em> to create custom charts and other visualizations. The <em>query</em> <em>builder</em> comes with three working modes: basic <em>query</em>-less mode, advanced (NRQL) mode, and advanced PromQL-style mode, which takes PromQL queries as an input for accessing metrics"
      },
      "id": "603e821e196a67a042a83df6"
    },
    {
      "sections": [
        "Introduction to the query builder",
        "Important",
        "Why it matters",
        "Use the query builder: basic and advanced modes",
        "Tip",
        "Basic mode",
        "Advanced (NRQL) mode",
        "Advanced (PromQL-style) mode",
        "Use your charts"
      ],
      "title": "Introduction to the query builder",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "5d862557e0e3f4ef89dbd7da6ffdbe0d358790d2",
      "image": "https://docs.newrelic.com/static/30b623e8356b28b9361bedb0813db4c6/8c557/querybuilder04.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/introduction-query-builder/",
      "published_at": "2021-05-05T04:26:44Z",
      "updated_at": "2021-03-16T02:53:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the query builder, you can run queries of your data to create custom charts and other visualizations. You can also build custom dashboards containing multiple charts. To get to the query builder, go to one.newrelic.com and press Ctrl+E to open it. You can build your chart specifying the data in an assisted mode, using NRQL, or via our PromQL-style queries. Important Are you a New Relic Insights user? See our transition guide. Why it matters Modern business systems are a complex maze of data-generating elements. You need an easy, solid way to fetch, analyze, and visualize the never-ending stream of data flowing from your daily working activities. Use the query builder to: Quickly access your data and build customized charts to learn and understand the health of your infrastructure, applications, and other services. Add charts to your dashboards to obtain a complete real-time view of the state of your system. Share your charts with colleagues or users in just two clicks. Get acquainted with querying by using basic mode, then switch to advanced mode to refine your charts using NRQL. Use the query builder: basic and advanced modes The query builder offers three methods for specifying the data you want to see in a chart: Basic mode Advanced (NRQL) mode Advanced (PromQL-style) mode Tip You can also switch to the Data explorer tab at any time to browse your data and create charts visually, without performing queries. Basic mode Basic mode doesn't require a query language, and so it's useful if you aren't familiar with NRQL or SQL. It's also a quick way to answer one-off questions, such as how many cities outside of the United States are accessing the shopping site for your company. one.newrelic.com > Query your data > Query builder > Basic mode Use basic mode to guide you through the process to specify data for a chart. With basic mode you can: Choose your data source. In basic mode, you start by selecting an event and then picking the attribute that corresponds to the information to show in your chart. Specify (filter) the data for your chart. You can narrow the results and choose an attribute to facet by. Select the time range to present in the chart. You can select a time range from the menu or use the custom option to create your own time range. See Use basic mode for more information about this feature. Advanced (NRQL) mode With the advanced (NRQL) mode you can create your own queries using the NRQL query language. NRQL queries may be simple or complex, depending on what data you want to use and how to display it in your chart. This example of the advanced mode shows the NRQL query with the same data as used in basic mode. one.newrelic.com > Query your data > Query builder > Advanced (NRQL). Use advanced (NRQL) mode to write a query that specifies data for a chart. Tip With APM's real time streaming, you can query and visualize your data for transactions, errors, and custom events in dashboards. See Use advanced (NRQL) mode for more information about using this feature. Advanced (PromQL-style) mode With the advanced (PromQL-style) mode you can run basic PromQL-style queries. You can switch between basic and advanced modes while defining your query in order to: customize some of the values. learn how NRQL queries are structured using the data you specified in basic mode. Important If you build your query in basic mode and update it using advanced mode, you cannot return to basic mode to edit that query. You must make any additional changes in advanced (NRQL) mode. Once you specify the data you want, your chart is ready to view. Your query automatically runs in basic mode as you make changes to the inputs. If using advanced (NRQL or PromQL-style) mode, run your query. Use your charts Once you have built your chart you can: Change the type of chart. Based on the data you specified, the query builder selects the chart type that displays your results most effectively. However, you can choose from other available chart types to present your data in the visual format that you want to use. Share your chart. Add your chart to a dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.31902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>query</em> <em>builder</em>",
        "sections": "Use the <em>query</em> <em>builder</em>: basic <em>and</em> advanced modes",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "With the <em>query</em> <em>builder</em>, you can run queries of <em>your</em> <em>data</em> to create custom charts and other visualizations. You can also build custom dashboards containing multiple charts. To get to the <em>query</em> <em>builder</em>, go to one.newrelic.com and press Ctrl+E to open it. You can build <em>your</em> chart specifying the <em>data</em>"
      },
      "id": "603ec08f196a67f7b7a83dd2"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/129e7a553450c47847a969c79a2f7f89/c1b63/Dashboards_conf.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-05-04T18:45:04Z",
      "updated_at": "2021-03-16T02:53:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's guid, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Add a new page. Pages allow you to better organize your dashboards. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Access the query builder to see or edit the query associated to the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.65479,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> <em>builder</em> features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard page or in the edit mode) to access the <em>query</em> <em>builder</em>, or to add"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/use-advanced-nrql-mode-query-data": [
    {
      "sections": [
        "Use advanced PromQL-style mode to query data",
        "Use the query builder in PromQL-style mode",
        "Tip",
        "PromQL-style and the query builder"
      ],
      "title": "Use advanced PromQL-style mode to query data",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "5df9e170e9b362362c674baddac1189ed281bbf0",
      "image": "https://docs.newrelic.com/static/e1280f23afa0475b4025564d56027f13/c1b63/PromQL-after.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/use-advanced-promql-style-mode-query-data/",
      "published_at": "2021-05-05T01:39:14Z",
      "updated_at": "2021-03-16T02:54:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the query builder you can run queries of your data to create custom charts and other visualizations. The query builder comes with three working modes: basic query-less mode, advanced (NRQL) mode, and advanced PromQL-style mode, which takes PromQL queries as an input for accessing metrics and building charts. Use the query builder in PromQL-style mode You can access the query builder advanced PromQL-style mode by going to one.newrelic.com and clicking on Query your data at the top right corner. Go to the query builder tab on the left, then click PromQL-style on the right. Tip We support the Prometheus query language (PromQL) through our PromQL-style query mode. We do our best to automatically translate PromQL syntax queries into the closest NRQL approximation. For more information on how this works and differences you may observe between Prometheus and New Relic, see Supported PromQL features. Go to one.newrelic.com, press CTRL+E to open our Query Builder, then click PromQL-style to write a PromQL-style query. Build your PromQL-style query with the following parameters: Account: Select the account you want to query. PromQL-style prompt: Write you query here. You can view the list of valid options of the metrics and functions in the account. Step and range: Select the step and range for the query, or click on instant. Run the query to obtain the chart with the results. You can name the chart, change the type of chart, or add it to a dashboard. Tip Click NRQL to see how your PromQL-style query is translated into NRQL. PromQL-style and the query builder The query builder in advanced PromQL-style mode translates your PromQL query to NRQL before running the query. The results may be different from how Prometheus executes the query. If you would like to learn more about New Relic's PromQL-style query language and how it behaves, including troubleshooting information for translated queries, see Supported PromQL features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.15327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use advanced PromQL-style mode to <em>query</em> <em>data</em>",
        "sections": "PromQL-style <em>and</em> the <em>query</em> <em>builder</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "With the <em>query</em> <em>builder</em> you can run queries of <em>your</em> <em>data</em> to create custom charts and other visualizations. The <em>query</em> <em>builder</em> comes with three working modes: basic <em>query</em>-less mode, advanced (NRQL) mode, and advanced PromQL-style mode, which takes PromQL queries as an input for accessing metrics"
      },
      "id": "603e821e196a67a042a83df6"
    },
    {
      "sections": [
        "Introduction to the query builder",
        "Important",
        "Why it matters",
        "Use the query builder: basic and advanced modes",
        "Tip",
        "Basic mode",
        "Advanced (NRQL) mode",
        "Advanced (PromQL-style) mode",
        "Use your charts"
      ],
      "title": "Introduction to the query builder",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "5d862557e0e3f4ef89dbd7da6ffdbe0d358790d2",
      "image": "https://docs.newrelic.com/static/30b623e8356b28b9361bedb0813db4c6/8c557/querybuilder04.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/introduction-query-builder/",
      "published_at": "2021-05-05T04:26:44Z",
      "updated_at": "2021-03-16T02:53:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the query builder, you can run queries of your data to create custom charts and other visualizations. You can also build custom dashboards containing multiple charts. To get to the query builder, go to one.newrelic.com and press Ctrl+E to open it. You can build your chart specifying the data in an assisted mode, using NRQL, or via our PromQL-style queries. Important Are you a New Relic Insights user? See our transition guide. Why it matters Modern business systems are a complex maze of data-generating elements. You need an easy, solid way to fetch, analyze, and visualize the never-ending stream of data flowing from your daily working activities. Use the query builder to: Quickly access your data and build customized charts to learn and understand the health of your infrastructure, applications, and other services. Add charts to your dashboards to obtain a complete real-time view of the state of your system. Share your charts with colleagues or users in just two clicks. Get acquainted with querying by using basic mode, then switch to advanced mode to refine your charts using NRQL. Use the query builder: basic and advanced modes The query builder offers three methods for specifying the data you want to see in a chart: Basic mode Advanced (NRQL) mode Advanced (PromQL-style) mode Tip You can also switch to the Data explorer tab at any time to browse your data and create charts visually, without performing queries. Basic mode Basic mode doesn't require a query language, and so it's useful if you aren't familiar with NRQL or SQL. It's also a quick way to answer one-off questions, such as how many cities outside of the United States are accessing the shopping site for your company. one.newrelic.com > Query your data > Query builder > Basic mode Use basic mode to guide you through the process to specify data for a chart. With basic mode you can: Choose your data source. In basic mode, you start by selecting an event and then picking the attribute that corresponds to the information to show in your chart. Specify (filter) the data for your chart. You can narrow the results and choose an attribute to facet by. Select the time range to present in the chart. You can select a time range from the menu or use the custom option to create your own time range. See Use basic mode for more information about this feature. Advanced (NRQL) mode With the advanced (NRQL) mode you can create your own queries using the NRQL query language. NRQL queries may be simple or complex, depending on what data you want to use and how to display it in your chart. This example of the advanced mode shows the NRQL query with the same data as used in basic mode. one.newrelic.com > Query your data > Query builder > Advanced (NRQL). Use advanced (NRQL) mode to write a query that specifies data for a chart. Tip With APM's real time streaming, you can query and visualize your data for transactions, errors, and custom events in dashboards. See Use advanced (NRQL) mode for more information about using this feature. Advanced (PromQL-style) mode With the advanced (PromQL-style) mode you can run basic PromQL-style queries. You can switch between basic and advanced modes while defining your query in order to: customize some of the values. learn how NRQL queries are structured using the data you specified in basic mode. Important If you build your query in basic mode and update it using advanced mode, you cannot return to basic mode to edit that query. You must make any additional changes in advanced (NRQL) mode. Once you specify the data you want, your chart is ready to view. Your query automatically runs in basic mode as you make changes to the inputs. If using advanced (NRQL or PromQL-style) mode, run your query. Use your charts Once you have built your chart you can: Change the type of chart. Based on the data you specified, the query builder selects the chart type that displays your results most effectively. However, you can choose from other available chart types to present your data in the visual format that you want to use. Share your chart. Add your chart to a dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.31902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>query</em> <em>builder</em>",
        "sections": "Use the <em>query</em> <em>builder</em>: basic <em>and</em> advanced modes",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "With the <em>query</em> <em>builder</em>, you can run queries of <em>your</em> <em>data</em> to create custom charts and other visualizations. You can also build custom dashboards containing multiple charts. To get to the <em>query</em> <em>builder</em>, go to one.newrelic.com and press Ctrl+E to open it. You can build <em>your</em> chart specifying the <em>data</em>"
      },
      "id": "603ec08f196a67f7b7a83dd2"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/129e7a553450c47847a969c79a2f7f89/c1b63/Dashboards_conf.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-05-04T18:45:04Z",
      "updated_at": "2021-03-16T02:53:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's guid, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Add a new page. Pages allow you to better organize your dashboards. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Access the query builder to see or edit the query associated to the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.65479,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> <em>builder</em> features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard page or in the edit mode) to access the <em>query</em> <em>builder</em>, or to add"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/use-advanced-promql-style-mode-query-data": [
    {
      "sections": [
        "Introduction to the query builder",
        "Important",
        "Why it matters",
        "Use the query builder: basic and advanced modes",
        "Tip",
        "Basic mode",
        "Advanced (NRQL) mode",
        "Advanced (PromQL-style) mode",
        "Use your charts"
      ],
      "title": "Introduction to the query builder",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "5d862557e0e3f4ef89dbd7da6ffdbe0d358790d2",
      "image": "https://docs.newrelic.com/static/30b623e8356b28b9361bedb0813db4c6/8c557/querybuilder04.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/introduction-query-builder/",
      "published_at": "2021-05-05T04:26:44Z",
      "updated_at": "2021-03-16T02:53:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the query builder, you can run queries of your data to create custom charts and other visualizations. You can also build custom dashboards containing multiple charts. To get to the query builder, go to one.newrelic.com and press Ctrl+E to open it. You can build your chart specifying the data in an assisted mode, using NRQL, or via our PromQL-style queries. Important Are you a New Relic Insights user? See our transition guide. Why it matters Modern business systems are a complex maze of data-generating elements. You need an easy, solid way to fetch, analyze, and visualize the never-ending stream of data flowing from your daily working activities. Use the query builder to: Quickly access your data and build customized charts to learn and understand the health of your infrastructure, applications, and other services. Add charts to your dashboards to obtain a complete real-time view of the state of your system. Share your charts with colleagues or users in just two clicks. Get acquainted with querying by using basic mode, then switch to advanced mode to refine your charts using NRQL. Use the query builder: basic and advanced modes The query builder offers three methods for specifying the data you want to see in a chart: Basic mode Advanced (NRQL) mode Advanced (PromQL-style) mode Tip You can also switch to the Data explorer tab at any time to browse your data and create charts visually, without performing queries. Basic mode Basic mode doesn't require a query language, and so it's useful if you aren't familiar with NRQL or SQL. It's also a quick way to answer one-off questions, such as how many cities outside of the United States are accessing the shopping site for your company. one.newrelic.com > Query your data > Query builder > Basic mode Use basic mode to guide you through the process to specify data for a chart. With basic mode you can: Choose your data source. In basic mode, you start by selecting an event and then picking the attribute that corresponds to the information to show in your chart. Specify (filter) the data for your chart. You can narrow the results and choose an attribute to facet by. Select the time range to present in the chart. You can select a time range from the menu or use the custom option to create your own time range. See Use basic mode for more information about this feature. Advanced (NRQL) mode With the advanced (NRQL) mode you can create your own queries using the NRQL query language. NRQL queries may be simple or complex, depending on what data you want to use and how to display it in your chart. This example of the advanced mode shows the NRQL query with the same data as used in basic mode. one.newrelic.com > Query your data > Query builder > Advanced (NRQL). Use advanced (NRQL) mode to write a query that specifies data for a chart. Tip With APM's real time streaming, you can query and visualize your data for transactions, errors, and custom events in dashboards. See Use advanced (NRQL) mode for more information about using this feature. Advanced (PromQL-style) mode With the advanced (PromQL-style) mode you can run basic PromQL-style queries. You can switch between basic and advanced modes while defining your query in order to: customize some of the values. learn how NRQL queries are structured using the data you specified in basic mode. Important If you build your query in basic mode and update it using advanced mode, you cannot return to basic mode to edit that query. You must make any additional changes in advanced (NRQL) mode. Once you specify the data you want, your chart is ready to view. Your query automatically runs in basic mode as you make changes to the inputs. If using advanced (NRQL or PromQL-style) mode, run your query. Use your charts Once you have built your chart you can: Change the type of chart. Based on the data you specified, the query builder selects the chart type that displays your results most effectively. However, you can choose from other available chart types to present your data in the visual format that you want to use. Share your chart. Add your chart to a dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>query</em> <em>builder</em>",
        "sections": "Use the <em>query</em> <em>builder</em>: basic <em>and</em> advanced modes",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "With the <em>query</em> <em>builder</em>, you can run queries of <em>your</em> <em>data</em> to create custom charts and other visualizations. You can also build custom dashboards containing multiple charts. To get to the <em>query</em> <em>builder</em>, go to one.newrelic.com and press Ctrl+E to open it. You can build <em>your</em> chart specifying the <em>data</em>"
      },
      "id": "603ec08f196a67f7b7a83dd2"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/129e7a553450c47847a969c79a2f7f89/c1b63/Dashboards_conf.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-05-04T18:45:04Z",
      "updated_at": "2021-03-16T02:53:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's guid, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Add a new page. Pages allow you to better organize your dashboards. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Access the query builder to see or edit the query associated to the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.65479,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> <em>builder</em> features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard page or in the edit mode) to access the <em>query</em> <em>builder</em>, or to add"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Query builder: Basic mode",
        "Data type",
        "Example of using basic mode",
        "Step 1: Select the source of the data for a chart",
        "Step 2: Filter the data",
        "Step 3: Adjust time range and limits",
        "Step 4: Customize the chart",
        "Important"
      ],
      "title": "Query builder: Basic mode",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "7f076b3909c9462829453bc59f0dae0f5d5501fd",
      "image": "https://docs.newrelic.com/static/6be4a8d2af5e02259c01e180d7f43326/58213/crop-basic-example-chart_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/query-builder-basic-mode/",
      "published_at": "2021-05-06T06:52:10Z",
      "updated_at": "2021-03-16T02:54:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the New Relic One query builder in basic mode to create a chart without having to use NRQL, our querying language. The basic mode helps guides you through a query-creation process. You can choose the source of the raw data, apply filters, and use other techniques to narrow the scope of the data in the chart. Data type The query builder basic mode has a Data type selector with two options: Events: In this context, this refers to all our non-Metric-type data, including events, logs, and trace data. Metrics: This refers to our dimensional Metric data type. You can also use this to query some types of metric timeslice data. For more on other types of metrics, see Data types. Example of using basic mode This example shows how to create a chart in basic mode. Step 1: Select the source of the data for a chart Begin by specifying what data you want to view in your chart. Click in the View a chart with box to select the event type, an attribute, and a function to perform on the attribute. You can use the event data dictionary to view information about an event type and its attributes on a single page. To see a tooltip with information about an event or attribute, hover over any term that has a dotted line underneath it. Here are the results of using the event data dictionary to specify the data: Event type. The Transaction event type measures a variety of data that describes what happens while a user is on a website, such as that user clicking on a button on a page. Attribute. The name attribute stores information on all transactions. Function. Select the unique_count function to get a count of all the transactions that occurred during the time frame. Basic mode now shows the selection: one.newrelic.com > Query builder > Basic > (event and attribute specified) As you specify data, the chart updates to show you the results from the data you specified. Based on the information specified so far, you can see a chart that shows the total number of transactions during the default time frame of 30 minutes. This total includes all transactions, whether the transaction was completed successfully or had errors. one.newrelic.com > Query builder > Basic > (event and attribute specified) Step 2: Filter the data Your next step is to determine which of those transactions got a 404 page not found error. If you look in the event data dictionary for the Transaction event type, you'll find this event also includes an attribute called httpResponseCode. Narrow the results to show only those transactions where a page not found error occurred. Use the Narrow results to box to create this filter: httpResponseCode = 404 . Because you want to be able to see the names of the apps that are resulting in the 404 errors, you use the Facet by box to see the results by appName (which is also an attribute for the Transaction event type). Faceting by appName updates the chart to break down the total number of 404 errors by the application names. This lets you know which apps are experiencing 404 errors. Your chart now shows the line chart with a line for each app, each with its own color. one.newrelic.com > Query builder > Basic > (event and attribute specified) > (filters and facets applied) Step 3: Adjust time range and limits You decide to focus on the five apps with the most page not found errors. The default value for the Limit field is 10, meaning that your chart will show the ten most relevant returns. You change that value to 5. Customer support told you that they had been getting calls about these errors for a little over two hours. You decide to change the time range from the last 30 minutes to the last three hours so that you can view the errors during the time when the customers were calling support. Now that you have the data set so that you are seeing exactly what you need, you can turn your attention to the appearance of the chart. Step 4: Customize the chart Because you are more interested in the total number of errors than a timeline view, you change the chart type to a bar chart. one.newrelic.com > Query builder > Basic > (event and attribute specified) > (filters and facets applied) > (time range and limit customized) > (chart type customized) When you're finished with your chart, you can add it to a dashboard or share it. This table contains notes about using basic mode. Item Description Prompts You can start typing directly in an empty box; a list of items that match the information you type will display. You can also click on an empty box to view a list of all of the items that are appropriate for the field, based on your earlier choices. Saving a basic mode data specification Every time you run a query, that query is saved in the My recent queries dropdown in advanced (NRQL) mode. Events Basic mode only supports data for one event and attribute. If you want to use more than one event and/or attribute, use the SELECT statement in advanced (NRQL) mode. Shortcuts Basic mode contains shortcuts that can display more complex events and attributes that aren't generally supported, as in this example (which shows the tooltip for the shortcut). Example of the Response time histogram shortcut, showing a tooltip. Tooltips Any time you see a dotted line under a term, you can hover over that term to see a tooltip with an explanation of the term. Narrow by You can use more than one Narrow by definition in basic mode filter; the conditions will be joined by AND. The WHERE clause in advanced (NRQL) allows OR in addition to AND. Important If your query was started using basic mode and if you make changes to that query using advanced (NRQL) mode, you cannot return to basic mode to edit that query. Any additional changes may only be made in advanced (NRQL) mode.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.92169,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> <em>builder</em>: Basic mode",
        "sections": "<em>Query</em> <em>builder</em>: Basic mode",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " was completed successfully or had errors. one.newrelic.com &gt; <em>Query</em> <em>builder</em> &gt; Basic &gt; (event and attribute specified) Step 2: Filter the <em>data</em> <em>Your</em> next step is to determine which of those transactions got a 404 page not found error. If you look in the event <em>data</em> dictionary for the Transaction event type"
      },
      "id": "603ec319e7b9d2008c2a07e0"
    }
  ],
  "/docs/query-your-data/explore-query-data/use-charts/use-your-charts": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/129e7a553450c47847a969c79a2f7f89/c1b63/Dashboards_conf.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-05-04T18:45:04Z",
      "updated_at": "2021-03-16T02:53:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's guid, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Add a new page. Pages allow you to better organize your dashboards. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Access the query builder to see or edit the query associated to the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.13452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Manage <em>your</em> <em>charts</em> <em>and</em> markdown content",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One dashboards to create or manage <em>your</em> <em>charts</em> directly from the <em>chart</em> menu, customize <em>your</em> dashboard&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> dashboard and built <em>your</em> <em>charts</em>, <em>use</em> our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "See your dashboards across all New Relic",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-04T18:29:22Z",
      "updated_at": "2021-03-30T02:06:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. Chart all the events and attributes from everywhere across our platform. For more information, see our documentation on default data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. See your dashboards across all New Relic New Relic One dashboards have full backwards compatibility with the original New Relic platform, so any dashboard you have created in Insights will be automatically available in dashboards from day one. Reciprocally, when you add a new dashboard, it is also created in Insights. No further action is needed. With New Relic One you can also view dashboards across your organization using cross-account search. Tip Switching to New Relic One from Insights? See our transition guide. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.76033,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "See <em>your</em> dashboards across all New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " and understand the <em>data</em> you collect. <em>Explore</em> <em>your</em> <em>data</em> and correlate connected sources with tailored, user-friendly <em>charts</em>, and quickly learn the state of <em>your</em> system and applications for faster, more efficient troubleshooting. <em>Use</em> dashboards to: Drive insight with custom, high-density interactive"
      },
      "id": "603ec16028ccbc8d07eba78d"
    },
    {
      "sections": [
        "Use advanced PromQL-style mode to query data",
        "Use the query builder in PromQL-style mode",
        "Tip",
        "PromQL-style and the query builder"
      ],
      "title": "Use advanced PromQL-style mode to query data",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "5df9e170e9b362362c674baddac1189ed281bbf0",
      "image": "https://docs.newrelic.com/static/e1280f23afa0475b4025564d56027f13/c1b63/PromQL-after.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/use-advanced-promql-style-mode-query-data/",
      "published_at": "2021-05-05T01:39:14Z",
      "updated_at": "2021-03-16T02:54:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the query builder you can run queries of your data to create custom charts and other visualizations. The query builder comes with three working modes: basic query-less mode, advanced (NRQL) mode, and advanced PromQL-style mode, which takes PromQL queries as an input for accessing metrics and building charts. Use the query builder in PromQL-style mode You can access the query builder advanced PromQL-style mode by going to one.newrelic.com and clicking on Query your data at the top right corner. Go to the query builder tab on the left, then click PromQL-style on the right. Tip We support the Prometheus query language (PromQL) through our PromQL-style query mode. We do our best to automatically translate PromQL syntax queries into the closest NRQL approximation. For more information on how this works and differences you may observe between Prometheus and New Relic, see Supported PromQL features. Go to one.newrelic.com, press CTRL+E to open our Query Builder, then click PromQL-style to write a PromQL-style query. Build your PromQL-style query with the following parameters: Account: Select the account you want to query. PromQL-style prompt: Write you query here. You can view the list of valid options of the metrics and functions in the account. Step and range: Select the step and range for the query, or click on instant. Run the query to obtain the chart with the results. You can name the chart, change the type of chart, or add it to a dashboard. Tip Click NRQL to see how your PromQL-style query is translated into NRQL. PromQL-style and the query builder The query builder in advanced PromQL-style mode translates your PromQL query to NRQL before running the query. The results may be different from how Prometheus executes the query. If you would like to learn more about New Relic's PromQL-style query language and how it behaves, including troubleshooting information for translated queries, see Supported PromQL features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.85927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> advanced PromQL-style mode to <em>query</em> <em>data</em>",
        "sections": "<em>Use</em> advanced PromQL-style mode to <em>query</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " and building <em>charts</em>. <em>Use</em> the <em>query</em> builder in PromQL-style mode You can access the <em>query</em> builder advanced PromQL-style mode by going to one.newrelic.com and clicking on <em>Query</em> <em>your</em> <em>data</em> at the top right corner. Go to the <em>query</em> builder tab on the left, then click PromQL-style on the right. Tip We support"
      },
      "id": "603e821e196a67a042a83df6"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-05T00:20:27Z",
      "updated_at": "2021-05-05T00:20:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Here are the available aggregator functions. The definitions below contain example NRQL queries. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 357.57697,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> metric <em>data</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Rate limits for NRQL queries",
        "Limits on queried events",
        "NRQL query rate limits",
        "Limits on count of data types"
      ],
      "title": "Rate limits for NRQL queries",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "6dd3504c517c84fe20e0066c36482a001d0e2f3a",
      "image": "https://docs.newrelic.com/static/a67951798a5b60f8aca1b4aac861f61a/466da/insights-inspected-event-count-modal_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/rate-limits-nrql-queries/",
      "published_at": "2021-05-05T00:20:24Z",
      "updated_at": "2021-04-05T16:30:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's query language, NRQL, has rate limits in place to ensure a high level of availability and reliability for all users. To understand the places NRQL can be used, see Where is NRQL used?. You will rarely encounter rate limiting, especially if you follow these general guidelines: Limit the amount of requests with complex queries (for example, queries with FACET or TIMESERIES clauses, or queries of over a million events) that run at the same time. Limit the amount of requests run concurrently over extended periods of time to a maximum of 5, especially if they include complex queries. Limits on queried events When you run a NRQL query, it will display the number of events inspected, as shown below: In this context, \"events\" is used in a general sense to refer to all NRQL-available objects; this includes events, metrics, logs, and distributed tracing (span) data. Each New Relic account has limits on the total number of events that can be inspected. There are limits that apply over two different time frames: A rolling 30-minute time window A 24-hour period These limits are as follows: Time period Limit Rolling 30 minutes 300 billion events inspected (equivalent to a sustained rate of 10 billion events inspected per minute) 24 hours 7.2 trillion events inspected Once the limit has been reached for a given time period, limiting will be imposed and some queries may be impacted. After the time period has passed, if query volume drops below the limit, restrictions will be removed automatically. NRQL query rate limits The limit on NRQL queries is 50 queries per second, or 3000 queries per minute. Past this, New Relic cannot guarantee query performance, and you may be rate limited. Limits on count of data types The limit for total number of reported data types is 250 per account over a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. This limit applies to all NRQL-queryable data types. Because there aren't that many different data types reported by New Relic products and integrations, this will mainly be a limit on custom events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.76059,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limits for <em>NRQL</em> <em>queries</em>",
        "sections": "Rate limits for <em>NRQL</em> <em>queries</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s <em>query</em> <em>language</em>, <em>NRQL</em>, has rate limits in place to ensure a high level of availability and reliability for all users. To understand the places <em>NRQL</em> can be used, see Where is <em>NRQL</em> used?. You will rarely encounter rate limiting, especially if you follow these general guidelines: Limit"
      },
      "id": "603e8e46e7b9d2143d2a07b0"
    },
    {
      "sections": [
        "NRQL math using SELECT",
        "Use math operators with SELECT",
        "Results with STRING or FLOAT",
        "Tip",
        "Advanced math functions",
        "abs",
        "round, floor, ceil(ing)",
        "clamp_max, clamp_min",
        "pow",
        "sqrt",
        "exp",
        "ln, log2, log10, log",
        "For more help"
      ],
      "title": "NRQL math using SELECT",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "99bfd8fb7663a1c589160ea026ff585acf9d4023",
      "image": "https://docs.newrelic.com/static/dbeb9b9f1fc039e9d5357d7c2206ad18/c1b63/floor-round-ceil.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select/",
      "published_at": "2021-05-06T02:24:40Z",
      "updated_at": "2021-03-16T10:24:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Query Language (NRQL) supports basic math functions within a SELECT clause. You can apply addition, subtraction, multiplication, and division on both individual attributes as well as the results of aggregator functions. Use math operators with SELECT To use basic math functions in NRQL, include operators within the SELECT clause: Addition: + Subtraction: - Multiplication: * Division: / Here are some examples: SELECT duration-databaseDuration FROM Transaction Copy SELECT count(*)/uniqueCount(session) FROM PageView Copy SELECT average(duration-databaseDuration) FROM Transaction Copy Results with STRING or FLOAT Here is how NRQL handles strings present in math calculations: Examples: sum(1+STRING) = 0 sum(1+MIXED) = skips records where MIXED is a string average(1+STRING) = 0 average(1+MIXED) = skips records where MIXED is a string NULL and zero both appear as 0 in the dashboard. To override NULL values with another numeric value, use the syntax: SELECT average(purchasePrice OR 0) Copy This will replace NULL values with 0 or any number specified. Tip This can also be used to test whether something returns NULL or zero. (zero) OR 1 returns 0. (NULL) OR 1 returns 1. Advanced math functions NRQL includes advanced mathematical functions that can be used for complex calculations and for processing data to display more effectively in the UI. abs abs(n) returns the absolute value of n. For non-negative n it returns n, and for negative n it returns the positive number -n. For example abs(2) = 2, and abs(-4) = 4. round, floor, ceil(ing) These three functions force decimal numbers to one of the neighboring integers. floor(n) returns the closest integer less than or equal to n. ceil(n) returns the closest integer greater than or equal to n. round(n) returns the closest integer to n in either direction. Sample graph showing raw data, with floor, round, and ceiling functions applied. clamp_max, clamp_min The clamping functions impose an upper or lower bound on values. For example, clamp_max(duration, 10) returns the duration, unless it exceeds 10, in which case 10 is returned. Similarly clamp_min(duration, 1) will not return any value lower than 1. The following chart shows the result of clamping both min and max to keep the value in the range 70-90. Sample graph showing raw data with clamp function applied. pow pow(n, m) computes n raised to the power m. (I.e. n * n * ... * n, with m copies of n) sqrt sqrt(n) returns the square root of n, that is, the number such that sqrt(n) * sqrt(n) = n. exp Computes the natural exponential function of the argument: exp(n) = pow(e, n). ln, log2, log10, log These functions compute the logarithm of the argument for various bases. ln(n) computes the natural logarithm: the logarithm base e. log2(n) computes the logarithm base 2. log10(n) computes the logarithm base 10. log(n, b) allows logarithms to be computed with an arbitrary base b. All logarithms satisfy the identity: log(pow(b, n), b) = n. Note that log(0) is undefined, for all bases. Be aware that if you take the logarithm of something that might be zero, you may end up getting \"No Value\" back from your query. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.53659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> math using SELECT",
        "sections": "<em>NRQL</em> math using SELECT",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>) supports basic math functions within a SELECT clause. You can apply addition, subtraction, multiplication, and division on both individual attributes as well as the results of aggregator functions. Use math operators with SELECT To use basic math functions in <em>NRQL</em>"
      },
      "id": "603ec31864441f942b4e884c"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-05T00:20:27Z",
      "updated_at": "2021-05-05T00:20:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Here are the available aggregator functions. The definitions below contain example NRQL queries. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 357.57678,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> metric <em>data</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Rate limits for NRQL queries",
        "Limits on queried events",
        "NRQL query rate limits",
        "Limits on count of data types"
      ],
      "title": "Rate limits for NRQL queries",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "6dd3504c517c84fe20e0066c36482a001d0e2f3a",
      "image": "https://docs.newrelic.com/static/a67951798a5b60f8aca1b4aac861f61a/466da/insights-inspected-event-count-modal_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/rate-limits-nrql-queries/",
      "published_at": "2021-05-05T00:20:24Z",
      "updated_at": "2021-04-05T16:30:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's query language, NRQL, has rate limits in place to ensure a high level of availability and reliability for all users. To understand the places NRQL can be used, see Where is NRQL used?. You will rarely encounter rate limiting, especially if you follow these general guidelines: Limit the amount of requests with complex queries (for example, queries with FACET or TIMESERIES clauses, or queries of over a million events) that run at the same time. Limit the amount of requests run concurrently over extended periods of time to a maximum of 5, especially if they include complex queries. Limits on queried events When you run a NRQL query, it will display the number of events inspected, as shown below: In this context, \"events\" is used in a general sense to refer to all NRQL-available objects; this includes events, metrics, logs, and distributed tracing (span) data. Each New Relic account has limits on the total number of events that can be inspected. There are limits that apply over two different time frames: A rolling 30-minute time window A 24-hour period These limits are as follows: Time period Limit Rolling 30 minutes 300 billion events inspected (equivalent to a sustained rate of 10 billion events inspected per minute) 24 hours 7.2 trillion events inspected Once the limit has been reached for a given time period, limiting will be imposed and some queries may be impacted. After the time period has passed, if query volume drops below the limit, restrictions will be removed automatically. NRQL query rate limits The limit on NRQL queries is 50 queries per second, or 3000 queries per minute. Past this, New Relic cannot guarantee query performance, and you may be rate limited. Limits on count of data types The limit for total number of reported data types is 250 per account over a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. This limit applies to all NRQL-queryable data types. Because there aren't that many different data types reported by New Relic products and integrations, this will mainly be a limit on custom events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.76057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limits for <em>NRQL</em> <em>queries</em>",
        "sections": "Rate limits for <em>NRQL</em> <em>queries</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s <em>query</em> <em>language</em>, <em>NRQL</em>, has rate limits in place to ensure a high level of availability and reliability for all users. To understand the places <em>NRQL</em> can be used, see Where is <em>NRQL</em> used?. You will rarely encounter rate limiting, especially if you follow these general guidelines: Limit"
      },
      "id": "603e8e46e7b9d2143d2a07b0"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of Browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-05-04T18:45:38Z",
      "updated_at": "2021-03-11T03:19:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder: Advanced mode is a NRQL query interface Basic mode provides a simplified query experience that doesn't require knowledge of NRQL but that uses NRQL to generate results New Relic Insights NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in both New Relic One and New Relic Insights. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by New Relic APM, Browser, and Mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the basic mode of New Relic One query builder. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by New Relic APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of Browser data Here's a NRQL query of PageView data, which is reported by New Relic Browser. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for New Relic Browser PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.95856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ", clauses, and functions. What is <em>NRQL</em>? <em>NRQL</em> is <em>New</em> <em>Relic</em>&#x27;s SQL-like <em>query</em> <em>language</em>. You can use <em>NRQL</em> to retrieve detailed <em>New</em> <em>Relic</em> <em>data</em> and <em>get</em> insight into <em>your</em> applications, hosts, and business-important activity. Reasons to use <em>NRQL</em> include: To answer a question for the purpose of troubleshooting"
      },
      "id": "60445a0e196a67cb09960f6e"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions": [
    {
      "sections": [
        "Rate limits for NRQL queries",
        "Limits on queried events",
        "NRQL query rate limits",
        "Limits on count of data types"
      ],
      "title": "Rate limits for NRQL queries",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "6dd3504c517c84fe20e0066c36482a001d0e2f3a",
      "image": "https://docs.newrelic.com/static/a67951798a5b60f8aca1b4aac861f61a/466da/insights-inspected-event-count-modal_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/rate-limits-nrql-queries/",
      "published_at": "2021-05-05T00:20:24Z",
      "updated_at": "2021-04-05T16:30:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's query language, NRQL, has rate limits in place to ensure a high level of availability and reliability for all users. To understand the places NRQL can be used, see Where is NRQL used?. You will rarely encounter rate limiting, especially if you follow these general guidelines: Limit the amount of requests with complex queries (for example, queries with FACET or TIMESERIES clauses, or queries of over a million events) that run at the same time. Limit the amount of requests run concurrently over extended periods of time to a maximum of 5, especially if they include complex queries. Limits on queried events When you run a NRQL query, it will display the number of events inspected, as shown below: In this context, \"events\" is used in a general sense to refer to all NRQL-available objects; this includes events, metrics, logs, and distributed tracing (span) data. Each New Relic account has limits on the total number of events that can be inspected. There are limits that apply over two different time frames: A rolling 30-minute time window A 24-hour period These limits are as follows: Time period Limit Rolling 30 minutes 300 billion events inspected (equivalent to a sustained rate of 10 billion events inspected per minute) 24 hours 7.2 trillion events inspected Once the limit has been reached for a given time period, limiting will be imposed and some queries may be impacted. After the time period has passed, if query volume drops below the limit, restrictions will be removed automatically. NRQL query rate limits The limit on NRQL queries is 50 queries per second, or 3000 queries per minute. Past this, New Relic cannot guarantee query performance, and you may be rate limited. Limits on count of data types The limit for total number of reported data types is 250 per account over a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. This limit applies to all NRQL-queryable data types. Because there aren't that many different data types reported by New Relic products and integrations, this will mainly be a limit on custom events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.76057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limits for <em>NRQL</em> <em>queries</em>",
        "sections": "Rate limits for <em>NRQL</em> <em>queries</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s <em>query</em> <em>language</em>, <em>NRQL</em>, has rate limits in place to ensure a high level of availability and reliability for all users. To understand the places <em>NRQL</em> can be used, see Where is <em>NRQL</em> used?. You will rarely encounter rate limiting, especially if you follow these general guidelines: Limit"
      },
      "id": "603e8e46e7b9d2143d2a07b0"
    },
    {
      "sections": [
        "NRQL math using SELECT",
        "Use math operators with SELECT",
        "Results with STRING or FLOAT",
        "Tip",
        "Advanced math functions",
        "abs",
        "round, floor, ceil(ing)",
        "clamp_max, clamp_min",
        "pow",
        "sqrt",
        "exp",
        "ln, log2, log10, log",
        "For more help"
      ],
      "title": "NRQL math using SELECT",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "99bfd8fb7663a1c589160ea026ff585acf9d4023",
      "image": "https://docs.newrelic.com/static/dbeb9b9f1fc039e9d5357d7c2206ad18/c1b63/floor-round-ceil.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select/",
      "published_at": "2021-05-06T02:24:40Z",
      "updated_at": "2021-03-16T10:24:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Query Language (NRQL) supports basic math functions within a SELECT clause. You can apply addition, subtraction, multiplication, and division on both individual attributes as well as the results of aggregator functions. Use math operators with SELECT To use basic math functions in NRQL, include operators within the SELECT clause: Addition: + Subtraction: - Multiplication: * Division: / Here are some examples: SELECT duration-databaseDuration FROM Transaction Copy SELECT count(*)/uniqueCount(session) FROM PageView Copy SELECT average(duration-databaseDuration) FROM Transaction Copy Results with STRING or FLOAT Here is how NRQL handles strings present in math calculations: Examples: sum(1+STRING) = 0 sum(1+MIXED) = skips records where MIXED is a string average(1+STRING) = 0 average(1+MIXED) = skips records where MIXED is a string NULL and zero both appear as 0 in the dashboard. To override NULL values with another numeric value, use the syntax: SELECT average(purchasePrice OR 0) Copy This will replace NULL values with 0 or any number specified. Tip This can also be used to test whether something returns NULL or zero. (zero) OR 1 returns 0. (NULL) OR 1 returns 1. Advanced math functions NRQL includes advanced mathematical functions that can be used for complex calculations and for processing data to display more effectively in the UI. abs abs(n) returns the absolute value of n. For non-negative n it returns n, and for negative n it returns the positive number -n. For example abs(2) = 2, and abs(-4) = 4. round, floor, ceil(ing) These three functions force decimal numbers to one of the neighboring integers. floor(n) returns the closest integer less than or equal to n. ceil(n) returns the closest integer greater than or equal to n. round(n) returns the closest integer to n in either direction. Sample graph showing raw data, with floor, round, and ceiling functions applied. clamp_max, clamp_min The clamping functions impose an upper or lower bound on values. For example, clamp_max(duration, 10) returns the duration, unless it exceeds 10, in which case 10 is returned. Similarly clamp_min(duration, 1) will not return any value lower than 1. The following chart shows the result of clamping both min and max to keep the value in the range 70-90. Sample graph showing raw data with clamp function applied. pow pow(n, m) computes n raised to the power m. (I.e. n * n * ... * n, with m copies of n) sqrt sqrt(n) returns the square root of n, that is, the number such that sqrt(n) * sqrt(n) = n. exp Computes the natural exponential function of the argument: exp(n) = pow(e, n). ln, log2, log10, log These functions compute the logarithm of the argument for various bases. ln(n) computes the natural logarithm: the logarithm base e. log2(n) computes the logarithm base 2. log10(n) computes the logarithm base 10. log(n, b) allows logarithms to be computed with an arbitrary base b. All logarithms satisfy the identity: log(pow(b, n), b) = n. Note that log(0) is undefined, for all bases. Be aware that if you take the logarithm of something that might be zero, you may end up getting \"No Value\" back from your query. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.53659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> math using SELECT",
        "sections": "<em>NRQL</em> math using SELECT",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>) supports basic math functions within a SELECT clause. You can apply addition, subtraction, multiplication, and division on both individual attributes as well as the results of aggregator functions. Use math operators with SELECT To use basic math functions in <em>NRQL</em>"
      },
      "id": "603ec31864441f942b4e884c"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of Browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-05-04T18:45:38Z",
      "updated_at": "2021-03-11T03:19:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder: Advanced mode is a NRQL query interface Basic mode provides a simplified query experience that doesn't require knowledge of NRQL but that uses NRQL to generate results New Relic Insights NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in both New Relic One and New Relic Insights. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by New Relic APM, Browser, and Mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the basic mode of New Relic One query builder. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by New Relic APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of Browser data Here's a NRQL query of PageView data, which is reported by New Relic Browser. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for New Relic Browser PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.95856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ", clauses, and functions. What is <em>NRQL</em>? <em>NRQL</em> is <em>New</em> <em>Relic</em>&#x27;s SQL-like <em>query</em> <em>language</em>. You can use <em>NRQL</em> to retrieve detailed <em>New</em> <em>Relic</em> <em>data</em> and <em>get</em> insight into <em>your</em> applications, hosts, and business-important activity. Reasons to use <em>NRQL</em> include: To answer a question for the purpose of troubleshooting"
      },
      "id": "60445a0e196a67cb09960f6e"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/rate-limits-nrql-queries": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-05T00:20:27Z",
      "updated_at": "2021-05-05T00:20:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Here are the available aggregator functions. The definitions below contain example NRQL queries. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 357.57657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> metric <em>data</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL math using SELECT",
        "Use math operators with SELECT",
        "Results with STRING or FLOAT",
        "Tip",
        "Advanced math functions",
        "abs",
        "round, floor, ceil(ing)",
        "clamp_max, clamp_min",
        "pow",
        "sqrt",
        "exp",
        "ln, log2, log10, log",
        "For more help"
      ],
      "title": "NRQL math using SELECT",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "99bfd8fb7663a1c589160ea026ff585acf9d4023",
      "image": "https://docs.newrelic.com/static/dbeb9b9f1fc039e9d5357d7c2206ad18/c1b63/floor-round-ceil.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select/",
      "published_at": "2021-05-06T02:24:40Z",
      "updated_at": "2021-03-16T10:24:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Query Language (NRQL) supports basic math functions within a SELECT clause. You can apply addition, subtraction, multiplication, and division on both individual attributes as well as the results of aggregator functions. Use math operators with SELECT To use basic math functions in NRQL, include operators within the SELECT clause: Addition: + Subtraction: - Multiplication: * Division: / Here are some examples: SELECT duration-databaseDuration FROM Transaction Copy SELECT count(*)/uniqueCount(session) FROM PageView Copy SELECT average(duration-databaseDuration) FROM Transaction Copy Results with STRING or FLOAT Here is how NRQL handles strings present in math calculations: Examples: sum(1+STRING) = 0 sum(1+MIXED) = skips records where MIXED is a string average(1+STRING) = 0 average(1+MIXED) = skips records where MIXED is a string NULL and zero both appear as 0 in the dashboard. To override NULL values with another numeric value, use the syntax: SELECT average(purchasePrice OR 0) Copy This will replace NULL values with 0 or any number specified. Tip This can also be used to test whether something returns NULL or zero. (zero) OR 1 returns 0. (NULL) OR 1 returns 1. Advanced math functions NRQL includes advanced mathematical functions that can be used for complex calculations and for processing data to display more effectively in the UI. abs abs(n) returns the absolute value of n. For non-negative n it returns n, and for negative n it returns the positive number -n. For example abs(2) = 2, and abs(-4) = 4. round, floor, ceil(ing) These three functions force decimal numbers to one of the neighboring integers. floor(n) returns the closest integer less than or equal to n. ceil(n) returns the closest integer greater than or equal to n. round(n) returns the closest integer to n in either direction. Sample graph showing raw data, with floor, round, and ceiling functions applied. clamp_max, clamp_min The clamping functions impose an upper or lower bound on values. For example, clamp_max(duration, 10) returns the duration, unless it exceeds 10, in which case 10 is returned. Similarly clamp_min(duration, 1) will not return any value lower than 1. The following chart shows the result of clamping both min and max to keep the value in the range 70-90. Sample graph showing raw data with clamp function applied. pow pow(n, m) computes n raised to the power m. (I.e. n * n * ... * n, with m copies of n) sqrt sqrt(n) returns the square root of n, that is, the number such that sqrt(n) * sqrt(n) = n. exp Computes the natural exponential function of the argument: exp(n) = pow(e, n). ln, log2, log10, log These functions compute the logarithm of the argument for various bases. ln(n) computes the natural logarithm: the logarithm base e. log2(n) computes the logarithm base 2. log10(n) computes the logarithm base 10. log(n, b) allows logarithms to be computed with an arbitrary base b. All logarithms satisfy the identity: log(pow(b, n), b) = n. Note that log(0) is undefined, for all bases. Be aware that if you take the logarithm of something that might be zero, you may end up getting \"No Value\" back from your query. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.53659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> math using SELECT",
        "sections": "<em>NRQL</em> math using SELECT",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>) supports basic math functions within a SELECT clause. You can apply addition, subtraction, multiplication, and division on both individual attributes as well as the results of aggregator functions. Use math operators with SELECT To use basic math functions in <em>NRQL</em>"
      },
      "id": "603ec31864441f942b4e884c"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of Browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-05-04T18:45:38Z",
      "updated_at": "2021-03-11T03:19:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder: Advanced mode is a NRQL query interface Basic mode provides a simplified query experience that doesn't require knowledge of NRQL but that uses NRQL to generate results New Relic Insights NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in both New Relic One and New Relic Insights. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by New Relic APM, Browser, and Mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the basic mode of New Relic One query builder. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by New Relic APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of Browser data Here's a NRQL query of PageView data, which is reported by New Relic Browser. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for New Relic Browser PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.95856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ", clauses, and functions. What is <em>NRQL</em>? <em>NRQL</em> is <em>New</em> <em>Relic</em>&#x27;s SQL-like <em>query</em> <em>language</em>. You can use <em>NRQL</em> to retrieve detailed <em>New</em> <em>Relic</em> <em>data</em> and <em>get</em> insight into <em>your</em> applications, hosts, and business-important activity. Reasons to use <em>NRQL</em> include: To answer a question for the purpose of troubleshooting"
      },
      "id": "60445a0e196a67cb09960f6e"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/app-data-nrql-query-examples": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-05T00:20:27Z",
      "updated_at": "2021-05-05T00:20:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Here are the available aggregator functions. The definitions below contain example NRQL queries. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.79047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ". Aggregator functions Use aggregator functions to filter and aggregate <em>data</em> in a <em>NRQL</em> <em>query</em>. Some helpful information about using aggregator functions: See the <em>New</em> <em>Relic</em> University <em>tutorials</em> for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing <em>NRQL</em>"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-05T00:20:24Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.46869,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Query the Metric data type",
        "Query APM metric timeslice data",
        "View and query your metrics",
        "View example metric queries",
        "Chart multiple metrics",
        "Perform mathematical operations on metric data",
        "Use filters to select specific time series",
        "View the raw metric data points",
        "Query multiple metrics with wildcards",
        "Chart multiple metrics with wildcards",
        "Perform mathematical operations on metric data with wildcards",
        "Explore metric data",
        "List all metric names in an account",
        "List all metric names for a particular host",
        "Show the attribute keys for a specific metric"
      ],
      "title": "Query the Metric data type",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "09615f55eb5452211f0980a81f4a85e8c758fd61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-data/apis/query-metric-data-type/",
      "published_at": "2021-05-05T00:21:28Z",
      "updated_at": "2021-03-16T17:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When metrics are reported to New Relic via the Metric API (including from integrations that use that API), the data is reported as the Metric data type and is available for querying. This document contains: How to view and query your metrics Example metric queries How to query multiple metrics with wildcards How to explore metric data Query APM metric timeslice data New Relic APM reports a specific type of data that we call metric timeslice data. For how to query that, see Query metric timeslice data. For information about other types of metrics, see Metric data types. View and query your metrics You can use NRQL to query your metric data in the New Relic One query builder or using our NerdGraph API. To query a metric, use the following query format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each metric type: Metric type Supported functions Summary count, sum, min, max, and average Count sum Gauge count, sum, min, max, average, and latest Add the names of the metrics you want to chart with the appropriate value functions in the SELECT clause. The WHERE and FACET clauses can be used with attribute values. Remember to include the keyword TIMESERIES if you want to chart the data. This example demonstrates how you could chart the CPU usage in seconds for cluster foo . This query breaks down CPU usage by container, given a count metric named container_cpu_usage_seconds_total with the attributes containerName and clusterName: FROM Metric select sum(container_cpu_usage_seconds_total) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy If you want the CPU usage per minute (the rate of change), then you can add the rate function to the query above. FROM Metric select rate(sum(container_cpu_usage_seconds_total), 1 minute) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy View example metric queries The previous examples demonstrate basic forms of metric queries, but NRQL can also be used to chart, explore, and analyze metric data. Chart multiple metrics Chart multiple metrics using a single query by providing a comma-separated list of metrics in the SELECT clause. For example, to chart the memory usage for a container along with the memory limit metric, use the following query: FROM Metric SELECT latest(container_memory_usage_bytes), latest(container_spec_memory_limit_bytes) WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Perform mathematical operations on metric data Perform math operations on one or more metrics to compute a new, derived metric. To monitor available memory, you can calculate the percentage of available memory from the two metrics used in the previous example: FROM Metric SELECT (latest(container_spec_memory_limit_bytes) - latest(container_memory_usage_bytes)) / latest(container_spec_memory_limit_bytes) * 100 AS '% Memory Available' WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Use filters to select specific time series In addition to using a WHERE clause which applies to everything in SELECT, NRQL provides another aggregation function called filter which can be used to select a specific time series to be charted or operated on. The following example charts a memory usage metric labeled \"Total (k8s)\" which is computed by adding together the memory usage of two specific containers within a pod: FROM Metric SELECT filter( latest( container_memory_usage_bytes), WHERE containerName = 'discovery') + filter( latest( container_memory_usage_bytes), WHERE containerName = 'istio-proxy') AS 'Total (k8s)' WHERE clusterName = 'my-cluster' AND podName LIKE 'istio-pilot-%' TIMESERIES Copy View the raw metric data points When querying metric data using FROM Metric, New Relic automatically selects the specific aggregate to use in the query, depending on the length of the query window and any bucket size specified as an argument to the TIMESERIES keyword. This ensures efficient querying and chart resolution. If you want to override this behavior to view or operate on the raw metric data points, use the optional RAW keyword in your query. When querying these raw metric data points, there is a query time window limit of 48 hours. Any query attempting to access more than 48 hours of raw metric data will result in a query error. This example shows how to list the last 20 data points received for a particular metric: FROM Metric SELECT * WHERE metricName = 'container_fs_usage_bytes' LIMIT 20 RAW Copy Query multiple metrics with wildcards Wildcards are represented in NRQL by the % character. If you want to query multiple metrics that use a standard naming convention, you can use the wildcard feature to return results for all of them without having to specify each metric name individually. Wildcards can help you: Aggregate metrics together and chart the results FACET results by metric name in a chart Find and chart all metrics matching a given naming convention Wildcards are particularly helpful if you later add new metrics matching an existing naming convention. By using % instead of writing out each metric name in your query, you won't have to rewrite the query when you add new metrics. Let's say you have multiple algorithms that perform a similar task. You can define the following metrics, which show the duration of the different algorithms: myNeatProcess.algorithm1.duration myNeatProcess.algorithm2.duration myNeatProcess.algorithm3.duration If used in a query, myNeatProcess.%.duration will return results for all three of the algorithms above. If you later create new algorithms named algorithm4, algorithm5, and algorithm6, the same query will return results for all six algorithms. Chart multiple metrics with wildcards You can chart multiple metrics using a single query by using wildcards (%) in the SELECT clause. For example, to query all the algorithms in the example above and plot a line on the chart for each algorithm's average duration, use the following query: FROM Metric SELECT average(myNeatProcess.%.duration) FACET metricName TIMESERIES Copy Perform mathematical operations on metric data with wildcards You can also use wildcards to perform math operations on multiple metrics and compute a new metric. You can calculate the mean duration for all algorithms listed in the example above: FROM Metric SELECT average(myNeatProcess.%.duration) TIMESERIES Copy You can calculate what percentage of overall runtime a single algorithm takes: FROM Metric SELECT myNeatProcess.algorithm1.duration / sum(myNeatProcess.%.duration) TIMESERIES Copy Explore metric data The NRQL keyset and uniques functions can be used together with the metricName attribute (available on all metrics) to perform tasks like listing all the available metrics in your account or discovering the attributes available on a particular metric. List all metric names in an account FROM Metric SELECT uniques(metricName) Copy List all metric names for a particular host FROM Metric SELECT uniques(metricName) WHERE hostname = 'host1.mycompany.com' Copy Show the attribute keys for a specific metric FROM Metric SELECT keyset() WHERE metricName = METRIC_NAME Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.53328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> the Metric <em>data</em> type",
        "sections": "<em>Query</em> the Metric <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " metrics You can use <em>NRQL</em> to <em>query</em> <em>your</em> metric <em>data</em> in the <em>New</em> <em>Relic</em> One <em>query</em> builder or using our NerdGraph API. To <em>query</em> a metric, use the following <em>query</em> format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each"
      },
      "id": "603ead4564441fd2a74e8851"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/browserspa-nrql-query-examples": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-05T00:20:27Z",
      "updated_at": "2021-05-05T00:20:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Here are the available aggregator functions. The definitions below contain example NRQL queries. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.79028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ". Aggregator functions Use aggregator functions to filter and aggregate <em>data</em> in a <em>NRQL</em> <em>query</em>. Some helpful information about using aggregator functions: See the <em>New</em> <em>Relic</em> University <em>tutorials</em> for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing <em>NRQL</em>"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-05T00:20:24Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.46867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Query the Metric data type",
        "Query APM metric timeslice data",
        "View and query your metrics",
        "View example metric queries",
        "Chart multiple metrics",
        "Perform mathematical operations on metric data",
        "Use filters to select specific time series",
        "View the raw metric data points",
        "Query multiple metrics with wildcards",
        "Chart multiple metrics with wildcards",
        "Perform mathematical operations on metric data with wildcards",
        "Explore metric data",
        "List all metric names in an account",
        "List all metric names for a particular host",
        "Show the attribute keys for a specific metric"
      ],
      "title": "Query the Metric data type",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "09615f55eb5452211f0980a81f4a85e8c758fd61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-data/apis/query-metric-data-type/",
      "published_at": "2021-05-05T00:21:28Z",
      "updated_at": "2021-03-16T17:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When metrics are reported to New Relic via the Metric API (including from integrations that use that API), the data is reported as the Metric data type and is available for querying. This document contains: How to view and query your metrics Example metric queries How to query multiple metrics with wildcards How to explore metric data Query APM metric timeslice data New Relic APM reports a specific type of data that we call metric timeslice data. For how to query that, see Query metric timeslice data. For information about other types of metrics, see Metric data types. View and query your metrics You can use NRQL to query your metric data in the New Relic One query builder or using our NerdGraph API. To query a metric, use the following query format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each metric type: Metric type Supported functions Summary count, sum, min, max, and average Count sum Gauge count, sum, min, max, average, and latest Add the names of the metrics you want to chart with the appropriate value functions in the SELECT clause. The WHERE and FACET clauses can be used with attribute values. Remember to include the keyword TIMESERIES if you want to chart the data. This example demonstrates how you could chart the CPU usage in seconds for cluster foo . This query breaks down CPU usage by container, given a count metric named container_cpu_usage_seconds_total with the attributes containerName and clusterName: FROM Metric select sum(container_cpu_usage_seconds_total) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy If you want the CPU usage per minute (the rate of change), then you can add the rate function to the query above. FROM Metric select rate(sum(container_cpu_usage_seconds_total), 1 minute) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy View example metric queries The previous examples demonstrate basic forms of metric queries, but NRQL can also be used to chart, explore, and analyze metric data. Chart multiple metrics Chart multiple metrics using a single query by providing a comma-separated list of metrics in the SELECT clause. For example, to chart the memory usage for a container along with the memory limit metric, use the following query: FROM Metric SELECT latest(container_memory_usage_bytes), latest(container_spec_memory_limit_bytes) WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Perform mathematical operations on metric data Perform math operations on one or more metrics to compute a new, derived metric. To monitor available memory, you can calculate the percentage of available memory from the two metrics used in the previous example: FROM Metric SELECT (latest(container_spec_memory_limit_bytes) - latest(container_memory_usage_bytes)) / latest(container_spec_memory_limit_bytes) * 100 AS '% Memory Available' WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Use filters to select specific time series In addition to using a WHERE clause which applies to everything in SELECT, NRQL provides another aggregation function called filter which can be used to select a specific time series to be charted or operated on. The following example charts a memory usage metric labeled \"Total (k8s)\" which is computed by adding together the memory usage of two specific containers within a pod: FROM Metric SELECT filter( latest( container_memory_usage_bytes), WHERE containerName = 'discovery') + filter( latest( container_memory_usage_bytes), WHERE containerName = 'istio-proxy') AS 'Total (k8s)' WHERE clusterName = 'my-cluster' AND podName LIKE 'istio-pilot-%' TIMESERIES Copy View the raw metric data points When querying metric data using FROM Metric, New Relic automatically selects the specific aggregate to use in the query, depending on the length of the query window and any bucket size specified as an argument to the TIMESERIES keyword. This ensures efficient querying and chart resolution. If you want to override this behavior to view or operate on the raw metric data points, use the optional RAW keyword in your query. When querying these raw metric data points, there is a query time window limit of 48 hours. Any query attempting to access more than 48 hours of raw metric data will result in a query error. This example shows how to list the last 20 data points received for a particular metric: FROM Metric SELECT * WHERE metricName = 'container_fs_usage_bytes' LIMIT 20 RAW Copy Query multiple metrics with wildcards Wildcards are represented in NRQL by the % character. If you want to query multiple metrics that use a standard naming convention, you can use the wildcard feature to return results for all of them without having to specify each metric name individually. Wildcards can help you: Aggregate metrics together and chart the results FACET results by metric name in a chart Find and chart all metrics matching a given naming convention Wildcards are particularly helpful if you later add new metrics matching an existing naming convention. By using % instead of writing out each metric name in your query, you won't have to rewrite the query when you add new metrics. Let's say you have multiple algorithms that perform a similar task. You can define the following metrics, which show the duration of the different algorithms: myNeatProcess.algorithm1.duration myNeatProcess.algorithm2.duration myNeatProcess.algorithm3.duration If used in a query, myNeatProcess.%.duration will return results for all three of the algorithms above. If you later create new algorithms named algorithm4, algorithm5, and algorithm6, the same query will return results for all six algorithms. Chart multiple metrics with wildcards You can chart multiple metrics using a single query by using wildcards (%) in the SELECT clause. For example, to query all the algorithms in the example above and plot a line on the chart for each algorithm's average duration, use the following query: FROM Metric SELECT average(myNeatProcess.%.duration) FACET metricName TIMESERIES Copy Perform mathematical operations on metric data with wildcards You can also use wildcards to perform math operations on multiple metrics and compute a new metric. You can calculate the mean duration for all algorithms listed in the example above: FROM Metric SELECT average(myNeatProcess.%.duration) TIMESERIES Copy You can calculate what percentage of overall runtime a single algorithm takes: FROM Metric SELECT myNeatProcess.algorithm1.duration / sum(myNeatProcess.%.duration) TIMESERIES Copy Explore metric data The NRQL keyset and uniques functions can be used together with the metricName attribute (available on all metrics) to perform tasks like listing all the available metrics in your account or discovering the attributes available on a particular metric. List all metric names in an account FROM Metric SELECT uniques(metricName) Copy List all metric names for a particular host FROM Metric SELECT uniques(metricName) WHERE hostname = 'host1.mycompany.com' Copy Show the attribute keys for a specific metric FROM Metric SELECT keyset() WHERE metricName = METRIC_NAME Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.53326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> the Metric <em>data</em> type",
        "sections": "<em>Query</em> the Metric <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " metrics You can use <em>NRQL</em> to <em>query</em> <em>your</em> metric <em>data</em> in the <em>New</em> <em>Relic</em> One <em>query</em> builder or using our NerdGraph API. To <em>query</em> a metric, use the following <em>query</em> format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each"
      },
      "id": "603ead4564441fd2a74e8851"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-05T00:20:27Z",
      "updated_at": "2021-05-05T00:20:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Here are the available aggregator functions. The definitions below contain example NRQL queries. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.7901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ". Aggregator functions Use aggregator functions to filter and aggregate <em>data</em> in a <em>NRQL</em> <em>query</em>. Some helpful information about using aggregator functions: See the <em>New</em> <em>Relic</em> University <em>tutorials</em> for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing <em>NRQL</em>"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-05T00:20:24Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.46864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Query the Metric data type",
        "Query APM metric timeslice data",
        "View and query your metrics",
        "View example metric queries",
        "Chart multiple metrics",
        "Perform mathematical operations on metric data",
        "Use filters to select specific time series",
        "View the raw metric data points",
        "Query multiple metrics with wildcards",
        "Chart multiple metrics with wildcards",
        "Perform mathematical operations on metric data with wildcards",
        "Explore metric data",
        "List all metric names in an account",
        "List all metric names for a particular host",
        "Show the attribute keys for a specific metric"
      ],
      "title": "Query the Metric data type",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "09615f55eb5452211f0980a81f4a85e8c758fd61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-data/apis/query-metric-data-type/",
      "published_at": "2021-05-05T00:21:28Z",
      "updated_at": "2021-03-16T17:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When metrics are reported to New Relic via the Metric API (including from integrations that use that API), the data is reported as the Metric data type and is available for querying. This document contains: How to view and query your metrics Example metric queries How to query multiple metrics with wildcards How to explore metric data Query APM metric timeslice data New Relic APM reports a specific type of data that we call metric timeslice data. For how to query that, see Query metric timeslice data. For information about other types of metrics, see Metric data types. View and query your metrics You can use NRQL to query your metric data in the New Relic One query builder or using our NerdGraph API. To query a metric, use the following query format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each metric type: Metric type Supported functions Summary count, sum, min, max, and average Count sum Gauge count, sum, min, max, average, and latest Add the names of the metrics you want to chart with the appropriate value functions in the SELECT clause. The WHERE and FACET clauses can be used with attribute values. Remember to include the keyword TIMESERIES if you want to chart the data. This example demonstrates how you could chart the CPU usage in seconds for cluster foo . This query breaks down CPU usage by container, given a count metric named container_cpu_usage_seconds_total with the attributes containerName and clusterName: FROM Metric select sum(container_cpu_usage_seconds_total) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy If you want the CPU usage per minute (the rate of change), then you can add the rate function to the query above. FROM Metric select rate(sum(container_cpu_usage_seconds_total), 1 minute) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy View example metric queries The previous examples demonstrate basic forms of metric queries, but NRQL can also be used to chart, explore, and analyze metric data. Chart multiple metrics Chart multiple metrics using a single query by providing a comma-separated list of metrics in the SELECT clause. For example, to chart the memory usage for a container along with the memory limit metric, use the following query: FROM Metric SELECT latest(container_memory_usage_bytes), latest(container_spec_memory_limit_bytes) WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Perform mathematical operations on metric data Perform math operations on one or more metrics to compute a new, derived metric. To monitor available memory, you can calculate the percentage of available memory from the two metrics used in the previous example: FROM Metric SELECT (latest(container_spec_memory_limit_bytes) - latest(container_memory_usage_bytes)) / latest(container_spec_memory_limit_bytes) * 100 AS '% Memory Available' WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Use filters to select specific time series In addition to using a WHERE clause which applies to everything in SELECT, NRQL provides another aggregation function called filter which can be used to select a specific time series to be charted or operated on. The following example charts a memory usage metric labeled \"Total (k8s)\" which is computed by adding together the memory usage of two specific containers within a pod: FROM Metric SELECT filter( latest( container_memory_usage_bytes), WHERE containerName = 'discovery') + filter( latest( container_memory_usage_bytes), WHERE containerName = 'istio-proxy') AS 'Total (k8s)' WHERE clusterName = 'my-cluster' AND podName LIKE 'istio-pilot-%' TIMESERIES Copy View the raw metric data points When querying metric data using FROM Metric, New Relic automatically selects the specific aggregate to use in the query, depending on the length of the query window and any bucket size specified as an argument to the TIMESERIES keyword. This ensures efficient querying and chart resolution. If you want to override this behavior to view or operate on the raw metric data points, use the optional RAW keyword in your query. When querying these raw metric data points, there is a query time window limit of 48 hours. Any query attempting to access more than 48 hours of raw metric data will result in a query error. This example shows how to list the last 20 data points received for a particular metric: FROM Metric SELECT * WHERE metricName = 'container_fs_usage_bytes' LIMIT 20 RAW Copy Query multiple metrics with wildcards Wildcards are represented in NRQL by the % character. If you want to query multiple metrics that use a standard naming convention, you can use the wildcard feature to return results for all of them without having to specify each metric name individually. Wildcards can help you: Aggregate metrics together and chart the results FACET results by metric name in a chart Find and chart all metrics matching a given naming convention Wildcards are particularly helpful if you later add new metrics matching an existing naming convention. By using % instead of writing out each metric name in your query, you won't have to rewrite the query when you add new metrics. Let's say you have multiple algorithms that perform a similar task. You can define the following metrics, which show the duration of the different algorithms: myNeatProcess.algorithm1.duration myNeatProcess.algorithm2.duration myNeatProcess.algorithm3.duration If used in a query, myNeatProcess.%.duration will return results for all three of the algorithms above. If you later create new algorithms named algorithm4, algorithm5, and algorithm6, the same query will return results for all six algorithms. Chart multiple metrics with wildcards You can chart multiple metrics using a single query by using wildcards (%) in the SELECT clause. For example, to query all the algorithms in the example above and plot a line on the chart for each algorithm's average duration, use the following query: FROM Metric SELECT average(myNeatProcess.%.duration) FACET metricName TIMESERIES Copy Perform mathematical operations on metric data with wildcards You can also use wildcards to perform math operations on multiple metrics and compute a new metric. You can calculate the mean duration for all algorithms listed in the example above: FROM Metric SELECT average(myNeatProcess.%.duration) TIMESERIES Copy You can calculate what percentage of overall runtime a single algorithm takes: FROM Metric SELECT myNeatProcess.algorithm1.duration / sum(myNeatProcess.%.duration) TIMESERIES Copy Explore metric data The NRQL keyset and uniques functions can be used together with the metricName attribute (available on all metrics) to perform tasks like listing all the available metrics in your account or discovering the attributes available on a particular metric. List all metric names in an account FROM Metric SELECT uniques(metricName) Copy List all metric names for a particular host FROM Metric SELECT uniques(metricName) WHERE hostname = 'host1.mycompany.com' Copy Show the attribute keys for a specific metric FROM Metric SELECT keyset() WHERE metricName = METRIC_NAME Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.53326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> the Metric <em>data</em> type",
        "sections": "<em>Query</em> the Metric <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " metrics You can use <em>NRQL</em> to <em>query</em> <em>your</em> metric <em>data</em> in the <em>New</em> <em>Relic</em> One <em>query</em> builder or using our NerdGraph API. To <em>query</em> a metric, use the following <em>query</em> format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each"
      },
      "id": "603ead4564441fd2a74e8851"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/funnels-evaluate-data-series-related-events": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-05T00:20:27Z",
      "updated_at": "2021-05-05T00:20:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Here are the available aggregator functions. The definitions below contain example NRQL queries. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.7901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ". Aggregator functions Use aggregator functions to filter and aggregate <em>data</em> in a <em>NRQL</em> <em>query</em>. Some helpful information about using aggregator functions: See the <em>New</em> <em>Relic</em> University <em>tutorials</em> for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing <em>NRQL</em>"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-05T00:20:24Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.46864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Query the Metric data type",
        "Query APM metric timeslice data",
        "View and query your metrics",
        "View example metric queries",
        "Chart multiple metrics",
        "Perform mathematical operations on metric data",
        "Use filters to select specific time series",
        "View the raw metric data points",
        "Query multiple metrics with wildcards",
        "Chart multiple metrics with wildcards",
        "Perform mathematical operations on metric data with wildcards",
        "Explore metric data",
        "List all metric names in an account",
        "List all metric names for a particular host",
        "Show the attribute keys for a specific metric"
      ],
      "title": "Query the Metric data type",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "09615f55eb5452211f0980a81f4a85e8c758fd61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-data/apis/query-metric-data-type/",
      "published_at": "2021-05-05T00:21:28Z",
      "updated_at": "2021-03-16T17:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When metrics are reported to New Relic via the Metric API (including from integrations that use that API), the data is reported as the Metric data type and is available for querying. This document contains: How to view and query your metrics Example metric queries How to query multiple metrics with wildcards How to explore metric data Query APM metric timeslice data New Relic APM reports a specific type of data that we call metric timeslice data. For how to query that, see Query metric timeslice data. For information about other types of metrics, see Metric data types. View and query your metrics You can use NRQL to query your metric data in the New Relic One query builder or using our NerdGraph API. To query a metric, use the following query format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each metric type: Metric type Supported functions Summary count, sum, min, max, and average Count sum Gauge count, sum, min, max, average, and latest Add the names of the metrics you want to chart with the appropriate value functions in the SELECT clause. The WHERE and FACET clauses can be used with attribute values. Remember to include the keyword TIMESERIES if you want to chart the data. This example demonstrates how you could chart the CPU usage in seconds for cluster foo . This query breaks down CPU usage by container, given a count metric named container_cpu_usage_seconds_total with the attributes containerName and clusterName: FROM Metric select sum(container_cpu_usage_seconds_total) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy If you want the CPU usage per minute (the rate of change), then you can add the rate function to the query above. FROM Metric select rate(sum(container_cpu_usage_seconds_total), 1 minute) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy View example metric queries The previous examples demonstrate basic forms of metric queries, but NRQL can also be used to chart, explore, and analyze metric data. Chart multiple metrics Chart multiple metrics using a single query by providing a comma-separated list of metrics in the SELECT clause. For example, to chart the memory usage for a container along with the memory limit metric, use the following query: FROM Metric SELECT latest(container_memory_usage_bytes), latest(container_spec_memory_limit_bytes) WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Perform mathematical operations on metric data Perform math operations on one or more metrics to compute a new, derived metric. To monitor available memory, you can calculate the percentage of available memory from the two metrics used in the previous example: FROM Metric SELECT (latest(container_spec_memory_limit_bytes) - latest(container_memory_usage_bytes)) / latest(container_spec_memory_limit_bytes) * 100 AS '% Memory Available' WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Use filters to select specific time series In addition to using a WHERE clause which applies to everything in SELECT, NRQL provides another aggregation function called filter which can be used to select a specific time series to be charted or operated on. The following example charts a memory usage metric labeled \"Total (k8s)\" which is computed by adding together the memory usage of two specific containers within a pod: FROM Metric SELECT filter( latest( container_memory_usage_bytes), WHERE containerName = 'discovery') + filter( latest( container_memory_usage_bytes), WHERE containerName = 'istio-proxy') AS 'Total (k8s)' WHERE clusterName = 'my-cluster' AND podName LIKE 'istio-pilot-%' TIMESERIES Copy View the raw metric data points When querying metric data using FROM Metric, New Relic automatically selects the specific aggregate to use in the query, depending on the length of the query window and any bucket size specified as an argument to the TIMESERIES keyword. This ensures efficient querying and chart resolution. If you want to override this behavior to view or operate on the raw metric data points, use the optional RAW keyword in your query. When querying these raw metric data points, there is a query time window limit of 48 hours. Any query attempting to access more than 48 hours of raw metric data will result in a query error. This example shows how to list the last 20 data points received for a particular metric: FROM Metric SELECT * WHERE metricName = 'container_fs_usage_bytes' LIMIT 20 RAW Copy Query multiple metrics with wildcards Wildcards are represented in NRQL by the % character. If you want to query multiple metrics that use a standard naming convention, you can use the wildcard feature to return results for all of them without having to specify each metric name individually. Wildcards can help you: Aggregate metrics together and chart the results FACET results by metric name in a chart Find and chart all metrics matching a given naming convention Wildcards are particularly helpful if you later add new metrics matching an existing naming convention. By using % instead of writing out each metric name in your query, you won't have to rewrite the query when you add new metrics. Let's say you have multiple algorithms that perform a similar task. You can define the following metrics, which show the duration of the different algorithms: myNeatProcess.algorithm1.duration myNeatProcess.algorithm2.duration myNeatProcess.algorithm3.duration If used in a query, myNeatProcess.%.duration will return results for all three of the algorithms above. If you later create new algorithms named algorithm4, algorithm5, and algorithm6, the same query will return results for all six algorithms. Chart multiple metrics with wildcards You can chart multiple metrics using a single query by using wildcards (%) in the SELECT clause. For example, to query all the algorithms in the example above and plot a line on the chart for each algorithm's average duration, use the following query: FROM Metric SELECT average(myNeatProcess.%.duration) FACET metricName TIMESERIES Copy Perform mathematical operations on metric data with wildcards You can also use wildcards to perform math operations on multiple metrics and compute a new metric. You can calculate the mean duration for all algorithms listed in the example above: FROM Metric SELECT average(myNeatProcess.%.duration) TIMESERIES Copy You can calculate what percentage of overall runtime a single algorithm takes: FROM Metric SELECT myNeatProcess.algorithm1.duration / sum(myNeatProcess.%.duration) TIMESERIES Copy Explore metric data The NRQL keyset and uniques functions can be used together with the metricName attribute (available on all metrics) to perform tasks like listing all the available metrics in your account or discovering the attributes available on a particular metric. List all metric names in an account FROM Metric SELECT uniques(metricName) Copy List all metric names for a particular host FROM Metric SELECT uniques(metricName) WHERE hostname = 'host1.mycompany.com' Copy Show the attribute keys for a specific metric FROM Metric SELECT keyset() WHERE metricName = METRIC_NAME Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.53326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> the Metric <em>data</em> type",
        "sections": "<em>Query</em> the Metric <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " metrics You can use <em>NRQL</em> to <em>query</em> <em>your</em> metric <em>data</em> in the <em>New</em> <em>Relic</em> One <em>query</em> builder or using our NerdGraph API. To <em>query</em> a metric, use the following <em>query</em> format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each"
      },
      "id": "603ead4564441fd2a74e8851"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/improvements-nrql-percentile": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-05T00:20:27Z",
      "updated_at": "2021-05-05T00:20:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Here are the available aggregator functions. The definitions below contain example NRQL queries. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.78995,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ". Aggregator functions Use aggregator functions to filter and aggregate <em>data</em> in a <em>NRQL</em> <em>query</em>. Some helpful information about using aggregator functions: See the <em>New</em> <em>Relic</em> University <em>tutorials</em> for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing <em>NRQL</em>"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-05T00:20:24Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.46861,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Query the Metric data type",
        "Query APM metric timeslice data",
        "View and query your metrics",
        "View example metric queries",
        "Chart multiple metrics",
        "Perform mathematical operations on metric data",
        "Use filters to select specific time series",
        "View the raw metric data points",
        "Query multiple metrics with wildcards",
        "Chart multiple metrics with wildcards",
        "Perform mathematical operations on metric data with wildcards",
        "Explore metric data",
        "List all metric names in an account",
        "List all metric names for a particular host",
        "Show the attribute keys for a specific metric"
      ],
      "title": "Query the Metric data type",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "09615f55eb5452211f0980a81f4a85e8c758fd61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-data/apis/query-metric-data-type/",
      "published_at": "2021-05-05T00:21:28Z",
      "updated_at": "2021-03-16T17:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When metrics are reported to New Relic via the Metric API (including from integrations that use that API), the data is reported as the Metric data type and is available for querying. This document contains: How to view and query your metrics Example metric queries How to query multiple metrics with wildcards How to explore metric data Query APM metric timeslice data New Relic APM reports a specific type of data that we call metric timeslice data. For how to query that, see Query metric timeslice data. For information about other types of metrics, see Metric data types. View and query your metrics You can use NRQL to query your metric data in the New Relic One query builder or using our NerdGraph API. To query a metric, use the following query format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each metric type: Metric type Supported functions Summary count, sum, min, max, and average Count sum Gauge count, sum, min, max, average, and latest Add the names of the metrics you want to chart with the appropriate value functions in the SELECT clause. The WHERE and FACET clauses can be used with attribute values. Remember to include the keyword TIMESERIES if you want to chart the data. This example demonstrates how you could chart the CPU usage in seconds for cluster foo . This query breaks down CPU usage by container, given a count metric named container_cpu_usage_seconds_total with the attributes containerName and clusterName: FROM Metric select sum(container_cpu_usage_seconds_total) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy If you want the CPU usage per minute (the rate of change), then you can add the rate function to the query above. FROM Metric select rate(sum(container_cpu_usage_seconds_total), 1 minute) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy View example metric queries The previous examples demonstrate basic forms of metric queries, but NRQL can also be used to chart, explore, and analyze metric data. Chart multiple metrics Chart multiple metrics using a single query by providing a comma-separated list of metrics in the SELECT clause. For example, to chart the memory usage for a container along with the memory limit metric, use the following query: FROM Metric SELECT latest(container_memory_usage_bytes), latest(container_spec_memory_limit_bytes) WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Perform mathematical operations on metric data Perform math operations on one or more metrics to compute a new, derived metric. To monitor available memory, you can calculate the percentage of available memory from the two metrics used in the previous example: FROM Metric SELECT (latest(container_spec_memory_limit_bytes) - latest(container_memory_usage_bytes)) / latest(container_spec_memory_limit_bytes) * 100 AS '% Memory Available' WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Use filters to select specific time series In addition to using a WHERE clause which applies to everything in SELECT, NRQL provides another aggregation function called filter which can be used to select a specific time series to be charted or operated on. The following example charts a memory usage metric labeled \"Total (k8s)\" which is computed by adding together the memory usage of two specific containers within a pod: FROM Metric SELECT filter( latest( container_memory_usage_bytes), WHERE containerName = 'discovery') + filter( latest( container_memory_usage_bytes), WHERE containerName = 'istio-proxy') AS 'Total (k8s)' WHERE clusterName = 'my-cluster' AND podName LIKE 'istio-pilot-%' TIMESERIES Copy View the raw metric data points When querying metric data using FROM Metric, New Relic automatically selects the specific aggregate to use in the query, depending on the length of the query window and any bucket size specified as an argument to the TIMESERIES keyword. This ensures efficient querying and chart resolution. If you want to override this behavior to view or operate on the raw metric data points, use the optional RAW keyword in your query. When querying these raw metric data points, there is a query time window limit of 48 hours. Any query attempting to access more than 48 hours of raw metric data will result in a query error. This example shows how to list the last 20 data points received for a particular metric: FROM Metric SELECT * WHERE metricName = 'container_fs_usage_bytes' LIMIT 20 RAW Copy Query multiple metrics with wildcards Wildcards are represented in NRQL by the % character. If you want to query multiple metrics that use a standard naming convention, you can use the wildcard feature to return results for all of them without having to specify each metric name individually. Wildcards can help you: Aggregate metrics together and chart the results FACET results by metric name in a chart Find and chart all metrics matching a given naming convention Wildcards are particularly helpful if you later add new metrics matching an existing naming convention. By using % instead of writing out each metric name in your query, you won't have to rewrite the query when you add new metrics. Let's say you have multiple algorithms that perform a similar task. You can define the following metrics, which show the duration of the different algorithms: myNeatProcess.algorithm1.duration myNeatProcess.algorithm2.duration myNeatProcess.algorithm3.duration If used in a query, myNeatProcess.%.duration will return results for all three of the algorithms above. If you later create new algorithms named algorithm4, algorithm5, and algorithm6, the same query will return results for all six algorithms. Chart multiple metrics with wildcards You can chart multiple metrics using a single query by using wildcards (%) in the SELECT clause. For example, to query all the algorithms in the example above and plot a line on the chart for each algorithm's average duration, use the following query: FROM Metric SELECT average(myNeatProcess.%.duration) FACET metricName TIMESERIES Copy Perform mathematical operations on metric data with wildcards You can also use wildcards to perform math operations on multiple metrics and compute a new metric. You can calculate the mean duration for all algorithms listed in the example above: FROM Metric SELECT average(myNeatProcess.%.duration) TIMESERIES Copy You can calculate what percentage of overall runtime a single algorithm takes: FROM Metric SELECT myNeatProcess.algorithm1.duration / sum(myNeatProcess.%.duration) TIMESERIES Copy Explore metric data The NRQL keyset and uniques functions can be used together with the metricName attribute (available on all metrics) to perform tasks like listing all the available metrics in your account or discovering the attributes available on a particular metric. List all metric names in an account FROM Metric SELECT uniques(metricName) Copy List all metric names for a particular host FROM Metric SELECT uniques(metricName) WHERE hostname = 'host1.mycompany.com' Copy Show the attribute keys for a specific metric FROM Metric SELECT keyset() WHERE metricName = METRIC_NAME Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.53326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> the Metric <em>data</em> type",
        "sections": "<em>Query</em> the Metric <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " metrics You can use <em>NRQL</em> to <em>query</em> <em>your</em> metric <em>data</em> in the <em>New</em> <em>Relic</em> One <em>query</em> builder or using our NerdGraph API. To <em>query</em> a metric, use the following <em>query</em> format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each"
      },
      "id": "603ead4564441fd2a74e8851"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nested-aggregation-make-ordered-computations-single-query": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-05T00:20:27Z",
      "updated_at": "2021-05-05T00:20:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Here are the available aggregator functions. The definitions below contain example NRQL queries. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.78976,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ". Aggregator functions Use aggregator functions to filter and aggregate <em>data</em> in a <em>NRQL</em> <em>query</em>. Some helpful information about using aggregator functions: See the <em>New</em> <em>Relic</em> University <em>tutorials</em> for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing <em>NRQL</em>"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-05T00:20:24Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.4686,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Query the Metric data type",
        "Query APM metric timeslice data",
        "View and query your metrics",
        "View example metric queries",
        "Chart multiple metrics",
        "Perform mathematical operations on metric data",
        "Use filters to select specific time series",
        "View the raw metric data points",
        "Query multiple metrics with wildcards",
        "Chart multiple metrics with wildcards",
        "Perform mathematical operations on metric data with wildcards",
        "Explore metric data",
        "List all metric names in an account",
        "List all metric names for a particular host",
        "Show the attribute keys for a specific metric"
      ],
      "title": "Query the Metric data type",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "09615f55eb5452211f0980a81f4a85e8c758fd61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-data/apis/query-metric-data-type/",
      "published_at": "2021-05-05T00:21:28Z",
      "updated_at": "2021-03-16T17:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When metrics are reported to New Relic via the Metric API (including from integrations that use that API), the data is reported as the Metric data type and is available for querying. This document contains: How to view and query your metrics Example metric queries How to query multiple metrics with wildcards How to explore metric data Query APM metric timeslice data New Relic APM reports a specific type of data that we call metric timeslice data. For how to query that, see Query metric timeslice data. For information about other types of metrics, see Metric data types. View and query your metrics You can use NRQL to query your metric data in the New Relic One query builder or using our NerdGraph API. To query a metric, use the following query format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each metric type: Metric type Supported functions Summary count, sum, min, max, and average Count sum Gauge count, sum, min, max, average, and latest Add the names of the metrics you want to chart with the appropriate value functions in the SELECT clause. The WHERE and FACET clauses can be used with attribute values. Remember to include the keyword TIMESERIES if you want to chart the data. This example demonstrates how you could chart the CPU usage in seconds for cluster foo . This query breaks down CPU usage by container, given a count metric named container_cpu_usage_seconds_total with the attributes containerName and clusterName: FROM Metric select sum(container_cpu_usage_seconds_total) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy If you want the CPU usage per minute (the rate of change), then you can add the rate function to the query above. FROM Metric select rate(sum(container_cpu_usage_seconds_total), 1 minute) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy View example metric queries The previous examples demonstrate basic forms of metric queries, but NRQL can also be used to chart, explore, and analyze metric data. Chart multiple metrics Chart multiple metrics using a single query by providing a comma-separated list of metrics in the SELECT clause. For example, to chart the memory usage for a container along with the memory limit metric, use the following query: FROM Metric SELECT latest(container_memory_usage_bytes), latest(container_spec_memory_limit_bytes) WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Perform mathematical operations on metric data Perform math operations on one or more metrics to compute a new, derived metric. To monitor available memory, you can calculate the percentage of available memory from the two metrics used in the previous example: FROM Metric SELECT (latest(container_spec_memory_limit_bytes) - latest(container_memory_usage_bytes)) / latest(container_spec_memory_limit_bytes) * 100 AS '% Memory Available' WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Use filters to select specific time series In addition to using a WHERE clause which applies to everything in SELECT, NRQL provides another aggregation function called filter which can be used to select a specific time series to be charted or operated on. The following example charts a memory usage metric labeled \"Total (k8s)\" which is computed by adding together the memory usage of two specific containers within a pod: FROM Metric SELECT filter( latest( container_memory_usage_bytes), WHERE containerName = 'discovery') + filter( latest( container_memory_usage_bytes), WHERE containerName = 'istio-proxy') AS 'Total (k8s)' WHERE clusterName = 'my-cluster' AND podName LIKE 'istio-pilot-%' TIMESERIES Copy View the raw metric data points When querying metric data using FROM Metric, New Relic automatically selects the specific aggregate to use in the query, depending on the length of the query window and any bucket size specified as an argument to the TIMESERIES keyword. This ensures efficient querying and chart resolution. If you want to override this behavior to view or operate on the raw metric data points, use the optional RAW keyword in your query. When querying these raw metric data points, there is a query time window limit of 48 hours. Any query attempting to access more than 48 hours of raw metric data will result in a query error. This example shows how to list the last 20 data points received for a particular metric: FROM Metric SELECT * WHERE metricName = 'container_fs_usage_bytes' LIMIT 20 RAW Copy Query multiple metrics with wildcards Wildcards are represented in NRQL by the % character. If you want to query multiple metrics that use a standard naming convention, you can use the wildcard feature to return results for all of them without having to specify each metric name individually. Wildcards can help you: Aggregate metrics together and chart the results FACET results by metric name in a chart Find and chart all metrics matching a given naming convention Wildcards are particularly helpful if you later add new metrics matching an existing naming convention. By using % instead of writing out each metric name in your query, you won't have to rewrite the query when you add new metrics. Let's say you have multiple algorithms that perform a similar task. You can define the following metrics, which show the duration of the different algorithms: myNeatProcess.algorithm1.duration myNeatProcess.algorithm2.duration myNeatProcess.algorithm3.duration If used in a query, myNeatProcess.%.duration will return results for all three of the algorithms above. If you later create new algorithms named algorithm4, algorithm5, and algorithm6, the same query will return results for all six algorithms. Chart multiple metrics with wildcards You can chart multiple metrics using a single query by using wildcards (%) in the SELECT clause. For example, to query all the algorithms in the example above and plot a line on the chart for each algorithm's average duration, use the following query: FROM Metric SELECT average(myNeatProcess.%.duration) FACET metricName TIMESERIES Copy Perform mathematical operations on metric data with wildcards You can also use wildcards to perform math operations on multiple metrics and compute a new metric. You can calculate the mean duration for all algorithms listed in the example above: FROM Metric SELECT average(myNeatProcess.%.duration) TIMESERIES Copy You can calculate what percentage of overall runtime a single algorithm takes: FROM Metric SELECT myNeatProcess.algorithm1.duration / sum(myNeatProcess.%.duration) TIMESERIES Copy Explore metric data The NRQL keyset and uniques functions can be used together with the metricName attribute (available on all metrics) to perform tasks like listing all the available metrics in your account or discovering the attributes available on a particular metric. List all metric names in an account FROM Metric SELECT uniques(metricName) Copy List all metric names for a particular host FROM Metric SELECT uniques(metricName) WHERE hostname = 'host1.mycompany.com' Copy Show the attribute keys for a specific metric FROM Metric SELECT keyset() WHERE metricName = METRIC_NAME Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.53325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> the Metric <em>data</em> type",
        "sections": "<em>Query</em> the Metric <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " metrics You can use <em>NRQL</em> to <em>query</em> <em>your</em> metric <em>data</em> in the <em>New</em> <em>Relic</em> One <em>query</em> builder or using our NerdGraph API. To <em>query</em> a metric, use the following <em>query</em> format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each"
      },
      "id": "603ead4564441fd2a74e8851"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-05T00:20:27Z",
      "updated_at": "2021-05-05T00:20:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Here are the available aggregator functions. The definitions below contain example NRQL queries. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.78958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ". Aggregator functions Use aggregator functions to filter and aggregate <em>data</em> in a <em>NRQL</em> <em>query</em>. Some helpful information about using aggregator functions: See the <em>New</em> <em>Relic</em> University <em>tutorials</em> for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing <em>NRQL</em>"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Query the Metric data type",
        "Query APM metric timeslice data",
        "View and query your metrics",
        "View example metric queries",
        "Chart multiple metrics",
        "Perform mathematical operations on metric data",
        "Use filters to select specific time series",
        "View the raw metric data points",
        "Query multiple metrics with wildcards",
        "Chart multiple metrics with wildcards",
        "Perform mathematical operations on metric data with wildcards",
        "Explore metric data",
        "List all metric names in an account",
        "List all metric names for a particular host",
        "Show the attribute keys for a specific metric"
      ],
      "title": "Query the Metric data type",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "09615f55eb5452211f0980a81f4a85e8c758fd61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-data/apis/query-metric-data-type/",
      "published_at": "2021-05-05T00:21:28Z",
      "updated_at": "2021-03-16T17:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When metrics are reported to New Relic via the Metric API (including from integrations that use that API), the data is reported as the Metric data type and is available for querying. This document contains: How to view and query your metrics Example metric queries How to query multiple metrics with wildcards How to explore metric data Query APM metric timeslice data New Relic APM reports a specific type of data that we call metric timeslice data. For how to query that, see Query metric timeslice data. For information about other types of metrics, see Metric data types. View and query your metrics You can use NRQL to query your metric data in the New Relic One query builder or using our NerdGraph API. To query a metric, use the following query format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each metric type: Metric type Supported functions Summary count, sum, min, max, and average Count sum Gauge count, sum, min, max, average, and latest Add the names of the metrics you want to chart with the appropriate value functions in the SELECT clause. The WHERE and FACET clauses can be used with attribute values. Remember to include the keyword TIMESERIES if you want to chart the data. This example demonstrates how you could chart the CPU usage in seconds for cluster foo . This query breaks down CPU usage by container, given a count metric named container_cpu_usage_seconds_total with the attributes containerName and clusterName: FROM Metric select sum(container_cpu_usage_seconds_total) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy If you want the CPU usage per minute (the rate of change), then you can add the rate function to the query above. FROM Metric select rate(sum(container_cpu_usage_seconds_total), 1 minute) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy View example metric queries The previous examples demonstrate basic forms of metric queries, but NRQL can also be used to chart, explore, and analyze metric data. Chart multiple metrics Chart multiple metrics using a single query by providing a comma-separated list of metrics in the SELECT clause. For example, to chart the memory usage for a container along with the memory limit metric, use the following query: FROM Metric SELECT latest(container_memory_usage_bytes), latest(container_spec_memory_limit_bytes) WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Perform mathematical operations on metric data Perform math operations on one or more metrics to compute a new, derived metric. To monitor available memory, you can calculate the percentage of available memory from the two metrics used in the previous example: FROM Metric SELECT (latest(container_spec_memory_limit_bytes) - latest(container_memory_usage_bytes)) / latest(container_spec_memory_limit_bytes) * 100 AS '% Memory Available' WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Use filters to select specific time series In addition to using a WHERE clause which applies to everything in SELECT, NRQL provides another aggregation function called filter which can be used to select a specific time series to be charted or operated on. The following example charts a memory usage metric labeled \"Total (k8s)\" which is computed by adding together the memory usage of two specific containers within a pod: FROM Metric SELECT filter( latest( container_memory_usage_bytes), WHERE containerName = 'discovery') + filter( latest( container_memory_usage_bytes), WHERE containerName = 'istio-proxy') AS 'Total (k8s)' WHERE clusterName = 'my-cluster' AND podName LIKE 'istio-pilot-%' TIMESERIES Copy View the raw metric data points When querying metric data using FROM Metric, New Relic automatically selects the specific aggregate to use in the query, depending on the length of the query window and any bucket size specified as an argument to the TIMESERIES keyword. This ensures efficient querying and chart resolution. If you want to override this behavior to view or operate on the raw metric data points, use the optional RAW keyword in your query. When querying these raw metric data points, there is a query time window limit of 48 hours. Any query attempting to access more than 48 hours of raw metric data will result in a query error. This example shows how to list the last 20 data points received for a particular metric: FROM Metric SELECT * WHERE metricName = 'container_fs_usage_bytes' LIMIT 20 RAW Copy Query multiple metrics with wildcards Wildcards are represented in NRQL by the % character. If you want to query multiple metrics that use a standard naming convention, you can use the wildcard feature to return results for all of them without having to specify each metric name individually. Wildcards can help you: Aggregate metrics together and chart the results FACET results by metric name in a chart Find and chart all metrics matching a given naming convention Wildcards are particularly helpful if you later add new metrics matching an existing naming convention. By using % instead of writing out each metric name in your query, you won't have to rewrite the query when you add new metrics. Let's say you have multiple algorithms that perform a similar task. You can define the following metrics, which show the duration of the different algorithms: myNeatProcess.algorithm1.duration myNeatProcess.algorithm2.duration myNeatProcess.algorithm3.duration If used in a query, myNeatProcess.%.duration will return results for all three of the algorithms above. If you later create new algorithms named algorithm4, algorithm5, and algorithm6, the same query will return results for all six algorithms. Chart multiple metrics with wildcards You can chart multiple metrics using a single query by using wildcards (%) in the SELECT clause. For example, to query all the algorithms in the example above and plot a line on the chart for each algorithm's average duration, use the following query: FROM Metric SELECT average(myNeatProcess.%.duration) FACET metricName TIMESERIES Copy Perform mathematical operations on metric data with wildcards You can also use wildcards to perform math operations on multiple metrics and compute a new metric. You can calculate the mean duration for all algorithms listed in the example above: FROM Metric SELECT average(myNeatProcess.%.duration) TIMESERIES Copy You can calculate what percentage of overall runtime a single algorithm takes: FROM Metric SELECT myNeatProcess.algorithm1.duration / sum(myNeatProcess.%.duration) TIMESERIES Copy Explore metric data The NRQL keyset and uniques functions can be used together with the metricName attribute (available on all metrics) to perform tasks like listing all the available metrics in your account or discovering the attributes available on a particular metric. List all metric names in an account FROM Metric SELECT uniques(metricName) Copy List all metric names for a particular host FROM Metric SELECT uniques(metricName) WHERE hostname = 'host1.mycompany.com' Copy Show the attribute keys for a specific metric FROM Metric SELECT keyset() WHERE metricName = METRIC_NAME Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.53325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> the Metric <em>data</em> type",
        "sections": "<em>Query</em> the Metric <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " metrics You can use <em>NRQL</em> to <em>query</em> <em>your</em> metric <em>data</em> in the <em>New</em> <em>Relic</em> One <em>query</em> builder or using our NerdGraph API. To <em>query</em> a metric, use the following <em>query</em> format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each"
      },
      "id": "603ead4564441fd2a74e8851"
    },
    {
      "sections": [
        "Query APM metric timeslice data with NRQL",
        "Why query metric timeslice data?",
        "Important",
        "Where to query?",
        "How to construct a query",
        "How metric timeslice data is converted",
        "Attributes",
        "Generic queries with the newrelic.timeslice.value metric",
        "When to use newrelic.timeslice.value?",
        "Get available metrics",
        "Facet on a wildcarded metric name segment",
        "Recommended aggregator functions",
        "Query examples",
        "Facet by multiple app names",
        "Throughput-per-minute rate",
        "Facet by host-related attributes",
        "Query of average duration of a metric",
        "Break down average time spent in a transaction by its component segments"
      ],
      "title": "Query APM metric timeslice data with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "82003500c863b2c25015d298ff390304ace9c389",
      "image": "https://docs.newrelic.com/static/4bf93cf4544a5c52d393090982b16eba/c1b63/new-relic-one-nrql-query-metric-timeslice-data.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-apm-metric-timeslice-data-nrql/",
      "published_at": "2021-05-05T03:50:57Z",
      "updated_at": "2021-03-16T16:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "APM reports metric data in the form of metric timeslice data, and you can use NRQL to query, facet, and alert on this type of data. To explore timeslice data in the data explorer, see Explore your metrics. Why query metric timeslice data? We report metrics in several ways. One variety of metric data we call metric timeslice data; this is the type of data used to generate many of the charts in APM, Mobile, and Browser (for more details, see metric timeslice data). Historically, this type of data couldn't be queried via our query language, NRQL. But now we are converting popular APM metrics from metric timeslice data to more-detailed dimensional metric data, which opens them up for querying via NRQL and via our NerdGraph API. This capability allows you to create powerful, in-depth custom visualizations of these important APM metrics. And this includes being able to query your custom metrics. Important You cannot query timeslice metrics in conjunction with dimensional metrics or event data. Any query involving newrelic.timeslice.value or an apm.* metric can only return APM metrics. Where to query? We recommend querying APM metric timeslice data using New Relic One query builder in advanced mode. This experience offers full NRQL functionality, and also gives helpful auto-complete suggestions and feedback on query errors. You can also: Make NRQL queries using our NerdGraph (GraphQL) API Alert on NRQL queries using NRQL alert conditions How to construct a query In APM, some charts have the option to view the NRQL query that generated that chart. This can be a good option for understanding how to query metrics. The NRQL query examined below is slightly modified from the error rate chart on the APM summary page. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE (entity.guid = 'AN_ENTITY_GUID') AND (transactionType = 'Web') SINCE 1 day ago TIMESERIES Copy Here is a breakdown of how the parts of this query work: Query segment What does it do? FROM Metric Metric is one of our core data types, and metric timeslice data is stored as this data type. For general tips on querying Metric data, see Metric query examples. SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) This math generates a count of errors out of a total count of transaction metrics. This query uses the converted metric names. Note that you can use other aggregator functions. WHERE (entity.guid = 'AN_ENTITY_GUID') You must specify at least one data source. You can select a single entity's GUID, as shown here, or you can select multiple sources. This query uses entity.guid, but you can also use appId or appName. AND (transactionType = 'Web') Sets the transaction type to web, meaning that background/non-web transactions won't be counted. SINCE 1 day ago Selecting a time range. TIMESERIES This optional clause displays the results in a time-based chart. For general information on NRQL syntax, including FROM, FACET, and TIMESERIES, see Intro to NRQL. For more queries, see Query examples. How metric timeslice data is converted The conversion of original APM metric timeslice metrics into dimensional metrics that are available for querying is an ongoing process and isn't complete. If you don't see a metric you're looking for in this section, see Generic queries. Here are how the original APM metric timeslice metrics are converted into dimensional metrics: Metric timeslice structure Dimensional metric structure APM metric names are represented as single strings of segments separated by forward slashes. For example, the “Datastore/statement/MySQL/users/select” metric represents the time spent in a select database operation on the users table. A single dimensional metric named apm.service.datastore.operation.duration represents the entire group of datastore metrics. This metric has three attributes representing the data values encoded into the metric name, datastoreType, table and operation: datastoreType = ‘MySQL’ table = ‘users’ operation = ‘select’ Some of the APM metrics made available as dimensional metrics: Metric name Description Attributes apm.service.cpu.usertime.utilization Time spent in user-mode code percentage apm.service.datastore.operation.duration Response time for database calls broken out by table operations datastoreType, table, operation apm.service.error.count Summary error count metrics transactionType apm.service.external.host.duration Response time for external calls broken out by external host name external.host apm.service.instance.count Count of the number of agent instances apm.service.memory.physical Process memory in MB apm.service.transaction.apdex Apdex scores per transaction transactionName, transactionType apm.service.transaction.duration Response time per transaction keyTransactionName, transactionName, transactionType apm.service.transaction.error.count Error counts per transaction keyTransactionName, transactionName, transactionType apm.service.transaction.external.duration External call response time by transaction type transactionType Learn how to see all metrics available to you. To understand more about the general structure of metric timeslice data, including some common examples, see Metric timeslice data. Attributes These attributes are available in addition to the metric-specific attributes listed in the APM metrics table above. Name Description appName The name of the application. appId The ID of the application. entity.guid The GUID of the application. host The host of the monitored process. host.bootId The ID of the boot of the host, if available. host.displayName The display_name of the host, if it was set in the agent. instanceName For Java APM agents, host : port metricName The name of the dimensional metric. metricTimesliceName The timeslice name of the legacy metric. scope (Optional) The timeslice name of the legacy metric that this metric is \"scoped\" to. Metrics with a scope belong to it--their measurements apply to the context of the metric named in the scope attribute. See below for examples. Generic queries with the newrelic.timeslice.value metric For metrics that haven't been converted to dimensional metrics, or for your own custom metrics, we have a dimensional metric named newrelic.timeslice.value. Important We recommend using the dimensional metrics from the table above when possible. When to use newrelic.timeslice.value? Given a metric timeslice name, you can query to see if it has a converted dimensional metric equivalent with this syntax: FROM Metric SELECT uniques(metricName) WHERE metricTimesliceName = 'Datastore/statement/MySQL/test/select' Copy If the only metric name returned is newrelic.timeslice.value, you'll need to query your data using this general approach. Get available metrics To get a list of available metrics for an application, you can use a query like: SELECT uniques(metricTimesliceName) FROM Metric WHERE appName='YOUR_APP_NAME' AND newrelic.timeslice.value IS NOT NULL Copy Facet on a wildcarded metric name segment Some metric timeslice names include attribute values as segments of the metric name. For example, our APM agents report metrics by tracking the duration of external calls using this format: External/{externalHost}/all Copy Here, {externalHost} represents the host name for the outbound network call. Here's an example of a generic newrelic.timeslice.value query of a custom metric that facets on a wildcarded metric segment: FROM Metric SELECT count(newrelic.timeslice.value) WHERE appName = 'MY APP' WITH METRIC_FORMAT 'Custom/Labels/{action}' TIMESERIES FACET action Copy In this query, {action} creates a temporary attribute, action, which is then used by FACET action. You can use any name you want, because it's only an attribute that exists for the duration of the query. You should choose a name that does not conflict with an existing attribute name. Here's another example of a faceted wildcard query: This shows a NRQL query of metric timeslice data that facets the rate of Flask functions by the wildcarded process name. Recommended aggregator functions Recommended NRQL aggregator functions include: apdex average sum count rate uniques Query examples Some examples of querying metric timeslice data: Facet by multiple app names This query uses WHERE… IN to specify two applications and then facet by them: FROM Metric SELECT rate(count(apm.service.transaction.duration), 1 minute) as 'Web throughput' WHERE appName IN ('MY_APPLICATION', 'MY_OTHER_APPLICATION') AND (transactionType = 'Web') FACET appName TIMESERIES Copy Throughput-per-minute rate This query displays requests-per-minute chart using the rate function: FROM Metric SELECT rate(count(apm.service.transaction.duration), 1 minute) as 'HttpDispatcher requests_per_minute' WHERE appName = 'MY_APPLICATION' AND (transactionType = 'Web') TIMESERIES SINCE 3 days ago Copy Facet by host-related attributes This query displays a requests-per-minute chart faceted by host name: FROM Metric SELECT count(apm.service.transaction.duration) as 'HttpDispatcher requests_per_minute' WHERE appName = 'MY_APPLICATION' AND (transactionType = 'Web') TIMESERIES SINCE 3 hours ago FACET host LIMIT 20 Copy Instead of using host, you can facet by other host-related attributes, like host.bootId. Query of average duration of a metric This queries the average duration for a metric using average: FROM Metric SELECT average(apm.service.transaction.duration) as 'HttpDispatcher average duration' WHERE appName = 'MY_APPLICATION' AND (transactionType = 'Web') TIMESERIES SINCE 3 days ago Copy Break down average time spent in a transaction by its component segments This query breaks down the average duration of single transaction (in this case, the show action in the UsersController of a Rails app named MY_APPLICATION) by the top 20 individual segments (database queries, external service calls, garbage collection time, etc.). It reproduces much of the \"Application breakdown\" chart as seen on the Transactions page In New Relic One for a service entity: FROM Metric SELECT average(newrelic.timeslice.value, exclusiveTime: true) as 'duration, seconds' WHERE appName = 'MY_APPLICATION' AND scope = 'Controller/users/show' LIMIT 20 FACET metricTimesliceName TIMESERIES SINCE 3 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.50293,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> APM metric timeslice <em>data</em> with <em>NRQL</em>",
        "sections": "<em>Query</em> APM metric timeslice <em>data</em> with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "APM reports metric <em>data</em> in the form of metric timeslice <em>data</em>, and you can use <em>NRQL</em> to <em>query</em>, facet, and alert on this type of <em>data</em>. To explore timeslice <em>data</em> in the <em>data</em> explorer, see Explore <em>your</em> metrics. Why <em>query</em> metric timeslice <em>data</em>? We report metrics in several ways. One variety of metric"
      },
      "id": "603e803a64441fd8804e8879"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-query-examples-mobile-monitoring": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-05T00:20:27Z",
      "updated_at": "2021-05-05T00:20:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Here are the available aggregator functions. The definitions below contain example NRQL queries. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.78958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ". Aggregator functions Use aggregator functions to filter and aggregate <em>data</em> in a <em>NRQL</em> <em>query</em>. Some helpful information about using aggregator functions: See the <em>New</em> <em>Relic</em> University <em>tutorials</em> for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing <em>NRQL</em>"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-05T00:20:24Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.46857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Query the Metric data type",
        "Query APM metric timeslice data",
        "View and query your metrics",
        "View example metric queries",
        "Chart multiple metrics",
        "Perform mathematical operations on metric data",
        "Use filters to select specific time series",
        "View the raw metric data points",
        "Query multiple metrics with wildcards",
        "Chart multiple metrics with wildcards",
        "Perform mathematical operations on metric data with wildcards",
        "Explore metric data",
        "List all metric names in an account",
        "List all metric names for a particular host",
        "Show the attribute keys for a specific metric"
      ],
      "title": "Query the Metric data type",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "09615f55eb5452211f0980a81f4a85e8c758fd61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-data/apis/query-metric-data-type/",
      "published_at": "2021-05-05T00:21:28Z",
      "updated_at": "2021-03-16T17:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When metrics are reported to New Relic via the Metric API (including from integrations that use that API), the data is reported as the Metric data type and is available for querying. This document contains: How to view and query your metrics Example metric queries How to query multiple metrics with wildcards How to explore metric data Query APM metric timeslice data New Relic APM reports a specific type of data that we call metric timeslice data. For how to query that, see Query metric timeslice data. For information about other types of metrics, see Metric data types. View and query your metrics You can use NRQL to query your metric data in the New Relic One query builder or using our NerdGraph API. To query a metric, use the following query format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each metric type: Metric type Supported functions Summary count, sum, min, max, and average Count sum Gauge count, sum, min, max, average, and latest Add the names of the metrics you want to chart with the appropriate value functions in the SELECT clause. The WHERE and FACET clauses can be used with attribute values. Remember to include the keyword TIMESERIES if you want to chart the data. This example demonstrates how you could chart the CPU usage in seconds for cluster foo . This query breaks down CPU usage by container, given a count metric named container_cpu_usage_seconds_total with the attributes containerName and clusterName: FROM Metric select sum(container_cpu_usage_seconds_total) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy If you want the CPU usage per minute (the rate of change), then you can add the rate function to the query above. FROM Metric select rate(sum(container_cpu_usage_seconds_total), 1 minute) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy View example metric queries The previous examples demonstrate basic forms of metric queries, but NRQL can also be used to chart, explore, and analyze metric data. Chart multiple metrics Chart multiple metrics using a single query by providing a comma-separated list of metrics in the SELECT clause. For example, to chart the memory usage for a container along with the memory limit metric, use the following query: FROM Metric SELECT latest(container_memory_usage_bytes), latest(container_spec_memory_limit_bytes) WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Perform mathematical operations on metric data Perform math operations on one or more metrics to compute a new, derived metric. To monitor available memory, you can calculate the percentage of available memory from the two metrics used in the previous example: FROM Metric SELECT (latest(container_spec_memory_limit_bytes) - latest(container_memory_usage_bytes)) / latest(container_spec_memory_limit_bytes) * 100 AS '% Memory Available' WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Use filters to select specific time series In addition to using a WHERE clause which applies to everything in SELECT, NRQL provides another aggregation function called filter which can be used to select a specific time series to be charted or operated on. The following example charts a memory usage metric labeled \"Total (k8s)\" which is computed by adding together the memory usage of two specific containers within a pod: FROM Metric SELECT filter( latest( container_memory_usage_bytes), WHERE containerName = 'discovery') + filter( latest( container_memory_usage_bytes), WHERE containerName = 'istio-proxy') AS 'Total (k8s)' WHERE clusterName = 'my-cluster' AND podName LIKE 'istio-pilot-%' TIMESERIES Copy View the raw metric data points When querying metric data using FROM Metric, New Relic automatically selects the specific aggregate to use in the query, depending on the length of the query window and any bucket size specified as an argument to the TIMESERIES keyword. This ensures efficient querying and chart resolution. If you want to override this behavior to view or operate on the raw metric data points, use the optional RAW keyword in your query. When querying these raw metric data points, there is a query time window limit of 48 hours. Any query attempting to access more than 48 hours of raw metric data will result in a query error. This example shows how to list the last 20 data points received for a particular metric: FROM Metric SELECT * WHERE metricName = 'container_fs_usage_bytes' LIMIT 20 RAW Copy Query multiple metrics with wildcards Wildcards are represented in NRQL by the % character. If you want to query multiple metrics that use a standard naming convention, you can use the wildcard feature to return results for all of them without having to specify each metric name individually. Wildcards can help you: Aggregate metrics together and chart the results FACET results by metric name in a chart Find and chart all metrics matching a given naming convention Wildcards are particularly helpful if you later add new metrics matching an existing naming convention. By using % instead of writing out each metric name in your query, you won't have to rewrite the query when you add new metrics. Let's say you have multiple algorithms that perform a similar task. You can define the following metrics, which show the duration of the different algorithms: myNeatProcess.algorithm1.duration myNeatProcess.algorithm2.duration myNeatProcess.algorithm3.duration If used in a query, myNeatProcess.%.duration will return results for all three of the algorithms above. If you later create new algorithms named algorithm4, algorithm5, and algorithm6, the same query will return results for all six algorithms. Chart multiple metrics with wildcards You can chart multiple metrics using a single query by using wildcards (%) in the SELECT clause. For example, to query all the algorithms in the example above and plot a line on the chart for each algorithm's average duration, use the following query: FROM Metric SELECT average(myNeatProcess.%.duration) FACET metricName TIMESERIES Copy Perform mathematical operations on metric data with wildcards You can also use wildcards to perform math operations on multiple metrics and compute a new metric. You can calculate the mean duration for all algorithms listed in the example above: FROM Metric SELECT average(myNeatProcess.%.duration) TIMESERIES Copy You can calculate what percentage of overall runtime a single algorithm takes: FROM Metric SELECT myNeatProcess.algorithm1.duration / sum(myNeatProcess.%.duration) TIMESERIES Copy Explore metric data The NRQL keyset and uniques functions can be used together with the metricName attribute (available on all metrics) to perform tasks like listing all the available metrics in your account or discovering the attributes available on a particular metric. List all metric names in an account FROM Metric SELECT uniques(metricName) Copy List all metric names for a particular host FROM Metric SELECT uniques(metricName) WHERE hostname = 'host1.mycompany.com' Copy Show the attribute keys for a specific metric FROM Metric SELECT keyset() WHERE metricName = METRIC_NAME Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.53325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> the Metric <em>data</em> type",
        "sections": "<em>Query</em> the Metric <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " metrics You can use <em>NRQL</em> to <em>query</em> <em>your</em> metric <em>data</em> in the <em>New</em> <em>Relic</em> One <em>query</em> builder or using our NerdGraph API. To <em>query</em> a metric, use the following <em>query</em> format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each"
      },
      "id": "603ead4564441fd2a74e8851"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-segment-your-data-buckets": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-05T00:20:27Z",
      "updated_at": "2021-05-05T00:20:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Here are the available aggregator functions. The definitions below contain example NRQL queries. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.78943,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ". Aggregator functions Use aggregator functions to filter and aggregate <em>data</em> in a <em>NRQL</em> <em>query</em>. Some helpful information about using aggregator functions: See the <em>New</em> <em>Relic</em> University <em>tutorials</em> for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing <em>NRQL</em>"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-05T00:20:24Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.46854,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Query the Metric data type",
        "Query APM metric timeslice data",
        "View and query your metrics",
        "View example metric queries",
        "Chart multiple metrics",
        "Perform mathematical operations on metric data",
        "Use filters to select specific time series",
        "View the raw metric data points",
        "Query multiple metrics with wildcards",
        "Chart multiple metrics with wildcards",
        "Perform mathematical operations on metric data with wildcards",
        "Explore metric data",
        "List all metric names in an account",
        "List all metric names for a particular host",
        "Show the attribute keys for a specific metric"
      ],
      "title": "Query the Metric data type",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "09615f55eb5452211f0980a81f4a85e8c758fd61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-data/apis/query-metric-data-type/",
      "published_at": "2021-05-05T00:21:28Z",
      "updated_at": "2021-03-16T17:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When metrics are reported to New Relic via the Metric API (including from integrations that use that API), the data is reported as the Metric data type and is available for querying. This document contains: How to view and query your metrics Example metric queries How to query multiple metrics with wildcards How to explore metric data Query APM metric timeslice data New Relic APM reports a specific type of data that we call metric timeslice data. For how to query that, see Query metric timeslice data. For information about other types of metrics, see Metric data types. View and query your metrics You can use NRQL to query your metric data in the New Relic One query builder or using our NerdGraph API. To query a metric, use the following query format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each metric type: Metric type Supported functions Summary count, sum, min, max, and average Count sum Gauge count, sum, min, max, average, and latest Add the names of the metrics you want to chart with the appropriate value functions in the SELECT clause. The WHERE and FACET clauses can be used with attribute values. Remember to include the keyword TIMESERIES if you want to chart the data. This example demonstrates how you could chart the CPU usage in seconds for cluster foo . This query breaks down CPU usage by container, given a count metric named container_cpu_usage_seconds_total with the attributes containerName and clusterName: FROM Metric select sum(container_cpu_usage_seconds_total) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy If you want the CPU usage per minute (the rate of change), then you can add the rate function to the query above. FROM Metric select rate(sum(container_cpu_usage_seconds_total), 1 minute) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy View example metric queries The previous examples demonstrate basic forms of metric queries, but NRQL can also be used to chart, explore, and analyze metric data. Chart multiple metrics Chart multiple metrics using a single query by providing a comma-separated list of metrics in the SELECT clause. For example, to chart the memory usage for a container along with the memory limit metric, use the following query: FROM Metric SELECT latest(container_memory_usage_bytes), latest(container_spec_memory_limit_bytes) WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Perform mathematical operations on metric data Perform math operations on one or more metrics to compute a new, derived metric. To monitor available memory, you can calculate the percentage of available memory from the two metrics used in the previous example: FROM Metric SELECT (latest(container_spec_memory_limit_bytes) - latest(container_memory_usage_bytes)) / latest(container_spec_memory_limit_bytes) * 100 AS '% Memory Available' WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Use filters to select specific time series In addition to using a WHERE clause which applies to everything in SELECT, NRQL provides another aggregation function called filter which can be used to select a specific time series to be charted or operated on. The following example charts a memory usage metric labeled \"Total (k8s)\" which is computed by adding together the memory usage of two specific containers within a pod: FROM Metric SELECT filter( latest( container_memory_usage_bytes), WHERE containerName = 'discovery') + filter( latest( container_memory_usage_bytes), WHERE containerName = 'istio-proxy') AS 'Total (k8s)' WHERE clusterName = 'my-cluster' AND podName LIKE 'istio-pilot-%' TIMESERIES Copy View the raw metric data points When querying metric data using FROM Metric, New Relic automatically selects the specific aggregate to use in the query, depending on the length of the query window and any bucket size specified as an argument to the TIMESERIES keyword. This ensures efficient querying and chart resolution. If you want to override this behavior to view or operate on the raw metric data points, use the optional RAW keyword in your query. When querying these raw metric data points, there is a query time window limit of 48 hours. Any query attempting to access more than 48 hours of raw metric data will result in a query error. This example shows how to list the last 20 data points received for a particular metric: FROM Metric SELECT * WHERE metricName = 'container_fs_usage_bytes' LIMIT 20 RAW Copy Query multiple metrics with wildcards Wildcards are represented in NRQL by the % character. If you want to query multiple metrics that use a standard naming convention, you can use the wildcard feature to return results for all of them without having to specify each metric name individually. Wildcards can help you: Aggregate metrics together and chart the results FACET results by metric name in a chart Find and chart all metrics matching a given naming convention Wildcards are particularly helpful if you later add new metrics matching an existing naming convention. By using % instead of writing out each metric name in your query, you won't have to rewrite the query when you add new metrics. Let's say you have multiple algorithms that perform a similar task. You can define the following metrics, which show the duration of the different algorithms: myNeatProcess.algorithm1.duration myNeatProcess.algorithm2.duration myNeatProcess.algorithm3.duration If used in a query, myNeatProcess.%.duration will return results for all three of the algorithms above. If you later create new algorithms named algorithm4, algorithm5, and algorithm6, the same query will return results for all six algorithms. Chart multiple metrics with wildcards You can chart multiple metrics using a single query by using wildcards (%) in the SELECT clause. For example, to query all the algorithms in the example above and plot a line on the chart for each algorithm's average duration, use the following query: FROM Metric SELECT average(myNeatProcess.%.duration) FACET metricName TIMESERIES Copy Perform mathematical operations on metric data with wildcards You can also use wildcards to perform math operations on multiple metrics and compute a new metric. You can calculate the mean duration for all algorithms listed in the example above: FROM Metric SELECT average(myNeatProcess.%.duration) TIMESERIES Copy You can calculate what percentage of overall runtime a single algorithm takes: FROM Metric SELECT myNeatProcess.algorithm1.duration / sum(myNeatProcess.%.duration) TIMESERIES Copy Explore metric data The NRQL keyset and uniques functions can be used together with the metricName attribute (available on all metrics) to perform tasks like listing all the available metrics in your account or discovering the attributes available on a particular metric. List all metric names in an account FROM Metric SELECT uniques(metricName) Copy List all metric names for a particular host FROM Metric SELECT uniques(metricName) WHERE hostname = 'host1.mycompany.com' Copy Show the attribute keys for a specific metric FROM Metric SELECT keyset() WHERE metricName = METRIC_NAME Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.53323,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> the Metric <em>data</em> type",
        "sections": "<em>Query</em> the Metric <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " metrics You can use <em>NRQL</em> to <em>query</em> <em>your</em> metric <em>data</em> in the <em>New</em> <em>Relic</em> One <em>query</em> builder or using our NerdGraph API. To <em>query</em> a metric, use the following <em>query</em> format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each"
      },
      "id": "603ead4564441fd2a74e8851"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-apm-metric-timeslice-data-nrql": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-05T00:20:27Z",
      "updated_at": "2021-05-05T00:20:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Here are the available aggregator functions. The definitions below contain example NRQL queries. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.78943,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ". Aggregator functions Use aggregator functions to filter and aggregate <em>data</em> in a <em>NRQL</em> <em>query</em>. Some helpful information about using aggregator functions: See the <em>New</em> <em>Relic</em> University <em>tutorials</em> for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing <em>NRQL</em>"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-05T00:20:24Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.46854,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Query the Metric data type",
        "Query APM metric timeslice data",
        "View and query your metrics",
        "View example metric queries",
        "Chart multiple metrics",
        "Perform mathematical operations on metric data",
        "Use filters to select specific time series",
        "View the raw metric data points",
        "Query multiple metrics with wildcards",
        "Chart multiple metrics with wildcards",
        "Perform mathematical operations on metric data with wildcards",
        "Explore metric data",
        "List all metric names in an account",
        "List all metric names for a particular host",
        "Show the attribute keys for a specific metric"
      ],
      "title": "Query the Metric data type",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "09615f55eb5452211f0980a81f4a85e8c758fd61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-data/apis/query-metric-data-type/",
      "published_at": "2021-05-05T00:21:28Z",
      "updated_at": "2021-03-16T17:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When metrics are reported to New Relic via the Metric API (including from integrations that use that API), the data is reported as the Metric data type and is available for querying. This document contains: How to view and query your metrics Example metric queries How to query multiple metrics with wildcards How to explore metric data Query APM metric timeslice data New Relic APM reports a specific type of data that we call metric timeslice data. For how to query that, see Query metric timeslice data. For information about other types of metrics, see Metric data types. View and query your metrics You can use NRQL to query your metric data in the New Relic One query builder or using our NerdGraph API. To query a metric, use the following query format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each metric type: Metric type Supported functions Summary count, sum, min, max, and average Count sum Gauge count, sum, min, max, average, and latest Add the names of the metrics you want to chart with the appropriate value functions in the SELECT clause. The WHERE and FACET clauses can be used with attribute values. Remember to include the keyword TIMESERIES if you want to chart the data. This example demonstrates how you could chart the CPU usage in seconds for cluster foo . This query breaks down CPU usage by container, given a count metric named container_cpu_usage_seconds_total with the attributes containerName and clusterName: FROM Metric select sum(container_cpu_usage_seconds_total) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy If you want the CPU usage per minute (the rate of change), then you can add the rate function to the query above. FROM Metric select rate(sum(container_cpu_usage_seconds_total), 1 minute) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy View example metric queries The previous examples demonstrate basic forms of metric queries, but NRQL can also be used to chart, explore, and analyze metric data. Chart multiple metrics Chart multiple metrics using a single query by providing a comma-separated list of metrics in the SELECT clause. For example, to chart the memory usage for a container along with the memory limit metric, use the following query: FROM Metric SELECT latest(container_memory_usage_bytes), latest(container_spec_memory_limit_bytes) WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Perform mathematical operations on metric data Perform math operations on one or more metrics to compute a new, derived metric. To monitor available memory, you can calculate the percentage of available memory from the two metrics used in the previous example: FROM Metric SELECT (latest(container_spec_memory_limit_bytes) - latest(container_memory_usage_bytes)) / latest(container_spec_memory_limit_bytes) * 100 AS '% Memory Available' WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Use filters to select specific time series In addition to using a WHERE clause which applies to everything in SELECT, NRQL provides another aggregation function called filter which can be used to select a specific time series to be charted or operated on. The following example charts a memory usage metric labeled \"Total (k8s)\" which is computed by adding together the memory usage of two specific containers within a pod: FROM Metric SELECT filter( latest( container_memory_usage_bytes), WHERE containerName = 'discovery') + filter( latest( container_memory_usage_bytes), WHERE containerName = 'istio-proxy') AS 'Total (k8s)' WHERE clusterName = 'my-cluster' AND podName LIKE 'istio-pilot-%' TIMESERIES Copy View the raw metric data points When querying metric data using FROM Metric, New Relic automatically selects the specific aggregate to use in the query, depending on the length of the query window and any bucket size specified as an argument to the TIMESERIES keyword. This ensures efficient querying and chart resolution. If you want to override this behavior to view or operate on the raw metric data points, use the optional RAW keyword in your query. When querying these raw metric data points, there is a query time window limit of 48 hours. Any query attempting to access more than 48 hours of raw metric data will result in a query error. This example shows how to list the last 20 data points received for a particular metric: FROM Metric SELECT * WHERE metricName = 'container_fs_usage_bytes' LIMIT 20 RAW Copy Query multiple metrics with wildcards Wildcards are represented in NRQL by the % character. If you want to query multiple metrics that use a standard naming convention, you can use the wildcard feature to return results for all of them without having to specify each metric name individually. Wildcards can help you: Aggregate metrics together and chart the results FACET results by metric name in a chart Find and chart all metrics matching a given naming convention Wildcards are particularly helpful if you later add new metrics matching an existing naming convention. By using % instead of writing out each metric name in your query, you won't have to rewrite the query when you add new metrics. Let's say you have multiple algorithms that perform a similar task. You can define the following metrics, which show the duration of the different algorithms: myNeatProcess.algorithm1.duration myNeatProcess.algorithm2.duration myNeatProcess.algorithm3.duration If used in a query, myNeatProcess.%.duration will return results for all three of the algorithms above. If you later create new algorithms named algorithm4, algorithm5, and algorithm6, the same query will return results for all six algorithms. Chart multiple metrics with wildcards You can chart multiple metrics using a single query by using wildcards (%) in the SELECT clause. For example, to query all the algorithms in the example above and plot a line on the chart for each algorithm's average duration, use the following query: FROM Metric SELECT average(myNeatProcess.%.duration) FACET metricName TIMESERIES Copy Perform mathematical operations on metric data with wildcards You can also use wildcards to perform math operations on multiple metrics and compute a new metric. You can calculate the mean duration for all algorithms listed in the example above: FROM Metric SELECT average(myNeatProcess.%.duration) TIMESERIES Copy You can calculate what percentage of overall runtime a single algorithm takes: FROM Metric SELECT myNeatProcess.algorithm1.duration / sum(myNeatProcess.%.duration) TIMESERIES Copy Explore metric data The NRQL keyset and uniques functions can be used together with the metricName attribute (available on all metrics) to perform tasks like listing all the available metrics in your account or discovering the attributes available on a particular metric. List all metric names in an account FROM Metric SELECT uniques(metricName) Copy List all metric names for a particular host FROM Metric SELECT uniques(metricName) WHERE hostname = 'host1.mycompany.com' Copy Show the attribute keys for a specific metric FROM Metric SELECT keyset() WHERE metricName = METRIC_NAME Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.53323,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> the Metric <em>data</em> type",
        "sections": "<em>Query</em> the Metric <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " metrics You can use <em>NRQL</em> to <em>query</em> <em>your</em> metric <em>data</em> in the <em>New</em> <em>Relic</em> One <em>query</em> builder or using our NerdGraph API. To <em>query</em> a metric, use the following <em>query</em> format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each"
      },
      "id": "603ead4564441fd2a74e8851"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-05T00:20:27Z",
      "updated_at": "2021-05-05T00:20:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Here are the available aggregator functions. The definitions below contain example NRQL queries. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.78925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ". Aggregator functions Use aggregator functions to filter and aggregate <em>data</em> in a <em>NRQL</em> <em>query</em>. Some helpful information about using aggregator functions: See the <em>New</em> <em>Relic</em> University <em>tutorials</em> for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing <em>NRQL</em>"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-05T00:20:24Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.4685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Query the Metric data type",
        "Query APM metric timeslice data",
        "View and query your metrics",
        "View example metric queries",
        "Chart multiple metrics",
        "Perform mathematical operations on metric data",
        "Use filters to select specific time series",
        "View the raw metric data points",
        "Query multiple metrics with wildcards",
        "Chart multiple metrics with wildcards",
        "Perform mathematical operations on metric data with wildcards",
        "Explore metric data",
        "List all metric names in an account",
        "List all metric names for a particular host",
        "Show the attribute keys for a specific metric"
      ],
      "title": "Query the Metric data type",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "09615f55eb5452211f0980a81f4a85e8c758fd61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-data/apis/query-metric-data-type/",
      "published_at": "2021-05-05T00:21:28Z",
      "updated_at": "2021-03-16T17:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When metrics are reported to New Relic via the Metric API (including from integrations that use that API), the data is reported as the Metric data type and is available for querying. This document contains: How to view and query your metrics Example metric queries How to query multiple metrics with wildcards How to explore metric data Query APM metric timeslice data New Relic APM reports a specific type of data that we call metric timeslice data. For how to query that, see Query metric timeslice data. For information about other types of metrics, see Metric data types. View and query your metrics You can use NRQL to query your metric data in the New Relic One query builder or using our NerdGraph API. To query a metric, use the following query format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each metric type: Metric type Supported functions Summary count, sum, min, max, and average Count sum Gauge count, sum, min, max, average, and latest Add the names of the metrics you want to chart with the appropriate value functions in the SELECT clause. The WHERE and FACET clauses can be used with attribute values. Remember to include the keyword TIMESERIES if you want to chart the data. This example demonstrates how you could chart the CPU usage in seconds for cluster foo . This query breaks down CPU usage by container, given a count metric named container_cpu_usage_seconds_total with the attributes containerName and clusterName: FROM Metric select sum(container_cpu_usage_seconds_total) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy If you want the CPU usage per minute (the rate of change), then you can add the rate function to the query above. FROM Metric select rate(sum(container_cpu_usage_seconds_total), 1 minute) WHERE clusterName = 'foo' FACET containerName TIMESERIES Copy View example metric queries The previous examples demonstrate basic forms of metric queries, but NRQL can also be used to chart, explore, and analyze metric data. Chart multiple metrics Chart multiple metrics using a single query by providing a comma-separated list of metrics in the SELECT clause. For example, to chart the memory usage for a container along with the memory limit metric, use the following query: FROM Metric SELECT latest(container_memory_usage_bytes), latest(container_spec_memory_limit_bytes) WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Perform mathematical operations on metric data Perform math operations on one or more metrics to compute a new, derived metric. To monitor available memory, you can calculate the percentage of available memory from the two metrics used in the previous example: FROM Metric SELECT (latest(container_spec_memory_limit_bytes) - latest(container_memory_usage_bytes)) / latest(container_spec_memory_limit_bytes) * 100 AS '% Memory Available' WHERE containerName = 'inventory' TIMESERIES Copy You can also do this using wildcards, as explained below. Use filters to select specific time series In addition to using a WHERE clause which applies to everything in SELECT, NRQL provides another aggregation function called filter which can be used to select a specific time series to be charted or operated on. The following example charts a memory usage metric labeled \"Total (k8s)\" which is computed by adding together the memory usage of two specific containers within a pod: FROM Metric SELECT filter( latest( container_memory_usage_bytes), WHERE containerName = 'discovery') + filter( latest( container_memory_usage_bytes), WHERE containerName = 'istio-proxy') AS 'Total (k8s)' WHERE clusterName = 'my-cluster' AND podName LIKE 'istio-pilot-%' TIMESERIES Copy View the raw metric data points When querying metric data using FROM Metric, New Relic automatically selects the specific aggregate to use in the query, depending on the length of the query window and any bucket size specified as an argument to the TIMESERIES keyword. This ensures efficient querying and chart resolution. If you want to override this behavior to view or operate on the raw metric data points, use the optional RAW keyword in your query. When querying these raw metric data points, there is a query time window limit of 48 hours. Any query attempting to access more than 48 hours of raw metric data will result in a query error. This example shows how to list the last 20 data points received for a particular metric: FROM Metric SELECT * WHERE metricName = 'container_fs_usage_bytes' LIMIT 20 RAW Copy Query multiple metrics with wildcards Wildcards are represented in NRQL by the % character. If you want to query multiple metrics that use a standard naming convention, you can use the wildcard feature to return results for all of them without having to specify each metric name individually. Wildcards can help you: Aggregate metrics together and chart the results FACET results by metric name in a chart Find and chart all metrics matching a given naming convention Wildcards are particularly helpful if you later add new metrics matching an existing naming convention. By using % instead of writing out each metric name in your query, you won't have to rewrite the query when you add new metrics. Let's say you have multiple algorithms that perform a similar task. You can define the following metrics, which show the duration of the different algorithms: myNeatProcess.algorithm1.duration myNeatProcess.algorithm2.duration myNeatProcess.algorithm3.duration If used in a query, myNeatProcess.%.duration will return results for all three of the algorithms above. If you later create new algorithms named algorithm4, algorithm5, and algorithm6, the same query will return results for all six algorithms. Chart multiple metrics with wildcards You can chart multiple metrics using a single query by using wildcards (%) in the SELECT clause. For example, to query all the algorithms in the example above and plot a line on the chart for each algorithm's average duration, use the following query: FROM Metric SELECT average(myNeatProcess.%.duration) FACET metricName TIMESERIES Copy Perform mathematical operations on metric data with wildcards You can also use wildcards to perform math operations on multiple metrics and compute a new metric. You can calculate the mean duration for all algorithms listed in the example above: FROM Metric SELECT average(myNeatProcess.%.duration) TIMESERIES Copy You can calculate what percentage of overall runtime a single algorithm takes: FROM Metric SELECT myNeatProcess.algorithm1.duration / sum(myNeatProcess.%.duration) TIMESERIES Copy Explore metric data The NRQL keyset and uniques functions can be used together with the metricName attribute (available on all metrics) to perform tasks like listing all the available metrics in your account or discovering the attributes available on a particular metric. List all metric names in an account FROM Metric SELECT uniques(metricName) Copy List all metric names for a particular host FROM Metric SELECT uniques(metricName) WHERE hostname = 'host1.mycompany.com' Copy Show the attribute keys for a specific metric FROM Metric SELECT keyset() WHERE metricName = METRIC_NAME Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.53323,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> the Metric <em>data</em> type",
        "sections": "<em>Query</em> the Metric <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " metrics You can use <em>NRQL</em> to <em>query</em> <em>your</em> metric <em>data</em> in the <em>New</em> <em>Relic</em> One <em>query</em> builder or using our NerdGraph API. To <em>query</em> a metric, use the following <em>query</em> format: FROM Metric SELECT function(metric_name) WHERE attribute=value FACET attribute TIMESERIES Copy Below are the functions supported for each"
      },
      "id": "603ead4564441fd2a74e8851"
    }
  ],
  "/docs/recommended-alerts-aws-services": [
    {
      "sections": [
        "Update serverless monitoring for AWS Lambda",
        "Important",
        "Update our Lambda integration via CLI",
        "Update layers via CLI",
        "Update a manual Serverless application repository install",
        "Enabling log management",
        "Caution"
      ],
      "title": "Update serverless monitoring for AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "7075499bcc9b1ff1e346a705ab414adcca54fd09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/update-serverless-monitoring-aws-lambda/",
      "published_at": "2021-05-06T03:23:18Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After enabling our monitoring for AWS Lambda, you should occasionally update our Lambda function that's used to report AWS log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our Lambda monitoring using our CLI tool. Update via AWS Serverless Application Repository: Use this if you enabled using the manual procedure. Important These update procedures apply to our serverless monitoring for AWS Lambda, and not to our infrastructure monitoring for AWS Lambda integration. Update our Lambda integration via CLI This section describes how to update if your Lambda monitoring was enabled using our recommended CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region identifier (for example, us-west-2). newrelic-lambda integrations update \\ --aws-region YOUR_REGION Copy If you do not have our logs enabled, you'll also need to update your Amazon CloudWatch log subscription filters with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --aws-region YOUR_REGION Copy Update layers via CLI This section describes how to update your function's Layer if you installed it with our CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy Pass the --upgrade flag to the install command: newrelic-lambda layers install \\ --function installed \\ --nr-account-id NR_ACCOUNT_ID \\ --upgrade Copy Update a manual Serverless application repository install If you manually installed the ingest function from the AWS Serverless Application Repository (and didn't use the CLI), update using this procedure: Run the following, replacing YOUR_REGION with your region (for example, us-west-2). aws serverlessrepo create-cloud-formation-change-set \\ --application-id arn:aws:serverlessrepo:us-east-1:463657938898:applications/NewRelic-log-ingestion \\ --stack-name NewRelic-log-ingestion \\ --capabilities CAPABILITY_RESOURCE_POLICY \\ --region YOUR_REGION Copy This command outputs several fields, one of which is the ChangeSetId: an ARN for the change set that you just created. Copy that ARN. Use the ARN in this command, which executes the change set: aws cloudformation execute-change-set --change-set-name YOUR_CHANGE_SET_ARN Copy Enabling log management If you currently don't have New Relic's log management enabled, but would like to: Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region (for example, us-west-2). newrelic-lambda integrations update \\ --enable-logs \\ --aws-region YOUR_REGION Copy Then do either of the following: Update your Amazon CloudWatch log subscription filters for each region with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --filter-pattern \"\" \\ --aws-region YOUR_REGION Copy Or, you can send function logs to New Relic directly, bypassing CloudWatch and the newrelic-log-ingestion Lambda. To do this, set the environment variable NEW_RELIC_EXTENSION_SEND_FUNCTION_LOGS=true in your Lambda function configuration. After that, be sure to remove any existing New Relic log subscriptions for that function using this command: newrelic-lambda subscriptions uninstall \\ --function FUNCTION_NAME \\ --aws-region YOUR_REGION Copy If the log subscription is present while the extension is sending logs, logs will be sent twice, resulting in duplicate log records in New Relic. Optionally, if you'd like to avoid Amazon's charges for CloudWatch Log ingestion, you can also modify your function's execution role so that it doesn't grant the CloudWatch Log permissions. This will prevent your function from logging to CloudWatch. Caution CloudWatch Logs ingest fees can be considerable, but this step should be taken with caution. Make sure your New Relic log ingestion integration is working well and meeting your needs before disabling CloudWatch logs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.45596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update serverless monitoring <em>for</em> <em>AWS</em> Lambda",
        "sections": "Update serverless monitoring <em>for</em> <em>AWS</em> Lambda",
        "tags": "<em>AWS</em> Lambda monitoring",
        "body": "After enabling our monitoring for <em>AWS</em> Lambda, you should occasionally update our Lambda function that&#x27;s used to report <em>AWS</em> log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our Lambda monitoring using our CLI tool. Update via <em>AWS</em> Serverless"
      },
      "id": "6045248c28ccbc98a82c606b"
    },
    {
      "sections": [
        "Link your AWS and New Relic accounts",
        "AWS permissions details",
        "Recommended method: The newrelic-lambda CLI",
        "Requirements",
        "CLI user AWS permissions details",
        "Integrate with CLI",
        "AWS regions and profiles",
        "Tip",
        "Alternative method",
        "Linking accounts manually",
        "The Infrastructure UI",
        "Manually Configuring the License Key Secret",
        "Troubleshooting",
        "Cannot Use AWS secrets manager",
        "Multiple AWS regions and accounts",
        "Failure to retrieve license key AccessDeniedException"
      ],
      "title": "Link your AWS and New Relic accounts",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Account Linking"
      ],
      "external_id": "8fdeff9ad6419bbcfbb1d35aeb8985cd6b43200c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/account-linking/",
      "published_at": "2021-05-06T02:45:39Z",
      "updated_at": "2021-05-06T02:45:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you link your AWS account to New Relic, you're granting permission to New Relic to create an inventory of your AWS account, and gather CloudWatch metrics for your Lambda functions. Resources in your AWS account then show up as entities in the entity explorer, decorated with config information. AWS permissions details To create this inventory, we need an IAM role that grants these IAM permissions, at a minimum: Resource: \"*\" Action: \"cloudwatch:GetMetricStatistics\" \"cloudwatch:ListMetrics\" \"cloudwatch:GetMetricData\" \"lambda:GetAccountSettings\" \"lambda:ListFunctions\" \"lambda:ListAliases\" \"lambda:ListTags\" \"lambda:ListEventSourceMappings\" Copy By default, we use the AWS Managed Policy ReadOnlyAccess. This allows the Infrastructure integration to see all the resources in your account, rather than just your Lambda functions and CloudWatch metrics. New Relic recommends this default, but we understand that some organizations have a very conservative security posture for third party integrations. A role with the permissions above is sufficient to allow Lambda telemetry collection, though traces that interact with other services may not work well. In this integration step, we'll also store your New Relic License Key in the AWS Secrets Manager service, so that we can send your telemetry to your New Relic account. Recommended method: The newrelic-lambda CLI Requirements To enable serverless monitoring using our Lambda layer, you need the following: AWS CLI v2 installed and configured using aws configure. Python version 3.3 or higher installed. newrelic-lambda CLI, which you can install by running pip3 install newrelic-lambda-cli. A New Relic account. You must be an admin, or have the Infrastructure manager add-on role. A user key. An AWS account with permissions for creating IAM resources, managed secrets, and Lambdas. You also need permissions for creating CloudFormation stacks and S3 buckets. CLI user AWS permissions details The CLI uses the AWS SDK to interact with AWS. The SDK will act using the same default profile as the AWS CLI. This profile needs, at a minimum, the following AWS permissions to run the CLI. Resource: * Actions: \"cloudformation:CreateChangeSet\", \"cloudformation:CreateStack\", \"cloudformation:DescribeStacks\", \"cloudformation:ExecuteChangeSets\", \"iam:AttachRolePolicy\", \"iam:CreateRole\", \"iam:GetRole\", \"iam:PassRole\", \"lambda:AddPermission\", \"lambda:CreateFunction\", \"lambda:GetFunction\", \"logs:DeleteSubscriptionFilter\", \"logs:DescribeSubscriptionFilters\", \"logs:PutSubscriptionFilter\" \"s3:GetObject\" \"serverlessrepo:CreateCloudFormationChangeSet\" \"secretsmanager:CreateSecret\" Resource: \"arn:aws:serverlessrepo:us-east-1:463657938898:applications/NewRelic-log-ingestion\" Actions: \"serverlessrepo:CreateCloudFormationTemplate\" \"serverlessrepo:GetCloudFormationTemplate\" Copy Integrate with CLI When all the requirements are in place, link your AWS account with your New Relic account by running the following command using your user key (replace all the highlighted values): AWS regions and profiles Setting the region To configure your region, use this environment variable to override the default region: export AWS_DEFAULT_REGION=MY_REGION # us-west-2, for example Copy The CLI tool also allows passing this per-command using --aws-region. Setting profiles If you have multiple AWS profiles and don't want to use the default, use AWS_PROFILE environment variable to set another profile name. Ensure the profile is properly configured (including the default region). Example: export AWS_PROFILE=MY_PROFILE Copy newrelic-lambda integrations install --nr-account-id YOUR_NR_ACCOUNT_ID \\ --nr-api-key YOUR_NEW_RELIC_USER_KEY Copy The newrelic-lambda CLI adds your New Relic license key as a secret in [AWS Secret Manager] (https://aws.amazon. com/secrets-manager/) for greater security. Tip Storing the New Relic license key in the AWS Secrets Manager Your New Relic license key identifies and authenticates you to New Relic, allowing us to associate your telemetry with your New Relic account. Each function that sends telemetry needs access to this value, and it needs to be managed securely. The AWS Secrets Manager solves these problems. If your organization prevents you from using AWS Secrets Manager or if you need to store more than one secret per region, see below for an alternative method to set your license key. Alternative method Linking accounts manually The Infrastructure UI The CLI is the least complicated way to link your accounts. Current CLI behavior limits the setup of one managed secret per region. If you need more control or need to integrate more than one New Relic account per region, you can go through the linking process manually. Be sure to enable Lambda when selecting services to be monitored. Don't forget to configure the License Key Secret manually, as described next. Manually Configuring the License Key Secret In addition to linking your accounts, you'll need to configure the license key secret. Download this CloudFormation Template: license-key-secret.yaml Using the AWS CLI, or the AWS CloudFormation Console, install the template, supplying the LicenseKey parameter. You can find your New Relic License Key here. It will be labeled \"INGEST - LICENSE\". Be sure to use the license key for the account you configured with the Infrastructure UI above. AWS CLI example: Be sure to replace YOUR_LICENSE_KEY with the license key you found above. aws cloudformation create-stack --stack-name NewRelicLicenseKeySecret \\ --template-body file://license-key-secret.yaml \\ --parameters 'ParameterKey=LicenseKey,ParameterValue=YOUR_LICENSE_KEY' Copy Troubleshooting Cannot Use AWS secrets manager If your organization does not allow the use of AWS Secrets Manager, the New Relic Lambda Extension will accept a NEW_RELIC_LICENSE_KEY environment variable. Add the --disable-license-key-secret flag from the newrelic-lambda integrations install command. Then set this environment variable to your New Relic license key in your Lambda function configuration. Multiple AWS regions and accounts The newrelic-lambda CLI should be run once per region, with the --aws-region parameter. Use the same linked account name, and the tool will detect that the account link has been created already. The license key secret needs to be created in each region. Similarly, several AWS accounts can be linked to a New Relic account. Give each account a different linked account name. The --aws-profile argument to the CLI tool will select the named profile. The tool uses the same configuration as the AWS CLI. Failure to retrieve license key AccessDeniedException Your lambda code requires the execution role which has permission to read AWS Secrets Manager. If you find a log like the following, add the appropriate permission to the policy of the execution role. In our examples, check out the template.yaml file to see an easy way to grant this permission. Failed to retrieve license key AccessDeniedException: User: <ARN> is not authorized to perform: secretsmanager:GetSecretValue on resource: <ARN> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.22815,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Link your <em>AWS</em> and New Relic accounts",
        "sections": "Link your <em>AWS</em> and New Relic accounts",
        "tags": "<em>AWS</em> Lambda monitoring",
        "body": " store your New Relic License Key in the <em>AWS</em> Secrets Manager service, so that we can send your telemetry to your New Relic account. <em>Recommended</em> method: The newrelic-lambda CLI Requirements To enable serverless monitoring using our Lambda layer, you need the following: <em>AWS</em> CLI v2 installed"
      },
      "id": "605aa856e7b9d2454d76f227"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by all integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permissions",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "80e215e7b2ba382de1b7ea758ee1b1f0a1e3c7df",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-05-04T18:30:29Z",
      "updated_at": "2021-05-04T18:30:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBilling' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by all integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permissions Additional Billing permissions: budgets:ViewBilling budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.9981,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Recommended</em> policy",
        "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web <em>Services</em> (<em>AWS</em>) uses managed policies to grant these permissions. <em>Recommended</em> policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "6045079fe7b9d27db95799d9"
    }
  ],
  "/docs/security/index": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.37869,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-05-04T18:28:40Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.08855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-05-01T12:36:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team is assigned a security engineer charged with ensuring the security of New Relic products. In the requirements building phase, the security engineer performs a risk assessment and then adds security requirements for the project. We add privacy and compliance experts to the project teams as needed. Design During the design phase, the New Relic Security team collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build In the build phase, the engineering team implements the features in the project following secure coding standards at New Relic. Each product engineer receives secure coding training, which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and processes already in place at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the repository. At the project level, teams may request a final review of the project before deploying. The security engineer verifies that the safeguards and controls discovered and documented in the risk assessment, requirements, and design phases have been addressed. All New Relic code has passed static code and composition analysis to look for vulnerabilities in the code and dependencies. All files published by New Relic will include their calculated hash and a digital signature. New Relic is in the process of including hashes and signatures, so that anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deploy Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular scans, third-party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.37986,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em>",
        "body": "Software built at New Relic goes through these five phases. Software development phase <em>Security</em> control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, <em>security</em> review, static code analysis, composition analysis"
      },
      "id": "608d4b4728ccbcac5d51c173"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/covid-19": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.9641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.9641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.964,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.3689,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68323,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.964,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.3689,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68323,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-03": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68307,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-04": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68307,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-05": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.9638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36868,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68292,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-06": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.9638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36868,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68292,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.9637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.3686,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68275,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96362,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.6826,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-03": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96362,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.6826,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-04": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96353,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36838,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-05": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96353,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36838,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-06": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96344,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.3683,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.6823,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-07": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96344,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.3683,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.6823,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-08": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68214,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-09": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68214,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-10": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68199,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-11": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68199,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-12": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96313,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68184,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96313,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68184,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96307,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-03": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96307,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-04": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96295,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.3678,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-05": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96295,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.3678,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr20-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.9629,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68137,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr20-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.9629,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68137,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96277,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68121,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.96277,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68121,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-05-04T18:28:40Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.78635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-heartbleed-vulnerability": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.9627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.3675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68106,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/solarwinds-orion": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.9626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> <em>bulletins</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Security Bulletin NR21-02",
        "Summary",
        "Affected software",
        "Vulnerability information",
        "Mitigating factors",
        "Workarounds",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security Bulletin NR21-02",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "7d26855ca012e9492ca043bf0feaa99822ad3261",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02/",
      "published_at": "2021-05-05T00:21:30Z",
      "updated_at": "2021-04-30T11:25:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary A security update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic agent versions are affected: Name Affected version Remediated version Java agent < 6.4.2 6.5.0 Vulnerability information A specified notation, when parsed through an unsafe Yaml.load() call, will create a new Java object and invoke its constructor, potentially leading to code execution. An attacker would have to have access to the agent’s host to edit the newrelic.yml file to include a crafted payload that would execute arbitrary code once the agent starts up. Mitigating factors This vulnerability requires an attacker already having access to the host in order to modify the newrelic.yml config file on a victim’s machine, which in itself is a mitigating factor. However, there are additional steps that you can take to either completely patch this issue or harden your systems against it: Update your Java agent to patch this vulnerability Revoke write privileges to your newrelic.yml file Workarounds Update to the latest New Relic Java agent. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "sections": "<em>Security</em> <em>Bulletin</em> NR21-02",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Summary A <em>security</em> update to the Java agent reconfigured the YAML parser to include a SafeConstructor, which removes the ability to have limited user controlled code executed. Release date: April 26th, 2021 Vulnerability identifier: NR21-02 Priority: Low Affected software The following New Relic"
      },
      "id": "608be924196a673ee964a786"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68091,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/security-privacy/compliance/data-encryption": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 354.401,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our <em>compliance</em> program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-05-04T18:28:40Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.2915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-05-01T12:36:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team is assigned a security engineer charged with ensuring the security of New Relic products. In the requirements building phase, the security engineer performs a risk assessment and then adds security requirements for the project. We add privacy and compliance experts to the project teams as needed. Design During the design phase, the New Relic Security team collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build In the build phase, the engineering team implements the features in the project following secure coding standards at New Relic. Each product engineer receives secure coding training, which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and processes already in place at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the repository. At the project level, teams may request a final review of the project before deploying. The security engineer verifies that the safeguards and controls discovered and documented in the risk assessment, requirements, and design phases have been addressed. All New Relic code has passed static code and composition analysis to look for vulnerabilities in the code and dependencies. All files published by New Relic will include their calculated hash and a digital signature. New Relic is in the process of including hashes and signatures, so that anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deploy Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular scans, third-party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.39346,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. We add <em>privacy</em> and <em>compliance</em> experts to the project teams as needed. Design During the design phase, the New Relic <em>Security</em> team collaborates with the stakeholders, engineering leaders, and architects"
      },
      "id": "608d4b4728ccbcac5d51c173"
    }
  ],
  "/docs/security/security-privacy/compliance/fedramp-compliant-endpoints": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 354.401,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our <em>compliance</em> program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-05-01T12:36:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team is assigned a security engineer charged with ensuring the security of New Relic products. In the requirements building phase, the security engineer performs a risk assessment and then adds security requirements for the project. We add privacy and compliance experts to the project teams as needed. Design During the design phase, the New Relic Security team collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build In the build phase, the engineering team implements the features in the project following secure coding standards at New Relic. Each product engineer receives secure coding training, which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and processes already in place at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the repository. At the project level, teams may request a final review of the project before deploying. The security engineer verifies that the safeguards and controls discovered and documented in the risk assessment, requirements, and design phases have been addressed. All New Relic code has passed static code and composition analysis to look for vulnerabilities in the code and dependencies. All files published by New Relic will include their calculated hash and a digital signature. New Relic is in the process of including hashes and signatures, so that anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deploy Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular scans, third-party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.39346,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. We add <em>privacy</em> and <em>compliance</em> experts to the project teams as needed. Design During the design phase, the New Relic <em>Security</em> team collaborates with the stakeholders, engineering leaders, and architects"
      },
      "id": "608d4b4728ccbcac5d51c173"
    },
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.39188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> bulletins",
        "sections": "<em>Security</em> bulletins",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and <em>compliance</em>, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> bulletins"
      },
      "id": "6045248b196a67f158960f1b"
    }
  ],
  "/docs/security/security-privacy/compliance/key-management-encryption-rest": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 354.40076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our <em>compliance</em> program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-05-04T18:28:40Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.29132,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-05-01T12:36:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team is assigned a security engineer charged with ensuring the security of New Relic products. In the requirements building phase, the security engineer performs a risk assessment and then adds security requirements for the project. We add privacy and compliance experts to the project teams as needed. Design During the design phase, the New Relic Security team collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build In the build phase, the engineering team implements the features in the project following secure coding standards at New Relic. Each product engineer receives secure coding training, which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and processes already in place at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the repository. At the project level, teams may request a final review of the project before deploying. The security engineer verifies that the safeguards and controls discovered and documented in the risk assessment, requirements, and design phases have been addressed. All New Relic code has passed static code and composition analysis to look for vulnerabilities in the code and dependencies. All files published by New Relic will include their calculated hash and a digital signature. New Relic is in the process of including hashes and signatures, so that anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deploy Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular scans, third-party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.39337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. We add <em>privacy</em> and <em>compliance</em> experts to the project teams as needed. Design During the design phase, the New Relic <em>Security</em> team collaborates with the stakeholders, engineering leaders, and architects"
      },
      "id": "608d4b4728ccbcac5d51c173"
    }
  ],
  "/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services": [
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-05-04T18:28:40Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 338.29114,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-05-01T12:36:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team is assigned a security engineer charged with ensuring the security of New Relic products. In the requirements building phase, the security engineer performs a risk assessment and then adds security requirements for the project. We add privacy and compliance experts to the project teams as needed. Design During the design phase, the New Relic Security team collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build In the build phase, the engineering team implements the features in the project following secure coding standards at New Relic. Each product engineer receives secure coding training, which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and processes already in place at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the repository. At the project level, teams may request a final review of the project before deploying. The security engineer verifies that the safeguards and controls discovered and documented in the risk assessment, requirements, and design phases have been addressed. All New Relic code has passed static code and composition analysis to look for vulnerabilities in the code and dependencies. All files published by New Relic will include their calculated hash and a digital signature. New Relic is in the process of including hashes and signatures, so that anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deploy Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular scans, third-party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.39328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. We add <em>privacy</em> and <em>compliance</em> experts to the project teams as needed. Design During the design phase, the New Relic <em>Security</em> team collaborates with the stakeholders, engineering leaders, and architects"
      },
      "id": "608d4b4728ccbcac5d51c173"
    },
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.39175,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> bulletins",
        "sections": "<em>Security</em> bulletins",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, data <em>privacy</em>, and <em>compliance</em>, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> bulletins"
      },
      "id": "6045248b196a67f158960f1b"
    }
  ],
  "/docs/security/security-privacy/data-privacy/data-privacy-new-relic": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.6806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its <em>data</em> only to New Relic’s FedRAMP-designated endpoints. Authorized services and features"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-05-04T18:28:40Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.78584,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Overview of <em>data</em> sources",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our <em>data</em> encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-05-01T12:36:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team is assigned a security engineer charged with ensuring the security of New Relic products. In the requirements building phase, the security engineer performs a risk assessment and then adds security requirements for the project. We add privacy and compliance experts to the project teams as needed. Design During the design phase, the New Relic Security team collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build In the build phase, the engineering team implements the features in the project following secure coding standards at New Relic. Each product engineer receives secure coding training, which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and processes already in place at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the repository. At the project level, teams may request a final review of the project before deploying. The security engineer verifies that the safeguards and controls discovered and documented in the risk assessment, requirements, and design phases have been addressed. All New Relic code has passed static code and composition analysis to look for vulnerabilities in the code and dependencies. All files published by New Relic will include their calculated hash and a digital signature. New Relic is in the process of including hashes and signatures, so that anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deploy Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular scans, third-party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.78345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. We add <em>privacy</em> and compliance experts to the project teams as needed. Design During the design phase, the New Relic <em>Security</em> team collaborates with the stakeholders, engineering leaders, and architects"
      },
      "id": "608d4b4728ccbcac5d51c173"
    }
  ],
  "/docs/security/security-privacy/data-privacy/new-relic-personal-data-requests": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68045,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its <em>data</em> only to New Relic’s FedRAMP-designated endpoints. Authorized services and features"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-05-04T18:28:40Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.7857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Overview of <em>data</em> sources",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our <em>data</em> encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-05-01T12:36:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team is assigned a security engineer charged with ensuring the security of New Relic products. In the requirements building phase, the security engineer performs a risk assessment and then adds security requirements for the project. We add privacy and compliance experts to the project teams as needed. Design During the design phase, the New Relic Security team collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build In the build phase, the engineering team implements the features in the project following secure coding standards at New Relic. Each product engineer receives secure coding training, which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and processes already in place at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the repository. At the project level, teams may request a final review of the project before deploying. The security engineer verifies that the safeguards and controls discovered and documented in the risk assessment, requirements, and design phases have been addressed. All New Relic code has passed static code and composition analysis to look for vulnerabilities in the code and dependencies. All files published by New Relic will include their calculated hash and a digital signature. New Relic is in the process of including hashes and signatures, so that anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deploy Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular scans, third-party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.78336,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. We add <em>privacy</em> and compliance experts to the project teams as needed. Design During the design phase, the New Relic <em>Security</em> team collaborates with the stakeholders, engineering leaders, and architects"
      },
      "id": "608d4b4728ccbcac5d51c173"
    }
  ],
  "/docs/security/security-privacy/data-privacy/security-controls-privacy": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68045,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its <em>data</em> only to New Relic’s FedRAMP-designated endpoints. Authorized services and features"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-05-04T18:28:40Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.7857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Overview of <em>data</em> sources",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our <em>data</em> encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-05-01T12:36:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team is assigned a security engineer charged with ensuring the security of New Relic products. In the requirements building phase, the security engineer performs a risk assessment and then adds security requirements for the project. We add privacy and compliance experts to the project teams as needed. Design During the design phase, the New Relic Security team collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build In the build phase, the engineering team implements the features in the project following secure coding standards at New Relic. Each product engineer receives secure coding training, which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and processes already in place at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the repository. At the project level, teams may request a final review of the project before deploying. The security engineer verifies that the safeguards and controls discovered and documented in the risk assessment, requirements, and design phases have been addressed. All New Relic code has passed static code and composition analysis to look for vulnerabilities in the code and dependencies. All files published by New Relic will include their calculated hash and a digital signature. New Relic is in the process of including hashes and signatures, so that anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deploy Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular scans, third-party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.78336,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. We add <em>privacy</em> and compliance experts to the project teams as needed. Design During the design phase, the New Relic <em>Security</em> team collaborates with the stakeholders, engineering leaders, and architects"
      },
      "id": "608d4b4728ccbcac5d51c173"
    }
  ],
  "/docs/security/security-privacy/information-security/report-security-vulnerabilities-hackerone": [
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-05-01T12:36:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team is assigned a security engineer charged with ensuring the security of New Relic products. In the requirements building phase, the security engineer performs a risk assessment and then adds security requirements for the project. We add privacy and compliance experts to the project teams as needed. Design During the design phase, the New Relic Security team collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build In the build phase, the engineering team implements the features in the project following secure coding standards at New Relic. Each product engineer receives secure coding training, which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and processes already in place at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the repository. At the project level, teams may request a final review of the project before deploying. The security engineer verifies that the safeguards and controls discovered and documented in the risk assessment, requirements, and design phases have been addressed. All New Relic code has passed static code and composition analysis to look for vulnerabilities in the code and dependencies. All files published by New Relic will include their calculated hash and a digital signature. New Relic is in the process of including hashes and signatures, so that anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deploy Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular scans, third-party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 314.18384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. We add <em>privacy</em> and compliance experts to the project teams as needed. Design During the design phase, the New Relic <em>Security</em> team collaborates with the stakeholders, engineering leaders, and architects"
      },
      "id": "608d4b4728ccbcac5d51c173"
    },
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 292.91132,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> bulletins",
        "sections": "<em>Security</em> bulletins",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more <em>information</em>, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> bulletins"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-05-04T18:28:40Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.8392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides <em>information</em> on FedRAMP-compliant endpoints in New Relic. For more <em>information</em> about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/security-privacy/information-security/security-bulletins": [
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-04T22:20:51Z",
      "updated_at": "2021-05-01T12:36:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team is assigned a security engineer charged with ensuring the security of New Relic products. In the requirements building phase, the security engineer performs a risk assessment and then adds security requirements for the project. We add privacy and compliance experts to the project teams as needed. Design During the design phase, the New Relic Security team collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build In the build phase, the engineering team implements the features in the project following secure coding standards at New Relic. Each product engineer receives secure coding training, which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and processes already in place at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the repository. At the project level, teams may request a final review of the project before deploying. The security engineer verifies that the safeguards and controls discovered and documented in the risk assessment, requirements, and design phases have been addressed. All New Relic code has passed static code and composition analysis to look for vulnerabilities in the code and dependencies. All files published by New Relic will include their calculated hash and a digital signature. New Relic is in the process of including hashes and signatures, so that anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deploy Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular scans, third-party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 314.18384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. We add <em>privacy</em> and compliance experts to the project teams as needed. Design During the design phase, the New Relic <em>Security</em> team collaborates with the stakeholders, engineering leaders, and architects"
      },
      "id": "608d4b4728ccbcac5d51c173"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-05-04T18:28:40Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.8392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides <em>information</em> on FedRAMP-compliant endpoints in New Relic. For more <em>information</em> about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.6803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ": New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more <em>information</em>, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP"
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/security-privacy/information-security/software-development-lifecycle": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-05T22:24:37Z",
      "updated_at": "2021-04-29T01:08:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 292.91122,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> bulletins",
        "sections": "<em>Security</em> bulletins",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more <em>information</em>, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. APM <em>Security</em> bulletins"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-05-04T18:28:40Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.83905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides <em>information</em> on FedRAMP-compliant endpoints in New Relic. For more <em>information</em> about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-05T16:00:41Z",
      "updated_at": "2021-05-05T16:00:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December, 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Notes on icons used in this table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.68015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ": New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more <em>information</em>, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP"
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/account-linking": [
    {
      "sections": [
        "Update serverless monitoring for AWS Lambda",
        "Important",
        "Update our Lambda integration via CLI",
        "Update layers via CLI",
        "Update a manual Serverless application repository install",
        "Enabling log management",
        "Caution"
      ],
      "title": "Update serverless monitoring for AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "7075499bcc9b1ff1e346a705ab414adcca54fd09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/update-serverless-monitoring-aws-lambda/",
      "published_at": "2021-05-06T03:23:18Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After enabling our monitoring for AWS Lambda, you should occasionally update our Lambda function that's used to report AWS log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our Lambda monitoring using our CLI tool. Update via AWS Serverless Application Repository: Use this if you enabled using the manual procedure. Important These update procedures apply to our serverless monitoring for AWS Lambda, and not to our infrastructure monitoring for AWS Lambda integration. Update our Lambda integration via CLI This section describes how to update if your Lambda monitoring was enabled using our recommended CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region identifier (for example, us-west-2). newrelic-lambda integrations update \\ --aws-region YOUR_REGION Copy If you do not have our logs enabled, you'll also need to update your Amazon CloudWatch log subscription filters with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --aws-region YOUR_REGION Copy Update layers via CLI This section describes how to update your function's Layer if you installed it with our CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy Pass the --upgrade flag to the install command: newrelic-lambda layers install \\ --function installed \\ --nr-account-id NR_ACCOUNT_ID \\ --upgrade Copy Update a manual Serverless application repository install If you manually installed the ingest function from the AWS Serverless Application Repository (and didn't use the CLI), update using this procedure: Run the following, replacing YOUR_REGION with your region (for example, us-west-2). aws serverlessrepo create-cloud-formation-change-set \\ --application-id arn:aws:serverlessrepo:us-east-1:463657938898:applications/NewRelic-log-ingestion \\ --stack-name NewRelic-log-ingestion \\ --capabilities CAPABILITY_RESOURCE_POLICY \\ --region YOUR_REGION Copy This command outputs several fields, one of which is the ChangeSetId: an ARN for the change set that you just created. Copy that ARN. Use the ARN in this command, which executes the change set: aws cloudformation execute-change-set --change-set-name YOUR_CHANGE_SET_ARN Copy Enabling log management If you currently don't have New Relic's log management enabled, but would like to: Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region (for example, us-west-2). newrelic-lambda integrations update \\ --enable-logs \\ --aws-region YOUR_REGION Copy Then do either of the following: Update your Amazon CloudWatch log subscription filters for each region with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --filter-pattern \"\" \\ --aws-region YOUR_REGION Copy Or, you can send function logs to New Relic directly, bypassing CloudWatch and the newrelic-log-ingestion Lambda. To do this, set the environment variable NEW_RELIC_EXTENSION_SEND_FUNCTION_LOGS=true in your Lambda function configuration. After that, be sure to remove any existing New Relic log subscriptions for that function using this command: newrelic-lambda subscriptions uninstall \\ --function FUNCTION_NAME \\ --aws-region YOUR_REGION Copy If the log subscription is present while the extension is sending logs, logs will be sent twice, resulting in duplicate log records in New Relic. Optionally, if you'd like to avoid Amazon's charges for CloudWatch Log ingestion, you can also modify your function's execution role so that it doesn't grant the CloudWatch Log permissions. This will prevent your function from logging to CloudWatch. Caution CloudWatch Logs ingest fees can be considerable, but this step should be taken with caution. Make sure your New Relic log ingestion integration is working well and meeting your needs before disabling CloudWatch logs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 402.9516,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "sections": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "After enabling our <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, you should occasionally update our <em>Lambda</em> <em>function</em> that&#x27;s used to report <em>AWS</em> log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our <em>Lambda</em> <em>monitoring</em> using our CLI tool. Update via <em>AWS</em> <em>Serverless</em>"
      },
      "id": "6045248c28ccbc98a82c606b"
    },
    {
      "sections": [
        "Instrument a Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "title": "Instrument a Lambda function",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "published_at": "2021-05-06T03:23:18Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate Distributed Tracing into a non-trivial serverless application in our Distributed Tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 402.9516,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument a <em>Lambda</em> <em>function</em>",
        "sections": "Instrument a <em>Lambda</em> <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "New Relic provides working minimal examples as a starting point for instrumenting your own <em>serverless</em> functions, so that you can become familiar with the necessary elements, test the <em>account</em> <em>link</em>, and use them as a reference for your own instrumentation. While there are many ways to manage"
      },
      "id": "605aa85628ccbcc6d13ae663"
    },
    {
      "sections": [
        "Legacy manual instrumentation",
        "Go",
        "Zip and upload recommendations",
        "Java",
        "Tip",
        ".NET Core",
        "Async handler function",
        "Inheriting from APIGatewayProxyFunction",
        "Important",
        "Using the SQS Wrapper",
        "Using the SNS Wrapper",
        "Node.js",
        "Python"
      ],
      "title": "Legacy manual instrumentation",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "694e22b2ce401a96d200ab2e12a08850532b3e5a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy/",
      "published_at": "2021-05-06T02:46:32Z",
      "updated_at": "2021-05-06T02:46:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On this page, you will learn how to manually instrument your lambda function. It is organized by runtime language. Go To instrument your Go-language Lambda: Download our Go agent package and place it in the same directory as your function. Install the agent: go get -u github.com/newrelic/go-agent. In your Lambda code, import our components, create an application, and update how you start your Lambda. See our GitHub repo for an example of an instrumented Lambda. Optional: Add custom events that will be associated with your Lambda invocation by using the RecordCustomEvent API. For example: func handler(ctx context.Context) { if txn := newrelic.FromContext(ctx); nil != txn { txn.Application().RecordCustomEvent(\"MyEvent\", map[string]interface{}{ \"zip\": \"zap\", }) } fmt.Println(\"hello world!\") } Copy Build and zip your Lambda function and upload it to AWS. Zip and upload recommendations Here are suggestions for zipping and uploading the Lambda: Build the binary for execution on Linux. This produces a binary file called main. You can use: $ GOOS=linux go build -o main Copy Zip the binary into a deployment package using: $ zip deployment.zip main Copy Upload the zip file to AWS using either the AWS Lambda console or the AWS CLI. Name the handler main (to match the name given during the binary build). The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this is the account ID for the root/parent account. Optional: To configure logging, see Go agent logging. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Java Monitoring for AWS Lambda in Java doesn't use our APM Java agent. Instead, it uses these two OpenTracing dependencies: AWS Lambda OpenTracing Java SDK: OpenTracing instrumentation for AWS Lambda RequestHandler and RequestStreamHandler. Our AWS Lambda OpenTracing Tracer: An OpenTracing Tracer implementation designed to monitor AWS Lambda. It generates spans, error events, transaction events, error traces, and provides distributed tracing support. Tip Supported OpenTracing Versions OpenTracing 0.31.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:1.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:1.0.0 OpenTracing 0.32.0, 0.33.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:2.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:2.1.0 To instrument your Java Lambda: In your project’s build.gradle file, include our OpenTracing AWS Lambda Tracer and the AWS Lambda OpenTracing SDK dependencies: dependencies { compile(\"com.newrelic.opentracing:java-aws-lambda:2.1.0\") compile(\"com.newrelic.opentracing:newrelic-java-lambda:2.1.1\") compile(\"io.opentracing:opentracing-util:0.33.0\") } Copy Implement the AWS Lambda RequestHandler interface as shown in the Java Lambda example and override the doHandleRequest method. In the doHandleRequest method, call the LambdaTracing.instrument(...) API to create a root span to trace the lambda function's execution. This is also where you will define your business logic for the lambda function. Register a LambdaTracer.INSTANCE as the OpenTracing Global tracer, as shown in the Java Lambda example. Create a ZIP deployment package and upload it to AWS Lambda. Or deploy it via other means. In the AWS Lambda console, set the handler. For the example Java Lambda, the handler would be com.handler.example.MyLambdaHandler::handleRequest. Because handleRequest is assumed, you could also use com.handler.example.MyLambdaHandler. The following AWS console environment variables are required if you want your Lambda function to be included in distributed tracing. This is recommended. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_PRIMARY_APPLICATION_ID. This is also your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this must be the account ID for the root/parent account. Optional: In the Lambda console, enable debug logging by adding this environment variable: NEW_RELIC_DEBUG is true. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Please see the AWS Lambda distributed tracing example for a complete project that illustrates common use cases such as: Distributed tracing between Lambda functions Manual span creation (aka custom instrumentation) Tracing external calls Adding custom attributes (aka Tags) to spans .NET Core Our monitoring of .NET Core-based AWS Lambda functions doesn't use our standard .NET Core APM agent. Instead, it uses a NuGet package. To instrument your .NET Core Lambda: In your Lambda Functions project, install the NewRelic.OpenTracing.AmazonLambda.Tracer NuGet package. Note: NewRelic.OpenTracing.AmazonLambda.Tracer depends on version 1.2.0+ of Amazon.Lambda.APIGatewayEvent NuGet package. If the environment already uses a lower version of Amazon.Lambda.APIGatewayEvent, the New Relic package may produce errors such as System.MissingMethodException . Import the NuGet package and OpenTracing utils: using OpenTracing.Util; using NewRelic.OpenTracing.AmazonLambda; Copy Instrument your function, as shown in this example: public class Function { static Function() { // Register The NewRelic Lambda Tracer Instance GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public object FunctionWrapper(ILambdaContext context) { // Instantiate NewRelic TracingWrapper and pass your FunctionHandler as // an argument return new TracingRequestHandler().LambdaWrapper(FunctionHandler, context); } /// <summary> /// A simple function that takes a string and does a ToUpper /// </summary> /// <param name=\"input\"></param> /// <param name=\"context\"></param> /// <returns></returns> public object FunctionHandler(ILambdaContext context) { ... } } Copy Tip The arguments passed to FunctionWrapper must match the signature of FunctionHandler. If your handler function returns a Task, the Lambda wrapper will block on the return task until it completes, so that it can measure the duration and capture exceptions, if any are present. In addition, you may also inherit from the APIGatewayProxyFunction. For an example, see below: Async handler function public override Task<int> FunctionHandlerAsync(ILambdaContext lambdaContext) { // This call will block by calling task.Result Task<int> task = new TracingRequestHandler().LambdaWrapper( ActualFunctionHandlerAsync, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(ILambdaContext lambdaContext) { // Function can make other async operations here ... } Copy Inheriting from APIGatewayProxyFunction public class LambdaFunction : APIGatewayProxyFunction { static LambdaFunction() { // Register The NewRelic Lambda Tracer Instance OpenTracing.Util.GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public override Task<APIGatewayProxyResponse> FunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { Task<APIGatewayProxyResponse> task = new TracingRequestHandler().LambdaWrapper(ActualFunctionHandlerAsync, request, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { return base.FunctionHandlerAsync(request, lambdaContext); } } Copy Optional for SQS and SNS: Starting in version 1.0 of our .NET Lambda Tracer, distributed tracing support has been added for SQS and SNS. To enable distributed tracing for SQS or SNS you will need to complete the items in this step as well as setup the environment variables in the step that follows this one. Important Enabling distributed tracing support for SQS and SNS will disable automatic instrumentation for both of SQS and SNS and require the use of these wrappers to instrument them. Set the NEW_RELIC_USE_DT_WRAPPER environment variable to true. To instrument SQS and SNS calls you will need to use the provided wrappers. Using the SQS Wrapper The SQS wrapper supports wrapping the following methods: Amazon.SQS.AmazonSQSClient.SendMessageAsync(...) Amazon.SQS.AmazonSQSClient.SendMessageBatchAsync(...) Examples // SQS Client AmazonSQSClient client = new AmazonSQSClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // SendMessageRequest SendMessageRequest sendRequest = new SendMessageRequest(\"QUEUE_URI_STRING\", \"An SQS Message\"); Task<SendMessageResponse> responseOne = SQSWrapper.WrapRequest(client.SendMessageAsync, sendRequest); // String-based Task<SendMessageResponse> responseTwo = SQSWrapper.WrapRequest(client.SendMessageAsync, \"QUEUE_URI_STRING\", \"Another SQS Message\"); // SendMessageBatchRequest List<SendMessageBatchRequestEntry> batchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id1\", \"First SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id2\", \"Second SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id3\", \"Third SQS Message\")); SendMessageBatchRequest sendBatchRequest = new SendMessageBatchRequest(QUEUE_URI, batchEntries); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, sendBatchRequest); // SendMessageBatchRequestEntry List List<SendMessageBatchRequestEntry> moreBatchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id4\", \"Fourth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id5\", \"Fifth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id6\", \"Sixth SQS Message\")); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, moreBatchEntries); Copy Using the SNS Wrapper The SNS wrapper supports wrapping the following methods: Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient.PublishAsync(...) Examples // SNS Client AmazonSimpleNotificationServiceClient client = new Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // PublishRequest - Phone Number PublishRequest phonePublishRequest = new PublishRequest(); phonePublishRequest.PhoneNumber = +1XXX5555100; phonePublishRequest.Message = \"An SNS Message for phones\"; Task<PublishResponse> phoneResponse = SNSWrapper.WrapRequest(client.PublishAsync, phonePublishRequest); // PublishRequest - ARN PublishRequest publishRequest = new PublishRequest(\"TOPIC_ARN\", \"An SNS Message\"); Task<PublishResponse> publishResponse = SNSWrapper.WrapRequest(client.PublishAsync, publishRequest); // String-based without subject Task<PublishResponse> ResponseOne = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Another SNS Message\"); // String-based with subject Task<PublishResponse> ResponseTwo = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Yet Another SNS Message\", \"A Subject\"); Copy The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS Lambda console: NEW_RELIC_ACCOUNT_ID: The account ID the Lambda is reporting to. NEW_RELIC_TRUSTED_ACCOUNT_KEY: This is also the account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Ensure that the wrapper function (FunctionWrapper in above example) is set up as the function handler. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Node.js To instrument your Node.js Lambda: Download our Node.js agent package and place it in the same directory as your function, ensuring the agent is installed as a dependency in the node_modules directory. Use the Node Package Manager: npm install newrelic --save Copy Install our AWS SDK module alongside the Node.js agent: npm install @newrelic/aws-sdk --save Copy In your Lambda code, require the agent module and the AWS SDK at the top of the file, and wrap the handler function. For example: const newrelic = require('newrelic'); require('@newrelic/aws-sdk'); // Other module loads go under the two require statements above module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { // This is your handler function code console.log('Lambda executed'); callback(); }); Copy Optional: You can also add custom events to your Lambda using the recordCustomEvent API. For example: module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { newrelic.recordCustomEvent(‘MyEventType’, {foo: ‘bar’}); console.log('Lambda executed'); callback(); }); Copy Zip your Lambda function and the Node.js agent folder together. Requirements and recommendations: The New Relic files outside the New Relic agent folder don't need to be included. If your Lambda function file name is, for example, lambda_function.node, we recommend naming your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set these environment variables: NEW_RELIC_NO_CONFIG_FILE. Set to true if not using a configuration file. NEW_RELIC_APP_NAME: Your application name. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Optional: To run the agent in serverless mode outside of AWS in a local environment, set the environment variable NEW_RELIC_SERVERLESS_MODE_ENABLED to true. (When executing this in an AWS Lambda environment, the agent will automatically run in serverless mode. Do not use this variable if you're running in AWS.) Optional: To enable logging in serverless mode, set these environment variables: Set NEW_RELIC_LOG_ENABLED to true. Set NEW_RELIC_LOG to stdout for output to CloudWatch, or set to any writeable file location. The log level is set to info by default. See other log levels. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Python To instrument your Python Lambda: Download our Python agent package and place it in the same directory as your function. To do this, use pip: pip install -t . newrelic Copy Important If you use Homebrew, you may get this error: DistutilsOptionError: must supply either home or prefix/exec-prefix -- not both. For details, see the Homebrew GitHub post. In your Lambda code, import the Python agent module and decorate the handler function using the New Relic decorator. The New Relic package must be imported first in your code. Here's an example: import newrelic.agent newrelic.agent.initialize() @newrelic.agent.lambda_handler() def handler(event, context): ... Copy Optional: You can also add custom events to your Lambda using the record_custom_event API. Here's an example: @newrelic.agent.lambda_handler() def handler(event, context): newrelic.agent.record_custom_event('CustomEvent', {'foo': 'bar'}) … Copy Zip your lambda_function.py and newrelic/ folder together using these guidelines: The New Relic files outside the newrelic/ folder don't need to be included. If your Lambda function file name is, for example, lambda_function.py, name your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set this environment variable: NEW_RELIC_SERVERLESS_MODE_ENABLED. Set to true The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED. Set to true. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Optional: To configure logging, use the NEW_RELIC_LOG and NEW_RELIC_LOG_LEVEL environment variables in the AWS Console. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. The New Relic decorator gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, configure CloudWatch to send those logs to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 402.3396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Async handler <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ". In the <em>AWS</em> console, set this environment variable: NEW_RELIC_<em>SERVERLESS</em>_MODE_ENABLED. Set to true The following environment variables are not required for <em>Lambda</em> <em>monitoring</em> to <em>function</em> but they are required if you want your <em>Lambda</em> functions to be included in distributed traces. To <em>enable</em> distributed"
      },
      "id": "603ebbcb64441f800a4e8850"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/configure-serverless-monitoring-aws-lambda": [
    {
      "sections": [
        "Update serverless monitoring for AWS Lambda",
        "Important",
        "Update our Lambda integration via CLI",
        "Update layers via CLI",
        "Update a manual Serverless application repository install",
        "Enabling log management",
        "Caution"
      ],
      "title": "Update serverless monitoring for AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "7075499bcc9b1ff1e346a705ab414adcca54fd09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/update-serverless-monitoring-aws-lambda/",
      "published_at": "2021-05-06T03:23:18Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After enabling our monitoring for AWS Lambda, you should occasionally update our Lambda function that's used to report AWS log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our Lambda monitoring using our CLI tool. Update via AWS Serverless Application Repository: Use this if you enabled using the manual procedure. Important These update procedures apply to our serverless monitoring for AWS Lambda, and not to our infrastructure monitoring for AWS Lambda integration. Update our Lambda integration via CLI This section describes how to update if your Lambda monitoring was enabled using our recommended CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region identifier (for example, us-west-2). newrelic-lambda integrations update \\ --aws-region YOUR_REGION Copy If you do not have our logs enabled, you'll also need to update your Amazon CloudWatch log subscription filters with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --aws-region YOUR_REGION Copy Update layers via CLI This section describes how to update your function's Layer if you installed it with our CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy Pass the --upgrade flag to the install command: newrelic-lambda layers install \\ --function installed \\ --nr-account-id NR_ACCOUNT_ID \\ --upgrade Copy Update a manual Serverless application repository install If you manually installed the ingest function from the AWS Serverless Application Repository (and didn't use the CLI), update using this procedure: Run the following, replacing YOUR_REGION with your region (for example, us-west-2). aws serverlessrepo create-cloud-formation-change-set \\ --application-id arn:aws:serverlessrepo:us-east-1:463657938898:applications/NewRelic-log-ingestion \\ --stack-name NewRelic-log-ingestion \\ --capabilities CAPABILITY_RESOURCE_POLICY \\ --region YOUR_REGION Copy This command outputs several fields, one of which is the ChangeSetId: an ARN for the change set that you just created. Copy that ARN. Use the ARN in this command, which executes the change set: aws cloudformation execute-change-set --change-set-name YOUR_CHANGE_SET_ARN Copy Enabling log management If you currently don't have New Relic's log management enabled, but would like to: Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region (for example, us-west-2). newrelic-lambda integrations update \\ --enable-logs \\ --aws-region YOUR_REGION Copy Then do either of the following: Update your Amazon CloudWatch log subscription filters for each region with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --filter-pattern \"\" \\ --aws-region YOUR_REGION Copy Or, you can send function logs to New Relic directly, bypassing CloudWatch and the newrelic-log-ingestion Lambda. To do this, set the environment variable NEW_RELIC_EXTENSION_SEND_FUNCTION_LOGS=true in your Lambda function configuration. After that, be sure to remove any existing New Relic log subscriptions for that function using this command: newrelic-lambda subscriptions uninstall \\ --function FUNCTION_NAME \\ --aws-region YOUR_REGION Copy If the log subscription is present while the extension is sending logs, logs will be sent twice, resulting in duplicate log records in New Relic. Optionally, if you'd like to avoid Amazon's charges for CloudWatch Log ingestion, you can also modify your function's execution role so that it doesn't grant the CloudWatch Log permissions. This will prevent your function from logging to CloudWatch. Caution CloudWatch Logs ingest fees can be considerable, but this step should be taken with caution. Make sure your New Relic log ingestion integration is working well and meeting your needs before disabling CloudWatch logs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 402.95132,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "sections": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "After enabling our <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, you should occasionally update our <em>Lambda</em> <em>function</em> that&#x27;s used to report <em>AWS</em> log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our <em>Lambda</em> <em>monitoring</em> using our CLI tool. Update via <em>AWS</em> <em>Serverless</em>"
      },
      "id": "6045248c28ccbc98a82c606b"
    },
    {
      "sections": [
        "Instrument a Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "title": "Instrument a Lambda function",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "published_at": "2021-05-06T03:23:18Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate Distributed Tracing into a non-trivial serverless application in our Distributed Tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 402.95132,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument a <em>Lambda</em> <em>function</em>",
        "sections": "Instrument a <em>Lambda</em> <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " and deploy <em>Lambda</em> functions, <em>AWS</em> CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates"
      },
      "id": "605aa85628ccbcc6d13ae663"
    },
    {
      "sections": [
        "Legacy manual instrumentation",
        "Go",
        "Zip and upload recommendations",
        "Java",
        "Tip",
        ".NET Core",
        "Async handler function",
        "Inheriting from APIGatewayProxyFunction",
        "Important",
        "Using the SQS Wrapper",
        "Using the SNS Wrapper",
        "Node.js",
        "Python"
      ],
      "title": "Legacy manual instrumentation",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "694e22b2ce401a96d200ab2e12a08850532b3e5a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy/",
      "published_at": "2021-05-06T02:46:32Z",
      "updated_at": "2021-05-06T02:46:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On this page, you will learn how to manually instrument your lambda function. It is organized by runtime language. Go To instrument your Go-language Lambda: Download our Go agent package and place it in the same directory as your function. Install the agent: go get -u github.com/newrelic/go-agent. In your Lambda code, import our components, create an application, and update how you start your Lambda. See our GitHub repo for an example of an instrumented Lambda. Optional: Add custom events that will be associated with your Lambda invocation by using the RecordCustomEvent API. For example: func handler(ctx context.Context) { if txn := newrelic.FromContext(ctx); nil != txn { txn.Application().RecordCustomEvent(\"MyEvent\", map[string]interface{}{ \"zip\": \"zap\", }) } fmt.Println(\"hello world!\") } Copy Build and zip your Lambda function and upload it to AWS. Zip and upload recommendations Here are suggestions for zipping and uploading the Lambda: Build the binary for execution on Linux. This produces a binary file called main. You can use: $ GOOS=linux go build -o main Copy Zip the binary into a deployment package using: $ zip deployment.zip main Copy Upload the zip file to AWS using either the AWS Lambda console or the AWS CLI. Name the handler main (to match the name given during the binary build). The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this is the account ID for the root/parent account. Optional: To configure logging, see Go agent logging. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Java Monitoring for AWS Lambda in Java doesn't use our APM Java agent. Instead, it uses these two OpenTracing dependencies: AWS Lambda OpenTracing Java SDK: OpenTracing instrumentation for AWS Lambda RequestHandler and RequestStreamHandler. Our AWS Lambda OpenTracing Tracer: An OpenTracing Tracer implementation designed to monitor AWS Lambda. It generates spans, error events, transaction events, error traces, and provides distributed tracing support. Tip Supported OpenTracing Versions OpenTracing 0.31.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:1.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:1.0.0 OpenTracing 0.32.0, 0.33.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:2.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:2.1.0 To instrument your Java Lambda: In your project’s build.gradle file, include our OpenTracing AWS Lambda Tracer and the AWS Lambda OpenTracing SDK dependencies: dependencies { compile(\"com.newrelic.opentracing:java-aws-lambda:2.1.0\") compile(\"com.newrelic.opentracing:newrelic-java-lambda:2.1.1\") compile(\"io.opentracing:opentracing-util:0.33.0\") } Copy Implement the AWS Lambda RequestHandler interface as shown in the Java Lambda example and override the doHandleRequest method. In the doHandleRequest method, call the LambdaTracing.instrument(...) API to create a root span to trace the lambda function's execution. This is also where you will define your business logic for the lambda function. Register a LambdaTracer.INSTANCE as the OpenTracing Global tracer, as shown in the Java Lambda example. Create a ZIP deployment package and upload it to AWS Lambda. Or deploy it via other means. In the AWS Lambda console, set the handler. For the example Java Lambda, the handler would be com.handler.example.MyLambdaHandler::handleRequest. Because handleRequest is assumed, you could also use com.handler.example.MyLambdaHandler. The following AWS console environment variables are required if you want your Lambda function to be included in distributed tracing. This is recommended. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_PRIMARY_APPLICATION_ID. This is also your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this must be the account ID for the root/parent account. Optional: In the Lambda console, enable debug logging by adding this environment variable: NEW_RELIC_DEBUG is true. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Please see the AWS Lambda distributed tracing example for a complete project that illustrates common use cases such as: Distributed tracing between Lambda functions Manual span creation (aka custom instrumentation) Tracing external calls Adding custom attributes (aka Tags) to spans .NET Core Our monitoring of .NET Core-based AWS Lambda functions doesn't use our standard .NET Core APM agent. Instead, it uses a NuGet package. To instrument your .NET Core Lambda: In your Lambda Functions project, install the NewRelic.OpenTracing.AmazonLambda.Tracer NuGet package. Note: NewRelic.OpenTracing.AmazonLambda.Tracer depends on version 1.2.0+ of Amazon.Lambda.APIGatewayEvent NuGet package. If the environment already uses a lower version of Amazon.Lambda.APIGatewayEvent, the New Relic package may produce errors such as System.MissingMethodException . Import the NuGet package and OpenTracing utils: using OpenTracing.Util; using NewRelic.OpenTracing.AmazonLambda; Copy Instrument your function, as shown in this example: public class Function { static Function() { // Register The NewRelic Lambda Tracer Instance GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public object FunctionWrapper(ILambdaContext context) { // Instantiate NewRelic TracingWrapper and pass your FunctionHandler as // an argument return new TracingRequestHandler().LambdaWrapper(FunctionHandler, context); } /// <summary> /// A simple function that takes a string and does a ToUpper /// </summary> /// <param name=\"input\"></param> /// <param name=\"context\"></param> /// <returns></returns> public object FunctionHandler(ILambdaContext context) { ... } } Copy Tip The arguments passed to FunctionWrapper must match the signature of FunctionHandler. If your handler function returns a Task, the Lambda wrapper will block on the return task until it completes, so that it can measure the duration and capture exceptions, if any are present. In addition, you may also inherit from the APIGatewayProxyFunction. For an example, see below: Async handler function public override Task<int> FunctionHandlerAsync(ILambdaContext lambdaContext) { // This call will block by calling task.Result Task<int> task = new TracingRequestHandler().LambdaWrapper( ActualFunctionHandlerAsync, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(ILambdaContext lambdaContext) { // Function can make other async operations here ... } Copy Inheriting from APIGatewayProxyFunction public class LambdaFunction : APIGatewayProxyFunction { static LambdaFunction() { // Register The NewRelic Lambda Tracer Instance OpenTracing.Util.GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public override Task<APIGatewayProxyResponse> FunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { Task<APIGatewayProxyResponse> task = new TracingRequestHandler().LambdaWrapper(ActualFunctionHandlerAsync, request, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { return base.FunctionHandlerAsync(request, lambdaContext); } } Copy Optional for SQS and SNS: Starting in version 1.0 of our .NET Lambda Tracer, distributed tracing support has been added for SQS and SNS. To enable distributed tracing for SQS or SNS you will need to complete the items in this step as well as setup the environment variables in the step that follows this one. Important Enabling distributed tracing support for SQS and SNS will disable automatic instrumentation for both of SQS and SNS and require the use of these wrappers to instrument them. Set the NEW_RELIC_USE_DT_WRAPPER environment variable to true. To instrument SQS and SNS calls you will need to use the provided wrappers. Using the SQS Wrapper The SQS wrapper supports wrapping the following methods: Amazon.SQS.AmazonSQSClient.SendMessageAsync(...) Amazon.SQS.AmazonSQSClient.SendMessageBatchAsync(...) Examples // SQS Client AmazonSQSClient client = new AmazonSQSClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // SendMessageRequest SendMessageRequest sendRequest = new SendMessageRequest(\"QUEUE_URI_STRING\", \"An SQS Message\"); Task<SendMessageResponse> responseOne = SQSWrapper.WrapRequest(client.SendMessageAsync, sendRequest); // String-based Task<SendMessageResponse> responseTwo = SQSWrapper.WrapRequest(client.SendMessageAsync, \"QUEUE_URI_STRING\", \"Another SQS Message\"); // SendMessageBatchRequest List<SendMessageBatchRequestEntry> batchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id1\", \"First SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id2\", \"Second SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id3\", \"Third SQS Message\")); SendMessageBatchRequest sendBatchRequest = new SendMessageBatchRequest(QUEUE_URI, batchEntries); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, sendBatchRequest); // SendMessageBatchRequestEntry List List<SendMessageBatchRequestEntry> moreBatchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id4\", \"Fourth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id5\", \"Fifth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id6\", \"Sixth SQS Message\")); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, moreBatchEntries); Copy Using the SNS Wrapper The SNS wrapper supports wrapping the following methods: Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient.PublishAsync(...) Examples // SNS Client AmazonSimpleNotificationServiceClient client = new Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // PublishRequest - Phone Number PublishRequest phonePublishRequest = new PublishRequest(); phonePublishRequest.PhoneNumber = +1XXX5555100; phonePublishRequest.Message = \"An SNS Message for phones\"; Task<PublishResponse> phoneResponse = SNSWrapper.WrapRequest(client.PublishAsync, phonePublishRequest); // PublishRequest - ARN PublishRequest publishRequest = new PublishRequest(\"TOPIC_ARN\", \"An SNS Message\"); Task<PublishResponse> publishResponse = SNSWrapper.WrapRequest(client.PublishAsync, publishRequest); // String-based without subject Task<PublishResponse> ResponseOne = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Another SNS Message\"); // String-based with subject Task<PublishResponse> ResponseTwo = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Yet Another SNS Message\", \"A Subject\"); Copy The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS Lambda console: NEW_RELIC_ACCOUNT_ID: The account ID the Lambda is reporting to. NEW_RELIC_TRUSTED_ACCOUNT_KEY: This is also the account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Ensure that the wrapper function (FunctionWrapper in above example) is set up as the function handler. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Node.js To instrument your Node.js Lambda: Download our Node.js agent package and place it in the same directory as your function, ensuring the agent is installed as a dependency in the node_modules directory. Use the Node Package Manager: npm install newrelic --save Copy Install our AWS SDK module alongside the Node.js agent: npm install @newrelic/aws-sdk --save Copy In your Lambda code, require the agent module and the AWS SDK at the top of the file, and wrap the handler function. For example: const newrelic = require('newrelic'); require('@newrelic/aws-sdk'); // Other module loads go under the two require statements above module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { // This is your handler function code console.log('Lambda executed'); callback(); }); Copy Optional: You can also add custom events to your Lambda using the recordCustomEvent API. For example: module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { newrelic.recordCustomEvent(‘MyEventType’, {foo: ‘bar’}); console.log('Lambda executed'); callback(); }); Copy Zip your Lambda function and the Node.js agent folder together. Requirements and recommendations: The New Relic files outside the New Relic agent folder don't need to be included. If your Lambda function file name is, for example, lambda_function.node, we recommend naming your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set these environment variables: NEW_RELIC_NO_CONFIG_FILE. Set to true if not using a configuration file. NEW_RELIC_APP_NAME: Your application name. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Optional: To run the agent in serverless mode outside of AWS in a local environment, set the environment variable NEW_RELIC_SERVERLESS_MODE_ENABLED to true. (When executing this in an AWS Lambda environment, the agent will automatically run in serverless mode. Do not use this variable if you're running in AWS.) Optional: To enable logging in serverless mode, set these environment variables: Set NEW_RELIC_LOG_ENABLED to true. Set NEW_RELIC_LOG to stdout for output to CloudWatch, or set to any writeable file location. The log level is set to info by default. See other log levels. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Python To instrument your Python Lambda: Download our Python agent package and place it in the same directory as your function. To do this, use pip: pip install -t . newrelic Copy Important If you use Homebrew, you may get this error: DistutilsOptionError: must supply either home or prefix/exec-prefix -- not both. For details, see the Homebrew GitHub post. In your Lambda code, import the Python agent module and decorate the handler function using the New Relic decorator. The New Relic package must be imported first in your code. Here's an example: import newrelic.agent newrelic.agent.initialize() @newrelic.agent.lambda_handler() def handler(event, context): ... Copy Optional: You can also add custom events to your Lambda using the record_custom_event API. Here's an example: @newrelic.agent.lambda_handler() def handler(event, context): newrelic.agent.record_custom_event('CustomEvent', {'foo': 'bar'}) … Copy Zip your lambda_function.py and newrelic/ folder together using these guidelines: The New Relic files outside the newrelic/ folder don't need to be included. If your Lambda function file name is, for example, lambda_function.py, name your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set this environment variable: NEW_RELIC_SERVERLESS_MODE_ENABLED. Set to true The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED. Set to true. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Optional: To configure logging, use the NEW_RELIC_LOG and NEW_RELIC_LOG_LEVEL environment variables in the AWS Console. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. The New Relic decorator gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, configure CloudWatch to send those logs to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 402.3393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Async handler <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ". In the <em>AWS</em> console, set this environment variable: NEW_RELIC_<em>SERVERLESS</em>_MODE_ENABLED. Set to true The following environment variables are not required for <em>Lambda</em> <em>monitoring</em> to <em>function</em> but they are required if you want your <em>Lambda</em> functions to be included in distributed traces. To <em>enable</em> distributed"
      },
      "id": "603ebbcb64441f800a4e8850"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy": [
    {
      "sections": [
        "Update serverless monitoring for AWS Lambda",
        "Important",
        "Update our Lambda integration via CLI",
        "Update layers via CLI",
        "Update a manual Serverless application repository install",
        "Enabling log management",
        "Caution"
      ],
      "title": "Update serverless monitoring for AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "7075499bcc9b1ff1e346a705ab414adcca54fd09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/update-serverless-monitoring-aws-lambda/",
      "published_at": "2021-05-06T03:23:18Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After enabling our monitoring for AWS Lambda, you should occasionally update our Lambda function that's used to report AWS log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our Lambda monitoring using our CLI tool. Update via AWS Serverless Application Repository: Use this if you enabled using the manual procedure. Important These update procedures apply to our serverless monitoring for AWS Lambda, and not to our infrastructure monitoring for AWS Lambda integration. Update our Lambda integration via CLI This section describes how to update if your Lambda monitoring was enabled using our recommended CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region identifier (for example, us-west-2). newrelic-lambda integrations update \\ --aws-region YOUR_REGION Copy If you do not have our logs enabled, you'll also need to update your Amazon CloudWatch log subscription filters with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --aws-region YOUR_REGION Copy Update layers via CLI This section describes how to update your function's Layer if you installed it with our CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy Pass the --upgrade flag to the install command: newrelic-lambda layers install \\ --function installed \\ --nr-account-id NR_ACCOUNT_ID \\ --upgrade Copy Update a manual Serverless application repository install If you manually installed the ingest function from the AWS Serverless Application Repository (and didn't use the CLI), update using this procedure: Run the following, replacing YOUR_REGION with your region (for example, us-west-2). aws serverlessrepo create-cloud-formation-change-set \\ --application-id arn:aws:serverlessrepo:us-east-1:463657938898:applications/NewRelic-log-ingestion \\ --stack-name NewRelic-log-ingestion \\ --capabilities CAPABILITY_RESOURCE_POLICY \\ --region YOUR_REGION Copy This command outputs several fields, one of which is the ChangeSetId: an ARN for the change set that you just created. Copy that ARN. Use the ARN in this command, which executes the change set: aws cloudformation execute-change-set --change-set-name YOUR_CHANGE_SET_ARN Copy Enabling log management If you currently don't have New Relic's log management enabled, but would like to: Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region (for example, us-west-2). newrelic-lambda integrations update \\ --enable-logs \\ --aws-region YOUR_REGION Copy Then do either of the following: Update your Amazon CloudWatch log subscription filters for each region with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --filter-pattern \"\" \\ --aws-region YOUR_REGION Copy Or, you can send function logs to New Relic directly, bypassing CloudWatch and the newrelic-log-ingestion Lambda. To do this, set the environment variable NEW_RELIC_EXTENSION_SEND_FUNCTION_LOGS=true in your Lambda function configuration. After that, be sure to remove any existing New Relic log subscriptions for that function using this command: newrelic-lambda subscriptions uninstall \\ --function FUNCTION_NAME \\ --aws-region YOUR_REGION Copy If the log subscription is present while the extension is sending logs, logs will be sent twice, resulting in duplicate log records in New Relic. Optionally, if you'd like to avoid Amazon's charges for CloudWatch Log ingestion, you can also modify your function's execution role so that it doesn't grant the CloudWatch Log permissions. This will prevent your function from logging to CloudWatch. Caution CloudWatch Logs ingest fees can be considerable, but this step should be taken with caution. Make sure your New Relic log ingestion integration is working well and meeting your needs before disabling CloudWatch logs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 402.95132,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "sections": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "After enabling our <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, you should occasionally update our <em>Lambda</em> <em>function</em> that&#x27;s used to report <em>AWS</em> log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our <em>Lambda</em> <em>monitoring</em> using our CLI tool. Update via <em>AWS</em> <em>Serverless</em>"
      },
      "id": "6045248c28ccbc98a82c606b"
    },
    {
      "sections": [
        "Instrument a Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "title": "Instrument a Lambda function",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "published_at": "2021-05-06T03:23:18Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate Distributed Tracing into a non-trivial serverless application in our Distributed Tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 402.95132,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument a <em>Lambda</em> <em>function</em>",
        "sections": "Instrument a <em>Lambda</em> <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " and deploy <em>Lambda</em> functions, <em>AWS</em> CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates"
      },
      "id": "605aa85628ccbcc6d13ae663"
    },
    {
      "sections": [
        "Link your AWS and New Relic accounts",
        "AWS permissions details",
        "Recommended method: The newrelic-lambda CLI",
        "Requirements",
        "CLI user AWS permissions details",
        "Integrate with CLI",
        "AWS regions and profiles",
        "Tip",
        "Alternative method",
        "Linking accounts manually",
        "The Infrastructure UI",
        "Manually Configuring the License Key Secret",
        "Troubleshooting",
        "Cannot Use AWS secrets manager",
        "Multiple AWS regions and accounts",
        "Failure to retrieve license key AccessDeniedException"
      ],
      "title": "Link your AWS and New Relic accounts",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Account Linking"
      ],
      "external_id": "8fdeff9ad6419bbcfbb1d35aeb8985cd6b43200c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/account-linking/",
      "published_at": "2021-05-06T02:45:39Z",
      "updated_at": "2021-05-06T02:45:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you link your AWS account to New Relic, you're granting permission to New Relic to create an inventory of your AWS account, and gather CloudWatch metrics for your Lambda functions. Resources in your AWS account then show up as entities in the entity explorer, decorated with config information. AWS permissions details To create this inventory, we need an IAM role that grants these IAM permissions, at a minimum: Resource: \"*\" Action: \"cloudwatch:GetMetricStatistics\" \"cloudwatch:ListMetrics\" \"cloudwatch:GetMetricData\" \"lambda:GetAccountSettings\" \"lambda:ListFunctions\" \"lambda:ListAliases\" \"lambda:ListTags\" \"lambda:ListEventSourceMappings\" Copy By default, we use the AWS Managed Policy ReadOnlyAccess. This allows the Infrastructure integration to see all the resources in your account, rather than just your Lambda functions and CloudWatch metrics. New Relic recommends this default, but we understand that some organizations have a very conservative security posture for third party integrations. A role with the permissions above is sufficient to allow Lambda telemetry collection, though traces that interact with other services may not work well. In this integration step, we'll also store your New Relic License Key in the AWS Secrets Manager service, so that we can send your telemetry to your New Relic account. Recommended method: The newrelic-lambda CLI Requirements To enable serverless monitoring using our Lambda layer, you need the following: AWS CLI v2 installed and configured using aws configure. Python version 3.3 or higher installed. newrelic-lambda CLI, which you can install by running pip3 install newrelic-lambda-cli. A New Relic account. You must be an admin, or have the Infrastructure manager add-on role. A user key. An AWS account with permissions for creating IAM resources, managed secrets, and Lambdas. You also need permissions for creating CloudFormation stacks and S3 buckets. CLI user AWS permissions details The CLI uses the AWS SDK to interact with AWS. The SDK will act using the same default profile as the AWS CLI. This profile needs, at a minimum, the following AWS permissions to run the CLI. Resource: * Actions: \"cloudformation:CreateChangeSet\", \"cloudformation:CreateStack\", \"cloudformation:DescribeStacks\", \"cloudformation:ExecuteChangeSets\", \"iam:AttachRolePolicy\", \"iam:CreateRole\", \"iam:GetRole\", \"iam:PassRole\", \"lambda:AddPermission\", \"lambda:CreateFunction\", \"lambda:GetFunction\", \"logs:DeleteSubscriptionFilter\", \"logs:DescribeSubscriptionFilters\", \"logs:PutSubscriptionFilter\" \"s3:GetObject\" \"serverlessrepo:CreateCloudFormationChangeSet\" \"secretsmanager:CreateSecret\" Resource: \"arn:aws:serverlessrepo:us-east-1:463657938898:applications/NewRelic-log-ingestion\" Actions: \"serverlessrepo:CreateCloudFormationTemplate\" \"serverlessrepo:GetCloudFormationTemplate\" Copy Integrate with CLI When all the requirements are in place, link your AWS account with your New Relic account by running the following command using your user key (replace all the highlighted values): AWS regions and profiles Setting the region To configure your region, use this environment variable to override the default region: export AWS_DEFAULT_REGION=MY_REGION # us-west-2, for example Copy The CLI tool also allows passing this per-command using --aws-region. Setting profiles If you have multiple AWS profiles and don't want to use the default, use AWS_PROFILE environment variable to set another profile name. Ensure the profile is properly configured (including the default region). Example: export AWS_PROFILE=MY_PROFILE Copy newrelic-lambda integrations install --nr-account-id YOUR_NR_ACCOUNT_ID \\ --nr-api-key YOUR_NEW_RELIC_USER_KEY Copy The newrelic-lambda CLI adds your New Relic license key as a secret in [AWS Secret Manager] (https://aws.amazon. com/secrets-manager/) for greater security. Tip Storing the New Relic license key in the AWS Secrets Manager Your New Relic license key identifies and authenticates you to New Relic, allowing us to associate your telemetry with your New Relic account. Each function that sends telemetry needs access to this value, and it needs to be managed securely. The AWS Secrets Manager solves these problems. If your organization prevents you from using AWS Secrets Manager or if you need to store more than one secret per region, see below for an alternative method to set your license key. Alternative method Linking accounts manually The Infrastructure UI The CLI is the least complicated way to link your accounts. Current CLI behavior limits the setup of one managed secret per region. If you need more control or need to integrate more than one New Relic account per region, you can go through the linking process manually. Be sure to enable Lambda when selecting services to be monitored. Don't forget to configure the License Key Secret manually, as described next. Manually Configuring the License Key Secret In addition to linking your accounts, you'll need to configure the license key secret. Download this CloudFormation Template: license-key-secret.yaml Using the AWS CLI, or the AWS CloudFormation Console, install the template, supplying the LicenseKey parameter. You can find your New Relic License Key here. It will be labeled \"INGEST - LICENSE\". Be sure to use the license key for the account you configured with the Infrastructure UI above. AWS CLI example: Be sure to replace YOUR_LICENSE_KEY with the license key you found above. aws cloudformation create-stack --stack-name NewRelicLicenseKeySecret \\ --template-body file://license-key-secret.yaml \\ --parameters 'ParameterKey=LicenseKey,ParameterValue=YOUR_LICENSE_KEY' Copy Troubleshooting Cannot Use AWS secrets manager If your organization does not allow the use of AWS Secrets Manager, the New Relic Lambda Extension will accept a NEW_RELIC_LICENSE_KEY environment variable. Add the --disable-license-key-secret flag from the newrelic-lambda integrations install command. Then set this environment variable to your New Relic license key in your Lambda function configuration. Multiple AWS regions and accounts The newrelic-lambda CLI should be run once per region, with the --aws-region parameter. Use the same linked account name, and the tool will detect that the account link has been created already. The license key secret needs to be created in each region. Similarly, several AWS accounts can be linked to a New Relic account. Give each account a different linked account name. The --aws-profile argument to the CLI tool will select the named profile. The tool uses the same configuration as the AWS CLI. Failure to retrieve license key AccessDeniedException Your lambda code requires the execution role which has permission to read AWS Secrets Manager. If you find a log like the following, add the appropriate permission to the policy of the execution role. In our examples, check out the template.yaml file to see an easy way to grant this permission. Failed to retrieve license key AccessDeniedException: User: <ARN> is not authorized to perform: secretsmanager:GetSecretValue on resource: <ARN> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 391.682,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Link your <em>AWS</em> and New Relic accounts",
        "sections": "Link your <em>AWS</em> and New Relic accounts",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " store your New Relic License Key in the <em>AWS</em> Secrets Manager service, so that we can send your telemetry to your New Relic account. Recommended method: The newrelic-<em>lambda</em> CLI Requirements To <em>enable</em> <em>serverless</em> <em>monitoring</em> using our <em>Lambda</em> layer, you need the following: <em>AWS</em> CLI v2 installed"
      },
      "id": "605aa856e7b9d2454d76f227"
    }
  ]
}