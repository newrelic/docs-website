{
  "/docs/agents/ruby-agent/api-guides/ruby-custom-metrics": [
    {
      "sections": [
        "Guide to using the Ruby agent API",
        "Important",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "Control the browser agent",
        "Instrument calls to datastores",
        "Instrument calls to externals",
        "Instrument calls for distributed tracing"
      ],
      "title": "Guide to using the Ruby agent API",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "b8a0743300bf602822bfdcf6c4760c64a4bebc0e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/guide-using-ruby-agent-api/",
      "published_at": "2021-10-12T12:38:51Z",
      "updated_at": "2021-07-27T14:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent provides a public API with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your Ruby app and collect more in-depth data: Overview Public API methods The following sections explain common goals, solutions, and links to relevant parts of the documentation. Important When using the Ruby agent API, ensure that you have the latest Ruby agent release. Several APIs used in the following examples require Ruby agent version 4.6.0 or higher. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or \"instruments\") the parent method in these transactions to measure your app's overall performance, and collects transaction traces from long-running transactions for additional detail. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Time a method New Relic is not instrumenting automatically Create a new transaction. See Tracing transaction entry points. Time something other than a single method call Use the Tracer API. Prevent a transaction from reporting to New Relic Ignore the transaction. Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don't have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method See Method tracers. Time something other than a single method call Use the Tracer API. Enhance the metadata of a transaction Sometimes the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example: The default name is causing a metric grouping issue. You want to add custom attributes to your transactions so you can filter them in the query builder. Use these methods when you want to change how New Relic instruments a transaction that is already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction See Naming transactions. Add metadata (such as your customer's account name or subscription level) to your transactions Use custom attributes. See Adding custom attributes. Mark a transaction as a background job See Monitor custom background jobs. Mark a transaction as a web transaction Pass a :category => :controller option to set_transaction_name(). For more information, see Naming transactions. Prevent a transaction from affecting your Apdex score See Ignoring Apdex contributions. Collect or ignore errors Usually the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically See Sending New Relic handled errors. Prevent the agent from reporting an error at all Mark the error as ignored. See Error Collector to use the error_collector.ignore_errors config option. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic Mark the error as expected. See Sending New Relic handled errors, and set :expected to true. Send custom event and metric data from your app APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in dashboards Create a custom event. See record_custom_event(). Tag your events with metadata to filter and facet them in dashboards or error analytics Add custom attributes. Pass a hash of attributes to record_custom_event(). Report custom performance data Create a custom metric. See record_metric(). Control the browser agent Usually the browser agent is added automatically to your pages or deployed by copy/pasting the JavaScript snippet. For more information about these recommended methods, see Add apps to browser monitoring. However, you can also retrieve the browser agent via APM agent API calls. For more information, see browser_timing_header(). Instrument calls to datastores Use these methods to collect data about your app's connections to other datastores: If you want to... Do this... Time a call to a datastore not instrumented automatically by New Relic See wrap(). Time a datastore call that can't cleanly be wrapped in a Ruby block See Tracer.start_datastore_segment(). You must call finish on the object returned by this method. Capture SQL queries along with timing See notice_sql(). Capture non-SQL queries along with timing See notice_statement(). Instrument calls to externals Use these methods to collect data for external requests: If you want to... Do this... Time a call to an external request not instrumented automatically by New Relic Use Tracer.start_external_segment(). You must call finish on the object returned by this method. Add cross-application tracing (CAT) headers to an outbound HTTP request Use add_request_headers(). Read CAT headers from an inbound HTTP request Use read_response_headers(). Generate an obfuscated string to transport CAT information in an outbound request Use get_request_metadata(). Process an obfuscated string containing CAT information received from an inbound request Use process_response_metadata(). Instrument calls for distributed tracing Important The following API examples require Ruby agent version 6.9.0 or higher. These APIs require distributed tracing to be enabled. Distributed tracing lets you see the paths requests take as they travel through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. If you want to... Do this... Send a payload/header to the called service. See insert_distributed_trace_headers(). Accept a payload/header received from the first service, which will link these services together in a trace See accept_distributed_trace_headers().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.28882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "sections": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> provides a public <em>API</em> with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your <em>Ruby</em> app and collect more in-depth data: Overview Public <em>API</em> methods The following sections explain common goals, solutions"
      },
      "id": "604403a5196a67e712960f33"
    },
    {
      "sections": [
        "Ignoring specific transactions",
        "Blocking all instrumentation",
        "Ignoring specific actions with Rails",
        "Ignoring specific routes with Sinatra",
        "Ignoring Apdex contributions",
        "Blocking browser instrumentation",
        "Ignoring transactions dynamically",
        "Ignoring transactions by URL with configuration",
        "Troubleshooting",
        "For more help"
      ],
      "title": "Ignoring specific transactions",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "711df6a6f072c451ca8a55a9316d8c13c083ada2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/",
      "published_at": "2021-10-12T12:38:51Z",
      "updated_at": "2021-07-21T19:10:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic for Ruby allows you to selectively disable instrumentation for particular requests within your Rails or Sinatra application. Blocking all instrumentation Call newrelic_ignore with no arguments from within a Rails controller or Sinatra application to prevent instrumentation of all requests serviced by that controller or application: newrelic_ignore Copy Using newrelic_ignore prevents the agent from recording any performance data (metrics, transaction traces, events, traced errors, and so on) for the targeted transactions, and will also prevent the transactions from contributing to your overall Apdex score. Ignoring specific actions with Rails If you want to ignore only specific actions with a Rails controller, you can use the :only or :except options with newrelic_ignore. For example, to ignore only the index and show actions on the controller, use: newrelic_ignore :only => [:index, :show] Copy To ignore all actions on the controller except index: newrelic_ignore :except => [:index] Copy Ignoring specific routes with Sinatra If you want to ignore only specific routes within your Sinatra application, you can pass a Sinatra-style route definition to newrelic_ignore from within your Sinatra application. For more information, see Sinatra: Ignoring routes. Ignoring Apdex contributions If you want to prevent all actions in a controller from contributing to your Apdex score, but still want other performance data, use newrelic_ignore_apdex: newrelic_ignore_apdex Copy In a Rails application, newrelic_ignore_apdex supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Blocking browser instrumentation Using newrelic_ignore_enduser prevents the agent from automatically inserting the JavaScript used to capture browser monitoring data. Server-side instrumentation will be unaffected. To prevent browser agent injection for all actions in a controller, add a call like this to the controller class: newrelic_ignore_enduser Copy In a Rails application, newrelic_ignore_enduser supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Ignoring transactions dynamically In some cases, you may want to base the decision to ignore a specific transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren't a good fit. Starting in Ruby agent version 3.9.2, you can instead use the following family of API calls from any point within your transaction: NewRelic::Agent.ignore_transaction NewRelic::Agent.ignore_apdex NewRelic::Agent.ignore_enduser Copy These methods will have a similar results to the newrelic_ignore, newrelic_ignore_apdex, and newrelic_ignore_enduser calls, but can be called during a request instead of during the class definition. Ignoring transactions by URL with configuration You can ignore transactions by URL using the rules.ignore_url_regexes configuration setting: rules: ignore_url_regexes: [\"secret\", \"^/admin\"] Copy This configuration will only prevent Transaction events that match the set pattern from reporting. Use any of the newrelic_ignore* family of methods if you would like to prevent all data, such as trace data, from reporting from a transaction. Note that regexes do not include any type of anchoring by default. The /secret/ regex will match 'newrelic.com/secret/login' and it will also match 'newrelic.com/users/secretpanda'. The anchored admin regex will match 'newrelic.com/admin/praetorians' but it will not match 'newrelic.com/users/totally-real-admin'. If necessary you may also provide a list of regexes in a comma-separated string, allowing you to set ignore regexes with an environment variable: NEW_RELIC_RULES_IGNORE_URL_REGEXES=\"secret,^/admin\" Copy As always configuration from environment variables will override configuration in newrelic.yml. Troubleshooting The newrelic_ignore* family of methods will only work from within Rails controller classes, or Sinatra applications (subclasses of Sinatra::Base). Other applications should use the NewRelic::Agent.ignore_* family of calls from within each request that you would like to ignore, which will work in any context. If you get a NoMethodError when trying to use newrelic_ignore from within a Rails controller or Sinatra application, make sure that newrelic_rpm has been required before you try to call newrelic_ignore inside of your class definition. For more help Additional documentation resources include Apdex: Measuring user satisfaction (how Apdex is calculated).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.54496,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>API</em> <em>guides</em>",
        "body": " transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren&#x27;t a good fit. Starting in <em>Ruby</em> <em>agent</em> version 3.9.2, you can instead use the following family of <em>API</em> calls from any point within your transaction: NewRelic"
      },
      "id": "603eb738196a67db90a83dbd"
    },
    {
      "sections": [
        "Sending handled errors to New Relic",
        "Notify the New Relic Ruby agent of an error"
      ],
      "title": "Sending handled errors to New Relic",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "349823d25fe83093a39bb114453b471888aacfb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/sending-handled-errors-new-relic/",
      "published_at": "2021-10-12T11:07:06Z",
      "updated_at": "2021-03-11T08:12:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To send error data that you are handling in your own code to New Relic, use the Ruby agent API NewRelic::Agent.notice_error call within your error handler. Notify the New Relic Ruby agent of an error This API call takes the exception and an optional options hash. Use this format: notice_error(exception, options = { }) â‡’ Object Copy This function records the given error and passes it through the normal error filtering process, including configuration-based ignoring of errors and the global #ignore_error_filter method if defined. The exception is the exception to be recorded, or an error message. If needed, you can also include options = { }. The following parameters will receive special treatment, and any other parameters you supply will be treated as custom parameters. options = { } Comments :expected Only records the error trace. This does not affect the error rate or Apdex status. For information on expected errors in the UI, see View expected errors. Replaces the :trace_only option, which was deprecated in version 4.3.x of the Ruby agent. :custom_params Custom parameters. :uri The request path, minus any request parameters or query string. Usually not needed. Include this only if you are calling notice_error outside a transaction. :metric The metric name associated with the transaction. Usually not needed. Include this only if you are calling notice_error outside a transaction. :request_params (deprecated) Older Ruby agent versions allowed passing a :request_params option, but those are now ignored. If you need to record the request parameters, call this method inside a transaction, or pass the information in :custom_params.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.7624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Notify the New Relic <em>Ruby</em> <em>agent</em> of an error",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "To send error data that you are handling in your own code to New Relic, use the <em>Ruby</em> <em>agent</em> <em>API</em> NewRelic::<em>Agent</em>.notice_error call within your error handler. Notify the New Relic <em>Ruby</em> <em>agent</em> of an error This <em>API</em> call takes the exception and an optional options hash. Use this format: notice_error"
      },
      "id": "604403e0e7b9d295a15799ec"
    }
  ],
  "/docs/agents/ruby-agent/api-guides/sending-handled-errors-new-relic": [
    {
      "sections": [
        "Guide to using the Ruby agent API",
        "Important",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "Control the browser agent",
        "Instrument calls to datastores",
        "Instrument calls to externals",
        "Instrument calls for distributed tracing"
      ],
      "title": "Guide to using the Ruby agent API",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "b8a0743300bf602822bfdcf6c4760c64a4bebc0e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/guide-using-ruby-agent-api/",
      "published_at": "2021-10-12T12:38:51Z",
      "updated_at": "2021-07-27T14:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent provides a public API with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your Ruby app and collect more in-depth data: Overview Public API methods The following sections explain common goals, solutions, and links to relevant parts of the documentation. Important When using the Ruby agent API, ensure that you have the latest Ruby agent release. Several APIs used in the following examples require Ruby agent version 4.6.0 or higher. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or \"instruments\") the parent method in these transactions to measure your app's overall performance, and collects transaction traces from long-running transactions for additional detail. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Time a method New Relic is not instrumenting automatically Create a new transaction. See Tracing transaction entry points. Time something other than a single method call Use the Tracer API. Prevent a transaction from reporting to New Relic Ignore the transaction. Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don't have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method See Method tracers. Time something other than a single method call Use the Tracer API. Enhance the metadata of a transaction Sometimes the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example: The default name is causing a metric grouping issue. You want to add custom attributes to your transactions so you can filter them in the query builder. Use these methods when you want to change how New Relic instruments a transaction that is already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction See Naming transactions. Add metadata (such as your customer's account name or subscription level) to your transactions Use custom attributes. See Adding custom attributes. Mark a transaction as a background job See Monitor custom background jobs. Mark a transaction as a web transaction Pass a :category => :controller option to set_transaction_name(). For more information, see Naming transactions. Prevent a transaction from affecting your Apdex score See Ignoring Apdex contributions. Collect or ignore errors Usually the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically See Sending New Relic handled errors. Prevent the agent from reporting an error at all Mark the error as ignored. See Error Collector to use the error_collector.ignore_errors config option. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic Mark the error as expected. See Sending New Relic handled errors, and set :expected to true. Send custom event and metric data from your app APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in dashboards Create a custom event. See record_custom_event(). Tag your events with metadata to filter and facet them in dashboards or error analytics Add custom attributes. Pass a hash of attributes to record_custom_event(). Report custom performance data Create a custom metric. See record_metric(). Control the browser agent Usually the browser agent is added automatically to your pages or deployed by copy/pasting the JavaScript snippet. For more information about these recommended methods, see Add apps to browser monitoring. However, you can also retrieve the browser agent via APM agent API calls. For more information, see browser_timing_header(). Instrument calls to datastores Use these methods to collect data about your app's connections to other datastores: If you want to... Do this... Time a call to a datastore not instrumented automatically by New Relic See wrap(). Time a datastore call that can't cleanly be wrapped in a Ruby block See Tracer.start_datastore_segment(). You must call finish on the object returned by this method. Capture SQL queries along with timing See notice_sql(). Capture non-SQL queries along with timing See notice_statement(). Instrument calls to externals Use these methods to collect data for external requests: If you want to... Do this... Time a call to an external request not instrumented automatically by New Relic Use Tracer.start_external_segment(). You must call finish on the object returned by this method. Add cross-application tracing (CAT) headers to an outbound HTTP request Use add_request_headers(). Read CAT headers from an inbound HTTP request Use read_response_headers(). Generate an obfuscated string to transport CAT information in an outbound request Use get_request_metadata(). Process an obfuscated string containing CAT information received from an inbound request Use process_response_metadata(). Instrument calls for distributed tracing Important The following API examples require Ruby agent version 6.9.0 or higher. These APIs require distributed tracing to be enabled. Distributed tracing lets you see the paths requests take as they travel through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. If you want to... Do this... Send a payload/header to the called service. See insert_distributed_trace_headers(). Accept a payload/header received from the first service, which will link these services together in a trace See accept_distributed_trace_headers().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.28881,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "sections": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> provides a public <em>API</em> with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your <em>Ruby</em> app and collect more in-depth data: Overview Public <em>API</em> methods The following sections explain common goals, solutions"
      },
      "id": "604403a5196a67e712960f33"
    },
    {
      "sections": [
        "Ignoring specific transactions",
        "Blocking all instrumentation",
        "Ignoring specific actions with Rails",
        "Ignoring specific routes with Sinatra",
        "Ignoring Apdex contributions",
        "Blocking browser instrumentation",
        "Ignoring transactions dynamically",
        "Ignoring transactions by URL with configuration",
        "Troubleshooting",
        "For more help"
      ],
      "title": "Ignoring specific transactions",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "711df6a6f072c451ca8a55a9316d8c13c083ada2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/",
      "published_at": "2021-10-12T12:38:51Z",
      "updated_at": "2021-07-21T19:10:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic for Ruby allows you to selectively disable instrumentation for particular requests within your Rails or Sinatra application. Blocking all instrumentation Call newrelic_ignore with no arguments from within a Rails controller or Sinatra application to prevent instrumentation of all requests serviced by that controller or application: newrelic_ignore Copy Using newrelic_ignore prevents the agent from recording any performance data (metrics, transaction traces, events, traced errors, and so on) for the targeted transactions, and will also prevent the transactions from contributing to your overall Apdex score. Ignoring specific actions with Rails If you want to ignore only specific actions with a Rails controller, you can use the :only or :except options with newrelic_ignore. For example, to ignore only the index and show actions on the controller, use: newrelic_ignore :only => [:index, :show] Copy To ignore all actions on the controller except index: newrelic_ignore :except => [:index] Copy Ignoring specific routes with Sinatra If you want to ignore only specific routes within your Sinatra application, you can pass a Sinatra-style route definition to newrelic_ignore from within your Sinatra application. For more information, see Sinatra: Ignoring routes. Ignoring Apdex contributions If you want to prevent all actions in a controller from contributing to your Apdex score, but still want other performance data, use newrelic_ignore_apdex: newrelic_ignore_apdex Copy In a Rails application, newrelic_ignore_apdex supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Blocking browser instrumentation Using newrelic_ignore_enduser prevents the agent from automatically inserting the JavaScript used to capture browser monitoring data. Server-side instrumentation will be unaffected. To prevent browser agent injection for all actions in a controller, add a call like this to the controller class: newrelic_ignore_enduser Copy In a Rails application, newrelic_ignore_enduser supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Ignoring transactions dynamically In some cases, you may want to base the decision to ignore a specific transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren't a good fit. Starting in Ruby agent version 3.9.2, you can instead use the following family of API calls from any point within your transaction: NewRelic::Agent.ignore_transaction NewRelic::Agent.ignore_apdex NewRelic::Agent.ignore_enduser Copy These methods will have a similar results to the newrelic_ignore, newrelic_ignore_apdex, and newrelic_ignore_enduser calls, but can be called during a request instead of during the class definition. Ignoring transactions by URL with configuration You can ignore transactions by URL using the rules.ignore_url_regexes configuration setting: rules: ignore_url_regexes: [\"secret\", \"^/admin\"] Copy This configuration will only prevent Transaction events that match the set pattern from reporting. Use any of the newrelic_ignore* family of methods if you would like to prevent all data, such as trace data, from reporting from a transaction. Note that regexes do not include any type of anchoring by default. The /secret/ regex will match 'newrelic.com/secret/login' and it will also match 'newrelic.com/users/secretpanda'. The anchored admin regex will match 'newrelic.com/admin/praetorians' but it will not match 'newrelic.com/users/totally-real-admin'. If necessary you may also provide a list of regexes in a comma-separated string, allowing you to set ignore regexes with an environment variable: NEW_RELIC_RULES_IGNORE_URL_REGEXES=\"secret,^/admin\" Copy As always configuration from environment variables will override configuration in newrelic.yml. Troubleshooting The newrelic_ignore* family of methods will only work from within Rails controller classes, or Sinatra applications (subclasses of Sinatra::Base). Other applications should use the NewRelic::Agent.ignore_* family of calls from within each request that you would like to ignore, which will work in any context. If you get a NoMethodError when trying to use newrelic_ignore from within a Rails controller or Sinatra application, make sure that newrelic_rpm has been required before you try to call newrelic_ignore inside of your class definition. For more help Additional documentation resources include Apdex: Measuring user satisfaction (how Apdex is calculated).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.54496,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>API</em> <em>guides</em>",
        "body": " transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren&#x27;t a good fit. Starting in <em>Ruby</em> <em>agent</em> version 3.9.2, you can instead use the following family of <em>API</em> calls from any point within your transaction: NewRelic"
      },
      "id": "603eb738196a67db90a83dbd"
    },
    {
      "sections": [
        "Ruby custom instrumentation",
        "Tip",
        "Method tracers",
        "Tracing in class definitions",
        "Tracing initializers",
        "Tracing blocks of code",
        "Naming transactions",
        "Important",
        "Tracing transaction entry points",
        "Instrumenting non-web transactions",
        "Advanced custom instrumentation",
        "Instrumenting a section of code",
        "Starting a transaction or segment",
        "For more help"
      ],
      "title": "Ruby custom instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "666d73d0d1bc86b9e1596cde83c68cf404a3a913",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ruby-custom-instrumentation/",
      "published_at": "2021-10-12T12:39:55Z",
      "updated_at": "2021-03-16T07:54:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent automatically collects many metrics. It also includes an API you can use to collect additional metrics about your application. If you see large Application Code segments in transaction trace details, custom instrumentation can give a more complete picture of what is going on in your application. Tip Collecting too many metrics can impact the performance of your application and New Relic. To avoid data problems, keep the total number of unique metrics introduced by custom instrumentation under 2000. Method tracers The easiest way to capture custom instrumentation is by tracing calls to a particular method. Tracing a method as described below will insert an additional node in your transaction traces for each invocation of that method, providing greater detail about where time is going in your transactions. Method tracers are software probes you can put on a method of any class. The probes use alias method chaining to insert themselves when the target methods execute and gather custom instrumentation on their performance. Tracing in class definitions Method tracers can be used within normal class definitions, as long as the target method has been defined first: require 'new_relic/agent/method_tracer' class Foo include ::NewRelic::Agent::MethodTracer def generate_image ... end add_method_tracer :generate_image, 'Custom/generate_image' end Copy To instrument a class method, add the method tracer in the class singleton: require 'new_relic/agent/method_tracer' class Foo def self.generate_image ... end class << self include ::NewRelic::Agent::MethodTracer add_method_tracer :generate_image, 'Custom/generate_image' end end Copy add_method_tracer takes an optional metric name and a hash of options. For more information, see add_method_tracer in the New Relic RubyDoc . Tracing initializers For Rails, a common way to add instrumentation is to create an initializer and \"monkey patch\" the instrumentation directives. For example, to add a method tracer to MyCache#get: Make sure the MyCache class is loaded before adding the method tracer. Add the following in a file named config/initializers/rpm_instrumentation.rb: require 'new_relic/agent/method_tracer' MyCache.class_eval do include ::NewRelic::Agent::MethodTracer add_method_tracer :get end Copy Tracing blocks of code Sometimes a single method is so complex that tracking overall time doesn't give enough detail. In these cases, you can wrap a block of code with a tracer. Call trace_execution_scoped passing the code to trace as a block: extend ::NewRelic::Agent::MethodTracer def slow_action self.class.trace_execution_scoped(['Custom/slow_action/beginning_work']) do # do stuff and report execution time with a custom metric name end # more stuff, whose time will be \"blamed\" to slow_action end Copy For more information, see add_method_tracer in the New Relic RubyDoc . Naming transactions Instrumented transactions are used to determine the throughput and overall response time for your application. The name of the method and the class will be used for the name of the transaction as reported to New Relic. For more information, see Viewing transaction traces. Normally the agent automatically chooses the transaction name. If you want to change the name of a transaction while it is still running, use NewRelic::Agent.set_transaction_name and the corresponding NewRelic::Agent.get_transaction_name. Important Do not use brackets [suffix] at the end of your transaction name. New Relic automatically strips brackets from the name. Instead, use parentheses (suffix) or other symbols if needed. This is useful if you want to segment your transaction based on some criteria. For example, if you wanted to vary the transaction name by response format in Rails: class UsersController def index @users = User.all respond_to do |format| format.html format.json do NewRelic::Agent.set_transaction_name('Users/index.json') render :json => @users end format.xml do NewRelic::Agent.set_transaction_name('Users/index.xml') render :xml => @users end end end end Copy Renaming transactions can also be used to segment your requests around some business criteria. For example, you could segment a transaction into \"Big Customer\" and \"Small Customer\" with code like this: class UsersController before_filter :segment_new_relic_by_customer_size def segment_new_relic_by_customer_size new_relic_name = NewRelic::Agent.get_transaction_name if current_user.big_customer? NewRelic::Agent.set_transaction_name(\"#{new_relic_name} - big customer\") else NewRelic::Agent.set_transaction_name(\"#{new_relic_name} - small customer\") end end end Copy Tracing transaction entry points Ordinarily the agent will be able to identify transactions within your application, but if you're not using a supported framework, or if you'd like to record transactions that the agent is not automatically recording, you can define methods as being transaction entry points: class Controller include NewRelic::Agent::Instrumentation::ControllerInstrumentation def transaction # execute a transaction end add_transaction_tracer :transaction end Copy Instrumenting non-web transactions Along with method-level tracing, you can instrument non-web transactions, such as background tasks, with the same level of transaction and error detail as web transactions. For more information, see Monitoring Ruby background processes and daemons. Advanced custom instrumentation When tracing code not automatically instrumented by the agent, the standard method tracers will usually be enough. However, sometimes you need to instrument something more complex than a single method call. For example, you may want to instrument a few lines of code within a method, or you may want to start a transaction in one part of your code and finish it elsewhere. The Tracer module, introduced in agent version 6.0, provides a flexible API that lets you create transactions and segments as well as interact with the current transaction. Instrumenting a section of code To instrument a section of code, wrap the code in a block, then pass the block to the Tracer.in_transaction method: require 'new_relic/agent/tracer' def long_and_complex_process expensive_setup Tracer.in_transaction(partial_name: 'Complex/process', category: :task) do code_to_be_instrumented end expensive_teardown end Copy The agent will ensure that a transaction exists, and will create a segment within it for the code inside the block. Starting a transaction or segment If you need to start a transaction at one location in your code but finish it in another (as can happen with callback-based events), call Tracer.start_transaction_or_segment. You must call finish on the return value of this method: require 'new_relic/agent/tracer' class MyEventWatcher def event_started @transaction = Tracer.start_transaction_or_segment( partial_name: 'MyEventWatcher/my_event', category: :task) end def event_completed @transaction.finish end end Copy For more information, see Tracer in the New Relic RubyDoc. For more help Additional documentation resources include: Custom instrumentation (Overview of custom instrumentation) Ruby custom metrics (Use an API call to record arbitrary metrics)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.96765,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> custom instrumentation",
        "sections": "<em>Ruby</em> custom instrumentation",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> automatically collects many metrics. It also includes an <em>API</em> you can use to collect additional metrics about your application. If you see large Application Code segments in transaction trace details, custom instrumentation can give a more complete picture of what is going"
      },
      "id": "603eb84b64441f1be34e8843"
    }
  ],
  "/docs/agents/ruby-agent/api-guides/third-party-instrumentation": [
    {
      "sections": [
        "Guide to using the Ruby agent API",
        "Important",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "Control the browser agent",
        "Instrument calls to datastores",
        "Instrument calls to externals",
        "Instrument calls for distributed tracing"
      ],
      "title": "Guide to using the Ruby agent API",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "b8a0743300bf602822bfdcf6c4760c64a4bebc0e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/guide-using-ruby-agent-api/",
      "published_at": "2021-10-12T12:38:51Z",
      "updated_at": "2021-07-27T14:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent provides a public API with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your Ruby app and collect more in-depth data: Overview Public API methods The following sections explain common goals, solutions, and links to relevant parts of the documentation. Important When using the Ruby agent API, ensure that you have the latest Ruby agent release. Several APIs used in the following examples require Ruby agent version 4.6.0 or higher. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or \"instruments\") the parent method in these transactions to measure your app's overall performance, and collects transaction traces from long-running transactions for additional detail. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Time a method New Relic is not instrumenting automatically Create a new transaction. See Tracing transaction entry points. Time something other than a single method call Use the Tracer API. Prevent a transaction from reporting to New Relic Ignore the transaction. Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don't have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method See Method tracers. Time something other than a single method call Use the Tracer API. Enhance the metadata of a transaction Sometimes the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example: The default name is causing a metric grouping issue. You want to add custom attributes to your transactions so you can filter them in the query builder. Use these methods when you want to change how New Relic instruments a transaction that is already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction See Naming transactions. Add metadata (such as your customer's account name or subscription level) to your transactions Use custom attributes. See Adding custom attributes. Mark a transaction as a background job See Monitor custom background jobs. Mark a transaction as a web transaction Pass a :category => :controller option to set_transaction_name(). For more information, see Naming transactions. Prevent a transaction from affecting your Apdex score See Ignoring Apdex contributions. Collect or ignore errors Usually the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically See Sending New Relic handled errors. Prevent the agent from reporting an error at all Mark the error as ignored. See Error Collector to use the error_collector.ignore_errors config option. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic Mark the error as expected. See Sending New Relic handled errors, and set :expected to true. Send custom event and metric data from your app APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in dashboards Create a custom event. See record_custom_event(). Tag your events with metadata to filter and facet them in dashboards or error analytics Add custom attributes. Pass a hash of attributes to record_custom_event(). Report custom performance data Create a custom metric. See record_metric(). Control the browser agent Usually the browser agent is added automatically to your pages or deployed by copy/pasting the JavaScript snippet. For more information about these recommended methods, see Add apps to browser monitoring. However, you can also retrieve the browser agent via APM agent API calls. For more information, see browser_timing_header(). Instrument calls to datastores Use these methods to collect data about your app's connections to other datastores: If you want to... Do this... Time a call to a datastore not instrumented automatically by New Relic See wrap(). Time a datastore call that can't cleanly be wrapped in a Ruby block See Tracer.start_datastore_segment(). You must call finish on the object returned by this method. Capture SQL queries along with timing See notice_sql(). Capture non-SQL queries along with timing See notice_statement(). Instrument calls to externals Use these methods to collect data for external requests: If you want to... Do this... Time a call to an external request not instrumented automatically by New Relic Use Tracer.start_external_segment(). You must call finish on the object returned by this method. Add cross-application tracing (CAT) headers to an outbound HTTP request Use add_request_headers(). Read CAT headers from an inbound HTTP request Use read_response_headers(). Generate an obfuscated string to transport CAT information in an outbound request Use get_request_metadata(). Process an obfuscated string containing CAT information received from an inbound request Use process_response_metadata(). Instrument calls for distributed tracing Important The following API examples require Ruby agent version 6.9.0 or higher. These APIs require distributed tracing to be enabled. Distributed tracing lets you see the paths requests take as they travel through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. If you want to... Do this... Send a payload/header to the called service. See insert_distributed_trace_headers(). Accept a payload/header received from the first service, which will link these services together in a trace See accept_distributed_trace_headers().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.28881,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "sections": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> provides a public <em>API</em> with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your <em>Ruby</em> app and collect more in-depth data: Overview Public <em>API</em> methods The following sections explain common goals, solutions"
      },
      "id": "604403a5196a67e712960f33"
    },
    {
      "sections": [
        "Ignoring specific transactions",
        "Blocking all instrumentation",
        "Ignoring specific actions with Rails",
        "Ignoring specific routes with Sinatra",
        "Ignoring Apdex contributions",
        "Blocking browser instrumentation",
        "Ignoring transactions dynamically",
        "Ignoring transactions by URL with configuration",
        "Troubleshooting",
        "For more help"
      ],
      "title": "Ignoring specific transactions",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "711df6a6f072c451ca8a55a9316d8c13c083ada2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/",
      "published_at": "2021-10-12T12:38:51Z",
      "updated_at": "2021-07-21T19:10:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic for Ruby allows you to selectively disable instrumentation for particular requests within your Rails or Sinatra application. Blocking all instrumentation Call newrelic_ignore with no arguments from within a Rails controller or Sinatra application to prevent instrumentation of all requests serviced by that controller or application: newrelic_ignore Copy Using newrelic_ignore prevents the agent from recording any performance data (metrics, transaction traces, events, traced errors, and so on) for the targeted transactions, and will also prevent the transactions from contributing to your overall Apdex score. Ignoring specific actions with Rails If you want to ignore only specific actions with a Rails controller, you can use the :only or :except options with newrelic_ignore. For example, to ignore only the index and show actions on the controller, use: newrelic_ignore :only => [:index, :show] Copy To ignore all actions on the controller except index: newrelic_ignore :except => [:index] Copy Ignoring specific routes with Sinatra If you want to ignore only specific routes within your Sinatra application, you can pass a Sinatra-style route definition to newrelic_ignore from within your Sinatra application. For more information, see Sinatra: Ignoring routes. Ignoring Apdex contributions If you want to prevent all actions in a controller from contributing to your Apdex score, but still want other performance data, use newrelic_ignore_apdex: newrelic_ignore_apdex Copy In a Rails application, newrelic_ignore_apdex supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Blocking browser instrumentation Using newrelic_ignore_enduser prevents the agent from automatically inserting the JavaScript used to capture browser monitoring data. Server-side instrumentation will be unaffected. To prevent browser agent injection for all actions in a controller, add a call like this to the controller class: newrelic_ignore_enduser Copy In a Rails application, newrelic_ignore_enduser supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Ignoring transactions dynamically In some cases, you may want to base the decision to ignore a specific transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren't a good fit. Starting in Ruby agent version 3.9.2, you can instead use the following family of API calls from any point within your transaction: NewRelic::Agent.ignore_transaction NewRelic::Agent.ignore_apdex NewRelic::Agent.ignore_enduser Copy These methods will have a similar results to the newrelic_ignore, newrelic_ignore_apdex, and newrelic_ignore_enduser calls, but can be called during a request instead of during the class definition. Ignoring transactions by URL with configuration You can ignore transactions by URL using the rules.ignore_url_regexes configuration setting: rules: ignore_url_regexes: [\"secret\", \"^/admin\"] Copy This configuration will only prevent Transaction events that match the set pattern from reporting. Use any of the newrelic_ignore* family of methods if you would like to prevent all data, such as trace data, from reporting from a transaction. Note that regexes do not include any type of anchoring by default. The /secret/ regex will match 'newrelic.com/secret/login' and it will also match 'newrelic.com/users/secretpanda'. The anchored admin regex will match 'newrelic.com/admin/praetorians' but it will not match 'newrelic.com/users/totally-real-admin'. If necessary you may also provide a list of regexes in a comma-separated string, allowing you to set ignore regexes with an environment variable: NEW_RELIC_RULES_IGNORE_URL_REGEXES=\"secret,^/admin\" Copy As always configuration from environment variables will override configuration in newrelic.yml. Troubleshooting The newrelic_ignore* family of methods will only work from within Rails controller classes, or Sinatra applications (subclasses of Sinatra::Base). Other applications should use the NewRelic::Agent.ignore_* family of calls from within each request that you would like to ignore, which will work in any context. If you get a NoMethodError when trying to use newrelic_ignore from within a Rails controller or Sinatra application, make sure that newrelic_rpm has been required before you try to call newrelic_ignore inside of your class definition. For more help Additional documentation resources include Apdex: Measuring user satisfaction (how Apdex is calculated).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.54496,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>API</em> <em>guides</em>",
        "body": " transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren&#x27;t a good fit. Starting in <em>Ruby</em> <em>agent</em> version 3.9.2, you can instead use the following family of <em>API</em> calls from any point within your transaction: NewRelic"
      },
      "id": "603eb738196a67db90a83dbd"
    },
    {
      "sections": [
        "Sending handled errors to New Relic",
        "Notify the New Relic Ruby agent of an error"
      ],
      "title": "Sending handled errors to New Relic",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "349823d25fe83093a39bb114453b471888aacfb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/sending-handled-errors-new-relic/",
      "published_at": "2021-10-12T11:07:06Z",
      "updated_at": "2021-03-11T08:12:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To send error data that you are handling in your own code to New Relic, use the Ruby agent API NewRelic::Agent.notice_error call within your error handler. Notify the New Relic Ruby agent of an error This API call takes the exception and an optional options hash. Use this format: notice_error(exception, options = { }) â‡’ Object Copy This function records the given error and passes it through the normal error filtering process, including configuration-based ignoring of errors and the global #ignore_error_filter method if defined. The exception is the exception to be recorded, or an error message. If needed, you can also include options = { }. The following parameters will receive special treatment, and any other parameters you supply will be treated as custom parameters. options = { } Comments :expected Only records the error trace. This does not affect the error rate or Apdex status. For information on expected errors in the UI, see View expected errors. Replaces the :trace_only option, which was deprecated in version 4.3.x of the Ruby agent. :custom_params Custom parameters. :uri The request path, minus any request parameters or query string. Usually not needed. Include this only if you are calling notice_error outside a transaction. :metric The metric name associated with the transaction. Usually not needed. Include this only if you are calling notice_error outside a transaction. :request_params (deprecated) Older Ruby agent versions allowed passing a :request_params option, but those are now ignored. If you need to record the request parameters, call this method inside a transaction, or pass the information in :custom_params.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.7624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Notify the New Relic <em>Ruby</em> <em>agent</em> of an error",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "To send error data that you are handling in your own code to New Relic, use the <em>Ruby</em> <em>agent</em> <em>API</em> NewRelic::<em>Agent</em>.notice_error call within your error handler. Notify the New Relic <em>Ruby</em> <em>agent</em> of an error This <em>API</em> call takes the exception and an optional options hash. Use this format: notice_error"
      },
      "id": "604403e0e7b9d295a15799ec"
    }
  ],
  "/docs/agents/ruby-agent/attributes/enable-disable-attributes-ruby": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.732376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-13T03:25:08Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.420074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " the capture_params setting, the <em>Ruby</em> <em>agent</em> will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the <em>attributes</em>.include setting instead. For more information, see the <em>Ruby</em> attribute examples. config_path Type String Default (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Ruby agent attributes",
        "httpResponseCode",
        "request.headers.referer",
        "request.parameters.*",
        "job.resque.args.*",
        "job.sidekiq.args.*",
        "Adding custom attributes",
        "Caution",
        "Upgrading the Ruby agent",
        "For more help"
      ],
      "title": "Ruby agent attributes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Attributes"
      ],
      "external_id": "76453699d829800b2dc9757c66c6f25f6c37f86a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/attributes/ruby-agent-attributes/",
      "published_at": "2021-10-12T11:55:05Z",
      "updated_at": "2021-06-02T22:15:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations. These attribute settings apply to version 3.12.0 or higher of the Ruby agent. Ruby agent attributes The following table lists the attributes that can be automatically captured by the Ruby agent: httpResponseCode The response status code for a web request. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Unavailable Note: The httpResponseCode attribute (string value) is deprecated as of agent version 6.12.0. http.statusCode (integer value) should be used instead. request.headers.referer The HTTP referrer header if present (minus the query string). Defaults: Transaction traces: Disabled Error collector (traced errors): Enabled Transaction events: Disabled Page views (browser monitoring): Unavailable request.parameters.* The HTTP request parameters, associated with the transaction. Available for Rails, Sinatra, and Grape applications only. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Disabled Note: The capture_params property is deprecated. However, if set to true, it will enable request parameters for transaction traces and traced errors. job.resque.args.* Job arguments passed to the Resque worker. Arguments passed to Resque workers are positional. These arguments are stored as keys of the form job.resque.args.<position> where position is the index of the argument to the perform method. For example, a Resque job that takes two arguments will have keys job.resque.args.0 and job.resque.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The resque.capture_params property is deprecated. However, if set to true, it will enable capture of Resque arguments for transaction traces, traced errors. job.sidekiq.args.* Job arguments passed to the Sidekiq worker. Arguments passed to Sidekiq workers are positional. These arguments are stored as keys of the form job.sidekiq.args.<position> where position is the index of the argument to the perform method. For example, a Sidekiq job that takes two arguments will have keys job.sidekiq.args.0 and job.sidekiq.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The sidekiq.capture_params property is deprecated. However, if set to true, it will enable capture of Sidekiq arguments for transaction traces and traced errors. Adding custom attributes To capture additional custom attributes from your application, use NewRelic::Agent.add_custom_attributes. For full reference see Collecting custom attributes. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Disabled Caution If you want to query your custom parameters or attributes, avoid using any of the reserved terms for naming them. Upgrading the Ruby agent When upgrading to Ruby agent 3.12.0 or higher, upgrade your newrelic.yml configuration. For more help Additional documentation resources include: Agent attributes (types, destinations, and limits for attributes used by New Relic agents) Enabling and disabling attributes (properties, rules, and backwards compatibility information for Ruby agent attributes) Attribute examples (scenarios and results of enabling and disabling different Ruby agent attributes)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.43631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " <em>attributes</em> (types, destinations, and limits for <em>attributes</em> used by New Relic <em>agents</em>) Enabling and disabling <em>attributes</em> (properties, rules, and backwards compatibility information for <em>Ruby</em> <em>agent</em> <em>attributes</em>) Attribute examples (scenarios and results of enabling and disabling different <em>Ruby</em> <em>agent</em> <em>attributes</em>)"
      },
      "id": "6044042028ccbc7da82c6083"
    }
  ],
  "/docs/agents/ruby-agent/attributes/ruby-agent-attributes": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.732376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-13T03:25:08Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.420074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " the capture_params setting, the <em>Ruby</em> <em>agent</em> will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the <em>attributes</em>.include setting instead. For more information, see the <em>Ruby</em> attribute examples. config_path Type String Default (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Enable and disable attributes (Ruby)",
        "Properties",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Attribute rules",
        "Root level takes precedence for enabled.",
        "Destination enabled takes precedence over include and exclude.",
        "Attribute is included if the destination is enabled.",
        "Exclude always supersedes include.",
        "Keys are case sensitive.",
        "Use \\* for wildcards.",
        "Most specific setting for a key takes priority.",
        "Include or exclude affects the specific destination.",
        "URI-related properties",
        "Deprecated properties"
      ],
      "title": "Enable and disable attributes (Ruby)",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Attributes"
      ],
      "external_id": "af78e50fc7741c48a005c8fe81225b84f06e6c3c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/attributes/enable-disable-attributes-ruby/",
      "published_at": "2021-10-12T11:50:02Z",
      "updated_at": "2021-03-11T10:09:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This describes the properties to enable or disable attributes, and the rules that New Relic uses when determining which attributes to include or exclude for a destination. This also includes a summary of the Ruby agent properties that have been deprecated with the release of New Relic agent attributes. Properties Use the following properties to enable or disable attributes: attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. To prevent error.message collection, instead use the strip_exception_messages configuration. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction segments. Allows * as wildcard at end. Attribute rules New Relic follows these rules when determining which attributes to include or exclude for a destination. Root level takes precedence for enabled. The attributes.enabled field trumps all other settings. When false, no attributes will be reported to New Relic. Example configuration: attributes.enabled: false attributes.include: foo, bar transaction_tracer.attributes.enabled: true Copy Example output: Keys passed in: foo, bar, baz Keys included for all destinations: Keys excluded for all destinations: foo, bar, baz Copy Destination enabled takes precedence over include and exclude. The YOUR_DESTINATION.attributes.enabled flags take precedence over include and exclude keys. Example configuration: transaction_tracer.attributes.enabled: false attributes.include: one, two transaction_tracer.attributes.include: three, four Copy Example output: Keys passed in: one, two, three, four Keys included for transaction traces: Keys excluded for transaction traces: one, two, three, four Copy Attribute is included if the destination is enabled. If a destination is enabled, all user attributes are sent to that destination by default. Note: All user attributes default to true. However, by default, request parameters are disabled for all destinations. Example configuration: attributes.enabled: true attributes.exclude: baz Copy Example output: Keys passed in: foo, bar, baz Keys included: foo, bar Keys excluded: baz Copy Exclude always supersedes include. If the same key is listed in the include and exclude lists, then attributes with the specified key will be excluded. Example configuration: attributes.enabled: true attributes.include: foo, bar attributes.exclude: nerd, bar Copy Example output: Keys passed in: foo, bar, nerd Keys included: foo Keys excluded: nerd, bar Copy Keys are case sensitive. Keys are case-sensitive. Example configuration: attributes.enabled: true attributes.exclude: username, UsErNaMe Copy Example output: Keys passed in: username, Username, USERNAME, UsErNaMe, userNAME Keys included: Username, USERNAME, userNAME Keys excluded: username, UsErNaMe Copy Use \\* for wildcards. You can use an asterisk * at the end of a key as a wildcard. This will match a set of attributes with the same prefix. Example configuration: attributes.enabled: true attributes.include: custom* attributes.exclude: request.parameters.* Copy Example output: Keys passed in: custom, custom.key1, custom.key2, request.parameters., request.parameters.foo, request.parameters.bar Keys included: custom, custom.key1, custom.key2 Keys excluded: request.parameters., request.parameters.foo, request.parameters.bar Copy Most specific setting for a key takes priority. If multiple include or exclude attributes affect the same key, the most specific setting will have priority. Example configuration: attributes.enabled: true attributes.include: request.parameters.foo attributes.exclude: request.parameters.* Copy Example output: Keys passed in: request.parameters., request.parameters.foo, request.parameters.bar Keys included: request.parameters.foo Keys excluded: request.parameters., request.parameters.bar Copy Include or exclude affects the specific destination. If the attribute include or exclude is specified on a destination, then it only impacts that destination. Example configuration: attributes.include: foo transaction_events.attributes.exclude: foo Copy Example output: Keys passed in: foo Keys included for transaction events: Keys included for other destinations: foo Keys excluded for transaction events: foo Copy URI-related properties By default, the Ruby Agent reports Uniform Resource Identifiers (URIs) to New Relic in several different places, including the following destinations: The request.uri attribute of error events The http.url attribute of span events The url attribute of slow SQL traces The uri attribute of external request segments New Relic recommends having these URIs reported, as they can contain useful debugging information. If your URIs contain sensitive data that you don't want reported, URI reporting can be disabled. For example, sensitive data could include email addresses or account IDs. To disable URI reporting, add any of the above attribute names to the attributes.exclude list. For example, if you adding the following key to your configuration file will stop the agent from reporting any of the URI-related properties: attributes.exclude: uri Copy Deprecated properties The following properties have been deprecated. Switch to the new attributes configuration for these properties when upgrading your Ruby agent. Deprecated property New property capture_params attributes.include: request.parameters.* resque.capture_params attributes.include: job.resque.args.* sidekiq.capture_params attributes.include: job.sidekiq.args.* transaction_tracer.capture_attributes transaction_tracer.attributes.enabled error_collector.capture_attributes error_collector.attributes.enabled browser_monitoring.capture_attributes browser_monitoring.attributes.enabled analytics_events.capture_attributes transaction_events.attributes.enabled",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.99051,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable and disable <em>attributes</em> (<em>Ruby</em>)",
        "sections": "Enable and disable <em>attributes</em> (<em>Ruby</em>)",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "This describes the properties to enable or disable <em>attributes</em>, and the rules that New Relic uses when determining which <em>attributes</em> to include or exclude for a destination. This also includes a summary of the <em>Ruby</em> <em>agent</em> properties that have been deprecated with the release of New Relic <em>agent</em>"
      },
      "id": "604403e0196a67cab0960f3a"
    }
  ],
  "/docs/agents/ruby-agent/attributes/ruby-attribute-examples": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.73236,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-13T03:25:08Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.42006,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " the capture_params setting, the <em>Ruby</em> <em>agent</em> will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the <em>attributes</em>.include setting instead. For more information, see the <em>Ruby</em> attribute examples. config_path Type String Default (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Ruby agent attributes",
        "httpResponseCode",
        "request.headers.referer",
        "request.parameters.*",
        "job.resque.args.*",
        "job.sidekiq.args.*",
        "Adding custom attributes",
        "Caution",
        "Upgrading the Ruby agent",
        "For more help"
      ],
      "title": "Ruby agent attributes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Attributes"
      ],
      "external_id": "76453699d829800b2dc9757c66c6f25f6c37f86a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/attributes/ruby-agent-attributes/",
      "published_at": "2021-10-12T11:55:05Z",
      "updated_at": "2021-06-02T22:15:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations. These attribute settings apply to version 3.12.0 or higher of the Ruby agent. Ruby agent attributes The following table lists the attributes that can be automatically captured by the Ruby agent: httpResponseCode The response status code for a web request. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Unavailable Note: The httpResponseCode attribute (string value) is deprecated as of agent version 6.12.0. http.statusCode (integer value) should be used instead. request.headers.referer The HTTP referrer header if present (minus the query string). Defaults: Transaction traces: Disabled Error collector (traced errors): Enabled Transaction events: Disabled Page views (browser monitoring): Unavailable request.parameters.* The HTTP request parameters, associated with the transaction. Available for Rails, Sinatra, and Grape applications only. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Disabled Note: The capture_params property is deprecated. However, if set to true, it will enable request parameters for transaction traces and traced errors. job.resque.args.* Job arguments passed to the Resque worker. Arguments passed to Resque workers are positional. These arguments are stored as keys of the form job.resque.args.<position> where position is the index of the argument to the perform method. For example, a Resque job that takes two arguments will have keys job.resque.args.0 and job.resque.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The resque.capture_params property is deprecated. However, if set to true, it will enable capture of Resque arguments for transaction traces, traced errors. job.sidekiq.args.* Job arguments passed to the Sidekiq worker. Arguments passed to Sidekiq workers are positional. These arguments are stored as keys of the form job.sidekiq.args.<position> where position is the index of the argument to the perform method. For example, a Sidekiq job that takes two arguments will have keys job.sidekiq.args.0 and job.sidekiq.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The sidekiq.capture_params property is deprecated. However, if set to true, it will enable capture of Sidekiq arguments for transaction traces and traced errors. Adding custom attributes To capture additional custom attributes from your application, use NewRelic::Agent.add_custom_attributes. For full reference see Collecting custom attributes. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Disabled Caution If you want to query your custom parameters or attributes, avoid using any of the reserved terms for naming them. Upgrading the Ruby agent When upgrading to Ruby agent 3.12.0 or higher, upgrade your newrelic.yml configuration. For more help Additional documentation resources include: Agent attributes (types, destinations, and limits for attributes used by New Relic agents) Enabling and disabling attributes (properties, rules, and backwards compatibility information for Ruby agent attributes) Attribute examples (scenarios and results of enabling and disabling different Ruby agent attributes)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.43631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " <em>attributes</em> (types, destinations, and limits for <em>attributes</em> used by New Relic <em>agents</em>) Enabling and disabling <em>attributes</em> (properties, rules, and backwards compatibility information for <em>Ruby</em> <em>agent</em> <em>attributes</em>) Attribute examples (scenarios and results of enabling and disabling different <em>Ruby</em> <em>agent</em> <em>attributes</em>)"
      },
      "id": "6044042028ccbc7da82c6083"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/delayedjob-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-10-12T11:52:01Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.77304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-10-12T11:57:24Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.76706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-10-12T11:57:24Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.8863,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes": [
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-10-12T11:57:24Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.76706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-10-12T11:57:24Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.8863,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    },
    {
      "sections": [
        "Rake instrumentation",
        "Enable Rake support",
        "Remove newrelic-rake when appropriate",
        "Caution",
        "Capture Rake job arguments"
      ],
      "title": "Rake instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "d9f92b20388116f3ad38161c58ea8238e6243c71",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/rake-instrumentation/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-03-16T07:58:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher Ruby agent version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app's Rake tasks, add the names of the target tasks to the rake.tasks element in your newrelic.yml file. The Ruby agent matches these names against your active tasks using string regex. Example: Instrumenting two Rake tasks For example, to instrument the Rake tasks deploy and deploy:all, add the following to your newrelic.yml file: rake: tasks: [\"deploy\", \"deploy:all\"] Copy Since task name matching is with regex, you can instrument all of your app's Rake tasks by using a wildcard regex like [\".+\"]. However, this will not include Rake tasks that are in your deny list by default from the autostart.blacklisted_rake_tasks configuration setting, such as db:migrate. To include any Rake tasks that are in your deny list by default, include them in your customized deny list. To ensure the tasks are instrumented before they run if you are using Rails but your Rake task does not require the Rails environment, add require 'tasks/newrelic' to the top of the Rake tasks. Remove newrelic-rake when appropriate The newrelic-rake third-party gem provides Rake instrumentation support as an add-on to the Ruby agent. If the agent detects newrelic-rake, it will not install the built-in Rake instrumentation, but it will record a log message like this at startup: INFO : Not installing New Relic supported Rake instrumentation because the third party newrelic-rake gem is present Copy Caution Removing the newrelic-rake gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. To switch to New Relic's built-in Rake instrumentation and change your transaction names: Remove the newrelic-rake gem. Specify the tasks you want to instrument in your config file. Capture Rake job arguments By default Rake job arguments are not captured. To capture Rake job arguments, use: attributes.include: job.rake.* Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.46777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Capture Rake <em>job</em> arguments",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher <em>Ruby</em> <em>agent</em> version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app&#x27;s Rake tasks, add"
      },
      "id": "603e9fea64441f1e104e8841"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/rake-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-10-12T11:52:01Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.77304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-10-12T11:57:24Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.76706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-10-12T11:57:24Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.8863,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/resque-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-10-12T11:52:01Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.77304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-10-12T11:57:24Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.76706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Rake instrumentation",
        "Enable Rake support",
        "Remove newrelic-rake when appropriate",
        "Caution",
        "Capture Rake job arguments"
      ],
      "title": "Rake instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "d9f92b20388116f3ad38161c58ea8238e6243c71",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/rake-instrumentation/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-03-16T07:58:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher Ruby agent version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app's Rake tasks, add the names of the target tasks to the rake.tasks element in your newrelic.yml file. The Ruby agent matches these names against your active tasks using string regex. Example: Instrumenting two Rake tasks For example, to instrument the Rake tasks deploy and deploy:all, add the following to your newrelic.yml file: rake: tasks: [\"deploy\", \"deploy:all\"] Copy Since task name matching is with regex, you can instrument all of your app's Rake tasks by using a wildcard regex like [\".+\"]. However, this will not include Rake tasks that are in your deny list by default from the autostart.blacklisted_rake_tasks configuration setting, such as db:migrate. To include any Rake tasks that are in your deny list by default, include them in your customized deny list. To ensure the tasks are instrumented before they run if you are using Rails but your Rake task does not require the Rails environment, add require 'tasks/newrelic' to the top of the Rake tasks. Remove newrelic-rake when appropriate The newrelic-rake third-party gem provides Rake instrumentation support as an add-on to the Ruby agent. If the agent detects newrelic-rake, it will not install the built-in Rake instrumentation, but it will record a log message like this at startup: INFO : Not installing New Relic supported Rake instrumentation because the third party newrelic-rake gem is present Copy Caution Removing the newrelic-rake gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. To switch to New Relic's built-in Rake instrumentation and change your transaction names: Remove the newrelic-rake gem. Specify the tasks you want to instrument in your config file. Capture Rake job arguments By default Rake job arguments are not captured. To capture Rake job arguments, use: attributes.include: job.rake.* Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.46777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Capture Rake <em>job</em> arguments",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher <em>Ruby</em> <em>agent</em> version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app&#x27;s Rake tasks, add"
      },
      "id": "603e9fea64441f1e104e8841"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-10-12T11:52:01Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.77304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-10-12T11:57:24Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.8863,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    },
    {
      "sections": [
        "Rake instrumentation",
        "Enable Rake support",
        "Remove newrelic-rake when appropriate",
        "Caution",
        "Capture Rake job arguments"
      ],
      "title": "Rake instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "d9f92b20388116f3ad38161c58ea8238e6243c71",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/rake-instrumentation/",
      "published_at": "2021-10-12T11:56:08Z",
      "updated_at": "2021-03-16T07:58:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher Ruby agent version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app's Rake tasks, add the names of the target tasks to the rake.tasks element in your newrelic.yml file. The Ruby agent matches these names against your active tasks using string regex. Example: Instrumenting two Rake tasks For example, to instrument the Rake tasks deploy and deploy:all, add the following to your newrelic.yml file: rake: tasks: [\"deploy\", \"deploy:all\"] Copy Since task name matching is with regex, you can instrument all of your app's Rake tasks by using a wildcard regex like [\".+\"]. However, this will not include Rake tasks that are in your deny list by default from the autostart.blacklisted_rake_tasks configuration setting, such as db:migrate. To include any Rake tasks that are in your deny list by default, include them in your customized deny list. To ensure the tasks are instrumented before they run if you are using Rails but your Rake task does not require the Rails environment, add require 'tasks/newrelic' to the top of the Rake tasks. Remove newrelic-rake when appropriate The newrelic-rake third-party gem provides Rake instrumentation support as an add-on to the Ruby agent. If the agent detects newrelic-rake, it will not install the built-in Rake instrumentation, but it will record a log message like this at startup: INFO : Not installing New Relic supported Rake instrumentation because the third party newrelic-rake gem is present Copy Caution Removing the newrelic-rake gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. To switch to New Relic's built-in Rake instrumentation and change your transaction names: Remove the newrelic-rake gem. Specify the tasks you want to instrument in your config file. Capture Rake job arguments By default Rake job arguments are not captured. To capture Rake job arguments, use: attributes.include: job.rake.* Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.46777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Capture Rake <em>job</em> arguments",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher <em>Ruby</em> <em>agent</em> version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app&#x27;s Rake tasks, add"
      },
      "id": "603e9fea64441f1e104e8841"
    }
  ],
  "/docs/agents/ruby-agent/configuration/connect-hosts-your-account": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/whats-new/2021/10/ruby-8-0-0-update/",
      "sections": [
        "Distributed Tracing enabled by default with Ruby Agent Update: Version 8.0.0"
      ],
      "published_at": "2021-10-17T12:59:25Z",
      "title": "Distributed Tracing enabled by default with Ruby Agent Update: Version 8.0.0",
      "updated_at": "2021-10-17T11:31:06Z",
      "type": "docs",
      "external_id": "cefc251f04969df932c038b1afee81f1ceebb7d0",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "With the release of Ruby Agent version v8.0.0, upon agent upgrade, you'll have Distributed Tracing on by default. This eliminates the need to configure the agent to have access to distributed traces. Distributed Tracing gives software teams working in modern environments an easy way to capture, visualize, and analyze traces through complex architectures, including architectures that use both monoliths and microservices. Whatâ€™s the impact? With this change, you'll see distributed traces immediately upon upgrading to Ruby version v8.0.0. Distributed Tracing on by default provides more data and better visibility for cross-application requests. If you do not need this feature, you can turn it off in the Ruby agent configuration file by setting distributed_tracing.enabled=false or by setting the environment variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=false. If you need more traces and are experiencing dropped spans, the agent reservoir can be expanded to accommodate more spans. To do so, set the environment variable or config item called span_events.max_samples_stored to a value greater than 2,000 up to a maximum value of 10,000. Note that increasing this value may impact memory usage. With Distributed Tracing on by default, Cross Application Tracing (CAT) will now be deprecated and will be removed in a future version of the agent. If you're on CAT, you'll now see distributed traces instead. If you want to revert back to CAT, you can do so by setting cross_application_tracer.enabled = true in the configuration file. We recommend you to keep using distributed tracing, given that CAT will be removed in the future.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.81519,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Distributed Tracing enabled by default with <em>Ruby</em> <em>Agent</em> Update: Version 8.0.0",
        "sections": "Distributed Tracing enabled by default with <em>Ruby</em> <em>Agent</em> Update: Version 8.0.0",
        "body": " and better visibility for cross-application requests. If you do not need this feature, you can turn it off in the <em>Ruby</em> <em>agent</em> <em>configuration</em> file by setting distributed_tracing.enabled=false or by setting the environment variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=false. If you need more traces"
      },
      "id": "616c097ae7b9d2f64c477225"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-13T03:25:08Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.795364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "You can configure the New Relic <em>Ruby</em> <em>agent</em> with settings in a <em>configuration</em> file, environment variables, or programmatically with server-side <em>configuration</em>. This document summarizes the <em>configuration</em> options available for the <em>Ruby</em> <em>agent</em>. If the default value for a <em>configuration</em> option is (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.00164,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "-check that your <em>Ruby</em> <em>agent</em> <em>configuration</em> file (config&#x2F;newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the <em>Ruby</em> <em>agent</em>&#x27;s plugin folder (vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em>&#x2F;newrelic.yml). Look for new <em>configuration</em> options that are not in your config&#x2F;newrelic.ymlÂ file. Update"
      },
      "id": "603eb6f4196a67251da83d95"
    }
  ],
  "/docs/agents/ruby-agent/configuration/custom-ssl-certificates-ruby": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/whats-new/2021/10/ruby-8-0-0-update/",
      "sections": [
        "Distributed Tracing enabled by default with Ruby Agent Update: Version 8.0.0"
      ],
      "published_at": "2021-10-17T12:59:25Z",
      "title": "Distributed Tracing enabled by default with Ruby Agent Update: Version 8.0.0",
      "updated_at": "2021-10-17T11:31:06Z",
      "type": "docs",
      "external_id": "cefc251f04969df932c038b1afee81f1ceebb7d0",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "With the release of Ruby Agent version v8.0.0, upon agent upgrade, you'll have Distributed Tracing on by default. This eliminates the need to configure the agent to have access to distributed traces. Distributed Tracing gives software teams working in modern environments an easy way to capture, visualize, and analyze traces through complex architectures, including architectures that use both monoliths and microservices. Whatâ€™s the impact? With this change, you'll see distributed traces immediately upon upgrading to Ruby version v8.0.0. Distributed Tracing on by default provides more data and better visibility for cross-application requests. If you do not need this feature, you can turn it off in the Ruby agent configuration file by setting distributed_tracing.enabled=false or by setting the environment variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=false. If you need more traces and are experiencing dropped spans, the agent reservoir can be expanded to accommodate more spans. To do so, set the environment variable or config item called span_events.max_samples_stored to a value greater than 2,000 up to a maximum value of 10,000. Note that increasing this value may impact memory usage. With Distributed Tracing on by default, Cross Application Tracing (CAT) will now be deprecated and will be removed in a future version of the agent. If you're on CAT, you'll now see distributed traces instead. If you want to revert back to CAT, you can do so by setting cross_application_tracer.enabled = true in the configuration file. We recommend you to keep using distributed tracing, given that CAT will be removed in the future.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.81519,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Distributed Tracing enabled by default with <em>Ruby</em> <em>Agent</em> Update: Version 8.0.0",
        "sections": "Distributed Tracing enabled by default with <em>Ruby</em> <em>Agent</em> Update: Version 8.0.0",
        "body": " and better visibility for cross-application requests. If you do not need this feature, you can turn it off in the <em>Ruby</em> <em>agent</em> <em>configuration</em> file by setting distributed_tracing.enabled=false or by setting the environment variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=false. If you need more traces"
      },
      "id": "616c097ae7b9d2f64c477225"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-13T03:25:08Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.795364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "You can configure the New Relic <em>Ruby</em> <em>agent</em> with settings in a <em>configuration</em> file, environment variables, or programmatically with server-side <em>configuration</em>. This document summarizes the <em>configuration</em> options available for the <em>Ruby</em> <em>agent</em>. If the default value for a <em>configuration</em> option is (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.00164,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "-check that your <em>Ruby</em> <em>agent</em> <em>configuration</em> file (config&#x2F;newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the <em>Ruby</em> <em>agent</em>&#x27;s plugin folder (vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em>&#x2F;newrelic.yml). Look for new <em>configuration</em> options that are not in your config&#x2F;newrelic.ymlÂ file. Update"
      },
      "id": "603eb6f4196a67251da83d95"
    }
  ],
  "/docs/agents/ruby-agent/configuration/ruby-agent-configuration": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/whats-new/2021/10/ruby-8-0-0-update/",
      "sections": [
        "Distributed Tracing enabled by default with Ruby Agent Update: Version 8.0.0"
      ],
      "published_at": "2021-10-17T12:59:25Z",
      "title": "Distributed Tracing enabled by default with Ruby Agent Update: Version 8.0.0",
      "updated_at": "2021-10-17T11:31:06Z",
      "type": "docs",
      "external_id": "cefc251f04969df932c038b1afee81f1ceebb7d0",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "With the release of Ruby Agent version v8.0.0, upon agent upgrade, you'll have Distributed Tracing on by default. This eliminates the need to configure the agent to have access to distributed traces. Distributed Tracing gives software teams working in modern environments an easy way to capture, visualize, and analyze traces through complex architectures, including architectures that use both monoliths and microservices. Whatâ€™s the impact? With this change, you'll see distributed traces immediately upon upgrading to Ruby version v8.0.0. Distributed Tracing on by default provides more data and better visibility for cross-application requests. If you do not need this feature, you can turn it off in the Ruby agent configuration file by setting distributed_tracing.enabled=false or by setting the environment variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=false. If you need more traces and are experiencing dropped spans, the agent reservoir can be expanded to accommodate more spans. To do so, set the environment variable or config item called span_events.max_samples_stored to a value greater than 2,000 up to a maximum value of 10,000. Note that increasing this value may impact memory usage. With Distributed Tracing on by default, Cross Application Tracing (CAT) will now be deprecated and will be removed in a future version of the agent. If you're on CAT, you'll now see distributed traces instead. If you want to revert back to CAT, you can do so by setting cross_application_tracer.enabled = true in the configuration file. We recommend you to keep using distributed tracing, given that CAT will be removed in the future.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.81506,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Distributed Tracing enabled by default with <em>Ruby</em> <em>Agent</em> Update: Version 8.0.0",
        "sections": "Distributed Tracing enabled by default with <em>Ruby</em> <em>Agent</em> Update: Version 8.0.0",
        "body": " and better visibility for cross-application requests. If you do not need this feature, you can turn it off in the <em>Ruby</em> <em>agent</em> <em>configuration</em> file by setting distributed_tracing.enabled=false or by setting the environment variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=false. If you need more traces"
      },
      "id": "616c097ae7b9d2f64c477225"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.001625,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "-check that your <em>Ruby</em> <em>agent</em> <em>configuration</em> file (config&#x2F;newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the <em>Ruby</em> <em>agent</em>&#x27;s plugin folder (vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em>&#x2F;newrelic.yml). Look for new <em>configuration</em> options that are not in your config&#x2F;newrelic.ymlÂ file. Update"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-12T11:58:08Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.38609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " cross application tracing, such as for a non-standard middleware framework, see the <em>configuration</em> information in this document. Requirements Follow these requirements to use cross application tracing with the <em>Ruby</em> <em>agent</em>: Make sure the requests being instrumented use a supported HTTP client library"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    }
  ],
  "/docs/agents/ruby-agent/features/cross-application-tracing-ruby": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-12T12:10:21Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.52809,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-12T12:50:49Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.23943,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.139046,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/features/developer-mode": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-12T12:10:21Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.52808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-12T11:58:08Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.42654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-12T12:50:49Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.23941,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/features/garbage-collection": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-12T12:10:21Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.52808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-12T11:58:08Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.42654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-12T12:50:49Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.23941,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/features/http-client-tracing-ruby": [
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-12T11:58:08Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.42651,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-12T12:50:49Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.2394,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.13903,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/features/message-queues": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-12T12:10:21Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.52805,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-12T11:58:08Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.42651,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-12T12:50:49Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.2394,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-12T12:10:21Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.52805,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-12T11:58:08Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.4265,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-12T12:50:49Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.23938,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/features/record-deployments-ruby-agent": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-12T12:10:21Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.52805,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-12T11:58:08Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.4265,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.13902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/features/ruby-vm-measurements": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-12T12:10:21Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.52802,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-12T11:58:08Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.42648,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-12T12:50:49Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.23936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/metal-controller-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-12T14:38:56Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > MonitorÂ > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > MonitorÂ > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.86693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-12T14:38:55Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.46176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-12T12:25:26Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.15056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/mongo-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-12T14:38:56Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > MonitorÂ > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > MonitorÂ > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.86691,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-12T14:38:55Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.46176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Redis instrumentation",
        "Tip",
        "Interaction with newrelic-redis",
        "Important",
        "Capture Redis command arguments"
      ],
      "title": "Redis instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "9923fcd7dd89191c620a9490fb89cd8ca4bf31e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation/",
      "published_at": "2021-10-12T14:38:55Z",
      "updated_at": "2021-03-16T08:03:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent automatically instruments the Redis gem (gem version 3.0.0 or higher). After you install the agent and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart on the APM Summary page will show color-coded Redis information. Tip Redis instrumentation requires Ruby agent version 3.13.0 or higher. Interaction with newrelic-redis The third-party newrelic-redis gem provides Redis instrumentation support as an add-on to New Relic's Ruby agent. If the Ruby agent detects newrelic-redis, it will not install the built-in Redis instrumentation and will record a log message like this at startup: INFO : Not installing New Relic supported Redis instrumentation because the third party newrelic-redis gem is present Copy To use New Relic's built-in Redis instrumentation and view Redis information in the UI, remove the newrelic-redis gem. Important Removing the newrelic-redis gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. Capture Redis command arguments By default, the Ruby agent only captures Redis command names. To capture Redis command arguments, use this configuration: transaction_tracer: record_redis_arguments: true Copy The agent limits the number of characters and arguments collected from each transaction trace node. The agent truncates items that exceed these limits.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.12064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Redis <em>instrumentation</em>",
        "sections": "Redis <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> automatically instruments the Redis <em>gem</em> (<em>gem</em> version 3.0.0 or higher). After you install the <em>agent</em> and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart"
      },
      "id": "603ed7a628ccbca064eba784"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/rack-metal-support": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-12T14:38:56Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > MonitorÂ > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > MonitorÂ > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.86691,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-12T14:38:55Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.46176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-12T12:25:26Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.15056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/sequel-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-12T14:38:56Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > MonitorÂ > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > MonitorÂ > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.86688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-12T14:38:55Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.46176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-12T12:25:26Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.15056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/apm-agent-security-ruby": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.00258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-12T14:37:06Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, â€˜metric_#{args[0]}â€™ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { â€œmetric_#{args[0]}â€ } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, â€˜metric1â€™ add_method_tracer :foo, â€˜metric2â€™, push_scope: false add_method_tracer :foo, â€˜metric3â€™, push_scope: false Copy # new add_method_tracer :foo, [â€˜metric1â€™, â€˜metric2â€™, â€˜metric3â€™] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.73785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-12T14:38:04Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.24379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby": [
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-12T14:37:06Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, â€˜metric_#{args[0]}â€™ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { â€œmetric_#{args[0]}â€ } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, â€˜metric1â€™ add_method_tracer :foo, â€˜metric2â€™, push_scope: false add_method_tracer :foo, â€˜metric3â€™, push_scope: false Copy # new add_method_tracer :foo, [â€˜metric1â€™, â€˜metric2â€™, â€˜metric3â€™] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.73784,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-12T14:38:04Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.24379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    },
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-10-12T14:37:06Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.70201,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and <em>start</em>"
      },
      "id": "605adf9b64441f9fed868b80"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/migration-7x-guide": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.00256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-12T14:37:06Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, â€˜metric_#{args[0]}â€™ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { â€œmetric_#{args[0]}â€ } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, â€˜metric1â€™ add_method_tracer :foo, â€˜metric2â€™, push_scope: false add_method_tracer :foo, â€˜metric3â€™, push_scope: false Copy # new add_method_tracer :foo, [â€˜metric1â€™, â€˜metric2â€™, â€˜metric3â€™] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.73784,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-12T14:38:04Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.24379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/migration-8x-guide": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.00253,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-12T14:38:04Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.24377,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    },
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-10-12T14:37:06Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and <em>start</em>"
      },
      "id": "605adf9b64441f9fed868b80"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/new-relics-github-repository": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.00253,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-12T14:37:06Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, â€˜metric_#{args[0]}â€™ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { â€œmetric_#{args[0]}â€ } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, â€˜metric1â€™ add_method_tracer :foo, â€˜metric2â€™, push_scope: false add_method_tracer :foo, â€˜metric3â€™, push_scope: false Copy # new add_method_tracer :foo, [â€˜metric1â€™, â€˜metric2â€™, â€˜metric3â€™] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.73782,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-12T14:38:04Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.24377,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.00253,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-12T14:37:06Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, â€˜metric_#{args[0]}â€™ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { â€œmetric_#{args[0]}â€ } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, â€˜metric1â€™ add_method_tracer :foo, â€˜metric2â€™, push_scope: false add_method_tracer :foo, â€˜metric3â€™, push_scope: false Copy # new add_method_tracer :foo, [â€˜metric1â€™, â€˜metric2â€™, â€˜metric3â€™] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.73781,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-10-12T14:37:06Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and <em>start</em>"
      },
      "id": "605adf9b64441f9fed868b80"
    }
  ],
  "/docs/agents/ruby-agent/index": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.3724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "These instructions are for installing the <em>Ruby</em> <em>agent</em> as a Rails plugin. For most use cases, you should instead install the <em>agent</em> gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the <em>Ruby</em> <em>agent</em> as a gem in order to have better control over versions"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/whats-new/2021/10/ruby-8-0-0-update/",
      "sections": [
        "Distributed Tracing enabled by default with Ruby Agent Update: Version 8.0.0"
      ],
      "published_at": "2021-10-17T12:59:25Z",
      "title": "Distributed Tracing enabled by default with Ruby Agent Update: Version 8.0.0",
      "updated_at": "2021-10-17T11:31:06Z",
      "type": "docs",
      "external_id": "cefc251f04969df932c038b1afee81f1ceebb7d0",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "With the release of Ruby Agent version v8.0.0, upon agent upgrade, you'll have Distributed Tracing on by default. This eliminates the need to configure the agent to have access to distributed traces. Distributed Tracing gives software teams working in modern environments an easy way to capture, visualize, and analyze traces through complex architectures, including architectures that use both monoliths and microservices. Whatâ€™s the impact? With this change, you'll see distributed traces immediately upon upgrading to Ruby version v8.0.0. Distributed Tracing on by default provides more data and better visibility for cross-application requests. If you do not need this feature, you can turn it off in the Ruby agent configuration file by setting distributed_tracing.enabled=false or by setting the environment variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=false. If you need more traces and are experiencing dropped spans, the agent reservoir can be expanded to accommodate more spans. To do so, set the environment variable or config item called span_events.max_samples_stored to a value greater than 2,000 up to a maximum value of 10,000. Note that increasing this value may impact memory usage. With Distributed Tracing on by default, Cross Application Tracing (CAT) will now be deprecated and will be removed in a future version of the agent. If you're on CAT, you'll now see distributed traces instead. If you want to revert back to CAT, you can do so by setting cross_application_tracer.enabled = true in the configuration file. We recommend you to keep using distributed tracing, given that CAT will be removed in the future.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.26875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Distributed Tracing enabled by default with <em>Ruby</em> <em>Agent</em> Update: Version 8.0.0",
        "sections": "Distributed Tracing enabled by default with <em>Ruby</em> <em>Agent</em> Update: Version 8.0.0",
        "body": "With the release of <em>Ruby</em> <em>Agent</em> version v8.0.0, upon <em>agent</em> upgrade, you&#x27;ll have Distributed Tracing on by default. This eliminates the need to configure the <em>agent</em> to have access to distributed traces. Distributed Tracing gives software teams working in modern environments an easy way to capture"
      },
      "id": "616c097ae7b9d2f64c477225"
    },
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-12T12:10:21Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 89.993126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    }
  ],
  "/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent-gae-flexible-environment": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.11546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-12T11:58:08Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.26487,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.05754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.11546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-12T11:58:08Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.26487,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.05754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/installation/ruby-agent-heroku": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.11545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-12T11:58:08Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.26486,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.057526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin": [
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-12T11:58:08Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.26486,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.057526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Install the New Relic Ruby agent",
        "Install the gem",
        "Important",
        "Install the configuration file",
        "Update the agent",
        "Install agent outside production environments",
        "Uninstall the Ruby agent gem",
        "Install on older versions of Rails"
      ],
      "title": "Install the New Relic Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "5550d694861d682735dc54a8582d2df311b05fc8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent/",
      "published_at": "2021-10-12T14:40:44Z",
      "updated_at": "2021-08-08T04:45:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic Ruby agent installation. Add Ruby data Install the gem Important If you are using the agent in a Docker container, install the agent within each container. The Ruby agent's gem is available from rubygems.org as newrelic_rpm. For applications using Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy To use Infinite Tracing, the Infinite Tracing gem is also available from rubygems.org as newrelic-infinite_tracing. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy The next step varies depending on if you are using Rails or Sinatra: Ruby installation Comments If using Rails or Sinatra Rails: If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic_rpm to be required during startup of your application. Sinatra: If you're using Sinatra or another framework, you must manually call require 'newrelic_rpm'. Additionally, if you're using Infinite Tracing, manually call require 'newrelic/infinite_tracing'. Alternately, manually call Bundler.require, which also enables Infinite Tracing. If not using Rails or Sinatra In order to use automatic browser application monitoring and Cross application tracing in a Rack application that does not use Sinatra or Rails, you must manually include additional Rack middlewares provided by the agent. Place the New Relic gem as low in the list as possible, allowing the frameworks above it to be instrumented when the gem initializes. Install the configuration file After installing the agent, you will need to install the newrelic.ymlÂ configuration file,Â and name your app: If you haven't already, create a New Relic account. It's free, forever. Or, sign in. From the account dropdown, select Account settings. On the Account settings page, look for the Download a clean configuration file section and click the newrelic.yml file. Copy the newrelic.yml file into the config sub-directory of your application. Change the default application name to a meaningful name. Alternatively, you can generate a newrelic.yml file manually with the following command: newrelic install --license_key=\"YOUR_KEY\" \"My application\" Copy You may also use the --force option with this command if you need to overwrite an existing newrelic.yml. Update the agent See Upgrade Ruby agent versions. Install agent outside production environments Typically you will install the Ruby agent in your production environment. If you want to try out the Ruby agent in a development or localhost environment, verify in the relevant environment: block of the newrelic.yml file that the monitor_mode config value has been set to true. For example, to deploy New Relic in your development environment and still be able to view your app's performance metrics: In the development: block, set the monitor_mode config value to true. Uninstall the Ruby agent gem To uninstall the Ruby agent using Bundler, remove gem 'newrelic_rpm' from your Gemfile. If you are not using Bundler, remove all references to newrelic_rpm from your environment.rb file. Install on older versions of Rails If you're installing the Ruby agent on Rails 2.x, and aren't using Bundler, follow these procedures. Ruby installation Comments Rails 2.1 - 2.3 without Bundler Install the gem using gem install newrelic_rpm. Edit environment.rb, and add to the initializer block: config.gem \"newrelic_rpm\" Copy If enabling Infinite Tracing, add the following to the next line in the environment.rb file: config.gem \"newrelic-infinite_tracing\" Copy Rails earlier than 2.1 New Relic does not officially support Rails versions prior to 2.1. However, if you want to use New Relic for Rails versions 2.0. * , edit environment.rb and add this statement after the initializer: block: require \"newrelic_rpm\" Copy Infinite Tracing If enabling Infinite Tracing, add the following to the next line in the environment.rb file: require \"newrelic/infinite_tracing\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.53107,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the New Relic <em>Ruby</em> <em>agent</em>",
        "sections": "<em>Install</em> the New Relic <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic <em>Ruby</em> <em>agent</em> <em>installation</em>. Add <em>Ruby</em> data Install the gem Important If you are using the <em>agent</em> in a Docker container, install"
      },
      "id": "603eb684e7b9d2d6fb2a07d3"
    }
  ],
  "/docs/agents/ruby-agent/installation/uninstall-ruby-agent": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.11545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-12T11:58:08Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.26486,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.057526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/installation/update-ruby-agent": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.11542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-12T11:58:08Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.26485,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.05751,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/rack-middlewares": [
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-12T14:38:55Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.46176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-12T12:25:26Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.15056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    },
    {
      "sections": [
        "Redis instrumentation",
        "Tip",
        "Interaction with newrelic-redis",
        "Important",
        "Capture Redis command arguments"
      ],
      "title": "Redis instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "9923fcd7dd89191c620a9490fb89cd8ca4bf31e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation/",
      "published_at": "2021-10-12T14:38:55Z",
      "updated_at": "2021-03-16T08:03:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent automatically instruments the Redis gem (gem version 3.0.0 or higher). After you install the agent and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart on the APM Summary page will show color-coded Redis information. Tip Redis instrumentation requires Ruby agent version 3.13.0 or higher. Interaction with newrelic-redis The third-party newrelic-redis gem provides Redis instrumentation support as an add-on to New Relic's Ruby agent. If the Ruby agent detects newrelic-redis, it will not install the built-in Redis instrumentation and will record a log message like this at startup: INFO : Not installing New Relic supported Redis instrumentation because the third party newrelic-redis gem is present Copy To use New Relic's built-in Redis instrumentation and view Redis information in the UI, remove the newrelic-redis gem. Important Removing the newrelic-redis gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. Capture Redis command arguments By default, the Ruby agent only captures Redis command names. To capture Redis command arguments, use this configuration: transaction_tracer: record_redis_arguments: true Copy The agent limits the number of characters and arguments collected from each transaction trace node. The agent truncates items that exceed these limits.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.12064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Redis <em>instrumentation</em>",
        "sections": "Redis <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> automatically instruments the Redis <em>gem</em> (<em>gem</em> version 3.0.0 or higher). After you install the <em>agent</em> and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart"
      },
      "id": "603ed7a628ccbca064eba784"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-12T14:38:56Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > MonitorÂ > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > MonitorÂ > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.86673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-12T14:38:55Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.46176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-12T12:25:26Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.15056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-12T14:38:56Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > MonitorÂ > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > MonitorÂ > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.86673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-12T12:25:26Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.15056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    },
    {
      "sections": [
        "Redis instrumentation",
        "Tip",
        "Interaction with newrelic-redis",
        "Important",
        "Capture Redis command arguments"
      ],
      "title": "Redis instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "9923fcd7dd89191c620a9490fb89cd8ca4bf31e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation/",
      "published_at": "2021-10-12T14:38:55Z",
      "updated_at": "2021-03-16T08:03:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent automatically instruments the Redis gem (gem version 3.0.0 or higher). After you install the agent and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart on the APM Summary page will show color-coded Redis information. Tip Redis instrumentation requires Ruby agent version 3.13.0 or higher. Interaction with newrelic-redis The third-party newrelic-redis gem provides Redis instrumentation support as an add-on to New Relic's Ruby agent. If the Ruby agent detects newrelic-redis, it will not install the built-in Redis instrumentation and will record a log message like this at startup: INFO : Not installing New Relic supported Redis instrumentation because the third party newrelic-redis gem is present Copy To use New Relic's built-in Redis instrumentation and view Redis information in the UI, remove the newrelic-redis gem. Important Removing the newrelic-redis gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. Capture Redis command arguments By default, the Ruby agent only captures Redis command names. To capture Redis command arguments, use this configuration: transaction_tracer: record_redis_arguments: true Copy The agent limits the number of characters and arguments collected from each transaction trace node. The agent truncates items that exceed these limits.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.12064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Redis <em>instrumentation</em>",
        "sections": "Redis <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> automatically instruments the Redis <em>gem</em> (<em>gem</em> version 3.0.0 or higher). After you install the <em>agent</em> and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart"
      },
      "id": "603ed7a628ccbca064eba784"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/control-when-ruby-agent-starts": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.19508,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.05731,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.05125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/generating-logs-troubleshooting-ruby": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.19508,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.05731,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.05125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/incompatible-gems": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.19507,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.0573,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.05124,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-data-appears-ruby": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.19507,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.0573,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.05124,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-data-unicorn": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.19505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.05728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.05124,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-log-file-ruby": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.19505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.05728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.05124,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/not-installing-new-relic-supported-grape": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.19504,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.05727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.05123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/passenger-troubleshooting": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.19504,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.05727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.05123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/ruby-agent-audit-log": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.19502,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.05725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.05122,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/systemstackerror-stack-level-too-deep": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.19502,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.05725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.05122,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/update-deprecated-api-calls": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.19501,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.057236,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.051216,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/update-private-api-calls-public-tracer-api": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "InstallÂ the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-12T14:41:39Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents InstallÂ the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/pluginsÂ directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.ymlÂ file into the configÂ subdirectory of your application. You can download a fresh newrelic.ymlÂ that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.ymlÂ file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.19501,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-12T14:36:12Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.057236,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.051216,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agile-handbook/appendices/backlog-review": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/appendices/project-scoping-cheatsheet/",
      "sections": [
        "Project scoping cheatsheet",
        "What is this",
        "Dates",
        "Scope",
        "Resources",
        "People",
        "Before meeting ends",
        "For more help"
      ],
      "published_at": "2021-10-17T12:53:52Z",
      "title": "Project scoping cheatsheet",
      "updated_at": "2021-10-17T11:50:18Z",
      "type": "docs",
      "external_id": "57d5de7b1eeb1ae1800d8186e1302ff677d1e278",
      "document_type": "page",
      "popularity": 1,
      "body": "We use this cheatsheet to help us scope projects in a consistent way. What is this What's the elevator pitch for the feature? What's the user value? What are the most exciting tasks/stories we can tell for this feature? Who is the primary audience? Any docs deliverables you already have in mind? Dates What are you working on right now? When does this \"release\" (private beta, public beta, GA, etc.)? If private beta, how many customers and do they need docs? Scope Who will write first drafts? Do you need any templates? Does this need a liaison? Resources Is there a test account/is this in staging? Are there mockups or other resources? Do you have any other collateral to share? People Who is the primary reviewer (and backups)? Who is product manager? Who is lead dev? Who is the designer? Who is program manager? Who is the researcher? Are we doing any user research? Who is the PMM? Who is the support point person? Before meeting ends Who is writing? When is it due? Do we need tickets? Who is following up with who? â† Appendix: Ticket best practices Appendix: Backlog review â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1042.9423,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " is the support point person? Before meeting ends Who is writing? When is it due? Do we need tickets? Who is following up with who? â† Appendix: Ticket best practices Appendix: <em>Backlog</em> <em>review</em> â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0dfa28ccbc90b0002530"
    },
    {
      "image": "https://docs.newrelic.com/static/aa5797a9c6aaadf52a7bac18b3ac8e83/c1b63/dealing_with_interrupts.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/sprint-workflow-and-jira-boards/",
      "sections": [
        "Sprint workflow",
        "Planned work",
        "Unplanned work (surprises!)",
        "Jira boards: Backlog and future sprints",
        "Jira boards: Current sprint",
        "Proposed",
        "In Progress",
        "Needs Peer Editor",
        "In Peer Edit",
        "Peer Edit Done",
        "Blocked",
        "Done",
        "Incomplete (\"carry-over\") tickets",
        "For more help"
      ],
      "published_at": "2021-10-17T13:00:51Z",
      "title": "Sprint workflow",
      "updated_at": "2021-10-17T11:49:20Z",
      "type": "docs",
      "external_id": "e18dcb23b9a43a083a2c4496d6fb9a20b9efc496",
      "document_type": "page",
      "popularity": 1,
      "body": "All of our sprint work is tracked in Jira. The workflow depends on what type of work we're dealing with: Planned or unplanned (\"surprise!\") work. Planned work Planned work includes all work that is currently in our backlog or has been added to the current sprint as a result of a Sprint Planning session. This could include writing or updating documentation, research, meeting with SMEs, information architecture, incorporating peer edits, SME review, and so on. Unplanned work (surprises!) Usually, we get notified of major requests far enough in advance that we can include them in liaison project plans, backlog grooming, and sprint planning. Occasionally, something bigger surprises us that needs emergency support. Follow this process with new docs asks to assess the scope of work and ensure we address valid docs needs within a reasonable amount of time. Our goal is to treat the sprint as sacred and insulate against \"surprise\" work that is not absolutely crucial. But we also want to ensure we're providing good internal customer service, and not getting hung up on process niceties for things that are small. Jira boards: Backlog and future sprints This is where the vast majority of tickets spend their time. Most tickets (even for active projects) spend at least a little time here before moving into a sprint to be actively worked. Being in the backlog doesn't mean something isn't important---just that we haven't committed to it yet.Â  You can also add tickets straight to a future sprint. This is where tickets tentatively assigned to a future sprint will be found. Tickets can be assigned here to be held for backlog grooming and sprint planning.Â  Jira boards: Current sprint Proposed This step is for work that has been assigned to the current sprint during Sprint Planning and is available to be picked up by a tech writer. When you're ready to take on a new ticket, try to work the queue from the top-down and avoid cherry picking. It's also better to pick up Needs Peer Edit tickets before committing to a new ticket. Something that needs a peer edit is close to done, and helping things across the finish line helps get value into users hands, and frees us up to think about new problems. In Progress This step is for all of the work to be done by the assignee: Research, meeting with SMEs, information architecture, writing, incorporating peer edits, SME review, and so on. Tickets are moved to this step once work is started by the TW, and remain here until the work is either complete, ready for peer review, or it becomes blocked. If additional large edits are needed after the peer review, the ticket can be moved back to In Progress for those edits. Needs Peer Editor Work that is ready for a peer edit. Once a peer editor picks it up, they move it into In Peer Edit. In Peer Edit This step is for a peer editor to review docs before they go live. Follow the Peer editor workflow, then move the ticket into Peer Edit Done.Â  Peer Edit Done This step is a holding state once peer editing is complete. After completing their peer edit and delivering their feedback, the peer editor moves the ticket into Peer Edit Done. From there, the assignee on the ticket (not the peer editor) moves the ticket into the appropriate column (In Progress, Blocked, or Closed). Minor edits can be completed from this column but for major doc rework, the ticket should be moved back into the In Progress column. Blocked This step is for tickets that cannot be moved forward by the team. This could be because we're waiting for a response from a SME, or for a feature to deploy, or for final signoff. The team keeps an eye on this column for tickets that may need escalation. Putting something in Blocked rather than In Progress lets us see the status of every ticket at a glance. This column can also be used for extended time out of the office for the assigned writer, if it's work that can be safely held. (If the work cannot be held while you're out, find another writer to step in and take over.) Once you're un-blocked, move the ticket to the appropriate column. If the ticket remains blocked at the end of the current sprint, it will need to be re-reviewed during backlog grooming to determine if the ticket will carry-over into the upcoming sprint, or return to the backlog until a future sprint. Done This step is for work that is 100% finished. Work gets cleared out this column before we start a new sprint. Incomplete (\"carry-over\") tickets Ticket don't carry over automatically between sprints. Instead, any ticket that gets carried over is treated as a \"new\" ticket in the next sprint planning. Before sprint planning, review any open tickets in the board that are assigned to you and figure out what to do with them. For each open ticket assigned to you (or \"carry over\"), decide if you should: Recommended: Clone the ticket and close the old one. This is the best option for partially completed work because it maes metrics easier. If you do: Clone the ticket. Note why we closed the ticket. Add an estimate of points completed in the Points Completed field. Create a follow-up ticket if necessary. Move the ticket to the next sprint. If you do: Review the ticket's action items and description to make sure they're still current. Clear out the ticket points. Move the ticket back to the backlog. If you do: Update the action items and description to make sure they're still current. Note why we moved to the backlog rather than carry over. â† Planning poker Liaisonships â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.8082,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Jira boards: <em>Backlog</em> and future sprints",
        "body": " ticket if necessary. Move the ticket to the next sprint. If you do: <em>Review</em> the ticket&#x27;s action items and description to make sure they&#x27;re still current. Clear out the ticket points. Move the ticket back to the <em>backlog</em>. If you do: Update the action items and description to make sure they&#x27;re still"
      },
      "id": "616c0dc0196a67e6583c8164"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/meetings-and-ceremonies/",
      "sections": [
        "Meetings and ceremonies",
        "Tip",
        "Sprint planning",
        "Backlog grooming",
        "Retro",
        "For more help"
      ],
      "published_at": "2021-10-17T11:51:09Z",
      "title": "Meetings and ceremonies",
      "updated_at": "2021-10-17T11:50:18Z",
      "type": "docs",
      "external_id": "873983fa778f17f1a92871ed4ad7673b333d4acc",
      "document_type": "page",
      "popularity": 1,
      "body": "Monday Tuesday Wednesday Thursday Friday Week 1 Sprint retro (every other sprint) Backlog grooming (end of sprint) Sprint planning (start of new sprint) Team meeting Meeting-free day Week 2 Team meeting Meeting-free day We break our work into two-week sprints. The new sprint starts on a Tuesday with sprint planning, where we commit to a set of stories that we're confident we can complete by the end of the sprint. Near the end of the sprint, we prepare for the next sprint with backlog grooming. The sprint closes with a retro where we discuss what went right and what went wrong, and then we kick off a new cycle. Each squad does their own backlog grooming and sprint planning, and manages their sprint backlog independently. We do retros together so we can talk through issues that affect both squads and share expertise and ideas. Tip Why do we end sprints on Mondays and start Tuesdays? This funny schedule makes things easier to work across timezones. If we ended sprints on Fridays, our Barcelona-based writers would need to do retros and grooming on Friday evening, and who wants that? Sprint planning On the first Tuesday of a new sprint, we commit to a series of stories until we have filled our capacity for the sprint. This is the largest meeting in the sprint---about 60 to 90 minutes. Before the sprint planning meeting, the scrum master for each squad calculates their point budget. Then, during the meeting: We select the highest priority item in the backlog. The person who nominated the story introduces it, and the team asks questions until everyone feels ready to vote. The team plays planning poker. Everyone secretly chooses a card, then we reveal them at the same time: If everyone picks the same card, that's the point value and we move on. If there's an even split between two cards, we choose the larger and move on. If it's mixed, the highest and lowest voters briefly explain their votes. Then we vote again. Once we're sure we can fit the story in, we subtract its story points from the sprint's points budget. We repeat the above steps until we've used up our points budget. We generally avoid pre-assigning people to stories during sprint planning. Instead, we pick up the next story or peer edit in the To Do column as stories are completed. Backlog grooming The day before the sprint starts, we do two rounds of backlog grooming. The purpose of backlog grooming is to prioritize work for sprint planning, and identify stories that need to be fixed before sprint planning to ensure scope is clear and planning runs smoothly. The first round of backlog grooming is by squad, where the members and manager of the squad get together and work through the grooming checklist. Then we do a second round of grooming with the managers and scrum masters to look at the sprint backlog for both squads and ensure nothing is or has fallen through the cracks. In the grooming, we: Each writer brings their personal \"top five\" tickets. The manager works with writers to prioritize those into a single, stack-ranked list for the team. We talk through stories and ensure they look ready for sprint planning (essentially, do they fit the Checklist for story readiness?). After grooming, the scrum master sends out a list of \"homework\" for stories that need improving. Retro Every other sprint, we conduct a 60 minute retrospective meeting, where we discuss: How do we feel about the sprint? What went well? Where can we improve? Anything we should start or stop doing? The goal of the retro is to improve the way we work together. That could be related to the sprint process, to how we collaborate with SMEs, to peer edits, and so on. â† Agile roles Planning poker â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.88849,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Backlog</em> grooming",
        "body": "Monday Tuesday Wednesday Thursday Friday Week 1 Sprint retro (every other sprint) <em>Backlog</em> grooming (end of sprint) Sprint planning (start of new sprint) Team meeting Meeting-free day Week 2 Team meeting Meeting-free day We break our work into two-week sprints. The new sprint starts on a Tuesday"
      },
      "id": "616c0dfa196a679fd43c9791"
    }
  ],
  "/docs/agile-handbook/appendices/project-scoping-cheatsheet": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/appendices/backlog-review/",
      "sections": [
        "Backlog review",
        "Goals of backlog review",
        "Who reviews the backlog",
        "What to look for in a backlog review",
        "For more help"
      ],
      "published_at": "2021-10-17T13:00:07Z",
      "title": "Backlog review",
      "updated_at": "2021-10-17T11:50:18Z",
      "type": "docs",
      "external_id": "6c1e047df7f4a43eaa253c0183625df4785455de",
      "document_type": "page",
      "popularity": 1,
      "body": "About once a quarter, the Docs team reviews our entire backlog in Jira and GitHub. This ensures that we actually know what's in there, and that we're bubbling up the right stories from the backlog into upcoming sprints. Goals of backlog review Fix easy issues: If you can fix something quickly, just do it. Find broken windows: What are the small (or big!) broken windows lurking in our backlog? What should we consider bubbling up into a future sprint? Identify gaps in the backlog: Discover important issues that are not at all covered in the backlog. Clear out cruft: Find duplicate issues, things we'll never fix, or issues that are just no longer relevant. Check labels and fields: Is the ticket assigned a correct priority score? Do we have the correct labels for other fields? Who reviews the backlog Sometimes we'll involve the whole team in a backlog review; other times, just the managers will handle the review. The most useful time to involve the whole team is when we're onboarding a new writer: Talking through issues promotes a lot of knowledge-sharing about the product, docs, stakeholders, and how to write a good ticket. Otherwise, we'll usually assign the review to the managers. This saves time, and it also tends to make it easier to close out issues (since our managers are also our product owners). If we don't involve the whole team, we'll prepare a spreadsheet of which issues we closed and list writers who might care so they can weigh in on whether the issue should have stayed open. What to look for in a backlog review When you review an issue, perform the following checks: Check if the issue can be closed: It's already resolved, or you can't reproduce the issue It's old, and we have little evidence anyone cares It's not important enough to fix If the issue doesn't have a clear goal/task, try to discover one (but don't feel obligated to rewrite the whole issue). Add context and update as-needed. Review fields and labels and ensure they're accurate. Add a label to the issue once you're done with your review. Use this format: year_month_backlog_review. For example: 2021_october_backlog_review. This helps keep track of which issues you've reviewed on this round of backlog review It's also a useful nudge for future round of review: If an issue has more than one or two review labels, you should probably close it. â† Appendix: Project scoping cheatsheet For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2757.1333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ". For example: 2021_october_backlog_review. This helps keep track of which issues you&#x27;ve reviewed on this round of backlog review It&#x27;s also a useful nudge for future round of review: If an issue has more than one or two review labels, you should probably close it. â† Appendix: <em>Project</em> <em>scoping</em> <em>cheatsheet</em> For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0dfa64441f2cb01d33a5"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/appendices/ticket-best-practices/",
      "sections": [
        "Ticket best practices: How to write a sprint-ready Jira",
        "Tip",
        "Why do we use Jira?",
        "What work needs a ticket?",
        "Keeping tickets up-to-date",
        "Add Jira context to PRs and commits",
        "Checklist for writing a good ticket",
        "For more help"
      ],
      "published_at": "2021-10-17T12:57:54Z",
      "title": "Ticket best practices: How to write a sprint-ready Jira",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "2109a54437970761f71a3940f189b7f10aef0bc1",
      "document_type": "page",
      "popularity": 1,
      "body": "Jira, a project management tool made by Atlassian, is how we manage our projects and understand the work we are doing and have done. Jira tickets may seem at first to be simple to-do lists that we use to know what things to do for a project. But they are much more important than that. Tip For Relics: Use the docs.newrelic.com/jira template when you create a ticket! It'll automatically pre-fill your ticket with a template that helps create a good ticket. Why do we use Jira? We create tickets to record work-to-be done for a project, scope new work, share information for any writer to complete a story, forecast our output and to estimate project timelines, and have a record of work done. In other words, Jira has a role at every point in a project: Before a project Scoping, syncing on expectations, giving tech writer instructions During a project Keeps team and management posted about project; allows for hand-offs and swarming After a project Understand what work we did, and helps researching on future projects What work needs a ticket? There aren't hard-and-fast rules about what work needs a Jira ticket and what doesn't. A good shorthand is that any project that takes more than a couple hours is a good candidate for a ticket. However, the goal of creating tickets is not to track writer time in detail. So many kinds of work (meetings, ongoing minor liaison tasks, hero work) generally do not need to go into Jira. Keeping tickets up-to-date In general, you should write your tickets as though you might win the lottery tomorrow (a principle known as lottery factor or bus factor). In practice, someone should be able to read your ticket and figure out within about ten minutes what the status is and what the next step is. This makes it easy for us to take vacations, pass work off to another docs writer if needed, and escalate blockers. These things help with lottery factor: Update the Action Item list as you complete tasks and add or remove scope. When you move a ticket to Blocked, include a note explaining the change in status. When you close a ticket, give a summary of the work done and any relevant thoughts you have on the work and potential related issues. Update the Timeline, People, and Resources sections as the project evolves. Add important conversations (emails or Slack convos from SMEs) that give important context for the work done. (Note: It's a good idea to ask permission before doing this, because some people might not like their informal words placed in a public place.) Add Jira context to PRs and commits When you edit the site, include the Jira issue key (DOC-1234, for example) in your pull request title and/or commit summary. That makes it easier for other writers to connect the dots later if we're trying to figure out why something changed or who knows about a particular subject. Checklist for writing a good ticket Helpful title A ticket name should be easy to find via search, understand the work at a glance, mention the product or feature, and describe the goal or issue. Examples of good ticket titles: Browser API: Update custom attribute-related docs or Distributed tracing: Add more detail about CAT relationship. Action items An action item list describing the work to be done What docs are affected Links to pull requests, Google Docs drafts, etc. How substantial the writing work is in each doc How the resulting work should be structured Whether or not a peer edit is needed Anyone who should be notified when a doc is published Proper sizing Story is scoped to the smallest reasonable size Can be completed within a 2 week sprint Delivers incremental value Dates Publication date or due date Dates for other key events (betas, limited releases, etc.) Resources and people People, including last names and roles List of related or affected docs Other internal and external resources Related issues Labels and fields Jira tickets: Component, Product Group, and Priority GitHub issues: from_, pg_, and content labels â† Managing the GitHub boards Appendix: Project scoping cheatsheet â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2198.851,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ": Component, Product Group, and Priority GitHub issues: from_, pg_, and content labels â† Managing the GitHub boards Appendix: <em>Project</em> <em>scoping</em> <em>cheatsheet</em> â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0d9628ccbc919400346e"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/liaisonships/",
      "sections": [
        "Liaisonships",
        "Liaison responsibilities: Manage project flow",
        "Liaison responsibilities: Build expertise",
        "Liaison responsibilities: Define content strategy (oh, and do the writing)",
        "For more help"
      ],
      "published_at": "2021-10-17T12:53:21Z",
      "title": "Liaisonships",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "bf8ec36541058fe18f8395db811344baf7f23e22",
      "document_type": "page",
      "popularity": 1,
      "body": "For large projects, we'll typically assign a particular tech writer to that project as a \"liaison.\" The liaisonâ€™s job is to ensure that we get complete, consistent, and timely docs. Not every project gets a liaisonship! For smaller projects, we'll encourage teams to edit the docs directly, and then have the hero review their changes. And a smallish project may not need a full liaisonâ€”a single ticket might be enough to manage the work. To figure out which type of support is best for a given project, one of the managers on the team will have a scoping conversation with a subject matter expert. Here's a few reasons a project might get a dedicated liaison: Project is complex and would benefit from intimate familiarity with the feature. Project requires significant information architecture work. Project will produce enough docs that consistency across those docs will be hard to achieve without a centralized editor. Project SMEs would benefit from a consistent \"face\" of the tech writing team. However, a liaison is not the only author on a project. Liaisons should structure their work to maximize swarming and knowledge sharing. Liaison responsibilities: Manage project flow Activity Who? Notes Learn new thing exists Team Ideally the Hero or a Tech Docs manager gets notified directly by a PM about a new project. But sometimes we'll find out about something unexpectedly. If you're not sure whether we have a writer working on something, ask a manager on the team and they'll reach out to the subject matter expert to scope it. Have a scoping meeting Tech Docs manager The manager is responsible for tracking the general state of major projects across the company, and is generally the first point of contact for new projects. When a large new project comes up, the manager will do a pre-scope meeting with the requestor. (Appendix: Project scoping cheatsheet has a list of common questions for this pre-scope meeting.) That conversation helps figure out timeline, complexity, key docs considerations, and which writer will be a good fit as liaison. Assign a liaison Tech Docs manager Once we know we need a liaison, a manager on our team will figure out who to assign. Some of the factors we use to decide who to assign include bandwidth, familiarity with the product or feature, career goals and writing strengths, and simple interest in the topic. Keep track of project dates Liaison The managers on the team keep track of upcoming projects that don't have a liaison assigned. Once a writer gets involved, that liaison keeps track of the specifics of dates: Betas, limited releases, GAs, fast-follows, and so on. Your manager's always here to help out if you're getting blocked or dates are shifting too rapidly to plan properly. Validate the docs plan with the project team Liaison The liaison works with their stakeholders to define the information architecture and deliverables. Create tickets Liaison Since the liaison defines the information architecture, the liaison will know what kinds of deliverables we need. The liaison also acts as an advocate for their tickets in the backlog grooming and sprint planning processes, and ensures their stories meet the story quality requirements. The liaison should also ensure that our partner teams have appropriate tickets in their backlogs for their work. Remove blockers (such as reviewer delay) Liaison + Manager While the liaison is primarily responsible for handling SME relationships and removing day-to-day blockers, your manager is here to help unstick things anytime you need help. Wrap up the liaisonship Liaison Liaisonships are not forever assignments! When the bulk of your work on a project is complete, it might be time to consider ending the liaisonship. Reach out to your manager to talk about it. When you end it, let stakeholders know and update the liaison roster. Also let your stakeholders know they can always ping the docs hero for help or if they have a new project. Liaison responsibilities: Build expertise Activity Who? Notes Develop a deep expertise on feature and audience. Liaison Become the Docs Team's local expert on the feature. Understand what it does, what problems it solves, and the implications for our content. Educate the team on the feature Liaison Part of your responsibility as liaison is to share expertise around the team. That helps with swarming, but it also makes for better hero review and a smarter team that can write more intelligently about the entire New Relic One platform. Coordinate with design and/or research and test your docs Liaison Reach out to the designer and/or researcher for the project, and periodically sync on any shared concerns, user needs, etc. And you should advocate for user testing and validation of your content. Liaison responsibilities: Define content strategy (oh, and do the writing) Activity Who? Notes Define the information architecture Liaison As liaison, you're the expert on both the feature the product team is building, and the docs content (new and existing) that will support that feature. Build an IA that will meet all project needs and scale to the future. Write content Team The liaison writes much of the content for their project, especially the conceptual content like intro docs. But the whole team is expected to swarm and contribute to large projects, with the liaison coordinating that work. Peer edit drafts Liaison When we swarm and have someone else contribute to the project, the liaison peer edits their drafts to ensure consistency with the overall vision. Coordinate publication Liaison When the time comes to release (whether that's beta, GA, limited release, or EoL), it's the liaison's job to coordinate with PM, Eng, and Product Marketing to ensure docs go out on time with other deliverables. â† Sprint workflow and Jira boards What is a hero? â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1782.4565,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Liaison responsibilities: Manage <em>project</em> flow",
        "body": "-<em>scope</em> meeting with the requestor. (Appendix: <em>Project</em> <em>scoping</em> <em>cheatsheet</em> has a list of common questions for this pre-<em>scope</em> meeting.) That conversation helps figure out timeline, complexity, key docs considerations, and which writer will be a good fit as liaison. Assign a liaison Tech Docs manager"
      },
      "id": "616c0d97e7b9d227264780c5"
    }
  ],
  "/docs/agile-handbook/appendices/ticket-best-practices": [
    {
      "image": "https://docs.newrelic.com/static/e74b3e31916f093c77d41e8beef9ecc9/c1b63/lines_of_communication.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-sprints-profusion-of-terms/",
      "sections": [
        "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
        "Agile",
        "Sprint (or scrum)",
        "Jira and GitHub issues",
        "Teams and squads",
        "For more help"
      ],
      "published_at": "2021-10-17T11:51:46Z",
      "title": "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "7f3f97222daf52cf14afcf8fc432b96b3cebd4b1",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses an agile Sprint workflow in Jira and GitHub to manage our work. We've further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let's break them down further. Agile People use agile to mean everything from a specific system of work (which we call sprints), to just \"moving fast, preferably in a way that lets me bend things to my whims.\" Luckily, we don't need to define it from scratch. Wikipedia does an admirable job defining it: Agile software development is an approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, empirical knowledge, and continual improvement, and it encourages rapid and flexible response to change. For our team, that means our process is optimized to ship early and often. This lets us respond swiftly to changes in the product roadmap. More importantly, it ensures we validate our solutions with stakeholders, and that we're not letting valuable work sit around and get moldy when it could be out in the world making our users' lives better. Sprint (or scrum) This is the particular flavor of agile we follow. The sprint system (often referred to as scrum) is one major approach to Agile, along with other Agile systems such as Kanban. Sprint systems are often accompanied by a lot of jargon and best practices, but for our team the most essential elements are: Working in strict timeboxes (two weeks in our case) Planning that sprint in advance, and not changing the scope of the sprint (much) once it starts Expecting all team members to contribute to making the sprint a success The video Agile Product Ownership in a Nutshell (18 minutes) is an excellent resource for learning about sprint methodology. The Kindle book Scrum: a Breathtakingly Brief and Agile Introduction is also a great read that you can get through in a short afternoon. For more on the \"why\" of Sprint as our chosen methodology, see Key agile principles. And for more on the \"how,\" see Sprint workflow. Jira and GitHub issues Jira and GitHub issues are the tools we use to manage our Agile workflow. If you remember one thing about them, it should be this: using Jira or GitHub issues is not the same as having an agile workflow. They're powerful tools for tracking work and managing a backlog, but the most important part of project management is the structure we impose on that tool. Jira is for sprint work. Sprints are where roadmap docs get written, monthly commits get delivered, and deeper research percolates. We have a backlog, board, and future sprint list in Jira that help us track what people want, what's coming up, and what we're working on now. For more on the mechanics of how we use Jira, see Sprint workflow and Jira boards and Ticket best practices. We use GitHub projects for hero work, customer-reported issues, and managing the flow of PRs and edits. The Docs PRs and Issues board contains everything we're actively working on in GitHub. We'll often connect work in GitHub back to Jira by putting a Jira issue key in the PR or issue title (DOC-1234, for example). For more on the mechanics of how we use GitHub, see Managing the GitHub boards. Teams and squads Our team is the Tech Docs team. We're collectively responsible for docs.newrelic.com and sundry writing content. Our team is further divided into two agile squads (The Odd Squad and The Amp Squad), one squad for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and liaisonships. Less people means shorter meetings. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain a shared understanding. Small squads can collaborate more easily than a large team, because not everyone needs to keep in mind everything that goes on everywhere. Each squad is responsible for its own grooming and sprint planning, but the managers and scrum masters coordinate grooming to ensure we're meeting our overall goals as a team. Key agile principles â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 391.80347,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agile</em> vs <em>sprints</em> (vs <em>Jira</em> vs GitHub): <em>A</em> profusion of terms",
        "sections": "<em>Agile</em> vs <em>sprints</em> (vs <em>Jira</em> vs GitHub): <em>A</em> profusion of terms",
        "body": " research percolates. We have a backlog, board, and future <em>sprint</em> list in <em>Jira</em> that help us track what people want, what&#x27;s coming up, and what we&#x27;re working on now. For more on the mechanics of <em>how</em> we use <em>Jira</em>, see <em>Sprint</em> workflow and <em>Jira</em> boards and <em>Ticket</em> <em>best</em> <em>practices</em>. We use GitHub projects"
      },
      "id": "616c0d96196a677e623c7bd2"
    },
    {
      "image": "https://docs.newrelic.com/static/aa5797a9c6aaadf52a7bac18b3ac8e83/c1b63/dealing_with_interrupts.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/sprint-workflow-and-jira-boards/",
      "sections": [
        "Sprint workflow",
        "Planned work",
        "Unplanned work (surprises!)",
        "Jira boards: Backlog and future sprints",
        "Jira boards: Current sprint",
        "Proposed",
        "In Progress",
        "Needs Peer Editor",
        "In Peer Edit",
        "Peer Edit Done",
        "Blocked",
        "Done",
        "Incomplete (\"carry-over\") tickets",
        "For more help"
      ],
      "published_at": "2021-10-17T13:00:51Z",
      "title": "Sprint workflow",
      "updated_at": "2021-10-17T11:49:20Z",
      "type": "docs",
      "external_id": "e18dcb23b9a43a083a2c4496d6fb9a20b9efc496",
      "document_type": "page",
      "popularity": 1,
      "body": "All of our sprint work is tracked in Jira. The workflow depends on what type of work we're dealing with: Planned or unplanned (\"surprise!\") work. Planned work Planned work includes all work that is currently in our backlog or has been added to the current sprint as a result of a Sprint Planning session. This could include writing or updating documentation, research, meeting with SMEs, information architecture, incorporating peer edits, SME review, and so on. Unplanned work (surprises!) Usually, we get notified of major requests far enough in advance that we can include them in liaison project plans, backlog grooming, and sprint planning. Occasionally, something bigger surprises us that needs emergency support. Follow this process with new docs asks to assess the scope of work and ensure we address valid docs needs within a reasonable amount of time. Our goal is to treat the sprint as sacred and insulate against \"surprise\" work that is not absolutely crucial. But we also want to ensure we're providing good internal customer service, and not getting hung up on process niceties for things that are small. Jira boards: Backlog and future sprints This is where the vast majority of tickets spend their time. Most tickets (even for active projects) spend at least a little time here before moving into a sprint to be actively worked. Being in the backlog doesn't mean something isn't important---just that we haven't committed to it yet.Â  You can also add tickets straight to a future sprint. This is where tickets tentatively assigned to a future sprint will be found. Tickets can be assigned here to be held for backlog grooming and sprint planning.Â  Jira boards: Current sprint Proposed This step is for work that has been assigned to the current sprint during Sprint Planning and is available to be picked up by a tech writer. When you're ready to take on a new ticket, try to work the queue from the top-down and avoid cherry picking. It's also better to pick up Needs Peer Edit tickets before committing to a new ticket. Something that needs a peer edit is close to done, and helping things across the finish line helps get value into users hands, and frees us up to think about new problems. In Progress This step is for all of the work to be done by the assignee: Research, meeting with SMEs, information architecture, writing, incorporating peer edits, SME review, and so on. Tickets are moved to this step once work is started by the TW, and remain here until the work is either complete, ready for peer review, or it becomes blocked. If additional large edits are needed after the peer review, the ticket can be moved back to In Progress for those edits. Needs Peer Editor Work that is ready for a peer edit. Once a peer editor picks it up, they move it into In Peer Edit. In Peer Edit This step is for a peer editor to review docs before they go live. Follow the Peer editor workflow, then move the ticket into Peer Edit Done.Â  Peer Edit Done This step is a holding state once peer editing is complete. After completing their peer edit and delivering their feedback, the peer editor moves the ticket into Peer Edit Done. From there, the assignee on the ticket (not the peer editor) moves the ticket into the appropriate column (In Progress, Blocked, or Closed). Minor edits can be completed from this column but for major doc rework, the ticket should be moved back into the In Progress column. Blocked This step is for tickets that cannot be moved forward by the team. This could be because we're waiting for a response from a SME, or for a feature to deploy, or for final signoff. The team keeps an eye on this column for tickets that may need escalation. Putting something in Blocked rather than In Progress lets us see the status of every ticket at a glance. This column can also be used for extended time out of the office for the assigned writer, if it's work that can be safely held. (If the work cannot be held while you're out, find another writer to step in and take over.) Once you're un-blocked, move the ticket to the appropriate column. If the ticket remains blocked at the end of the current sprint, it will need to be re-reviewed during backlog grooming to determine if the ticket will carry-over into the upcoming sprint, or return to the backlog until a future sprint. Done This step is for work that is 100% finished. Work gets cleared out this column before we start a new sprint. Incomplete (\"carry-over\") tickets Ticket don't carry over automatically between sprints. Instead, any ticket that gets carried over is treated as a \"new\" ticket in the next sprint planning. Before sprint planning, review any open tickets in the board that are assigned to you and figure out what to do with them. For each open ticket assigned to you (or \"carry over\"), decide if you should: Recommended: Clone the ticket and close the old one. This is the best option for partially completed work because it maes metrics easier. If you do: Clone the ticket. Note why we closed the ticket. Add an estimate of points completed in the Points Completed field. Create a follow-up ticket if necessary. Move the ticket to the next sprint. If you do: Review the ticket's action items and description to make sure they're still current. Clear out the ticket points. Move the ticket back to the backlog. If you do: Update the action items and description to make sure they're still current. Note why we moved to the backlog rather than carry over. â† Planning poker Liaisonships â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 377.63855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Sprint</em> workflow",
        "sections": "<em>Jira</em> boards: Backlog <em>and</em> future <em>sprints</em>",
        "body": "All of our <em>sprint</em> work is tracked in <em>Jira</em>. The workflow depends on what type of work we&#x27;re dealing with: Planned or unplanned (&quot;surprise!&quot;) work. Planned work Planned work includes all work that is currently in our backlog or has been added to the current <em>sprint</em> as a result of a <em>Sprint</em> Planning"
      },
      "id": "616c0dc0196a67e6583c8164"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/appendices/backlog-review/",
      "sections": [
        "Backlog review",
        "Goals of backlog review",
        "Who reviews the backlog",
        "What to look for in a backlog review",
        "For more help"
      ],
      "published_at": "2021-10-17T13:00:07Z",
      "title": "Backlog review",
      "updated_at": "2021-10-17T11:50:18Z",
      "type": "docs",
      "external_id": "6c1e047df7f4a43eaa253c0183625df4785455de",
      "document_type": "page",
      "popularity": 1,
      "body": "About once a quarter, the Docs team reviews our entire backlog in Jira and GitHub. This ensures that we actually know what's in there, and that we're bubbling up the right stories from the backlog into upcoming sprints. Goals of backlog review Fix easy issues: If you can fix something quickly, just do it. Find broken windows: What are the small (or big!) broken windows lurking in our backlog? What should we consider bubbling up into a future sprint? Identify gaps in the backlog: Discover important issues that are not at all covered in the backlog. Clear out cruft: Find duplicate issues, things we'll never fix, or issues that are just no longer relevant. Check labels and fields: Is the ticket assigned a correct priority score? Do we have the correct labels for other fields? Who reviews the backlog Sometimes we'll involve the whole team in a backlog review; other times, just the managers will handle the review. The most useful time to involve the whole team is when we're onboarding a new writer: Talking through issues promotes a lot of knowledge-sharing about the product, docs, stakeholders, and how to write a good ticket. Otherwise, we'll usually assign the review to the managers. This saves time, and it also tends to make it easier to close out issues (since our managers are also our product owners). If we don't involve the whole team, we'll prepare a spreadsheet of which issues we closed and list writers who might care so they can weigh in on whether the issue should have stayed open. What to look for in a backlog review When you review an issue, perform the following checks: Check if the issue can be closed: It's already resolved, or you can't reproduce the issue It's old, and we have little evidence anyone cares It's not important enough to fix If the issue doesn't have a clear goal/task, try to discover one (but don't feel obligated to rewrite the whole issue). Add context and update as-needed. Review fields and labels and ensure they're accurate. Add a label to the issue once you're done with your review. Use this format: year_month_backlog_review. For example: 2021_october_backlog_review. This helps keep track of which issues you've reviewed on this round of backlog review It's also a useful nudge for future round of review: If an issue has more than one or two review labels, you should probably close it. â† Appendix: Project scoping cheatsheet For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.48178,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "What <em>to</em> look for in <em>a</em> backlog review",
        "body": " will handle the review. The most useful time to involve the whole team is when we&#x27;re onboarding a new writer: Talking through issues promotes a lot of knowledge-sharing about the product, docs, stakeholders, and <em>how</em> to <em>write</em> a good <em>ticket</em>. Otherwise, we&#x27;ll usually assign the review to the managers"
      },
      "id": "616c0dfa64441f2cb01d33a5"
    }
  ],
  "/docs/agile-handbook/heroing/managing-the-github-boards": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/heroing/what-is-a-hero/",
      "sections": [
        "What is a hero?",
        "Goals for heroing",
        "Heroing is a full-time job",
        "GitHub hero responsibilities",
        "Triage issues and PRs",
        "Review PRs",
        "Merge develop into main",
        "Provide peer reviews if time allows",
        "Slack hero responsibilities",
        "Update the Slack alias",
        "Field questions in the #documentation channel",
        "Second-shift hero support",
        "For more help"
      ],
      "published_at": "2021-10-17T13:00:51Z",
      "title": "What is a hero?",
      "updated_at": "2021-10-17T11:46:24Z",
      "type": "docs",
      "external_id": "d861167d0bea38aa6f7efdcef760bfcdcb0610ff",
      "document_type": "page",
      "popularity": 1,
      "body": "\"Hero\" is a common term across New Relic for a dedicated, interruptible person who acts as an interface for a team. When you're a docs hero, you're the face of the team. We have two heroes at any given time: the GitHub hero (for issues and pull requests) and the Slack hero (for questions through Slack). We also have a second-shift hero to support EMEA Relics. Every hero's job is to keep things moving for Relics and users. We change GitHub and heroes once a day (we used to do weekly shifts, but we've found daily shifts reduce hero burnout). Goals for heroing A Relic once described the New Relic culture this way: In the end, everyone here is working toward the same purpose [...] That person pinging you with some random request that seems unrelated to your world has the same goals as you. Help them, be kind, be patient. Your mission as hero is to personify that attitude in Docs-land. Here's what that looks like in practice: Create a consistent interface for the team. Having a dedicated hero means the answer to how to get help is always the same: \"Ping the hero!\" Because we've made this our mantra for 7 years, we don't have to re-educate the org on how to get help or who to go to with docs questions. Even as new people join the team, our processes evolve, and our entire publication toolchain has changed, our interaction model remains consistent. Directing questions to the hero avoids having a single point of failure: Even if a liaison is on leave, on the beach, or has moved onto another project, the hero is there to help. Provide a great (internal and external) customer experience. The heroes respond quickly to questions, give timely draft reviews, and perform great customer service and problem solving. Build and share knowledge about the site and our products. The heroes end up touching all kinds of obscure areas of our site and interacting with teams they may never have worked with directly. It's a great opportunity to learn more about New Relic and to build relationships across the org. Edit new content to our standards. We depend on self-service to cover lots of products with relatively few writers. The GitHub hero gives us a single accountable person who can review new content against Tech Docs team standards and turn it around quickly. Buffer the team from interrupts. Since the heroes are our \"designated interruptibles\" for their shifts, the rest of the team is freed up for deeper focus time. When it is appropriate to bring in another team member, heroes can help in streamlining the handoff and providing helpful context so that their teammate can get started quickly with the lowest possible context-switching burden. Heroing is a full-time job As the hero, you're often pulled in a lot of directions in a given shift. Because of this, the expectation is that you do not take on sprint work during your hero shift, unless you really have nothing else to do after completing your hero duties. You're also not expected to know everything as a hero! If something comes up for which you have no easy answer, let the requestor know you're on it and then ping your fellow writers or other SMEs and helpers from across New Relic for help. GitHub hero responsibilities The GitHub hero monitors the GitHub board and the flow of work through GitHub. Triage issues and PRs The GitHub hero triages every incoming pull request and issue. You'll tag the issue and pull request, route it to the correct column or team, and also help review incoming edits. For details on handling all of this, see Managing the GitHub boards. Review PRs The bulk of your time is generally spent reviewing and approving PRs from non-writers. To review an incoming PR: Label the pull request appropriately (see Managing the GitHub boards for details). Assign yourself to the pull request, so it's clear that you're on point to review and merge. Review the pull request, depending on what type of edit it is: If it's a simple \"cosmetic\" edit, review the pull request to ensure it's formatted correctly, technically accurate, and fits New Relic style guidelines. If it's a deeper edit, or a completely new doc, give it an in-depth review. The Docs site edit checklist is a great resource here. If it's a really complex or large edit, consider creating a Jira ticket for an upcoming sprint to give it the review time it needs. If it's a What's new post, pay special attention to frontmatter, links, and image formatting. This content follows marketing style, so it doesn't need to fully match our style guidelines for things like capitalization. If it's a release note, focus your review on formatting and basic style, and ensuring the release note itself is helpful. Release notes don't need to follow all docs style guidelines religiously. Preview your change in Gatsby Cloud or locally. Merge the pull request into develop. Merge develop into main We merge the develop branch into the main branch a few times a day. This kicks off a build, and ultimately is how draft docs become published docs. Currently we do this three times a day: Around 9 am PST, noon PST, and 3 pm PST. To merge, just click this magic link and follow the prompts. Provide peer reviews if time allows During super busy shifts, you likely won't have time for many of these, but if you're having a slow shift please take some time to periodically check the Writer Needs Peer Edit swim lane for fresh peer edit asks from your teammates before you switch over to doing sprint work. Slack hero responsibilities The Slack hero monitors Slack and helps answer questions about docs and route people to the right resource on the team. Update the Slack alias Update the alias to ping your name at the start of your hero shift. To update the alias, type the following into the chat box: !hero set @YOUR_SLACK_HANDLE. For example, if it's Austin's hero shift, the thing to type would be !hero set @austin. Field questions in the #documentation channel Common questions and requests include: Questions about docs content. Answer the question if you know it, or reach out to other writers if it's an area you're not familiar with. Encourage the requestor to edit the docs or submit an issue wherever possible. Triage requests for docs support. If it's a project that already has a liaison attached, connect the requestor to the appropriate writer. If it's a project without exisitng writing support, connect them to a tech docs team manager to have a scoping conversation. Questions about status of a pull request or issue. Check in and see if you can figure out, or pull in the assignee for that pull reuqest if the status isn't clear. Questions about things we don't own (blog, API Explorer, newrelic.com, etc). Help them out by directing them to the appropriate Slack channel. (For a list of properties and their owner, see Who owns the other wesbites? in Google Docs.) If you can't figure out who owns it, try asking the writing team in Slack. Second-shift hero support Our tech writers in Barcelona cover the 2nd shift heroing during their regular working hours. Unlike the US-based heroes, our Barcelona writers hero for an entire two-week sprint. Second-shift heroes cover both GitHub and Slack, but we don't expect that second-shift heroes will field every single request that comes in during their working hours since they're also carrying standard sprint duties during their hero shift. â† Liaisonships Managing the GitHub boards â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2309.9995,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>GitHub</em> hero responsibilities",
        "body": " issues and PRs The <em>GitHub</em> hero triages every incoming pull request and issue. You&#x27;ll tag the issue and pull request, route it to the correct column or team, and also help review incoming edits. For details on handling all of this, see <em>Managing</em> the <em>GitHub</em> <em>boards</em>. Review PRs The bulk of your time"
      },
      "id": "616c0d10e7b9d259f647857b"
    },
    {
      "image": "https://docs.newrelic.com/static/e74b3e31916f093c77d41e8beef9ecc9/c1b63/lines_of_communication.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-sprints-profusion-of-terms/",
      "sections": [
        "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
        "Agile",
        "Sprint (or scrum)",
        "Jira and GitHub issues",
        "Teams and squads",
        "For more help"
      ],
      "published_at": "2021-10-17T11:51:46Z",
      "title": "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "7f3f97222daf52cf14afcf8fc432b96b3cebd4b1",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses an agile Sprint workflow in Jira and GitHub to manage our work. We've further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let's break them down further. Agile People use agile to mean everything from a specific system of work (which we call sprints), to just \"moving fast, preferably in a way that lets me bend things to my whims.\" Luckily, we don't need to define it from scratch. Wikipedia does an admirable job defining it: Agile software development is an approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, empirical knowledge, and continual improvement, and it encourages rapid and flexible response to change. For our team, that means our process is optimized to ship early and often. This lets us respond swiftly to changes in the product roadmap. More importantly, it ensures we validate our solutions with stakeholders, and that we're not letting valuable work sit around and get moldy when it could be out in the world making our users' lives better. Sprint (or scrum) This is the particular flavor of agile we follow. The sprint system (often referred to as scrum) is one major approach to Agile, along with other Agile systems such as Kanban. Sprint systems are often accompanied by a lot of jargon and best practices, but for our team the most essential elements are: Working in strict timeboxes (two weeks in our case) Planning that sprint in advance, and not changing the scope of the sprint (much) once it starts Expecting all team members to contribute to making the sprint a success The video Agile Product Ownership in a Nutshell (18 minutes) is an excellent resource for learning about sprint methodology. The Kindle book Scrum: a Breathtakingly Brief and Agile Introduction is also a great read that you can get through in a short afternoon. For more on the \"why\" of Sprint as our chosen methodology, see Key agile principles. And for more on the \"how,\" see Sprint workflow. Jira and GitHub issues Jira and GitHub issues are the tools we use to manage our Agile workflow. If you remember one thing about them, it should be this: using Jira or GitHub issues is not the same as having an agile workflow. They're powerful tools for tracking work and managing a backlog, but the most important part of project management is the structure we impose on that tool. Jira is for sprint work. Sprints are where roadmap docs get written, monthly commits get delivered, and deeper research percolates. We have a backlog, board, and future sprint list in Jira that help us track what people want, what's coming up, and what we're working on now. For more on the mechanics of how we use Jira, see Sprint workflow and Jira boards and Ticket best practices. We use GitHub projects for hero work, customer-reported issues, and managing the flow of PRs and edits. The Docs PRs and Issues board contains everything we're actively working on in GitHub. We'll often connect work in GitHub back to Jira by putting a Jira issue key in the PR or issue title (DOC-1234, for example). For more on the mechanics of how we use GitHub, see Managing the GitHub boards. Teams and squads Our team is the Tech Docs team. We're collectively responsible for docs.newrelic.com and sundry writing content. Our team is further divided into two agile squads (The Odd Squad and The Amp Squad), one squad for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and liaisonships. Less people means shorter meetings. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain a shared understanding. Small squads can collaborate more easily than a large team, because not everyone needs to keep in mind everything that goes on everywhere. Each squad is responsible for its own grooming and sprint planning, but the managers and scrum masters coordinate grooming to ensure we're meeting our overall goals as a team. Key agile principles â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1517.9277,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Agile vs sprints (vs Jira vs <em>GitHub</em>): A profusion of terms",
        "sections": "Agile vs sprints (vs Jira vs <em>GitHub</em>): A profusion of terms",
        "body": " research percolates. We have a backlog, <em>board</em>, and future sprint list in Jira that help us track what people want, what&#x27;s coming up, and what we&#x27;re working on now. For more on the mechanics of how we use Jira, see Sprint workflow and Jira <em>boards</em> and Ticket best practices. We use <em>GitHub</em> projects"
      },
      "id": "616c0d96196a677e623c7bd2"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/appendices/ticket-best-practices/",
      "sections": [
        "Ticket best practices: How to write a sprint-ready Jira",
        "Tip",
        "Why do we use Jira?",
        "What work needs a ticket?",
        "Keeping tickets up-to-date",
        "Add Jira context to PRs and commits",
        "Checklist for writing a good ticket",
        "For more help"
      ],
      "published_at": "2021-10-17T12:57:54Z",
      "title": "Ticket best practices: How to write a sprint-ready Jira",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "2109a54437970761f71a3940f189b7f10aef0bc1",
      "document_type": "page",
      "popularity": 1,
      "body": "Jira, a project management tool made by Atlassian, is how we manage our projects and understand the work we are doing and have done. Jira tickets may seem at first to be simple to-do lists that we use to know what things to do for a project. But they are much more important than that. Tip For Relics: Use the docs.newrelic.com/jira template when you create a ticket! It'll automatically pre-fill your ticket with a template that helps create a good ticket. Why do we use Jira? We create tickets to record work-to-be done for a project, scope new work, share information for any writer to complete a story, forecast our output and to estimate project timelines, and have a record of work done. In other words, Jira has a role at every point in a project: Before a project Scoping, syncing on expectations, giving tech writer instructions During a project Keeps team and management posted about project; allows for hand-offs and swarming After a project Understand what work we did, and helps researching on future projects What work needs a ticket? There aren't hard-and-fast rules about what work needs a Jira ticket and what doesn't. A good shorthand is that any project that takes more than a couple hours is a good candidate for a ticket. However, the goal of creating tickets is not to track writer time in detail. So many kinds of work (meetings, ongoing minor liaison tasks, hero work) generally do not need to go into Jira. Keeping tickets up-to-date In general, you should write your tickets as though you might win the lottery tomorrow (a principle known as lottery factor or bus factor). In practice, someone should be able to read your ticket and figure out within about ten minutes what the status is and what the next step is. This makes it easy for us to take vacations, pass work off to another docs writer if needed, and escalate blockers. These things help with lottery factor: Update the Action Item list as you complete tasks and add or remove scope. When you move a ticket to Blocked, include a note explaining the change in status. When you close a ticket, give a summary of the work done and any relevant thoughts you have on the work and potential related issues. Update the Timeline, People, and Resources sections as the project evolves. Add important conversations (emails or Slack convos from SMEs) that give important context for the work done. (Note: It's a good idea to ask permission before doing this, because some people might not like their informal words placed in a public place.) Add Jira context to PRs and commits When you edit the site, include the Jira issue key (DOC-1234, for example) in your pull request title and/or commit summary. That makes it easier for other writers to connect the dots later if we're trying to figure out why something changed or who knows about a particular subject. Checklist for writing a good ticket Helpful title A ticket name should be easy to find via search, understand the work at a glance, mention the product or feature, and describe the goal or issue. Examples of good ticket titles: Browser API: Update custom attribute-related docs or Distributed tracing: Add more detail about CAT relationship. Action items An action item list describing the work to be done What docs are affected Links to pull requests, Google Docs drafts, etc. How substantial the writing work is in each doc How the resulting work should be structured Whether or not a peer edit is needed Anyone who should be notified when a doc is published Proper sizing Story is scoped to the smallest reasonable size Can be completed within a 2 week sprint Delivers incremental value Dates Publication date or due date Dates for other key events (betas, limited releases, etc.) Resources and people People, including last names and roles List of related or affected docs Other internal and external resources Related issues Labels and fields Jira tickets: Component, Product Group, and Priority GitHub issues: from_, pg_, and content labels â† Managing the GitHub boards Appendix: Project scoping cheatsheet â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1412.8003,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ": Component, Product Group, and Priority <em>GitHub</em> issues: from_, pg_, and content labels â† <em>Managing</em> the <em>GitHub</em> <em>boards</em> Appendix: Project scoping cheatsheet â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a <em>GitHub</em> issue."
      },
      "id": "616c0d9628ccbc919400346e"
    }
  ],
  "/docs/agile-handbook/heroing/what-is-a-hero": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/heroing/managing-the-github-boards/",
      "sections": [
        "Managing the GitHub boards",
        "A note on Assignee vs Reviewer",
        "Drafts column",
        "Hero to triage column",
        "Hero: To do column",
        "In progress/being reviewed column",
        "Writer needs PR review column",
        "Writer needs peer edit column",
        "Waiting on SME/blocked column",
        "Waiting on TW to merge column",
        "For more help"
      ],
      "published_at": "2021-10-17T12:59:25Z",
      "title": "Managing the GitHub boards",
      "updated_at": "2021-10-17T11:47:50Z",
      "type": "docs",
      "external_id": "8552cb5f3cec74364831b7d0d85a5d3bdd734e09",
      "document_type": "page",
      "popularity": 1,
      "body": "The Docs pull requests and Issues board is our source of truth for what's going on in our project. The board is divided into a series of columns so we can see visually what the status of each issue and pull request is. A note on Assignee vs Reviewer Assignee and Reviewer have different meanings: Assignee means you own the pull request or issue and are getting it into a merge-ready state. If you are no longer owning a given pull request or issue, take your name off as assignee. Reviewer means you are actively reviewing a pull request. If it's a pull request from outside the docs team, the reviewer is also responsible for merging the pull request into develop. If you're reviewing a pull request from a fellow docs writer, add your comments and mark the pull request as Approved, then move it to Waiting on TW to merge. Drafts column These issues and pull requests are in a draft state. Do not merge until their owner moves them out of the column. This column should only be for draft pull requests. Do not \"hold\" pull requests or issues here. The Hero should look at this column multiple times per day in case a pull request has been marked ready for review. Move any ready-for-review pull requests into the correct column. Hero to triage column New issues and pull requests flow into this column automatically. As hero, you need to triage each one: Determine if the pull request or issue is content-related. If it's an eng issue or pull request, you can just Archive it to remove it from the board. Assign mandatory labels: Label type Required on Description content Issues and pull requests Use this label to indicate an issue or pull request relates to content (versus the code of the site). from_ Issues and pull requests Use this label to indicate who created the issue or pull request. Use from_tw when it's created by a docs writer, from_internal when it's created by a Relic, and from_external when it's from outside the company. pg_ Issues Indicates which New Relic product group is associated with this issue. Give the ticket an assignee (most likely you). Move the ticket to the appropriate column. Hero: To do column Work that the GitHub has triaged, but hasn't started working on yet. Tickets in this column need to have an assignee. In progress/being reviewed column Work is underway on this issue or pull request. For example, reviewing pull requests from outside the team, doing a peer edit, investigating a GitHub issue. The person doing the work should make themselves the assignee as soon as they move the pull request or issue into this column to prevent others from duplicating work. Writer needs PR review column Exactly what it says. Typically, the writer who submitted the pull request will move it to this column. A pull request review means reviewing for basic stuff like is it rendering correctly, are there typos or wording issues, and are there any obvious errors in the .mdx content shown in the diff. Once you've reviewed the pull request, mark it approved in the GitHub review UI, and move it to the Waiting on TW to merge column. Writer needs peer edit column Also exactly what it says. As with pull request review column, the writer who submitted the pull request will drag to this column. This includes all the stuff in a pull request review plus an actual peer edit. Once you've reviewed the pull request and left your feedback in the GitHub review UI, mark it Approved and move it to the Waiting on TW to merge column. From there, the author of pull request is responsible for reviewing the feedback and updating it before merging. If you find significant issues (inaccuracies, bad formatting, build issues), don't mark it Approved. Waiting on SME/blocked column Blocked until something else happens. Usually this means it's waiting on answers or approval from the SME or the person who submitted the pull request. Waiting on TW to merge column When a docs writer creates a pull request, it's their responsibility to merge it into develop at the appropriate time. After a reviewer is done with their pull reuqest review or peer edit, they move it into this column so the original writer can merge when ready. â† What is a hero? Appendix: Ticket best practices â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.7839,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>A</em> note on <em>Assignee</em> vs Reviewer",
        "body": " a docs writer creates a pull request, it&#x27;s their responsibility to merge it into develop at the appropriate time. After a reviewer is done with their pull reuqest review or peer edit, they move it into this column so the original writer can merge when ready. â† <em>What</em> is a <em>hero</em>? Appendix: Ticket best practices â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0d6628ccbcbb0b003a72"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/liaisonships/",
      "sections": [
        "Liaisonships",
        "Liaison responsibilities: Manage project flow",
        "Liaison responsibilities: Build expertise",
        "Liaison responsibilities: Define content strategy (oh, and do the writing)",
        "For more help"
      ],
      "published_at": "2021-10-17T12:53:21Z",
      "title": "Liaisonships",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "bf8ec36541058fe18f8395db811344baf7f23e22",
      "document_type": "page",
      "popularity": 1,
      "body": "For large projects, we'll typically assign a particular tech writer to that project as a \"liaison.\" The liaisonâ€™s job is to ensure that we get complete, consistent, and timely docs. Not every project gets a liaisonship! For smaller projects, we'll encourage teams to edit the docs directly, and then have the hero review their changes. And a smallish project may not need a full liaisonâ€”a single ticket might be enough to manage the work. To figure out which type of support is best for a given project, one of the managers on the team will have a scoping conversation with a subject matter expert. Here's a few reasons a project might get a dedicated liaison: Project is complex and would benefit from intimate familiarity with the feature. Project requires significant information architecture work. Project will produce enough docs that consistency across those docs will be hard to achieve without a centralized editor. Project SMEs would benefit from a consistent \"face\" of the tech writing team. However, a liaison is not the only author on a project. Liaisons should structure their work to maximize swarming and knowledge sharing. Liaison responsibilities: Manage project flow Activity Who? Notes Learn new thing exists Team Ideally the Hero or a Tech Docs manager gets notified directly by a PM about a new project. But sometimes we'll find out about something unexpectedly. If you're not sure whether we have a writer working on something, ask a manager on the team and they'll reach out to the subject matter expert to scope it. Have a scoping meeting Tech Docs manager The manager is responsible for tracking the general state of major projects across the company, and is generally the first point of contact for new projects. When a large new project comes up, the manager will do a pre-scope meeting with the requestor. (Appendix: Project scoping cheatsheet has a list of common questions for this pre-scope meeting.) That conversation helps figure out timeline, complexity, key docs considerations, and which writer will be a good fit as liaison. Assign a liaison Tech Docs manager Once we know we need a liaison, a manager on our team will figure out who to assign. Some of the factors we use to decide who to assign include bandwidth, familiarity with the product or feature, career goals and writing strengths, and simple interest in the topic. Keep track of project dates Liaison The managers on the team keep track of upcoming projects that don't have a liaison assigned. Once a writer gets involved, that liaison keeps track of the specifics of dates: Betas, limited releases, GAs, fast-follows, and so on. Your manager's always here to help out if you're getting blocked or dates are shifting too rapidly to plan properly. Validate the docs plan with the project team Liaison The liaison works with their stakeholders to define the information architecture and deliverables. Create tickets Liaison Since the liaison defines the information architecture, the liaison will know what kinds of deliverables we need. The liaison also acts as an advocate for their tickets in the backlog grooming and sprint planning processes, and ensures their stories meet the story quality requirements. The liaison should also ensure that our partner teams have appropriate tickets in their backlogs for their work. Remove blockers (such as reviewer delay) Liaison + Manager While the liaison is primarily responsible for handling SME relationships and removing day-to-day blockers, your manager is here to help unstick things anytime you need help. Wrap up the liaisonship Liaison Liaisonships are not forever assignments! When the bulk of your work on a project is complete, it might be time to consider ending the liaisonship. Reach out to your manager to talk about it. When you end it, let stakeholders know and update the liaison roster. Also let your stakeholders know they can always ping the docs hero for help or if they have a new project. Liaison responsibilities: Build expertise Activity Who? Notes Develop a deep expertise on feature and audience. Liaison Become the Docs Team's local expert on the feature. Understand what it does, what problems it solves, and the implications for our content. Educate the team on the feature Liaison Part of your responsibility as liaison is to share expertise around the team. That helps with swarming, but it also makes for better hero review and a smarter team that can write more intelligently about the entire New Relic One platform. Coordinate with design and/or research and test your docs Liaison Reach out to the designer and/or researcher for the project, and periodically sync on any shared concerns, user needs, etc. And you should advocate for user testing and validation of your content. Liaison responsibilities: Define content strategy (oh, and do the writing) Activity Who? Notes Define the information architecture Liaison As liaison, you're the expert on both the feature the product team is building, and the docs content (new and existing) that will support that feature. Build an IA that will meet all project needs and scale to the future. Write content Team The liaison writes much of the content for their project, especially the conceptual content like intro docs. But the whole team is expected to swarm and contribute to large projects, with the liaison coordinating that work. Peer edit drafts Liaison When we swarm and have someone else contribute to the project, the liaison peer edits their drafts to ensure consistency with the overall vision. Coordinate publication Liaison When the time comes to release (whether that's beta, GA, limited release, or EoL), it's the liaison's job to coordinate with PM, Eng, and Product Marketing to ensure docs go out on time with other deliverables. â† Sprint workflow and Jira boards What is a hero? â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.07022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Liaison responsibilities: Define content strategy (oh, <em>and</em> do the writing)",
        "body": " ping the docs <em>hero</em> for help or if they have a new project. Liaison responsibilities: Build expertise Activity Who? Notes Develop a deep expertise on feature and audience. Liaison Become the Docs Team&#x27;s local expert on the feature. Understand <em>what</em> it does, <em>what</em> problems it solves, and the implications"
      },
      "id": "616c0d97e7b9d227264780c5"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/planning-poker/",
      "sections": [
        "Planning poker and points budgets",
        "Poker card definitions",
        "How we calculate the points budget",
        "Tip",
        "For more help"
      ],
      "published_at": "2021-10-17T12:48:37Z",
      "title": "Planning poker and points budgets",
      "updated_at": "2021-10-17T11:51:09Z",
      "type": "docs",
      "external_id": "d002b0635204648ebe36dbdc6c242e80fa971aa3",
      "document_type": "page",
      "popularity": 1,
      "body": "Planning poker is a consensus-based estimating and planning technique. To start a planning poker session, the story reporter or liaison presents a story to the team. Then, the team all votes (at the same time, to prevent groupthink) on how difficult they think the story is. Most agile teams that estimate with planning poker use cards that follow a Fibonacci sequence. We've found over the years that those large jumps weren't very helpful to us in estimating, and that we estimated better with smaller numbers. So we use fairly small, granular numbers that roughly break down to 1 point â‰ˆ 1 day. Note that even though each of the possible scores have approximate time values associated with them, we vote in points, not time. Scoring with points prevents getting into weedsy debates about exactly how long something will take, and instead focuses us on the requirements and difficulty of the story. Poker card definitions These how we define our poker cards: Card Value Â¼ An hour or two. Anything smaller than this isn't worth bringing into a sprint or even ticketingâ€”just do it right now. Â½ About half of an \"ideal\" day. We define an \"ideal\" day as one without meetings or interruptions. Using \"ideal\" days makes it easier to estimate a story without litigating the details of how we spend our time. 1 About one \"ideal\" day. This is one of our most common story sizes. 1Â½ About one and a half \"ideal\" days. This is our other most common story size. 2 About two \"ideal\" days. 3 About three \"ideal\" days. We jump from 2 straight to 3 to avoid unrealistic granularity in our estimates. 5 About a week of work. 7 About a full sprint (two weeks) of work. We very rarely use this cardâ€”a ticket that takes a full sprint on its own is almost always too large and should be chunked into smaller, incremental tickets. Break! \"I need a break.\" When someone plays a break card, we finish estimating the current story then immediately take a five minute break. Defer No strong opinion. Don't play this card on the first round of poker! Seeing wildly different estimates is a sign we don't have a shared understanding of the work. Playing an early Defer card can mask that uncertainty. How we calculate the points budget In order to ensure we're not filling up our sprint with more \"ideal days\" of time than we realistically have available, we calculate the points budget based on the actual output of the team. Over time, we've found writers average 0.6 (technically, 0.57) points per day. Tip This value is totally unique to each team! A high number doesn't indicate a more productive team, and a low number isn't a problem. Story points are only meaningful within a team. If you're starting a new team or new process, you'll need to zero in on the ideal number of points per writer. An easy way to figure out the right budget is to have the team vote in retro on whether to increase, decrease, or keep the same budget next sprint. You'll overshoot or undershoot a few times, but after a couple sprints you'll get a good sense of what constistutes a sustainable pace. Once you know your baseline, calculating the budget is straightforward: Take the number of writers, and multiply by the number of days in the sprint. To make the math easy, let's say 5 writers and a 10 business day (2 calendar week) sprint. Or, 50 person-days total. Subtract out time off days, plus 1 day for each day of hero duty. Let's say we have 1 writer on vacation in Maui, and 1 day of hero time per day. 50 person days, minus 10 days of vacation and 10 days of hero time, gives us 30 person-days. Multiply the number of days times the average velocity per writer, per day. Our average velocity is 0.6 points/writer/day. 30 person days multiplied by 0.6 would give us an 18 point budget for the sprint. Because we work in two squads, we calculate a separate points budget for each squad ahead of sprint planning. â† Meetings and ceremonies Sprint workflow and Jira boards â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.77072,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Planning poker <em>and</em> points budgets",
        "sections": "Planning poker <em>and</em> points budgets",
        "body": " you&#x27;ll get a good sense of <em>what</em> constistutes a sustainable pace. Once you know your baseline, calculating the budget is straightforward: Take the number of writers, and multiply by the number of days in the sprint. To make the math easy, let&#x27;s say 5 writers and a 10 business day (2 calendar week) sprint"
      },
      "id": "616c0e2d28ccbc6e5e00337f"
    }
  ],
  "/docs/agile-handbook/key-concepts/agile-roles": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/key-agile-principles/",
      "sections": [
        "Key agile principles for our team",
        "Focus on the team's work",
        "Maximize swarming",
        "Enforce our points budgets",
        "Work incrementally",
        "Encourage self-service edits",
        "For more help"
      ],
      "published_at": "2021-10-17T12:55:49Z",
      "title": "Key agile principles for our team",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "749e499964c577501e9ae64249513d23f3d97cdb",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses a fairly \"by the book\" agile-scrum implementation, with the understanding that we can tweak the workflow as needed to work better for our flow. This handbook doesn't describe every aspect of how a sprint system should work, but focuses on the specific choices our team made as we evolved our agile process. As we evolve the system, it's helpful to know what our goals are. That can help illuminate whether a problem with the system is worth solving, and how to solve it without compromising on the essential things that make the team run smoothly. Focus on the team's work Our goal is for our team to deliver the most valuable work for the business and our users, every sprint. This description from Scrum: A Breathtakingly Brief and Agile Introduction nails what that means in practice: The role of each and every team member is to help the team deliver potentially shippable product in each sprint. Often, the best way to do this is by contributing work in their area of specialty. Other times, however, the team will need them to work outside of their area of specialty in order to best move backlog items from \"in progress\" to \"done.\" What we are describing is a mindset change from \"doing my job\" to \"doing the job.\" We aim to complete 100% of our work every sprint. In practice this is rarely attainable: We know that dates will move, scopes will expand, or our estimates will be wrong. But we've found that this 100% benchmark ensures we prioritize our shared team goal (the sprint), rather than our individual deliverables. Maximize swarming We want writers to build expertise, but we don't want to isolate ourselves. An alerts team at New Relic summed it up nicely: Our philosophy is, \"The team is the unit of work.\" This means that teams contribute to projects, teams solve problems, etc. We don't assign projects to individuals, and no one should ever be a single point of failure in the organization. If your team struggles to function effectively without you, your flexibility to take time off will be very limited. In such a case, we need to improve the skills and overall health of your team, ensure the team is setup for success, and ensure we have an appropriate team structure and charter in place. And an ops team demonstrates the most important practical implication: Our intention for tickets is that anyone should be able to select a task and have the information needed to understand and start on the work. Sometimes, this means we work a little slower in order to learn or teach something---and that's okay! Ultimately, working this way makes our team more resilient and makes it easier for New Relic to get consistent, high-quality docs. The Ticket best practices doc describes in detail the rules and best practices we've discovered help us achieve this. Enforce our points budgets Our team votes on all stories brought into a sprint, and we cap the number of stories based on our points budget. We generally vote as though the least-experienced person on the team will take the ticket. Having a strict points budget allows us to protect the team from overwork, predict our velocity over time, and ensure we actually have enough time to finish our work. Work incrementally Our goal is to deliver value as often as possible. Work that sits in a draft state for a long time can easily become wasted work: SMEs can become unavailable, priorities can change, and our knowledge can become stale. In practice, this means we work in fairly short two week sprints, publish early and often, and plan our projects so we can easily deliver 70% and then pivot to different priorities if something more important comes along. Encourage self-service edits Anyone can edit our open-sourced docs. With hundreds of Relics and users editing the docs each year, we can spend more of our writing time on high-impact work rather than simple maintenance edits. In order to reward teams that help us work this way, we prioritize this work in our queue. For work the writers need to do themselves, we ask for at least one full sprint of lead time. If someone comes to us the Tuesday after a sprint starts, that means they could be waiting up to two weeks for us to kick off work! But if someone edits the docs themselves, we promise to get their edit live within a 1 to 3 business day SLA. This lets us create win-wins: Rather than a simple \"no,\" a requestor can decide whether they truly need that content out now (in which case they can create that first draft) or whether they're okay waiting a week or two. â† Agile vs sprints: A profusion of terms Agile roles â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 831.9907,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Key <em>agile</em> principles for our team",
        "sections": "Key <em>agile</em> principles for our team",
        "body": " is for our team to deliver the most valuable work for the business and our users, every sprint. This description from Scrum: A Breathtakingly Brief and <em>Agile</em> Introduction nails what that means in practice: The <em>role</em> of each and every team member is to help the team deliver potentially shippable product"
      },
      "id": "616c0d96196a6768873c845b"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/meetings-and-ceremonies/",
      "sections": [
        "Meetings and ceremonies",
        "Tip",
        "Sprint planning",
        "Backlog grooming",
        "Retro",
        "For more help"
      ],
      "published_at": "2021-10-17T11:51:09Z",
      "title": "Meetings and ceremonies",
      "updated_at": "2021-10-17T11:50:18Z",
      "type": "docs",
      "external_id": "873983fa778f17f1a92871ed4ad7673b333d4acc",
      "document_type": "page",
      "popularity": 1,
      "body": "Monday Tuesday Wednesday Thursday Friday Week 1 Sprint retro (every other sprint) Backlog grooming (end of sprint) Sprint planning (start of new sprint) Team meeting Meeting-free day Week 2 Team meeting Meeting-free day We break our work into two-week sprints. The new sprint starts on a Tuesday with sprint planning, where we commit to a set of stories that we're confident we can complete by the end of the sprint. Near the end of the sprint, we prepare for the next sprint with backlog grooming. The sprint closes with a retro where we discuss what went right and what went wrong, and then we kick off a new cycle. Each squad does their own backlog grooming and sprint planning, and manages their sprint backlog independently. We do retros together so we can talk through issues that affect both squads and share expertise and ideas. Tip Why do we end sprints on Mondays and start Tuesdays? This funny schedule makes things easier to work across timezones. If we ended sprints on Fridays, our Barcelona-based writers would need to do retros and grooming on Friday evening, and who wants that? Sprint planning On the first Tuesday of a new sprint, we commit to a series of stories until we have filled our capacity for the sprint. This is the largest meeting in the sprint---about 60 to 90 minutes. Before the sprint planning meeting, the scrum master for each squad calculates their point budget. Then, during the meeting: We select the highest priority item in the backlog. The person who nominated the story introduces it, and the team asks questions until everyone feels ready to vote. The team plays planning poker. Everyone secretly chooses a card, then we reveal them at the same time: If everyone picks the same card, that's the point value and we move on. If there's an even split between two cards, we choose the larger and move on. If it's mixed, the highest and lowest voters briefly explain their votes. Then we vote again. Once we're sure we can fit the story in, we subtract its story points from the sprint's points budget. We repeat the above steps until we've used up our points budget. We generally avoid pre-assigning people to stories during sprint planning. Instead, we pick up the next story or peer edit in the To Do column as stories are completed. Backlog grooming The day before the sprint starts, we do two rounds of backlog grooming. The purpose of backlog grooming is to prioritize work for sprint planning, and identify stories that need to be fixed before sprint planning to ensure scope is clear and planning runs smoothly. The first round of backlog grooming is by squad, where the members and manager of the squad get together and work through the grooming checklist. Then we do a second round of grooming with the managers and scrum masters to look at the sprint backlog for both squads and ensure nothing is or has fallen through the cracks. In the grooming, we: Each writer brings their personal \"top five\" tickets. The manager works with writers to prioritize those into a single, stack-ranked list for the team. We talk through stories and ensure they look ready for sprint planning (essentially, do they fit the Checklist for story readiness?). After grooming, the scrum master sends out a list of \"homework\" for stories that need improving. Retro Every other sprint, we conduct a 60 minute retrospective meeting, where we discuss: How do we feel about the sprint? What went well? Where can we improve? Anything we should start or stop doing? The goal of the retro is to improve the way we work together. That could be related to the sprint process, to how we collaborate with SMEs, to peer edits, and so on. â† Agile roles Planning poker â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 777.51825,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " we collaborate with SMEs, to peer edits, and so on. â† <em>Agile</em> <em>roles</em> Planning poker â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0dfa196a679fd43c9791"
    },
    {
      "image": "https://docs.newrelic.com/static/e74b3e31916f093c77d41e8beef9ecc9/c1b63/lines_of_communication.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-sprints-profusion-of-terms/",
      "sections": [
        "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
        "Agile",
        "Sprint (or scrum)",
        "Jira and GitHub issues",
        "Teams and squads",
        "For more help"
      ],
      "published_at": "2021-10-17T11:51:46Z",
      "title": "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "7f3f97222daf52cf14afcf8fc432b96b3cebd4b1",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses an agile Sprint workflow in Jira and GitHub to manage our work. We've further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let's break them down further. Agile People use agile to mean everything from a specific system of work (which we call sprints), to just \"moving fast, preferably in a way that lets me bend things to my whims.\" Luckily, we don't need to define it from scratch. Wikipedia does an admirable job defining it: Agile software development is an approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, empirical knowledge, and continual improvement, and it encourages rapid and flexible response to change. For our team, that means our process is optimized to ship early and often. This lets us respond swiftly to changes in the product roadmap. More importantly, it ensures we validate our solutions with stakeholders, and that we're not letting valuable work sit around and get moldy when it could be out in the world making our users' lives better. Sprint (or scrum) This is the particular flavor of agile we follow. The sprint system (often referred to as scrum) is one major approach to Agile, along with other Agile systems such as Kanban. Sprint systems are often accompanied by a lot of jargon and best practices, but for our team the most essential elements are: Working in strict timeboxes (two weeks in our case) Planning that sprint in advance, and not changing the scope of the sprint (much) once it starts Expecting all team members to contribute to making the sprint a success The video Agile Product Ownership in a Nutshell (18 minutes) is an excellent resource for learning about sprint methodology. The Kindle book Scrum: a Breathtakingly Brief and Agile Introduction is also a great read that you can get through in a short afternoon. For more on the \"why\" of Sprint as our chosen methodology, see Key agile principles. And for more on the \"how,\" see Sprint workflow. Jira and GitHub issues Jira and GitHub issues are the tools we use to manage our Agile workflow. If you remember one thing about them, it should be this: using Jira or GitHub issues is not the same as having an agile workflow. They're powerful tools for tracking work and managing a backlog, but the most important part of project management is the structure we impose on that tool. Jira is for sprint work. Sprints are where roadmap docs get written, monthly commits get delivered, and deeper research percolates. We have a backlog, board, and future sprint list in Jira that help us track what people want, what's coming up, and what we're working on now. For more on the mechanics of how we use Jira, see Sprint workflow and Jira boards and Ticket best practices. We use GitHub projects for hero work, customer-reported issues, and managing the flow of PRs and edits. The Docs PRs and Issues board contains everything we're actively working on in GitHub. We'll often connect work in GitHub back to Jira by putting a Jira issue key in the PR or issue title (DOC-1234, for example). For more on the mechanics of how we use GitHub, see Managing the GitHub boards. Teams and squads Our team is the Tech Docs team. We're collectively responsible for docs.newrelic.com and sundry writing content. Our team is further divided into two agile squads (The Odd Squad and The Amp Squad), one squad for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and liaisonships. Less people means shorter meetings. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain a shared understanding. Small squads can collaborate more easily than a large team, because not everyone needs to keep in mind everything that goes on everywhere. Each squad is responsible for its own grooming and sprint planning, but the managers and scrum masters coordinate grooming to ensure we're meeting our overall goals as a team. Key agile principles â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.439,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agile</em> vs sprints (vs Jira vs GitHub): A profusion of terms",
        "sections": "<em>Agile</em> vs sprints (vs Jira vs GitHub): A profusion of terms",
        "body": "Our team uses an <em>agile</em> Sprint workflow in Jira and GitHub to manage our work. We&#x27;ve further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let&#x27;s break them down further. <em>Agile</em> People use <em>agile</em> to mean"
      },
      "id": "616c0d96196a677e623c7bd2"
    }
  ],
  "/docs/agile-handbook/key-concepts/agile-sprints-profusion-of-terms": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/key-agile-principles/",
      "sections": [
        "Key agile principles for our team",
        "Focus on the team's work",
        "Maximize swarming",
        "Enforce our points budgets",
        "Work incrementally",
        "Encourage self-service edits",
        "For more help"
      ],
      "published_at": "2021-10-17T12:55:49Z",
      "title": "Key agile principles for our team",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "749e499964c577501e9ae64249513d23f3d97cdb",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses a fairly \"by the book\" agile-scrum implementation, with the understanding that we can tweak the workflow as needed to work better for our flow. This handbook doesn't describe every aspect of how a sprint system should work, but focuses on the specific choices our team made as we evolved our agile process. As we evolve the system, it's helpful to know what our goals are. That can help illuminate whether a problem with the system is worth solving, and how to solve it without compromising on the essential things that make the team run smoothly. Focus on the team's work Our goal is for our team to deliver the most valuable work for the business and our users, every sprint. This description from Scrum: A Breathtakingly Brief and Agile Introduction nails what that means in practice: The role of each and every team member is to help the team deliver potentially shippable product in each sprint. Often, the best way to do this is by contributing work in their area of specialty. Other times, however, the team will need them to work outside of their area of specialty in order to best move backlog items from \"in progress\" to \"done.\" What we are describing is a mindset change from \"doing my job\" to \"doing the job.\" We aim to complete 100% of our work every sprint. In practice this is rarely attainable: We know that dates will move, scopes will expand, or our estimates will be wrong. But we've found that this 100% benchmark ensures we prioritize our shared team goal (the sprint), rather than our individual deliverables. Maximize swarming We want writers to build expertise, but we don't want to isolate ourselves. An alerts team at New Relic summed it up nicely: Our philosophy is, \"The team is the unit of work.\" This means that teams contribute to projects, teams solve problems, etc. We don't assign projects to individuals, and no one should ever be a single point of failure in the organization. If your team struggles to function effectively without you, your flexibility to take time off will be very limited. In such a case, we need to improve the skills and overall health of your team, ensure the team is setup for success, and ensure we have an appropriate team structure and charter in place. And an ops team demonstrates the most important practical implication: Our intention for tickets is that anyone should be able to select a task and have the information needed to understand and start on the work. Sometimes, this means we work a little slower in order to learn or teach something---and that's okay! Ultimately, working this way makes our team more resilient and makes it easier for New Relic to get consistent, high-quality docs. The Ticket best practices doc describes in detail the rules and best practices we've discovered help us achieve this. Enforce our points budgets Our team votes on all stories brought into a sprint, and we cap the number of stories based on our points budget. We generally vote as though the least-experienced person on the team will take the ticket. Having a strict points budget allows us to protect the team from overwork, predict our velocity over time, and ensure we actually have enough time to finish our work. Work incrementally Our goal is to deliver value as often as possible. Work that sits in a draft state for a long time can easily become wasted work: SMEs can become unavailable, priorities can change, and our knowledge can become stale. In practice, this means we work in fairly short two week sprints, publish early and often, and plan our projects so we can easily deliver 70% and then pivot to different priorities if something more important comes along. Encourage self-service edits Anyone can edit our open-sourced docs. With hundreds of Relics and users editing the docs each year, we can spend more of our writing time on high-impact work rather than simple maintenance edits. In order to reward teams that help us work this way, we prioritize this work in our queue. For work the writers need to do themselves, we ask for at least one full sprint of lead time. If someone comes to us the Tuesday after a sprint starts, that means they could be waiting up to two weeks for us to kick off work! But if someone edits the docs themselves, we promise to get their edit live within a 1 to 3 business day SLA. This lets us create win-wins: Rather than a simple \"no,\" a requestor can decide whether they truly need that content out now (in which case they can create that first draft) or whether they're okay waiting a week or two. â† Agile vs sprints: A profusion of terms Agile roles â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 588.7135,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Key <em>agile</em> principles for our team",
        "sections": "Key <em>agile</em> principles for our team",
        "body": " okay waiting a week or two. â† <em>Agile</em> <em>vs</em> <em>sprints</em>: A <em>profusion</em> of <em>terms</em> <em>Agile</em> roles â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a <em>GitHub</em> issue."
      },
      "id": "616c0d96196a6768873c845b"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/heroing/managing-the-github-boards/",
      "sections": [
        "Managing the GitHub boards",
        "A note on Assignee vs Reviewer",
        "Drafts column",
        "Hero to triage column",
        "Hero: To do column",
        "In progress/being reviewed column",
        "Writer needs PR review column",
        "Writer needs peer edit column",
        "Waiting on SME/blocked column",
        "Waiting on TW to merge column",
        "For more help"
      ],
      "published_at": "2021-10-17T12:59:25Z",
      "title": "Managing the GitHub boards",
      "updated_at": "2021-10-17T11:47:50Z",
      "type": "docs",
      "external_id": "8552cb5f3cec74364831b7d0d85a5d3bdd734e09",
      "document_type": "page",
      "popularity": 1,
      "body": "The Docs pull requests and Issues board is our source of truth for what's going on in our project. The board is divided into a series of columns so we can see visually what the status of each issue and pull request is. A note on Assignee vs Reviewer Assignee and Reviewer have different meanings: Assignee means you own the pull request or issue and are getting it into a merge-ready state. If you are no longer owning a given pull request or issue, take your name off as assignee. Reviewer means you are actively reviewing a pull request. If it's a pull request from outside the docs team, the reviewer is also responsible for merging the pull request into develop. If you're reviewing a pull request from a fellow docs writer, add your comments and mark the pull request as Approved, then move it to Waiting on TW to merge. Drafts column These issues and pull requests are in a draft state. Do not merge until their owner moves them out of the column. This column should only be for draft pull requests. Do not \"hold\" pull requests or issues here. The Hero should look at this column multiple times per day in case a pull request has been marked ready for review. Move any ready-for-review pull requests into the correct column. Hero to triage column New issues and pull requests flow into this column automatically. As hero, you need to triage each one: Determine if the pull request or issue is content-related. If it's an eng issue or pull request, you can just Archive it to remove it from the board. Assign mandatory labels: Label type Required on Description content Issues and pull requests Use this label to indicate an issue or pull request relates to content (versus the code of the site). from_ Issues and pull requests Use this label to indicate who created the issue or pull request. Use from_tw when it's created by a docs writer, from_internal when it's created by a Relic, and from_external when it's from outside the company. pg_ Issues Indicates which New Relic product group is associated with this issue. Give the ticket an assignee (most likely you). Move the ticket to the appropriate column. Hero: To do column Work that the GitHub has triaged, but hasn't started working on yet. Tickets in this column need to have an assignee. In progress/being reviewed column Work is underway on this issue or pull request. For example, reviewing pull requests from outside the team, doing a peer edit, investigating a GitHub issue. The person doing the work should make themselves the assignee as soon as they move the pull request or issue into this column to prevent others from duplicating work. Writer needs PR review column Exactly what it says. Typically, the writer who submitted the pull request will move it to this column. A pull request review means reviewing for basic stuff like is it rendering correctly, are there typos or wording issues, and are there any obvious errors in the .mdx content shown in the diff. Once you've reviewed the pull request, mark it approved in the GitHub review UI, and move it to the Waiting on TW to merge column. Writer needs peer edit column Also exactly what it says. As with pull request review column, the writer who submitted the pull request will drag to this column. This includes all the stuff in a pull request review plus an actual peer edit. Once you've reviewed the pull request and left your feedback in the GitHub review UI, mark it Approved and move it to the Waiting on TW to merge column. From there, the author of pull request is responsible for reviewing the feedback and updating it before merging. If you find significant issues (inaccuracies, bad formatting, build issues), don't mark it Approved. Waiting on SME/blocked column Blocked until something else happens. Usually this means it's waiting on answers or approval from the SME or the person who submitted the pull request. Waiting on TW to merge column When a docs writer creates a pull request, it's their responsibility to merge it into develop at the appropriate time. After a reviewer is done with their pull reuqest review or peer edit, they move it into this column so the original writer can merge when ready. â† What is a hero? Appendix: Ticket best practices â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.87927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Managing the <em>GitHub</em> boards",
        "sections": "Managing the <em>GitHub</em> boards",
        "body": " to the appropriate column. Hero: To do column Work that the <em>GitHub</em> has triaged, but hasn&#x27;t started working on yet. Tickets in this column need to have an assignee. In progress&#x2F;being reviewed column Work is underway on this issue or pull request. For example, reviewing pull requests from outside the team"
      },
      "id": "616c0d6628ccbcbb0b003a72"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/planning-poker/",
      "sections": [
        "Planning poker and points budgets",
        "Poker card definitions",
        "How we calculate the points budget",
        "Tip",
        "For more help"
      ],
      "published_at": "2021-10-17T12:48:37Z",
      "title": "Planning poker and points budgets",
      "updated_at": "2021-10-17T11:51:09Z",
      "type": "docs",
      "external_id": "d002b0635204648ebe36dbdc6c242e80fa971aa3",
      "document_type": "page",
      "popularity": 1,
      "body": "Planning poker is a consensus-based estimating and planning technique. To start a planning poker session, the story reporter or liaison presents a story to the team. Then, the team all votes (at the same time, to prevent groupthink) on how difficult they think the story is. Most agile teams that estimate with planning poker use cards that follow a Fibonacci sequence. We've found over the years that those large jumps weren't very helpful to us in estimating, and that we estimated better with smaller numbers. So we use fairly small, granular numbers that roughly break down to 1 point â‰ˆ 1 day. Note that even though each of the possible scores have approximate time values associated with them, we vote in points, not time. Scoring with points prevents getting into weedsy debates about exactly how long something will take, and instead focuses us on the requirements and difficulty of the story. Poker card definitions These how we define our poker cards: Card Value Â¼ An hour or two. Anything smaller than this isn't worth bringing into a sprint or even ticketingâ€”just do it right now. Â½ About half of an \"ideal\" day. We define an \"ideal\" day as one without meetings or interruptions. Using \"ideal\" days makes it easier to estimate a story without litigating the details of how we spend our time. 1 About one \"ideal\" day. This is one of our most common story sizes. 1Â½ About one and a half \"ideal\" days. This is our other most common story size. 2 About two \"ideal\" days. 3 About three \"ideal\" days. We jump from 2 straight to 3 to avoid unrealistic granularity in our estimates. 5 About a week of work. 7 About a full sprint (two weeks) of work. We very rarely use this cardâ€”a ticket that takes a full sprint on its own is almost always too large and should be chunked into smaller, incremental tickets. Break! \"I need a break.\" When someone plays a break card, we finish estimating the current story then immediately take a five minute break. Defer No strong opinion. Don't play this card on the first round of poker! Seeing wildly different estimates is a sign we don't have a shared understanding of the work. Playing an early Defer card can mask that uncertainty. How we calculate the points budget In order to ensure we're not filling up our sprint with more \"ideal days\" of time than we realistically have available, we calculate the points budget based on the actual output of the team. Over time, we've found writers average 0.6 (technically, 0.57) points per day. Tip This value is totally unique to each team! A high number doesn't indicate a more productive team, and a low number isn't a problem. Story points are only meaningful within a team. If you're starting a new team or new process, you'll need to zero in on the ideal number of points per writer. An easy way to figure out the right budget is to have the team vote in retro on whether to increase, decrease, or keep the same budget next sprint. You'll overshoot or undershoot a few times, but after a couple sprints you'll get a good sense of what constistutes a sustainable pace. Once you know your baseline, calculating the budget is straightforward: Take the number of writers, and multiply by the number of days in the sprint. To make the math easy, let's say 5 writers and a 10 business day (2 calendar week) sprint. Or, 50 person-days total. Subtract out time off days, plus 1 day for each day of hero duty. Let's say we have 1 writer on vacation in Maui, and 1 day of hero time per day. 50 person days, minus 10 days of vacation and 10 days of hero time, gives us 30 person-days. Multiply the number of days times the average velocity per writer, per day. Our average velocity is 0.6 points/writer/day. 30 person days multiplied by 0.6 would give us an 18 point budget for the sprint. Because we work in two squads, we calculate a separate points budget for each squad ahead of sprint planning. â† Meetings and ceremonies Sprint workflow and Jira boards â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.5587,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Planning poker <em>and</em> points budgets",
        "sections": "Planning poker <em>and</em> points budgets",
        "body": " and ceremonies <em>Sprint</em> workflow and <em>Jira</em> boards â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a <em>GitHub</em> issue."
      },
      "id": "616c0e2d28ccbc6e5e00337f"
    }
  ],
  "/docs/agile-handbook/key-concepts/key-agile-principles": [
    {
      "image": "https://docs.newrelic.com/static/e74b3e31916f093c77d41e8beef9ecc9/c1b63/lines_of_communication.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-sprints-profusion-of-terms/",
      "sections": [
        "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
        "Agile",
        "Sprint (or scrum)",
        "Jira and GitHub issues",
        "Teams and squads",
        "For more help"
      ],
      "published_at": "2021-10-17T11:51:46Z",
      "title": "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "7f3f97222daf52cf14afcf8fc432b96b3cebd4b1",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses an agile Sprint workflow in Jira and GitHub to manage our work. We've further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let's break them down further. Agile People use agile to mean everything from a specific system of work (which we call sprints), to just \"moving fast, preferably in a way that lets me bend things to my whims.\" Luckily, we don't need to define it from scratch. Wikipedia does an admirable job defining it: Agile software development is an approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, empirical knowledge, and continual improvement, and it encourages rapid and flexible response to change. For our team, that means our process is optimized to ship early and often. This lets us respond swiftly to changes in the product roadmap. More importantly, it ensures we validate our solutions with stakeholders, and that we're not letting valuable work sit around and get moldy when it could be out in the world making our users' lives better. Sprint (or scrum) This is the particular flavor of agile we follow. The sprint system (often referred to as scrum) is one major approach to Agile, along with other Agile systems such as Kanban. Sprint systems are often accompanied by a lot of jargon and best practices, but for our team the most essential elements are: Working in strict timeboxes (two weeks in our case) Planning that sprint in advance, and not changing the scope of the sprint (much) once it starts Expecting all team members to contribute to making the sprint a success The video Agile Product Ownership in a Nutshell (18 minutes) is an excellent resource for learning about sprint methodology. The Kindle book Scrum: a Breathtakingly Brief and Agile Introduction is also a great read that you can get through in a short afternoon. For more on the \"why\" of Sprint as our chosen methodology, see Key agile principles. And for more on the \"how,\" see Sprint workflow. Jira and GitHub issues Jira and GitHub issues are the tools we use to manage our Agile workflow. If you remember one thing about them, it should be this: using Jira or GitHub issues is not the same as having an agile workflow. They're powerful tools for tracking work and managing a backlog, but the most important part of project management is the structure we impose on that tool. Jira is for sprint work. Sprints are where roadmap docs get written, monthly commits get delivered, and deeper research percolates. We have a backlog, board, and future sprint list in Jira that help us track what people want, what's coming up, and what we're working on now. For more on the mechanics of how we use Jira, see Sprint workflow and Jira boards and Ticket best practices. We use GitHub projects for hero work, customer-reported issues, and managing the flow of PRs and edits. The Docs PRs and Issues board contains everything we're actively working on in GitHub. We'll often connect work in GitHub back to Jira by putting a Jira issue key in the PR or issue title (DOC-1234, for example). For more on the mechanics of how we use GitHub, see Managing the GitHub boards. Teams and squads Our team is the Tech Docs team. We're collectively responsible for docs.newrelic.com and sundry writing content. Our team is further divided into two agile squads (The Odd Squad and The Amp Squad), one squad for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and liaisonships. Less people means shorter meetings. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain a shared understanding. Small squads can collaborate more easily than a large team, because not everyone needs to keep in mind everything that goes on everywhere. Each squad is responsible for its own grooming and sprint planning, but the managers and scrum masters coordinate grooming to ensure we're meeting our overall goals as a team. Key agile principles â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 315.8017,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agile</em> vs sprints (vs Jira vs GitHub): A profusion of terms",
        "sections": "<em>Agile</em> vs sprints (vs Jira vs GitHub): A profusion of terms",
        "body": " meeting <em>our</em> overall goals as a <em>team</em>. <em>Key</em> <em>agile</em> <em>principles</em> â†’ For more help We welcome thoughts or questions on <em>our</em> handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0d96196a677e623c7bd2"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-roles/",
      "sections": [
        "Agile roles",
        "Team member",
        "Scrum master",
        "Tech Docs managers (and product owner)",
        "Key stakeholders",
        "For more help"
      ],
      "published_at": "2021-10-17T12:49:54Z",
      "title": "Agile roles",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "fcfd8b2a56ccc61ba57d207f49876b4788a1ca51",
      "document_type": "page",
      "popularity": 1,
      "body": "Like most agile teams, we divide up the roles on our team into team members, scrum masters, product owners, and managers. We treat some of those roles differently than a traditional engineer-centric scrum team: We combine the role of team manager and product owner into one person. Each writer is responsible for \"liaisonships\" where they track work across a particular product or feature and bring in appropriate stories. We don't expect scrum masters to clear blockers (that's a manager's job), and scrum mastering is not a full-time job. We divide the team further into two squads, each with its own team members, scrum master, and product owners. Team member Team members are responsible for: Doing writing work. Improving the team's processes and how we work together. Writing stories for sprints in accordance with their work (via laisionships, SME conversations, hero work, etc.). The person who nominates a story will also present it during sprint planning. See Ticket best practices for tips on writing a good ticket. Most team members will be assigned one or more Liaisonships (project assignments). Liaisons are responsible for nominating stories for sprints from other teams. Scrum master Each squad has a scrum master. The scrum master is not responsible for unblocking stories or communicating with stakeholders on behalf of the team (this work belongs to individual writers and their manager). We believe this lets the business have a single point of accountability (managers) for decisions, and ensures scrum masters have hands-on experience of what it's like to be a writer. Instead, for us the scrum master is a custodian of the sprint process and the MC for sprint meetings. In backlog grooming: The scrum master handles the mechanics of talking through each ticket and facilitating conversations about story quality. In sprint planning: The scrum master leads conversation, tracks discussion time, adds point values to stories, and organizes/ranks sprint candidates in real time. They don't present the stories, thoughâ€”stories should be introduced by the person who nominated the story for the sprint. In retros: The scrum master facilitates the discussion, captures action items, and takes notes. Tech Docs managers (and product owner) Each squad has a manager---or perhaps you could say each manager has a squad. Either way, the manager's role is to prioritize the right work for the business, maintain a healthy workload, and help escalate when a writer needs help. The managers are responsible for understanding how our entire body of work serves the organization, and making informed decisions about our velocity and workload. The manager engages with other teams to know which features may be coming into the pipeline and has a general understanding of work that may be in future sprints. This lets them make final priority decisions for the team and be accountable to the business for those tradeoffs. The manager is also responsible for assigning liaisonships and ensuring we're covering the portfolio. They'll also work with other teams to unblock writers when needed. Key stakeholders Our key internal stakeholders include PMs, engineers, designers, and executives. Writers work with the stakeholders to know when new work is coming, and to communicate documentation needs/timelines. We should ensure our stakeholders know that we work in two week sprints, so that they can give us adequate lead time and get their documentation needs met. â† Key agile principles Meetings and ceremonies â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.03143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agile</em> roles",
        "sections": "<em>Agile</em> roles",
        "body": " needs&#x2F;timelines. We should ensure <em>our</em> stakeholders know that we work in two week sprints, so that they can give us adequate lead time and get their documentation needs met. â† <em>Key</em> <em>agile</em> <em>principles</em> Meetings and ceremonies â†’ For more help We welcome thoughts or questions on <em>our</em> handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0d97e7b9d2b2f047837d"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/planning-poker/",
      "sections": [
        "Planning poker and points budgets",
        "Poker card definitions",
        "How we calculate the points budget",
        "Tip",
        "For more help"
      ],
      "published_at": "2021-10-17T12:48:37Z",
      "title": "Planning poker and points budgets",
      "updated_at": "2021-10-17T11:51:09Z",
      "type": "docs",
      "external_id": "d002b0635204648ebe36dbdc6c242e80fa971aa3",
      "document_type": "page",
      "popularity": 1,
      "body": "Planning poker is a consensus-based estimating and planning technique. To start a planning poker session, the story reporter or liaison presents a story to the team. Then, the team all votes (at the same time, to prevent groupthink) on how difficult they think the story is. Most agile teams that estimate with planning poker use cards that follow a Fibonacci sequence. We've found over the years that those large jumps weren't very helpful to us in estimating, and that we estimated better with smaller numbers. So we use fairly small, granular numbers that roughly break down to 1 point â‰ˆ 1 day. Note that even though each of the possible scores have approximate time values associated with them, we vote in points, not time. Scoring with points prevents getting into weedsy debates about exactly how long something will take, and instead focuses us on the requirements and difficulty of the story. Poker card definitions These how we define our poker cards: Card Value Â¼ An hour or two. Anything smaller than this isn't worth bringing into a sprint or even ticketingâ€”just do it right now. Â½ About half of an \"ideal\" day. We define an \"ideal\" day as one without meetings or interruptions. Using \"ideal\" days makes it easier to estimate a story without litigating the details of how we spend our time. 1 About one \"ideal\" day. This is one of our most common story sizes. 1Â½ About one and a half \"ideal\" days. This is our other most common story size. 2 About two \"ideal\" days. 3 About three \"ideal\" days. We jump from 2 straight to 3 to avoid unrealistic granularity in our estimates. 5 About a week of work. 7 About a full sprint (two weeks) of work. We very rarely use this cardâ€”a ticket that takes a full sprint on its own is almost always too large and should be chunked into smaller, incremental tickets. Break! \"I need a break.\" When someone plays a break card, we finish estimating the current story then immediately take a five minute break. Defer No strong opinion. Don't play this card on the first round of poker! Seeing wildly different estimates is a sign we don't have a shared understanding of the work. Playing an early Defer card can mask that uncertainty. How we calculate the points budget In order to ensure we're not filling up our sprint with more \"ideal days\" of time than we realistically have available, we calculate the points budget based on the actual output of the team. Over time, we've found writers average 0.6 (technically, 0.57) points per day. Tip This value is totally unique to each team! A high number doesn't indicate a more productive team, and a low number isn't a problem. Story points are only meaningful within a team. If you're starting a new team or new process, you'll need to zero in on the ideal number of points per writer. An easy way to figure out the right budget is to have the team vote in retro on whether to increase, decrease, or keep the same budget next sprint. You'll overshoot or undershoot a few times, but after a couple sprints you'll get a good sense of what constistutes a sustainable pace. Once you know your baseline, calculating the budget is straightforward: Take the number of writers, and multiply by the number of days in the sprint. To make the math easy, let's say 5 writers and a 10 business day (2 calendar week) sprint. Or, 50 person-days total. Subtract out time off days, plus 1 day for each day of hero duty. Let's say we have 1 writer on vacation in Maui, and 1 day of hero time per day. 50 person days, minus 10 days of vacation and 10 days of hero time, gives us 30 person-days. Multiply the number of days times the average velocity per writer, per day. Our average velocity is 0.6 points/writer/day. 30 person days multiplied by 0.6 would give us an 18 point budget for the sprint. Because we work in two squads, we calculate a separate points budget for each squad ahead of sprint planning. â† Meetings and ceremonies Sprint workflow and Jira boards â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.211136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>For</em> more help",
        "body": "Planning poker is a consensus-based estimating and planning technique. To start a planning poker session, the story reporter or liaison presents a story to the <em>team</em>. Then, the <em>team</em> all votes (at the same time, to prevent groupthink) on how difficult they think the story is. Most <em>agile</em> teams"
      },
      "id": "616c0e2d28ccbc6e5e00337f"
    }
  ],
  "/docs/agile-handbook/sprint-mechanics/liaisonships": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-roles/",
      "sections": [
        "Agile roles",
        "Team member",
        "Scrum master",
        "Tech Docs managers (and product owner)",
        "Key stakeholders",
        "For more help"
      ],
      "published_at": "2021-10-17T12:49:54Z",
      "title": "Agile roles",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "fcfd8b2a56ccc61ba57d207f49876b4788a1ca51",
      "document_type": "page",
      "popularity": 1,
      "body": "Like most agile teams, we divide up the roles on our team into team members, scrum masters, product owners, and managers. We treat some of those roles differently than a traditional engineer-centric scrum team: We combine the role of team manager and product owner into one person. Each writer is responsible for \"liaisonships\" where they track work across a particular product or feature and bring in appropriate stories. We don't expect scrum masters to clear blockers (that's a manager's job), and scrum mastering is not a full-time job. We divide the team further into two squads, each with its own team members, scrum master, and product owners. Team member Team members are responsible for: Doing writing work. Improving the team's processes and how we work together. Writing stories for sprints in accordance with their work (via laisionships, SME conversations, hero work, etc.). The person who nominates a story will also present it during sprint planning. See Ticket best practices for tips on writing a good ticket. Most team members will be assigned one or more Liaisonships (project assignments). Liaisons are responsible for nominating stories for sprints from other teams. Scrum master Each squad has a scrum master. The scrum master is not responsible for unblocking stories or communicating with stakeholders on behalf of the team (this work belongs to individual writers and their manager). We believe this lets the business have a single point of accountability (managers) for decisions, and ensures scrum masters have hands-on experience of what it's like to be a writer. Instead, for us the scrum master is a custodian of the sprint process and the MC for sprint meetings. In backlog grooming: The scrum master handles the mechanics of talking through each ticket and facilitating conversations about story quality. In sprint planning: The scrum master leads conversation, tracks discussion time, adds point values to stories, and organizes/ranks sprint candidates in real time. They don't present the stories, thoughâ€”stories should be introduced by the person who nominated the story for the sprint. In retros: The scrum master facilitates the discussion, captures action items, and takes notes. Tech Docs managers (and product owner) Each squad has a manager---or perhaps you could say each manager has a squad. Either way, the manager's role is to prioritize the right work for the business, maintain a healthy workload, and help escalate when a writer needs help. The managers are responsible for understanding how our entire body of work serves the organization, and making informed decisions about our velocity and workload. The manager engages with other teams to know which features may be coming into the pipeline and has a general understanding of work that may be in future sprints. This lets them make final priority decisions for the team and be accountable to the business for those tradeoffs. The manager is also responsible for assigning liaisonships and ensuring we're covering the portfolio. They'll also work with other teams to unblock writers when needed. Key stakeholders Our key internal stakeholders include PMs, engineers, designers, and executives. Writers work with the stakeholders to know when new work is coming, and to communicate documentation needs/timelines. We should ensure our stakeholders know that we work in two week sprints, so that they can give us adequate lead time and get their documentation needs met. â† Key agile principles Meetings and ceremonies â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.12915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " is responsible for &quot;<em>liaisonships</em>&quot; where they track work across a particular product or feature and bring in appropriate stories. We don&#x27;t expect scrum masters to clear blockers (that&#x27;s a manager&#x27;s job), and scrum mastering is not a full-time job. We divide the team further into two squads, each with its"
      },
      "id": "616c0d97e7b9d2b2f047837d"
    },
    {
      "image": "https://docs.newrelic.com/static/e74b3e31916f093c77d41e8beef9ecc9/c1b63/lines_of_communication.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-sprints-profusion-of-terms/",
      "sections": [
        "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
        "Agile",
        "Sprint (or scrum)",
        "Jira and GitHub issues",
        "Teams and squads",
        "For more help"
      ],
      "published_at": "2021-10-17T11:51:46Z",
      "title": "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "7f3f97222daf52cf14afcf8fc432b96b3cebd4b1",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses an agile Sprint workflow in Jira and GitHub to manage our work. We've further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let's break them down further. Agile People use agile to mean everything from a specific system of work (which we call sprints), to just \"moving fast, preferably in a way that lets me bend things to my whims.\" Luckily, we don't need to define it from scratch. Wikipedia does an admirable job defining it: Agile software development is an approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, empirical knowledge, and continual improvement, and it encourages rapid and flexible response to change. For our team, that means our process is optimized to ship early and often. This lets us respond swiftly to changes in the product roadmap. More importantly, it ensures we validate our solutions with stakeholders, and that we're not letting valuable work sit around and get moldy when it could be out in the world making our users' lives better. Sprint (or scrum) This is the particular flavor of agile we follow. The sprint system (often referred to as scrum) is one major approach to Agile, along with other Agile systems such as Kanban. Sprint systems are often accompanied by a lot of jargon and best practices, but for our team the most essential elements are: Working in strict timeboxes (two weeks in our case) Planning that sprint in advance, and not changing the scope of the sprint (much) once it starts Expecting all team members to contribute to making the sprint a success The video Agile Product Ownership in a Nutshell (18 minutes) is an excellent resource for learning about sprint methodology. The Kindle book Scrum: a Breathtakingly Brief and Agile Introduction is also a great read that you can get through in a short afternoon. For more on the \"why\" of Sprint as our chosen methodology, see Key agile principles. And for more on the \"how,\" see Sprint workflow. Jira and GitHub issues Jira and GitHub issues are the tools we use to manage our Agile workflow. If you remember one thing about them, it should be this: using Jira or GitHub issues is not the same as having an agile workflow. They're powerful tools for tracking work and managing a backlog, but the most important part of project management is the structure we impose on that tool. Jira is for sprint work. Sprints are where roadmap docs get written, monthly commits get delivered, and deeper research percolates. We have a backlog, board, and future sprint list in Jira that help us track what people want, what's coming up, and what we're working on now. For more on the mechanics of how we use Jira, see Sprint workflow and Jira boards and Ticket best practices. We use GitHub projects for hero work, customer-reported issues, and managing the flow of PRs and edits. The Docs PRs and Issues board contains everything we're actively working on in GitHub. We'll often connect work in GitHub back to Jira by putting a Jira issue key in the PR or issue title (DOC-1234, for example). For more on the mechanics of how we use GitHub, see Managing the GitHub boards. Teams and squads Our team is the Tech Docs team. We're collectively responsible for docs.newrelic.com and sundry writing content. Our team is further divided into two agile squads (The Odd Squad and The Amp Squad), one squad for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and liaisonships. Less people means shorter meetings. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain a shared understanding. Small squads can collaborate more easily than a large team, because not everyone needs to keep in mind everything that goes on everywhere. Each squad is responsible for its own grooming and sprint planning, but the managers and scrum masters coordinate grooming to ensure we're meeting our overall goals as a team. Key agile principles â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.23947,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and <em>liaisonships</em>. Less people means shorter meetings. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain"
      },
      "id": "616c0d96196a677e623c7bd2"
    },
    {
      "image": "https://docs.newrelic.com/static/aa5797a9c6aaadf52a7bac18b3ac8e83/c1b63/dealing_with_interrupts.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/sprint-workflow-and-jira-boards/",
      "sections": [
        "Sprint workflow",
        "Planned work",
        "Unplanned work (surprises!)",
        "Jira boards: Backlog and future sprints",
        "Jira boards: Current sprint",
        "Proposed",
        "In Progress",
        "Needs Peer Editor",
        "In Peer Edit",
        "Peer Edit Done",
        "Blocked",
        "Done",
        "Incomplete (\"carry-over\") tickets",
        "For more help"
      ],
      "published_at": "2021-10-17T13:00:51Z",
      "title": "Sprint workflow",
      "updated_at": "2021-10-17T11:49:20Z",
      "type": "docs",
      "external_id": "e18dcb23b9a43a083a2c4496d6fb9a20b9efc496",
      "document_type": "page",
      "popularity": 1,
      "body": "All of our sprint work is tracked in Jira. The workflow depends on what type of work we're dealing with: Planned or unplanned (\"surprise!\") work. Planned work Planned work includes all work that is currently in our backlog or has been added to the current sprint as a result of a Sprint Planning session. This could include writing or updating documentation, research, meeting with SMEs, information architecture, incorporating peer edits, SME review, and so on. Unplanned work (surprises!) Usually, we get notified of major requests far enough in advance that we can include them in liaison project plans, backlog grooming, and sprint planning. Occasionally, something bigger surprises us that needs emergency support. Follow this process with new docs asks to assess the scope of work and ensure we address valid docs needs within a reasonable amount of time. Our goal is to treat the sprint as sacred and insulate against \"surprise\" work that is not absolutely crucial. But we also want to ensure we're providing good internal customer service, and not getting hung up on process niceties for things that are small. Jira boards: Backlog and future sprints This is where the vast majority of tickets spend their time. Most tickets (even for active projects) spend at least a little time here before moving into a sprint to be actively worked. Being in the backlog doesn't mean something isn't important---just that we haven't committed to it yet.Â  You can also add tickets straight to a future sprint. This is where tickets tentatively assigned to a future sprint will be found. Tickets can be assigned here to be held for backlog grooming and sprint planning.Â  Jira boards: Current sprint Proposed This step is for work that has been assigned to the current sprint during Sprint Planning and is available to be picked up by a tech writer. When you're ready to take on a new ticket, try to work the queue from the top-down and avoid cherry picking. It's also better to pick up Needs Peer Edit tickets before committing to a new ticket. Something that needs a peer edit is close to done, and helping things across the finish line helps get value into users hands, and frees us up to think about new problems. In Progress This step is for all of the work to be done by the assignee: Research, meeting with SMEs, information architecture, writing, incorporating peer edits, SME review, and so on. Tickets are moved to this step once work is started by the TW, and remain here until the work is either complete, ready for peer review, or it becomes blocked. If additional large edits are needed after the peer review, the ticket can be moved back to In Progress for those edits. Needs Peer Editor Work that is ready for a peer edit. Once a peer editor picks it up, they move it into In Peer Edit. In Peer Edit This step is for a peer editor to review docs before they go live. Follow the Peer editor workflow, then move the ticket into Peer Edit Done.Â  Peer Edit Done This step is a holding state once peer editing is complete. After completing their peer edit and delivering their feedback, the peer editor moves the ticket into Peer Edit Done. From there, the assignee on the ticket (not the peer editor) moves the ticket into the appropriate column (In Progress, Blocked, or Closed). Minor edits can be completed from this column but for major doc rework, the ticket should be moved back into the In Progress column. Blocked This step is for tickets that cannot be moved forward by the team. This could be because we're waiting for a response from a SME, or for a feature to deploy, or for final signoff. The team keeps an eye on this column for tickets that may need escalation. Putting something in Blocked rather than In Progress lets us see the status of every ticket at a glance. This column can also be used for extended time out of the office for the assigned writer, if it's work that can be safely held. (If the work cannot be held while you're out, find another writer to step in and take over.) Once you're un-blocked, move the ticket to the appropriate column. If the ticket remains blocked at the end of the current sprint, it will need to be re-reviewed during backlog grooming to determine if the ticket will carry-over into the upcoming sprint, or return to the backlog until a future sprint. Done This step is for work that is 100% finished. Work gets cleared out this column before we start a new sprint. Incomplete (\"carry-over\") tickets Ticket don't carry over automatically between sprints. Instead, any ticket that gets carried over is treated as a \"new\" ticket in the next sprint planning. Before sprint planning, review any open tickets in the board that are assigned to you and figure out what to do with them. For each open ticket assigned to you (or \"carry over\"), decide if you should: Recommended: Clone the ticket and close the old one. This is the best option for partially completed work because it maes metrics easier. If you do: Clone the ticket. Note why we closed the ticket. Add an estimate of points completed in the Points Completed field. Create a follow-up ticket if necessary. Move the ticket to the next sprint. If you do: Review the ticket's action items and description to make sure they're still current. Clear out the ticket points. Move the ticket back to the backlog. If you do: Update the action items and description to make sure they're still current. Note why we moved to the backlog rather than carry over. â† Planning poker Liaisonships â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 75.28871,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " current. Note why we moved to the backlog rather than carry over. â† Planning poker <em>Liaisonships</em> â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0dc0196a67e6583c8164"
    }
  ],
  "/docs/agile-handbook/sprint-mechanics/meetings-and-ceremonies": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-roles/",
      "sections": [
        "Agile roles",
        "Team member",
        "Scrum master",
        "Tech Docs managers (and product owner)",
        "Key stakeholders",
        "For more help"
      ],
      "published_at": "2021-10-17T12:49:54Z",
      "title": "Agile roles",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "fcfd8b2a56ccc61ba57d207f49876b4788a1ca51",
      "document_type": "page",
      "popularity": 1,
      "body": "Like most agile teams, we divide up the roles on our team into team members, scrum masters, product owners, and managers. We treat some of those roles differently than a traditional engineer-centric scrum team: We combine the role of team manager and product owner into one person. Each writer is responsible for \"liaisonships\" where they track work across a particular product or feature and bring in appropriate stories. We don't expect scrum masters to clear blockers (that's a manager's job), and scrum mastering is not a full-time job. We divide the team further into two squads, each with its own team members, scrum master, and product owners. Team member Team members are responsible for: Doing writing work. Improving the team's processes and how we work together. Writing stories for sprints in accordance with their work (via laisionships, SME conversations, hero work, etc.). The person who nominates a story will also present it during sprint planning. See Ticket best practices for tips on writing a good ticket. Most team members will be assigned one or more Liaisonships (project assignments). Liaisons are responsible for nominating stories for sprints from other teams. Scrum master Each squad has a scrum master. The scrum master is not responsible for unblocking stories or communicating with stakeholders on behalf of the team (this work belongs to individual writers and their manager). We believe this lets the business have a single point of accountability (managers) for decisions, and ensures scrum masters have hands-on experience of what it's like to be a writer. Instead, for us the scrum master is a custodian of the sprint process and the MC for sprint meetings. In backlog grooming: The scrum master handles the mechanics of talking through each ticket and facilitating conversations about story quality. In sprint planning: The scrum master leads conversation, tracks discussion time, adds point values to stories, and organizes/ranks sprint candidates in real time. They don't present the stories, thoughâ€”stories should be introduced by the person who nominated the story for the sprint. In retros: The scrum master facilitates the discussion, captures action items, and takes notes. Tech Docs managers (and product owner) Each squad has a manager---or perhaps you could say each manager has a squad. Either way, the manager's role is to prioritize the right work for the business, maintain a healthy workload, and help escalate when a writer needs help. The managers are responsible for understanding how our entire body of work serves the organization, and making informed decisions about our velocity and workload. The manager engages with other teams to know which features may be coming into the pipeline and has a general understanding of work that may be in future sprints. This lets them make final priority decisions for the team and be accountable to the business for those tradeoffs. The manager is also responsible for assigning liaisonships and ensuring we're covering the portfolio. They'll also work with other teams to unblock writers when needed. Key stakeholders Our key internal stakeholders include PMs, engineers, designers, and executives. Writers work with the stakeholders to know when new work is coming, and to communicate documentation needs/timelines. We should ensure our stakeholders know that we work in two week sprints, so that they can give us adequate lead time and get their documentation needs met. â† Key agile principles Meetings and ceremonies â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2109.2593,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Tech Docs managers (<em>and</em> product owner)",
        "body": " needs&#x2F;timelines. We should ensure our stakeholders know that we work in two week sprints, so that they can give us adequate lead time and get their documentation needs met. â† Key agile principles <em>Meetings</em> and <em>ceremonies</em> â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0d97e7b9d2b2f047837d"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/planning-poker/",
      "sections": [
        "Planning poker and points budgets",
        "Poker card definitions",
        "How we calculate the points budget",
        "Tip",
        "For more help"
      ],
      "published_at": "2021-10-17T12:48:37Z",
      "title": "Planning poker and points budgets",
      "updated_at": "2021-10-17T11:51:09Z",
      "type": "docs",
      "external_id": "d002b0635204648ebe36dbdc6c242e80fa971aa3",
      "document_type": "page",
      "popularity": 1,
      "body": "Planning poker is a consensus-based estimating and planning technique. To start a planning poker session, the story reporter or liaison presents a story to the team. Then, the team all votes (at the same time, to prevent groupthink) on how difficult they think the story is. Most agile teams that estimate with planning poker use cards that follow a Fibonacci sequence. We've found over the years that those large jumps weren't very helpful to us in estimating, and that we estimated better with smaller numbers. So we use fairly small, granular numbers that roughly break down to 1 point â‰ˆ 1 day. Note that even though each of the possible scores have approximate time values associated with them, we vote in points, not time. Scoring with points prevents getting into weedsy debates about exactly how long something will take, and instead focuses us on the requirements and difficulty of the story. Poker card definitions These how we define our poker cards: Card Value Â¼ An hour or two. Anything smaller than this isn't worth bringing into a sprint or even ticketingâ€”just do it right now. Â½ About half of an \"ideal\" day. We define an \"ideal\" day as one without meetings or interruptions. Using \"ideal\" days makes it easier to estimate a story without litigating the details of how we spend our time. 1 About one \"ideal\" day. This is one of our most common story sizes. 1Â½ About one and a half \"ideal\" days. This is our other most common story size. 2 About two \"ideal\" days. 3 About three \"ideal\" days. We jump from 2 straight to 3 to avoid unrealistic granularity in our estimates. 5 About a week of work. 7 About a full sprint (two weeks) of work. We very rarely use this cardâ€”a ticket that takes a full sprint on its own is almost always too large and should be chunked into smaller, incremental tickets. Break! \"I need a break.\" When someone plays a break card, we finish estimating the current story then immediately take a five minute break. Defer No strong opinion. Don't play this card on the first round of poker! Seeing wildly different estimates is a sign we don't have a shared understanding of the work. Playing an early Defer card can mask that uncertainty. How we calculate the points budget In order to ensure we're not filling up our sprint with more \"ideal days\" of time than we realistically have available, we calculate the points budget based on the actual output of the team. Over time, we've found writers average 0.6 (technically, 0.57) points per day. Tip This value is totally unique to each team! A high number doesn't indicate a more productive team, and a low number isn't a problem. Story points are only meaningful within a team. If you're starting a new team or new process, you'll need to zero in on the ideal number of points per writer. An easy way to figure out the right budget is to have the team vote in retro on whether to increase, decrease, or keep the same budget next sprint. You'll overshoot or undershoot a few times, but after a couple sprints you'll get a good sense of what constistutes a sustainable pace. Once you know your baseline, calculating the budget is straightforward: Take the number of writers, and multiply by the number of days in the sprint. To make the math easy, let's say 5 writers and a 10 business day (2 calendar week) sprint. Or, 50 person-days total. Subtract out time off days, plus 1 day for each day of hero duty. Let's say we have 1 writer on vacation in Maui, and 1 day of hero time per day. 50 person days, minus 10 days of vacation and 10 days of hero time, gives us 30 person-days. Multiply the number of days times the average velocity per writer, per day. Our average velocity is 0.6 points/writer/day. 30 person days multiplied by 0.6 would give us an 18 point budget for the sprint. Because we work in two squads, we calculate a separate points budget for each squad ahead of sprint planning. â† Meetings and ceremonies Sprint workflow and Jira boards â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1810.7518,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Planning poker <em>and</em> points budgets",
        "sections": "Planning poker <em>and</em> points budgets",
        "body": ". Poker card definitions These how we define our poker cards: Card Value Â¼ An hour or two. Anything smaller than this isn&#x27;t worth bringing into a sprint or even ticketingâ€”just do it right now. Â½ About half of an &quot;ideal&quot; day. We define an &quot;ideal&quot; day as one without <em>meetings</em> or interruptions. Using"
      },
      "id": "616c0e2d28ccbc6e5e00337f"
    },
    {
      "image": "https://docs.newrelic.com/static/e74b3e31916f093c77d41e8beef9ecc9/c1b63/lines_of_communication.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-sprints-profusion-of-terms/",
      "sections": [
        "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
        "Agile",
        "Sprint (or scrum)",
        "Jira and GitHub issues",
        "Teams and squads",
        "For more help"
      ],
      "published_at": "2021-10-17T11:51:46Z",
      "title": "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "7f3f97222daf52cf14afcf8fc432b96b3cebd4b1",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses an agile Sprint workflow in Jira and GitHub to manage our work. We've further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let's break them down further. Agile People use agile to mean everything from a specific system of work (which we call sprints), to just \"moving fast, preferably in a way that lets me bend things to my whims.\" Luckily, we don't need to define it from scratch. Wikipedia does an admirable job defining it: Agile software development is an approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, empirical knowledge, and continual improvement, and it encourages rapid and flexible response to change. For our team, that means our process is optimized to ship early and often. This lets us respond swiftly to changes in the product roadmap. More importantly, it ensures we validate our solutions with stakeholders, and that we're not letting valuable work sit around and get moldy when it could be out in the world making our users' lives better. Sprint (or scrum) This is the particular flavor of agile we follow. The sprint system (often referred to as scrum) is one major approach to Agile, along with other Agile systems such as Kanban. Sprint systems are often accompanied by a lot of jargon and best practices, but for our team the most essential elements are: Working in strict timeboxes (two weeks in our case) Planning that sprint in advance, and not changing the scope of the sprint (much) once it starts Expecting all team members to contribute to making the sprint a success The video Agile Product Ownership in a Nutshell (18 minutes) is an excellent resource for learning about sprint methodology. The Kindle book Scrum: a Breathtakingly Brief and Agile Introduction is also a great read that you can get through in a short afternoon. For more on the \"why\" of Sprint as our chosen methodology, see Key agile principles. And for more on the \"how,\" see Sprint workflow. Jira and GitHub issues Jira and GitHub issues are the tools we use to manage our Agile workflow. If you remember one thing about them, it should be this: using Jira or GitHub issues is not the same as having an agile workflow. They're powerful tools for tracking work and managing a backlog, but the most important part of project management is the structure we impose on that tool. Jira is for sprint work. Sprints are where roadmap docs get written, monthly commits get delivered, and deeper research percolates. We have a backlog, board, and future sprint list in Jira that help us track what people want, what's coming up, and what we're working on now. For more on the mechanics of how we use Jira, see Sprint workflow and Jira boards and Ticket best practices. We use GitHub projects for hero work, customer-reported issues, and managing the flow of PRs and edits. The Docs PRs and Issues board contains everything we're actively working on in GitHub. We'll often connect work in GitHub back to Jira by putting a Jira issue key in the PR or issue title (DOC-1234, for example). For more on the mechanics of how we use GitHub, see Managing the GitHub boards. Teams and squads Our team is the Tech Docs team. We're collectively responsible for docs.newrelic.com and sundry writing content. Our team is further divided into two agile squads (The Odd Squad and The Amp Squad), one squad for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and liaisonships. Less people means shorter meetings. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain a shared understanding. Small squads can collaborate more easily than a large team, because not everyone needs to keep in mind everything that goes on everywhere. Each squad is responsible for its own grooming and sprint planning, but the managers and scrum masters coordinate grooming to ensure we're meeting our overall goals as a team. Key agile principles â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 74.73313,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Jira <em>and</em> GitHub issues",
        "body": " for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and liaisonships. Less people means shorter <em>meetings</em>. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain"
      },
      "id": "616c0d96196a677e623c7bd2"
    }
  ],
  "/docs/agile-handbook/sprint-mechanics/planning-poker": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/meetings-and-ceremonies/",
      "sections": [
        "Meetings and ceremonies",
        "Tip",
        "Sprint planning",
        "Backlog grooming",
        "Retro",
        "For more help"
      ],
      "published_at": "2021-10-17T11:51:09Z",
      "title": "Meetings and ceremonies",
      "updated_at": "2021-10-17T11:50:18Z",
      "type": "docs",
      "external_id": "873983fa778f17f1a92871ed4ad7673b333d4acc",
      "document_type": "page",
      "popularity": 1,
      "body": "Monday Tuesday Wednesday Thursday Friday Week 1 Sprint retro (every other sprint) Backlog grooming (end of sprint) Sprint planning (start of new sprint) Team meeting Meeting-free day Week 2 Team meeting Meeting-free day We break our work into two-week sprints. The new sprint starts on a Tuesday with sprint planning, where we commit to a set of stories that we're confident we can complete by the end of the sprint. Near the end of the sprint, we prepare for the next sprint with backlog grooming. The sprint closes with a retro where we discuss what went right and what went wrong, and then we kick off a new cycle. Each squad does their own backlog grooming and sprint planning, and manages their sprint backlog independently. We do retros together so we can talk through issues that affect both squads and share expertise and ideas. Tip Why do we end sprints on Mondays and start Tuesdays? This funny schedule makes things easier to work across timezones. If we ended sprints on Fridays, our Barcelona-based writers would need to do retros and grooming on Friday evening, and who wants that? Sprint planning On the first Tuesday of a new sprint, we commit to a series of stories until we have filled our capacity for the sprint. This is the largest meeting in the sprint---about 60 to 90 minutes. Before the sprint planning meeting, the scrum master for each squad calculates their point budget. Then, during the meeting: We select the highest priority item in the backlog. The person who nominated the story introduces it, and the team asks questions until everyone feels ready to vote. The team plays planning poker. Everyone secretly chooses a card, then we reveal them at the same time: If everyone picks the same card, that's the point value and we move on. If there's an even split between two cards, we choose the larger and move on. If it's mixed, the highest and lowest voters briefly explain their votes. Then we vote again. Once we're sure we can fit the story in, we subtract its story points from the sprint's points budget. We repeat the above steps until we've used up our points budget. We generally avoid pre-assigning people to stories during sprint planning. Instead, we pick up the next story or peer edit in the To Do column as stories are completed. Backlog grooming The day before the sprint starts, we do two rounds of backlog grooming. The purpose of backlog grooming is to prioritize work for sprint planning, and identify stories that need to be fixed before sprint planning to ensure scope is clear and planning runs smoothly. The first round of backlog grooming is by squad, where the members and manager of the squad get together and work through the grooming checklist. Then we do a second round of grooming with the managers and scrum masters to look at the sprint backlog for both squads and ensure nothing is or has fallen through the cracks. In the grooming, we: Each writer brings their personal \"top five\" tickets. The manager works with writers to prioritize those into a single, stack-ranked list for the team. We talk through stories and ensure they look ready for sprint planning (essentially, do they fit the Checklist for story readiness?). After grooming, the scrum master sends out a list of \"homework\" for stories that need improving. Retro Every other sprint, we conduct a 60 minute retrospective meeting, where we discuss: How do we feel about the sprint? What went well? Where can we improve? Anything we should start or stop doing? The goal of the retro is to improve the way we work together. That could be related to the sprint process, to how we collaborate with SMEs, to peer edits, and so on. â† Agile roles Planning poker â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 320.8383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Meetings <em>and</em> ceremonies",
        "sections": "Sprint <em>planning</em>",
        "body": " filled our capacity for the sprint. This is the largest meeting in the sprint---about 60 to 90 minutes. Before the sprint <em>planning</em> meeting, the scrum master for each squad calculates their <em>point</em> <em>budget</em>. Then, during the meeting: We select the highest priority item in the backlog. The person who"
      },
      "id": "616c0dfa196a679fd43c9791"
    },
    {
      "image": "https://docs.newrelic.com/static/aa5797a9c6aaadf52a7bac18b3ac8e83/c1b63/dealing_with_interrupts.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/sprint-workflow-and-jira-boards/",
      "sections": [
        "Sprint workflow",
        "Planned work",
        "Unplanned work (surprises!)",
        "Jira boards: Backlog and future sprints",
        "Jira boards: Current sprint",
        "Proposed",
        "In Progress",
        "Needs Peer Editor",
        "In Peer Edit",
        "Peer Edit Done",
        "Blocked",
        "Done",
        "Incomplete (\"carry-over\") tickets",
        "For more help"
      ],
      "published_at": "2021-10-17T13:00:51Z",
      "title": "Sprint workflow",
      "updated_at": "2021-10-17T11:49:20Z",
      "type": "docs",
      "external_id": "e18dcb23b9a43a083a2c4496d6fb9a20b9efc496",
      "document_type": "page",
      "popularity": 1,
      "body": "All of our sprint work is tracked in Jira. The workflow depends on what type of work we're dealing with: Planned or unplanned (\"surprise!\") work. Planned work Planned work includes all work that is currently in our backlog or has been added to the current sprint as a result of a Sprint Planning session. This could include writing or updating documentation, research, meeting with SMEs, information architecture, incorporating peer edits, SME review, and so on. Unplanned work (surprises!) Usually, we get notified of major requests far enough in advance that we can include them in liaison project plans, backlog grooming, and sprint planning. Occasionally, something bigger surprises us that needs emergency support. Follow this process with new docs asks to assess the scope of work and ensure we address valid docs needs within a reasonable amount of time. Our goal is to treat the sprint as sacred and insulate against \"surprise\" work that is not absolutely crucial. But we also want to ensure we're providing good internal customer service, and not getting hung up on process niceties for things that are small. Jira boards: Backlog and future sprints This is where the vast majority of tickets spend their time. Most tickets (even for active projects) spend at least a little time here before moving into a sprint to be actively worked. Being in the backlog doesn't mean something isn't important---just that we haven't committed to it yet.Â  You can also add tickets straight to a future sprint. This is where tickets tentatively assigned to a future sprint will be found. Tickets can be assigned here to be held for backlog grooming and sprint planning.Â  Jira boards: Current sprint Proposed This step is for work that has been assigned to the current sprint during Sprint Planning and is available to be picked up by a tech writer. When you're ready to take on a new ticket, try to work the queue from the top-down and avoid cherry picking. It's also better to pick up Needs Peer Edit tickets before committing to a new ticket. Something that needs a peer edit is close to done, and helping things across the finish line helps get value into users hands, and frees us up to think about new problems. In Progress This step is for all of the work to be done by the assignee: Research, meeting with SMEs, information architecture, writing, incorporating peer edits, SME review, and so on. Tickets are moved to this step once work is started by the TW, and remain here until the work is either complete, ready for peer review, or it becomes blocked. If additional large edits are needed after the peer review, the ticket can be moved back to In Progress for those edits. Needs Peer Editor Work that is ready for a peer edit. Once a peer editor picks it up, they move it into In Peer Edit. In Peer Edit This step is for a peer editor to review docs before they go live. Follow the Peer editor workflow, then move the ticket into Peer Edit Done.Â  Peer Edit Done This step is a holding state once peer editing is complete. After completing their peer edit and delivering their feedback, the peer editor moves the ticket into Peer Edit Done. From there, the assignee on the ticket (not the peer editor) moves the ticket into the appropriate column (In Progress, Blocked, or Closed). Minor edits can be completed from this column but for major doc rework, the ticket should be moved back into the In Progress column. Blocked This step is for tickets that cannot be moved forward by the team. This could be because we're waiting for a response from a SME, or for a feature to deploy, or for final signoff. The team keeps an eye on this column for tickets that may need escalation. Putting something in Blocked rather than In Progress lets us see the status of every ticket at a glance. This column can also be used for extended time out of the office for the assigned writer, if it's work that can be safely held. (If the work cannot be held while you're out, find another writer to step in and take over.) Once you're un-blocked, move the ticket to the appropriate column. If the ticket remains blocked at the end of the current sprint, it will need to be re-reviewed during backlog grooming to determine if the ticket will carry-over into the upcoming sprint, or return to the backlog until a future sprint. Done This step is for work that is 100% finished. Work gets cleared out this column before we start a new sprint. Incomplete (\"carry-over\") tickets Ticket don't carry over automatically between sprints. Instead, any ticket that gets carried over is treated as a \"new\" ticket in the next sprint planning. Before sprint planning, review any open tickets in the board that are assigned to you and figure out what to do with them. For each open ticket assigned to you (or \"carry over\"), decide if you should: Recommended: Clone the ticket and close the old one. This is the best option for partially completed work because it maes metrics easier. If you do: Clone the ticket. Note why we closed the ticket. Add an estimate of points completed in the Points Completed field. Create a follow-up ticket if necessary. Move the ticket to the next sprint. If you do: Review the ticket's action items and description to make sure they're still current. Clear out the ticket points. Move the ticket back to the backlog. If you do: Update the action items and description to make sure they're still current. Note why we moved to the backlog rather than carry over. â† Planning poker Liaisonships â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.25105,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Planned</em> work",
        "body": " current. Note why we moved to the backlog rather than carry over. â† <em>Planning</em> <em>poker</em> Liaisonships â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0dc0196a67e6583c8164"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/key-agile-principles/",
      "sections": [
        "Key agile principles for our team",
        "Focus on the team's work",
        "Maximize swarming",
        "Enforce our points budgets",
        "Work incrementally",
        "Encourage self-service edits",
        "For more help"
      ],
      "published_at": "2021-10-17T12:55:49Z",
      "title": "Key agile principles for our team",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "749e499964c577501e9ae64249513d23f3d97cdb",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses a fairly \"by the book\" agile-scrum implementation, with the understanding that we can tweak the workflow as needed to work better for our flow. This handbook doesn't describe every aspect of how a sprint system should work, but focuses on the specific choices our team made as we evolved our agile process. As we evolve the system, it's helpful to know what our goals are. That can help illuminate whether a problem with the system is worth solving, and how to solve it without compromising on the essential things that make the team run smoothly. Focus on the team's work Our goal is for our team to deliver the most valuable work for the business and our users, every sprint. This description from Scrum: A Breathtakingly Brief and Agile Introduction nails what that means in practice: The role of each and every team member is to help the team deliver potentially shippable product in each sprint. Often, the best way to do this is by contributing work in their area of specialty. Other times, however, the team will need them to work outside of their area of specialty in order to best move backlog items from \"in progress\" to \"done.\" What we are describing is a mindset change from \"doing my job\" to \"doing the job.\" We aim to complete 100% of our work every sprint. In practice this is rarely attainable: We know that dates will move, scopes will expand, or our estimates will be wrong. But we've found that this 100% benchmark ensures we prioritize our shared team goal (the sprint), rather than our individual deliverables. Maximize swarming We want writers to build expertise, but we don't want to isolate ourselves. An alerts team at New Relic summed it up nicely: Our philosophy is, \"The team is the unit of work.\" This means that teams contribute to projects, teams solve problems, etc. We don't assign projects to individuals, and no one should ever be a single point of failure in the organization. If your team struggles to function effectively without you, your flexibility to take time off will be very limited. In such a case, we need to improve the skills and overall health of your team, ensure the team is setup for success, and ensure we have an appropriate team structure and charter in place. And an ops team demonstrates the most important practical implication: Our intention for tickets is that anyone should be able to select a task and have the information needed to understand and start on the work. Sometimes, this means we work a little slower in order to learn or teach something---and that's okay! Ultimately, working this way makes our team more resilient and makes it easier for New Relic to get consistent, high-quality docs. The Ticket best practices doc describes in detail the rules and best practices we've discovered help us achieve this. Enforce our points budgets Our team votes on all stories brought into a sprint, and we cap the number of stories based on our points budget. We generally vote as though the least-experienced person on the team will take the ticket. Having a strict points budget allows us to protect the team from overwork, predict our velocity over time, and ensure we actually have enough time to finish our work. Work incrementally Our goal is to deliver value as often as possible. Work that sits in a draft state for a long time can easily become wasted work: SMEs can become unavailable, priorities can change, and our knowledge can become stale. In practice, this means we work in fairly short two week sprints, publish early and often, and plan our projects so we can easily deliver 70% and then pivot to different priorities if something more important comes along. Encourage self-service edits Anyone can edit our open-sourced docs. With hundreds of Relics and users editing the docs each year, we can spend more of our writing time on high-impact work rather than simple maintenance edits. In order to reward teams that help us work this way, we prioritize this work in our queue. For work the writers need to do themselves, we ask for at least one full sprint of lead time. If someone comes to us the Tuesday after a sprint starts, that means they could be waiting up to two weeks for us to kick off work! But if someone edits the docs themselves, we promise to get their edit live within a 1 to 3 business day SLA. This lets us create win-wins: Rather than a simple \"no,\" a requestor can decide whether they truly need that content out now (in which case they can create that first draft) or whether they're okay waiting a week or two. â† Agile vs sprints: A profusion of terms Agile roles â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.09792,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Enforce our <em>points</em> <em>budgets</em>",
        "body": " practices doc describes in detail the rules and best practices we&#x27;ve discovered help us achieve this. Enforce our <em>points</em> <em>budgets</em> Our team votes on all stories brought into a sprint, and we cap the number of stories based on our <em>points</em> <em>budget</em>. We generally vote as though the least-experienced person"
      },
      "id": "616c0d96196a6768873c845b"
    }
  ],
  "/docs/agile-handbook/sprint-mechanics/sprint-workflow-and-jira-boards": [
    {
      "image": "https://docs.newrelic.com/static/e74b3e31916f093c77d41e8beef9ecc9/c1b63/lines_of_communication.png",
      "url": "https://docs.newrelic.com/docs/agile-handbook/key-concepts/agile-sprints-profusion-of-terms/",
      "sections": [
        "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
        "Agile",
        "Sprint (or scrum)",
        "Jira and GitHub issues",
        "Teams and squads",
        "For more help"
      ],
      "published_at": "2021-10-17T11:51:46Z",
      "title": "Agile vs sprints (vs Jira vs GitHub): A profusion of terms",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "7f3f97222daf52cf14afcf8fc432b96b3cebd4b1",
      "document_type": "page",
      "popularity": 1,
      "body": "Our team uses an agile Sprint workflow in Jira and GitHub to manage our work. We've further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let's break them down further. Agile People use agile to mean everything from a specific system of work (which we call sprints), to just \"moving fast, preferably in a way that lets me bend things to my whims.\" Luckily, we don't need to define it from scratch. Wikipedia does an admirable job defining it: Agile software development is an approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, empirical knowledge, and continual improvement, and it encourages rapid and flexible response to change. For our team, that means our process is optimized to ship early and often. This lets us respond swiftly to changes in the product roadmap. More importantly, it ensures we validate our solutions with stakeholders, and that we're not letting valuable work sit around and get moldy when it could be out in the world making our users' lives better. Sprint (or scrum) This is the particular flavor of agile we follow. The sprint system (often referred to as scrum) is one major approach to Agile, along with other Agile systems such as Kanban. Sprint systems are often accompanied by a lot of jargon and best practices, but for our team the most essential elements are: Working in strict timeboxes (two weeks in our case) Planning that sprint in advance, and not changing the scope of the sprint (much) once it starts Expecting all team members to contribute to making the sprint a success The video Agile Product Ownership in a Nutshell (18 minutes) is an excellent resource for learning about sprint methodology. The Kindle book Scrum: a Breathtakingly Brief and Agile Introduction is also a great read that you can get through in a short afternoon. For more on the \"why\" of Sprint as our chosen methodology, see Key agile principles. And for more on the \"how,\" see Sprint workflow. Jira and GitHub issues Jira and GitHub issues are the tools we use to manage our Agile workflow. If you remember one thing about them, it should be this: using Jira or GitHub issues is not the same as having an agile workflow. They're powerful tools for tracking work and managing a backlog, but the most important part of project management is the structure we impose on that tool. Jira is for sprint work. Sprints are where roadmap docs get written, monthly commits get delivered, and deeper research percolates. We have a backlog, board, and future sprint list in Jira that help us track what people want, what's coming up, and what we're working on now. For more on the mechanics of how we use Jira, see Sprint workflow and Jira boards and Ticket best practices. We use GitHub projects for hero work, customer-reported issues, and managing the flow of PRs and edits. The Docs PRs and Issues board contains everything we're actively working on in GitHub. We'll often connect work in GitHub back to Jira by putting a Jira issue key in the PR or issue title (DOC-1234, for example). For more on the mechanics of how we use GitHub, see Managing the GitHub boards. Teams and squads Our team is the Tech Docs team. We're collectively responsible for docs.newrelic.com and sundry writing content. Our team is further divided into two agile squads (The Odd Squad and The Amp Squad), one squad for each manager. The primary function of squads is to simplify sprint planning, backlog grooming, and liaisonships. Less people means shorter meetings. It also means better information sharing: The more people you have in a group, the more lines of communication are needed (see illustration) to maintain a shared understanding. Small squads can collaborate more easily than a large team, because not everyone needs to keep in mind everything that goes on everywhere. Each squad is responsible for its own grooming and sprint planning, but the managers and scrum masters coordinate grooming to ensure we're meeting our overall goals as a team. Key agile principles â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1550.0688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Agile vs <em>sprints</em> (vs Jira vs GitHub): A profusion of terms",
        "sections": "Agile vs <em>sprints</em> (vs Jira vs GitHub): A profusion of terms",
        "body": "Our team uses an agile <em>Sprint</em> <em>workflow</em> in Jira and GitHub to manage our work. We&#x27;ve further divided our team into squads to simplify planning and improve accountability. All those words are pretty inconsistent in their usage, so let&#x27;s break them down further. Agile People use agile to mean"
      },
      "id": "616c0d96196a677e623c7bd2"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/planning-poker/",
      "sections": [
        "Planning poker and points budgets",
        "Poker card definitions",
        "How we calculate the points budget",
        "Tip",
        "For more help"
      ],
      "published_at": "2021-10-17T12:48:37Z",
      "title": "Planning poker and points budgets",
      "updated_at": "2021-10-17T11:51:09Z",
      "type": "docs",
      "external_id": "d002b0635204648ebe36dbdc6c242e80fa971aa3",
      "document_type": "page",
      "popularity": 1,
      "body": "Planning poker is a consensus-based estimating and planning technique. To start a planning poker session, the story reporter or liaison presents a story to the team. Then, the team all votes (at the same time, to prevent groupthink) on how difficult they think the story is. Most agile teams that estimate with planning poker use cards that follow a Fibonacci sequence. We've found over the years that those large jumps weren't very helpful to us in estimating, and that we estimated better with smaller numbers. So we use fairly small, granular numbers that roughly break down to 1 point â‰ˆ 1 day. Note that even though each of the possible scores have approximate time values associated with them, we vote in points, not time. Scoring with points prevents getting into weedsy debates about exactly how long something will take, and instead focuses us on the requirements and difficulty of the story. Poker card definitions These how we define our poker cards: Card Value Â¼ An hour or two. Anything smaller than this isn't worth bringing into a sprint or even ticketingâ€”just do it right now. Â½ About half of an \"ideal\" day. We define an \"ideal\" day as one without meetings or interruptions. Using \"ideal\" days makes it easier to estimate a story without litigating the details of how we spend our time. 1 About one \"ideal\" day. This is one of our most common story sizes. 1Â½ About one and a half \"ideal\" days. This is our other most common story size. 2 About two \"ideal\" days. 3 About three \"ideal\" days. We jump from 2 straight to 3 to avoid unrealistic granularity in our estimates. 5 About a week of work. 7 About a full sprint (two weeks) of work. We very rarely use this cardâ€”a ticket that takes a full sprint on its own is almost always too large and should be chunked into smaller, incremental tickets. Break! \"I need a break.\" When someone plays a break card, we finish estimating the current story then immediately take a five minute break. Defer No strong opinion. Don't play this card on the first round of poker! Seeing wildly different estimates is a sign we don't have a shared understanding of the work. Playing an early Defer card can mask that uncertainty. How we calculate the points budget In order to ensure we're not filling up our sprint with more \"ideal days\" of time than we realistically have available, we calculate the points budget based on the actual output of the team. Over time, we've found writers average 0.6 (technically, 0.57) points per day. Tip This value is totally unique to each team! A high number doesn't indicate a more productive team, and a low number isn't a problem. Story points are only meaningful within a team. If you're starting a new team or new process, you'll need to zero in on the ideal number of points per writer. An easy way to figure out the right budget is to have the team vote in retro on whether to increase, decrease, or keep the same budget next sprint. You'll overshoot or undershoot a few times, but after a couple sprints you'll get a good sense of what constistutes a sustainable pace. Once you know your baseline, calculating the budget is straightforward: Take the number of writers, and multiply by the number of days in the sprint. To make the math easy, let's say 5 writers and a 10 business day (2 calendar week) sprint. Or, 50 person-days total. Subtract out time off days, plus 1 day for each day of hero duty. Let's say we have 1 writer on vacation in Maui, and 1 day of hero time per day. 50 person days, minus 10 days of vacation and 10 days of hero time, gives us 30 person-days. Multiply the number of days times the average velocity per writer, per day. Our average velocity is 0.6 points/writer/day. 30 person days multiplied by 0.6 would give us an 18 point budget for the sprint. Because we work in two squads, we calculate a separate points budget for each squad ahead of sprint planning. â† Meetings and ceremonies Sprint workflow and Jira boards â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 986.2459,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " and ceremonies <em>Sprint</em> <em>workflow</em> and Jira boards â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0e2d28ccbc6e5e00337f"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/agile-handbook/sprint-mechanics/liaisonships/",
      "sections": [
        "Liaisonships",
        "Liaison responsibilities: Manage project flow",
        "Liaison responsibilities: Build expertise",
        "Liaison responsibilities: Define content strategy (oh, and do the writing)",
        "For more help"
      ],
      "published_at": "2021-10-17T12:53:21Z",
      "title": "Liaisonships",
      "updated_at": "2021-10-17T11:48:38Z",
      "type": "docs",
      "external_id": "bf8ec36541058fe18f8395db811344baf7f23e22",
      "document_type": "page",
      "popularity": 1,
      "body": "For large projects, we'll typically assign a particular tech writer to that project as a \"liaison.\" The liaisonâ€™s job is to ensure that we get complete, consistent, and timely docs. Not every project gets a liaisonship! For smaller projects, we'll encourage teams to edit the docs directly, and then have the hero review their changes. And a smallish project may not need a full liaisonâ€”a single ticket might be enough to manage the work. To figure out which type of support is best for a given project, one of the managers on the team will have a scoping conversation with a subject matter expert. Here's a few reasons a project might get a dedicated liaison: Project is complex and would benefit from intimate familiarity with the feature. Project requires significant information architecture work. Project will produce enough docs that consistency across those docs will be hard to achieve without a centralized editor. Project SMEs would benefit from a consistent \"face\" of the tech writing team. However, a liaison is not the only author on a project. Liaisons should structure their work to maximize swarming and knowledge sharing. Liaison responsibilities: Manage project flow Activity Who? Notes Learn new thing exists Team Ideally the Hero or a Tech Docs manager gets notified directly by a PM about a new project. But sometimes we'll find out about something unexpectedly. If you're not sure whether we have a writer working on something, ask a manager on the team and they'll reach out to the subject matter expert to scope it. Have a scoping meeting Tech Docs manager The manager is responsible for tracking the general state of major projects across the company, and is generally the first point of contact for new projects. When a large new project comes up, the manager will do a pre-scope meeting with the requestor. (Appendix: Project scoping cheatsheet has a list of common questions for this pre-scope meeting.) That conversation helps figure out timeline, complexity, key docs considerations, and which writer will be a good fit as liaison. Assign a liaison Tech Docs manager Once we know we need a liaison, a manager on our team will figure out who to assign. Some of the factors we use to decide who to assign include bandwidth, familiarity with the product or feature, career goals and writing strengths, and simple interest in the topic. Keep track of project dates Liaison The managers on the team keep track of upcoming projects that don't have a liaison assigned. Once a writer gets involved, that liaison keeps track of the specifics of dates: Betas, limited releases, GAs, fast-follows, and so on. Your manager's always here to help out if you're getting blocked or dates are shifting too rapidly to plan properly. Validate the docs plan with the project team Liaison The liaison works with their stakeholders to define the information architecture and deliverables. Create tickets Liaison Since the liaison defines the information architecture, the liaison will know what kinds of deliverables we need. The liaison also acts as an advocate for their tickets in the backlog grooming and sprint planning processes, and ensures their stories meet the story quality requirements. The liaison should also ensure that our partner teams have appropriate tickets in their backlogs for their work. Remove blockers (such as reviewer delay) Liaison + Manager While the liaison is primarily responsible for handling SME relationships and removing day-to-day blockers, your manager is here to help unstick things anytime you need help. Wrap up the liaisonship Liaison Liaisonships are not forever assignments! When the bulk of your work on a project is complete, it might be time to consider ending the liaisonship. Reach out to your manager to talk about it. When you end it, let stakeholders know and update the liaison roster. Also let your stakeholders know they can always ping the docs hero for help or if they have a new project. Liaison responsibilities: Build expertise Activity Who? Notes Develop a deep expertise on feature and audience. Liaison Become the Docs Team's local expert on the feature. Understand what it does, what problems it solves, and the implications for our content. Educate the team on the feature Liaison Part of your responsibility as liaison is to share expertise around the team. That helps with swarming, but it also makes for better hero review and a smarter team that can write more intelligently about the entire New Relic One platform. Coordinate with design and/or research and test your docs Liaison Reach out to the designer and/or researcher for the project, and periodically sync on any shared concerns, user needs, etc. And you should advocate for user testing and validation of your content. Liaison responsibilities: Define content strategy (oh, and do the writing) Activity Who? Notes Define the information architecture Liaison As liaison, you're the expert on both the feature the product team is building, and the docs content (new and existing) that will support that feature. Build an IA that will meet all project needs and scale to the future. Write content Team The liaison writes much of the content for their project, especially the conceptual content like intro docs. But the whole team is expected to swarm and contribute to large projects, with the liaison coordinating that work. Peer edit drafts Liaison When we swarm and have someone else contribute to the project, the liaison peer edits their drafts to ensure consistency with the overall vision. Coordinate publication Liaison When the time comes to release (whether that's beta, GA, limited release, or EoL), it's the liaison's job to coordinate with PM, Eng, and Product Marketing to ensure docs go out on time with other deliverables. â† Sprint workflow and Jira boards What is a hero? â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 741.573,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ", and Product Marketing to ensure docs go out on time with other deliverables. â† <em>Sprint</em> <em>workflow</em> and Jira boards What is a hero? â†’ For more help We welcome thoughts or questions on our handbook! The easiest way to get in touch is to file a GitHub issue."
      },
      "id": "616c0d97e7b9d227264780c5"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/change-applied-intelligence-correlation-logic-decisions": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-12T12:45:38Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporiaâ€™s monitors to New Relicâ€™s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporiaâ€™s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. Youâ€™ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporiaâ€™s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that youâ€™ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once youâ€™ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporiaâ€™s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip Thereâ€™s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.22389,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started <em>with</em> Incident <em>Intelligence</em>",
        "sections": "Get started <em>with</em> Incident <em>Intelligence</em>",
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": "As part of <em>Applied</em> <em>Intelligence</em>, Incident <em>Intelligence</em> helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident <em>Intelligence</em> Before setting up Incident <em>Intelligence</em>, note"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "image": "https://docs.newrelic.com/static/82d53ad1a17b876fc5a92f51e5c01a54/ae694/whats_up_accelerated_decisions.png",
      "url": "https://docs.newrelic.com/whats-new/2020/10/applied-intelligence-now-features-accelerated-suggested-decisions/",
      "sections": [
        "Applied Intelligence now features accelerated suggested decisions"
      ],
      "published_at": "2021-10-13T02:13:52Z",
      "title": "Applied Intelligence now features accelerated suggested decisions",
      "updated_at": "2021-03-11T00:20:00Z",
      "type": "docs",
      "external_id": "3366f3f7d7258c27c856967f1a8d2a90c00f2342",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "Incident Intelligence continuously analyzes alerts and incident data to find patterns in event sequences and offers suggested correlation decisions that merge incidents to reduce alert noise further. Suggested decisions use machine learning to tailor correlations based on your data. Usually, we can create suggestions after a few weeks of use and data ingestion. However, if youâ€™re an existing New Relic user, we can now leverage your historical New Relic Alerts data to bring you tailored suggested decision logic in a matter of days. You wonâ€™t need to perform any additional configurationâ€”choose the alert policies you want to feed in for correlation as usual, and weâ€™ll take care of the rest. The more policies you add, and the more data we have access to, the better suggestions youâ€™ll receive. Be sure to set up your New Relic alerts source to take advantage of this new capability.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.93219,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Applied</em> <em>Intelligence</em> now features accelerated suggested <em>decisions</em>",
        "sections": "<em>Applied</em> <em>Intelligence</em> now features accelerated suggested <em>decisions</em>",
        "body": "Incident <em>Intelligence</em> continuously analyzes alerts and incident data to find patterns in event sequences and offers suggested <em>correlation</em> <em>decisions</em> that merge incidents to reduce alert noise further. Suggested <em>decisions</em> use machine learning to tailor correlations based on your data. Usually, we can"
      },
      "id": "60446abe196a672c4c960f90"
    },
    {
      "sections": [
        "Custom variables for Incident Workflows",
        "BETA FEATURE",
        "Use custom variables in a filter statement",
        "Workflow data enrichment examples",
        "Query for when application traffic drops",
        "Query for transaction failures",
        "Query for Kubernetes consumption overview",
        "Full variables list by category"
      ],
      "title": "Custom variables for Incident Workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "48f9db1f21750574985a1563c6b2dad8f4dcb2ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows/",
      "published_at": "2021-10-12T12:46:27Z",
      "updated_at": "2021-09-14T20:01:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With Incident Workflows, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the workflow, and violation attributes are transferred into the notification creation. Custom variables are violation-related properties you can use as part of the configuration of a workflow action. You can retrieve Information about the alert, condition, violation, and entity by using double curly brackets:: {{variable_name}}. Use custom variables in a filter statement To get information about the entity that violated a condition, you can use custom variables as part of the where statement of the query. For example, to get the state of the EC2 instance use: SELECT latest(ec2State) FROM ComputeSample where provider = 'Ec2Instance' where entityName = `{{entity.name}}' Copy This query returns a single value (for example, stopped), as the query only uses a single field. The variable entity.name is the identifier of the entity. You can use any other entity properties in the same way. Workflow data enrichment examples You can use custom variables to enrich your workflow data queries in different ways: Query for when application traffic drops There are times when you want to know when traffic to your application drops. You can use the { { entity.name}} variable in place of your application's name. SELECT count(*) FROM Transaction WHERE appName = '{{entity.name}}' since 10 minutes ago Copy Query for transaction failures There are times when you want to know when your application transactions have failed. This query shows the latest HTTP status code responses filtered by the { { entity.name}} variable that violated your alert policy threshold. From Transaction select latest(httpResponseCode), average(duration) where appName = '{{entity.name}}' Copy Query for Kubernetes consumption overview Use a query like this to get the number of entities and their ingest times within a Kubernetes pod. By identifying what entities have large ingest times, you can begin to address that issue and find a potential remedy. SELECT uniqueCount(displayName), sum(nr.ingestTimeMs) from K8sServiceSample where entityName = '{{entity.name}}' since 1 hour ago. Copy Full variables list by category We'll be updating this table frequently as we make updates to Applied Intelligence. Key Name Display Name alert/account_id alert.account_id Alert Account ID internal alert. * ALL alert/description alert.description Alert Description alert/label_names alert.labels Alert Labels alert/deep_link alert.link Alert Link alert/message alert.message Alert Message alert/policy_name alert.name Alert Name alert/policy_id alert.id Alert Policy ID alert/priority alert.priority Alert Priority alert/state alert.state Alert State internal * ALL internal aws. * ALL internal condition. * ALL newrelic/violation/condition_name condition.name Condition Name newrelic/product condition.product Condition Product newrelic/evaluation/threshold condition.threshold Condition Threshold newrelic/evaluation/threshold_duration_seconds condition.threshold_duration Condition Threshold Duration newrelic/evaluation/threshold_occurrences condition.threshold_occurrences Condition Threshold Occurrences internal entity. * (queries both entity.name and entity.type) ALL newrelic/entity/name entity.name Entity Name newrelic/entity/type entity.type Entity Type newrelic/violation/close_time violation.close_time Violation Close Time internal violation. * ALL newrelic/signal/nrql/query condition.nrql.query Signal NRQL Query newrelic/violation/deep_link_url violation.deep_link_url Violation Deep Link URL newrelic/violation/degradation_time violation.degradation_time Violation Degradation Time newrelic/violation/event violation.event Violation Event Status host/id violation.host.id Violation Host ID host/name violation.host.name Violation Host Name newrelic/violation/id violation.id Violation ID newrelic/violation/muted violation.muted Violation Muted newrelic/violation/open_time violation.open_time Violation Open Time newrelic/violation/priority violation.priority Violation Priority newrelic/violation/recovery_time violation.recovery_time Violation Recovery Time newrelic/violation/runbook_url violation.runbook_url Violation Runbook URL newrelic/violation/time_limit violation.time_limit Violation Time Limit newrelic/violation/title violation.title Violation Title internal workflow.id Workflow Id internal workflow.name Workflow Name",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.11113,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Query for when <em>application</em> traffic drops",
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": " a potential remedy. SELECT uniqueCount(displayName), sum(nr.ingestTimeMs) from K8sServiceSample where entityName = &#x27;{{entity.name}}&#x27; since 1 hour ago. Copy Full variables list by category We&#x27;ll be updating this table frequently as we make updates to <em>Applied</em> <em>Intelligence</em>. Key Name Display Name alert&#x2F;account_id"
      },
      "id": "603e7a6528ccbcad47eba77f"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-12T12:45:38Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporiaâ€™s monitors to New Relicâ€™s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporiaâ€™s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. Youâ€™ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporiaâ€™s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that youâ€™ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once youâ€™ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporiaâ€™s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip Thereâ€™s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 290.93338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-10-12T12:46:27Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, youâ€™ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If youâ€™re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If youâ€™re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not usersâ€™ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, youâ€™ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.87468,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If youâ€™re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click â€œAdd Incoming WebHooks Integrationâ€ Copy the WebHook URL In the next screen, click â€œSave settingsâ€ at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{â€œidâ€: â€œpathway idâ€, â€œnameâ€: â€œpathway nameâ€}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: â€œseverityâ€: {{ priority | int }} Copy If clause to check if an attributeâ€™s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.84538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence": [
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-10-12T12:46:27Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, youâ€™ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If youâ€™re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If youâ€™re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not usersâ€™ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, youâ€™ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.87468,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If youâ€™re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click â€œAdd Incoming WebHooks Integrationâ€ Copy the WebHook URL In the next screen, click â€œSave settingsâ€ at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{â€œidâ€: â€œpathway idâ€, â€œnameâ€: â€œpathway nameâ€}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: â€œseverityâ€: {{ priority | int }} Copy If clause to check if an attributeâ€™s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.84538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    },
    {
      "sections": [
        "EU/US datacenters and Incident Intelligence"
      ],
      "title": "EU/US datacenters and Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "7ff5005d6728922c357974438d731b8432cd3ffb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence/",
      "published_at": "2021-10-12T13:19:26Z",
      "updated_at": "2021-04-21T13:32:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Incident Intelligence service is performed solely in the United States. By using New Relic Incident Intelligence, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic's US region data center or in our EU region data center. If you elect to use the Suggested Responder feature and manage EU-based individuals, you may need to confirm that an appropriate data processing agreement is in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.5946,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "sections": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "New Relic&#x27;s <em>Incident</em> <em>Intelligence</em> service is performed solely in the United States. By using New Relic <em>Incident</em> <em>Intelligence</em>, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic&#x27;s US region data center"
      },
      "id": "60802950196a67858464a7cb"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-12T12:45:38Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporiaâ€™s monitors to New Relicâ€™s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporiaâ€™s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. Youâ€™ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporiaâ€™s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that youâ€™ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once youâ€™ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporiaâ€™s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip Thereâ€™s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 290.93335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-10-12T12:46:27Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, youâ€™ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If youâ€™re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If youâ€™re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not usersâ€™ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, youâ€™ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.87468,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If youâ€™re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "EU/US datacenters and Incident Intelligence"
      ],
      "title": "EU/US datacenters and Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "7ff5005d6728922c357974438d731b8432cd3ffb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence/",
      "published_at": "2021-10-12T13:19:26Z",
      "updated_at": "2021-04-21T13:32:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Incident Intelligence service is performed solely in the United States. By using New Relic Incident Intelligence, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic's US region data center or in our EU region data center. If you elect to use the Suggested Responder feature and manage EU-based individuals, you may need to confirm that an appropriate data processing agreement is in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.5946,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "sections": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "New Relic&#x27;s <em>Incident</em> <em>Intelligence</em> service is performed solely in the United States. By using New Relic <em>Incident</em> <em>Intelligence</em>, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic&#x27;s US region data center"
      },
      "id": "60802950196a67858464a7cb"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/rest-api-applied-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-12T12:45:38Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporiaâ€™s monitors to New Relicâ€™s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporiaâ€™s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. Youâ€™ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporiaâ€™s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that youâ€™ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once youâ€™ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporiaâ€™s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip Thereâ€™s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 290.9333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-10-12T12:46:27Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, youâ€™ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If youâ€™re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If youâ€™re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not usersâ€™ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, youâ€™ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.87466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If youâ€™re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click â€œAdd Incoming WebHooks Integrationâ€ Copy the WebHook URL In the next screen, click â€œSave settingsâ€ at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{â€œidâ€: â€œpathway idâ€, â€œnameâ€: â€œpathway nameâ€}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: â€œseverityâ€: {{ priority | int }} Copy If clause to check if an attributeâ€™s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.84538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-12T12:45:38Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporiaâ€™s monitors to New Relicâ€™s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporiaâ€™s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. Youâ€™ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporiaâ€™s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that youâ€™ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once youâ€™ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporiaâ€™s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip Thereâ€™s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 290.9333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-10-12T12:56:55Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click â€œAdd Incoming WebHooks Integrationâ€ Copy the WebHook URL In the next screen, click â€œSave settingsâ€ at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{â€œidâ€: â€œpathway idâ€, â€œnameâ€: â€œpathway nameâ€}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: â€œseverityâ€: {{ priority | int }} Copy If clause to check if an attributeâ€™s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.84538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    },
    {
      "sections": [
        "EU/US datacenters and Incident Intelligence"
      ],
      "title": "EU/US datacenters and Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "7ff5005d6728922c357974438d731b8432cd3ffb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence/",
      "published_at": "2021-10-12T13:19:26Z",
      "updated_at": "2021-04-21T13:32:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Incident Intelligence service is performed solely in the United States. By using New Relic Incident Intelligence, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic's US region data center or in our EU region data center. If you elect to use the Suggested Responder feature and manage EU-based individuals, you may need to confirm that an appropriate data processing agreement is in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.5946,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "sections": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "New Relic&#x27;s <em>Incident</em> <em>Intelligence</em> service is performed solely in the United States. By using New Relic <em>Incident</em> <em>Intelligence</em>, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic&#x27;s US region data center"
      },
      "id": "60802950196a67858464a7cb"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows": [
    {
      "sections": [
        "Incident workflows",
        "BETA FEATURE",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-10-12T12:46:27Z",
      "updated_at": "2021-09-14T11:14:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click â€œupdate messageâ€ once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variableâ€™s value/s. In order to use the enrichersâ€™ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = â€˜errorâ€™ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be â€˜basic authentication or a â€˜bearer tokenâ€™ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click â€˜test connectionâ€™ on the bottom right. Thereâ€™s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW â€˜api_key_credentialsâ€™ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a â€˜connection successfulâ€™ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.02515,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>workflows</em>",
        "sections": "<em>Incident</em> <em>workflows</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " The <em>Workflows</em> feature is located under the <em>Alerts</em> &amp; AI menu. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI, in the left navigation under Enrich and Respond click <em>Workflow</em>, then click Add a <em>workflow</em>. Tip The maximum <em>workflows</em> you can add per environment is 1000 Name your <em>workflow</em>. This field is mandatory and needs"
      },
      "id": "603e967664441f7e6f4e889b"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-12T12:45:38Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporiaâ€™s monitors to New Relicâ€™s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporiaâ€™s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. Youâ€™ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporiaâ€™s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that youâ€™ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once youâ€™ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporiaâ€™s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip Thereâ€™s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.81631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.97433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> conditions. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows": [
    {
      "sections": [
        "Custom variables for Incident Workflows",
        "BETA FEATURE",
        "Use custom variables in a filter statement",
        "Workflow data enrichment examples",
        "Query for when application traffic drops",
        "Query for transaction failures",
        "Query for Kubernetes consumption overview",
        "Full variables list by category"
      ],
      "title": "Custom variables for Incident Workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "48f9db1f21750574985a1563c6b2dad8f4dcb2ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows/",
      "published_at": "2021-10-12T12:46:27Z",
      "updated_at": "2021-09-14T20:01:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With Incident Workflows, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the workflow, and violation attributes are transferred into the notification creation. Custom variables are violation-related properties you can use as part of the configuration of a workflow action. You can retrieve Information about the alert, condition, violation, and entity by using double curly brackets:: {{variable_name}}. Use custom variables in a filter statement To get information about the entity that violated a condition, you can use custom variables as part of the where statement of the query. For example, to get the state of the EC2 instance use: SELECT latest(ec2State) FROM ComputeSample where provider = 'Ec2Instance' where entityName = `{{entity.name}}' Copy This query returns a single value (for example, stopped), as the query only uses a single field. The variable entity.name is the identifier of the entity. You can use any other entity properties in the same way. Workflow data enrichment examples You can use custom variables to enrich your workflow data queries in different ways: Query for when application traffic drops There are times when you want to know when traffic to your application drops. You can use the { { entity.name}} variable in place of your application's name. SELECT count(*) FROM Transaction WHERE appName = '{{entity.name}}' since 10 minutes ago Copy Query for transaction failures There are times when you want to know when your application transactions have failed. This query shows the latest HTTP status code responses filtered by the { { entity.name}} variable that violated your alert policy threshold. From Transaction select latest(httpResponseCode), average(duration) where appName = '{{entity.name}}' Copy Query for Kubernetes consumption overview Use a query like this to get the number of entities and their ingest times within a Kubernetes pod. By identifying what entities have large ingest times, you can begin to address that issue and find a potential remedy. SELECT uniqueCount(displayName), sum(nr.ingestTimeMs) from K8sServiceSample where entityName = '{{entity.name}}' since 1 hour ago. Copy Full variables list by category We'll be updating this table frequently as we make updates to Applied Intelligence. Key Name Display Name alert/account_id alert.account_id Alert Account ID internal alert. * ALL alert/description alert.description Alert Description alert/label_names alert.labels Alert Labels alert/deep_link alert.link Alert Link alert/message alert.message Alert Message alert/policy_name alert.name Alert Name alert/policy_id alert.id Alert Policy ID alert/priority alert.priority Alert Priority alert/state alert.state Alert State internal * ALL internal aws. * ALL internal condition. * ALL newrelic/violation/condition_name condition.name Condition Name newrelic/product condition.product Condition Product newrelic/evaluation/threshold condition.threshold Condition Threshold newrelic/evaluation/threshold_duration_seconds condition.threshold_duration Condition Threshold Duration newrelic/evaluation/threshold_occurrences condition.threshold_occurrences Condition Threshold Occurrences internal entity. * (queries both entity.name and entity.type) ALL newrelic/entity/name entity.name Entity Name newrelic/entity/type entity.type Entity Type newrelic/violation/close_time violation.close_time Violation Close Time internal violation. * ALL newrelic/signal/nrql/query condition.nrql.query Signal NRQL Query newrelic/violation/deep_link_url violation.deep_link_url Violation Deep Link URL newrelic/violation/degradation_time violation.degradation_time Violation Degradation Time newrelic/violation/event violation.event Violation Event Status host/id violation.host.id Violation Host ID host/name violation.host.name Violation Host Name newrelic/violation/id violation.id Violation ID newrelic/violation/muted violation.muted Violation Muted newrelic/violation/open_time violation.open_time Violation Open Time newrelic/violation/priority violation.priority Violation Priority newrelic/violation/recovery_time violation.recovery_time Violation Recovery Time newrelic/violation/runbook_url violation.runbook_url Violation Runbook URL newrelic/violation/time_limit violation.time_limit Violation Time Limit newrelic/violation/title violation.title Violation Title internal workflow.id Workflow Id internal workflow.name Workflow Name",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.56686,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Custom variables for <em>Incident</em> <em>Workflows</em>",
        "sections": "Custom variables for <em>Incident</em> <em>Workflows</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "BETA FEATURE This feature is currently in beta. With <em>Incident</em> <em>Workflows</em>, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the <em>workflow</em>, and violation attributes are transferred into the notification creation. Custom variables are violation"
      },
      "id": "603e7a6528ccbcad47eba77f"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-12T12:45:38Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporiaâ€™s monitors to New Relicâ€™s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporiaâ€™s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. Youâ€™ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporiaâ€™s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that youâ€™ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once youâ€™ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporiaâ€™s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip Thereâ€™s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.81631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.97433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> conditions. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/expanded-anomaly-detection": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-12T11:59:06Z",
      "updated_at": "2021-09-14T07:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps youâ€™re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the Applied Intelligence application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. Itâ€™s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this appâ€™s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomalyâ€™s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make wonâ€™t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Lauraâ€™s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321â€ Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 295.7284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Proactive</em> <em>Detection</em> with <em>Applied</em> <em>Intelligence</em>",
        "sections": "<em>Proactive</em> <em>Detection</em> with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " cost. When an anomaly is detected, you can view it in the <em>Applied</em> <em>Intelligence</em> anomalies feed, or we&#x27;ll send notifications directly to your Slack channel or a webhook. How it works <em>Proactive</em> <em>Detection</em> uses the following methods to <em>detect</em> anomalies in your app data: <em>Proactive</em> <em>Detection</em> monitors metric"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-12T12:45:38Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporiaâ€™s monitors to New Relicâ€™s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporiaâ€™s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. Youâ€™ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporiaâ€™s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that youâ€™ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once youâ€™ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporiaâ€™s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip Thereâ€™s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.38788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with Incident <em>Intelligence</em>",
        "sections": "Get started with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic <em>Proactive</em> <em>Detection</em> anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under Incident <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Introduction to Applied Intelligence",
        "Why use Applied Intelligence?",
        "Determine root causes with Incident Intelligence",
        "Find unknowns with Proactive Detection"
      ],
      "title": "Introduction to Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "68af5032ebe9c91467f78169bb5d30976d7f67ee",
      "image": "https://docs.newrelic.com/static/c95c61f5a259d33c01781273aed8311d/30c92/diagram-applied-intelligence-workflow.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/",
      "published_at": "2021-10-12T23:29:57Z",
      "updated_at": "2021-09-14T07:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Applied Intelligence (AI) is our AIOps solution for DevOps, site reliability engineers, and on-call teams. At its core, Applied Intelligence helps you find, troubleshoot, and resolve problems more quickly. Specifically, itâ€™s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. By applying machine learning to your data and feedback, Applied Intelligence is designed to improve functionality and deliver smarter context over time. After connecting your data sources to Applied Intelligence, it looks for potential problems and improves based on your feedback. Why use Applied Intelligence? How you respond to an incident can mean thousands of dollars or clicks for your company. Applied Intelligence helps you solve problems faster. Feature Description Troubleshoot and respond to incidents Our solution helps you understand your incidents and gives you ideas for what to do next. Here are a few examples: Automatically classifies incidents based on the golden signals of site reliability engineering. Identifies entities in your stack that may relate to the underlying issue. Suggests responses for incidents based on historical context. Less noise, more focus As tools and systems become more complex, alert noise can overwhelm DevOps and SRE teams. Applied Intelligence correlates related incidents and suppresses noise, so you're only notified when human action is required. Incidents with a hybrid approach Applied Intelligence streamlines your incidents by combining its built-in inputs with your knowledge and feedback. Over time, the system delivers more accurate insights. For example: Our correlation and classification engine adjusts based on your feedback. The system automatically suggests new correlation rules based on your production data. You can create custom logic using the decision builder. Automatic anomaly detection Applied Intelligence provides automatic anomaly detection on all your APM-monitored applications. We detect anomalies in throughput, latency, and error rate, with no action required from you. Benefits include: No setup required. See anomalies surfaced automatically in the anomalies feed. See them in various New Relic activity streams (for example, on the New Relic One home page). Ability to run NRQL queries of anomalies and create custom dashboards with that data. Determine root causes with Incident Intelligence As part of Applied Intelligence, Incident Intelligence helps you correlate incident events and reduce noise in your environment. With it, you can get an overview of all your issues, see suggested responders, and configure your own correlation logic. To get started, see Incident Intelligence. Find unknowns with Proactive Detection Another feature of Applied Intelligence is Proactive Detection. Proactive Detection is, by default, always on and detecting anomalies. These anomalies are surfaced in the Applied Intelligence anomalies feed, New Relic One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and/or added as a source for Incident Intelligence correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and alerts via the analysis page. To get started, see Proactive Detection.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.43588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "sections": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " on your production data. You can create custom logic using the decision builder. Automatic anomaly <em>detection</em> <em>Applied</em> <em>Intelligence</em> provides automatic anomaly <em>detection</em> on all your APM-monitored applications. We <em>detect</em> anomalies in throughput, latency, and error rate, with no action required from you"
      },
      "id": "603ea67c64441ffd1c4e8860"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence": [
    {
      "sections": [
        "Expanded anomaly detection",
        "Important",
        "Requirements",
        "Why it matters",
        "Get started with anomaly detection",
        "Detect anomalies with a faceted NRQL query",
        "See your anomalies in one place",
        "Tip",
        "Query anomaly data",
        "Reduce the number of detected anomalies"
      ],
      "title": "Expanded anomaly detection",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "0b07c0b6ce27f39b5edb3e112a0f949835cbb8c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/expanded-anomaly-detection/",
      "published_at": "2021-10-12T13:22:28Z",
      "updated_at": "2021-09-14T10:33:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This feature is a limited release. Weâ€™ve expanded anomaly detection coverage beyond your APM applications. Configure anomaly detection for your browser applications, mobile applications, infrastructure hosts, and nearly anything you want to monitor. Requirements Expanded anomaly detection is available as a limited beta. You can request access here. Why it matters When starting to configure alert conditions for a variety of applications and hosts, it can be difficult to know what youâ€™ll want to be notified about ahead of time. Anomaly detection helps you distinguish between whatâ€™s typical performance in your system and where youâ€™re starting to have trouble. Instead of creating your alert conditions manually, you can simply tell us what you want to monitor. Anomaly detection will help you identify baseline performance in your system and flags anomalous activity in your system. Get started with anomaly detection To get started with expanded anomaly detection: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab, and then click + Add a configuration. Select the account you want to use to record anomaly data, then select the workload or entities youâ€™d like to monitor. Select the detection sensitivity. We recommend Low sensitivity so that you donâ€™t see too many anomalies. Finally, name your configuration and save. Detect anomalies with a faceted NRQL query To detect anomalies with a faceted NRQL query: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab, and then click + Add a configuration. Click Use a query instead. You may need to select an account, if you have more than one. Add one or more queries with a FACET clause. Name the query and confirm the facets you want to monitor for anomalies. Select the detection sensitivity. We recommend Low sensitivity so that you donâ€™t see too many anomalies. Finally, name the configuration and save. See your anomalies in one place When you set up anomaly detection, New Relic starts analyzing the golden signals of your entities and workloads. Anomalies appear in your activity feeds throughout New Relic One and the Anomalies tab as soon as theyâ€™re detected. Click any anomaly to get more detail about it, including analysis and context for the anomaly. Tip For this limited release, anomaly detection wonâ€™t generate notifications. However, you can configure a NRQL alert condition for the NrAiAnomaly event. To view anomalies, from one.newrelic.com, go to Alerts & AI > Issues & activity > Anomalies. Query anomaly data Detected anomalies are written to the NrAiAnomaly event in your NRDB account. You can learn more about this event and how to query it here. Reduce the number of detected anomalies If youâ€™re seeing too many anomalies, the first step is to make sure your sensitivity level is set to Low. If itâ€™s already set to Low, you can define specific thresholds to distinguish between normal and anomalous behavior. To define custom thresholds: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab and the configuration you want to modify. Select an entity or workload, and then change the sensitivity level. You can use custom sensitivity to define specific thresholds for different entity types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 295.9354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Expanded anomaly <em>detection</em>",
        "sections": "Expanded anomaly <em>detection</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Get started with anomaly <em>detection</em> To get started with expanded anomaly <em>detection</em>: From one.newrelic.com, go to <em>Alerts</em> &amp; AI &gt; <em>Proactive</em> <em>Detection</em> &gt; Settings. Click the Custom tab, and then click + Add a configuration. Select the account you want to use to record anomaly data, then select the workload"
      },
      "id": "60b5124064441ff965e2cb01"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-12T12:45:38Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporiaâ€™s monitors to New Relicâ€™s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporiaâ€™s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. Youâ€™ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporiaâ€™s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that youâ€™ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once youâ€™ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporiaâ€™s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip Thereâ€™s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.38788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with Incident <em>Intelligence</em>",
        "sections": "Get started with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic <em>Proactive</em> <em>Detection</em> anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under Incident <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Introduction to Applied Intelligence",
        "Why use Applied Intelligence?",
        "Determine root causes with Incident Intelligence",
        "Find unknowns with Proactive Detection"
      ],
      "title": "Introduction to Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "68af5032ebe9c91467f78169bb5d30976d7f67ee",
      "image": "https://docs.newrelic.com/static/c95c61f5a259d33c01781273aed8311d/30c92/diagram-applied-intelligence-workflow.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/",
      "published_at": "2021-10-12T23:29:57Z",
      "updated_at": "2021-09-14T07:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Applied Intelligence (AI) is our AIOps solution for DevOps, site reliability engineers, and on-call teams. At its core, Applied Intelligence helps you find, troubleshoot, and resolve problems more quickly. Specifically, itâ€™s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. By applying machine learning to your data and feedback, Applied Intelligence is designed to improve functionality and deliver smarter context over time. After connecting your data sources to Applied Intelligence, it looks for potential problems and improves based on your feedback. Why use Applied Intelligence? How you respond to an incident can mean thousands of dollars or clicks for your company. Applied Intelligence helps you solve problems faster. Feature Description Troubleshoot and respond to incidents Our solution helps you understand your incidents and gives you ideas for what to do next. Here are a few examples: Automatically classifies incidents based on the golden signals of site reliability engineering. Identifies entities in your stack that may relate to the underlying issue. Suggests responses for incidents based on historical context. Less noise, more focus As tools and systems become more complex, alert noise can overwhelm DevOps and SRE teams. Applied Intelligence correlates related incidents and suppresses noise, so you're only notified when human action is required. Incidents with a hybrid approach Applied Intelligence streamlines your incidents by combining its built-in inputs with your knowledge and feedback. Over time, the system delivers more accurate insights. For example: Our correlation and classification engine adjusts based on your feedback. The system automatically suggests new correlation rules based on your production data. You can create custom logic using the decision builder. Automatic anomaly detection Applied Intelligence provides automatic anomaly detection on all your APM-monitored applications. We detect anomalies in throughput, latency, and error rate, with no action required from you. Benefits include: No setup required. See anomalies surfaced automatically in the anomalies feed. See them in various New Relic activity streams (for example, on the New Relic One home page). Ability to run NRQL queries of anomalies and create custom dashboards with that data. Determine root causes with Incident Intelligence As part of Applied Intelligence, Incident Intelligence helps you correlate incident events and reduce noise in your environment. With it, you can get an overview of all your issues, see suggested responders, and configure your own correlation logic. To get started, see Incident Intelligence. Find unknowns with Proactive Detection Another feature of Applied Intelligence is Proactive Detection. Proactive Detection is, by default, always on and detecting anomalies. These anomalies are surfaced in the Applied Intelligence anomalies feed, New Relic One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and/or added as a source for Incident Intelligence correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and alerts via the analysis page. To get started, see Proactive Detection.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.43588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "sections": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " on your production data. You can create custom logic using the decision builder. Automatic anomaly <em>detection</em> <em>Applied</em> <em>Intelligence</em> provides automatic anomaly <em>detection</em> on all your APM-monitored applications. We <em>detect</em> anomalies in throughput, latency, and error rate, with no action required from you"
      },
      "id": "603ea67c64441ffd1c4e8860"
    }
  ],
  "/docs/alerts-applied-intelligence/index": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1430.4854,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> conditions. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-13T02:49:42Z",
      "updated_at": "2021-10-13T02:49:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) FROM Transaction WHERE appName='my-app-name'\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } } } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: { description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"} ) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1428.8472,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NerdGraph tutorial: NRQL condition <em>alerts</em>",
        "sections": "NerdGraph tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on <em>Alerts</em>NrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL <em>alert</em> condition. Get all the conditions for a policy: { actor { account(id"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "List notification channels with their associated policies",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-10-13T02:03:21Z",
      "updated_at": "2021-10-13T02:03:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy List notification channels with their associated policies This example returns the ID, name, and type for every notification channel on the supplied account ID, as well as a list of every policy that is associated with that channel. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type associatedPolicies { policies { id name } totalCount } } nextCursor totalCount } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the channel because it might be used by other policies. On the other hand, deleting a channel will cause all associated policies to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1427.0682,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ":&#x2F;&#x2F;company.instance.xmatters.com&#x2F;api&#x2F;xm&#x2F;v&lt;version&gt;&#x2F;...&quot;, name: &quot;xMatters notification channel name&quot; } }) { notificationChannel { ... on <em>Alerts</em>XMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an <em>alert</em> notification"
      },
      "id": "6130bf9c28ccbc027d56a863"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/alert-custom-violation-descriptions": [
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-12T21:53:32Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.25552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.68567,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "View entity health status and find entities without alert conditions",
        "Important",
        "Exceptions",
        "Color-coded health status",
        "Health status transitions",
        "Example: App without conditions",
        "Example: App with conditions",
        "Tip"
      ],
      "title": "View entity health status and find entities without alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "b2826e95805df46a371e48e17c2439cf566240e8",
      "image": "https://docs.newrelic.com/static/e9ca85d8e1b3cf5d1ab549e0a3955990/38cea/032715crop-events-no-v3_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions/",
      "published_at": "2021-10-13T02:02:28Z",
      "updated_at": "2021-10-13T02:02:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With alerts you can easily tell whether an entity (the target for the notification) has one or more conditions associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current alert violations, mouse over its health status indicator. If no, its health status indicator on the selected index will appear grey. Important To learn more about how conditions and policies work together, see Introduction to important concepts. Exceptions The health status indicator doesn't apply for: Infrastructure entities Dashboards Entities targeted by labels Color-coded health status The index automatically appears when you select the product from the New Relic menu bar. For example, to view the index of APM apps, go to one.newrelic.com, then click APM. The Applications index lists all APM product entities and their current health status. Color Health status Green The entity is operational. We are collecting data that you can view in the appropriate UI. No alert violations are currently reported for it. Yellow The entity is degraded. A warning threshold has been violated. Red A critical threshold has been violated: Notifications have been sent based on the selected incident rollup preference. The incident appears in the Incidents index. Gray The entity's status is unknown. We're not receiving alerts data for the entity. This could mean alerts are muted, not set up, or the reporting system is down. Health status transitions The following table describes the different health status transitions an entity can endure: From... To... Transition explanation Gray Green The entity is evaluated for at least one condition, and the results show there are no violations present. Green / Red Gray Possible explanations: The last condition associated to the entity has been deleted and therefore there's no status to report. The last condition associated to the entity has been disabled and therefore there's no status to report. The entity has stopped reporting data. There's a New Relic platform issue. Check the New Relic status page for updates. Green Yellow / Red There's at least one open violation at the time the entity is undergoing the evaluation. Yellow / Red Green The last open violation associated to the entity has been closed. Example: App without conditions Here's an example of an app listed on the APM index that is not associated with any conditions. Its color-coded health status is light grey, which indicates no alert conditions are set up for that entity. Go to one.newrelic.com, then click Explorer: This example shows an app that currently isn't associated with any alerts conditions. Its grey status icon means it doesn't have any conditions. Follow standard procedures to add it to an existing condition or to create a new condition for it. Example: App with conditions Here's an example of an app listed on the APM index that is associated with one or more conditions. Its color-coded health status is green, because we are collecting data for it, and currently there are no Warning (yellow) or Critical (red) violations. Go to one.newrelic.com, then click Explorer: This example shows an app that has one or more conditions. Its color-coded health status (green) shows the app hasn't reached any threshold violations. Tip To view the index listing currently open incidents across all products, not just this entity, select View all violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "sections": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>alerts</em> you can easily tell whether an entity (the target for the notification) has one or more <em>conditions</em> associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current <em>alert</em> violations"
      },
      "id": "6130c01e196a679fa84948f5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload": [
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "List notification channels with their associated policies",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-10-13T02:03:21Z",
      "updated_at": "2021-10-13T02:03:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy List notification channels with their associated policies This example returns the ID, name, and type for every notification channel on the supplied account ID, as well as a list of every policy that is associated with that channel. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type associatedPolicies { policies { id name } totalCount } } nextCursor totalCount } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the channel because it might be used by other policies. On the other hand, deleting a channel will cause all associated policies to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.4054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NerdGraph tutorial: <em>Notification</em> channels",
        "sections": "NerdGraph tutorial: <em>Notification</em> channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " has been created, it can be associated with one or more <em>alert</em> policies. Once associated, those channels will receive <em>notifications</em> from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them"
      },
      "id": "6130bf9c28ccbc027d56a863"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.51755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-13T02:49:42Z",
      "updated_at": "2021-10-13T02:49:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) FROM Transaction WHERE appName='my-app-name'\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } } } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: { description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"} ) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.3051,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NerdGraph tutorial: NRQL condition <em>alerts</em>",
        "sections": "NerdGraph tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on <em>Alerts</em>NrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL <em>alert</em> condition. Get all the conditions for a policy: { actor { account(id"
      },
      "id": "6130bf6528ccbcb0d856a821"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/define-custom-metrics-alert-condition": [
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-12T21:53:32Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.2554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.68555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "View entity health status and find entities without alert conditions",
        "Important",
        "Exceptions",
        "Color-coded health status",
        "Health status transitions",
        "Example: App without conditions",
        "Example: App with conditions",
        "Tip"
      ],
      "title": "View entity health status and find entities without alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "b2826e95805df46a371e48e17c2439cf566240e8",
      "image": "https://docs.newrelic.com/static/e9ca85d8e1b3cf5d1ab549e0a3955990/38cea/032715crop-events-no-v3_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions/",
      "published_at": "2021-10-13T02:02:28Z",
      "updated_at": "2021-10-13T02:02:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With alerts you can easily tell whether an entity (the target for the notification) has one or more conditions associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current alert violations, mouse over its health status indicator. If no, its health status indicator on the selected index will appear grey. Important To learn more about how conditions and policies work together, see Introduction to important concepts. Exceptions The health status indicator doesn't apply for: Infrastructure entities Dashboards Entities targeted by labels Color-coded health status The index automatically appears when you select the product from the New Relic menu bar. For example, to view the index of APM apps, go to one.newrelic.com, then click APM. The Applications index lists all APM product entities and their current health status. Color Health status Green The entity is operational. We are collecting data that you can view in the appropriate UI. No alert violations are currently reported for it. Yellow The entity is degraded. A warning threshold has been violated. Red A critical threshold has been violated: Notifications have been sent based on the selected incident rollup preference. The incident appears in the Incidents index. Gray The entity's status is unknown. We're not receiving alerts data for the entity. This could mean alerts are muted, not set up, or the reporting system is down. Health status transitions The following table describes the different health status transitions an entity can endure: From... To... Transition explanation Gray Green The entity is evaluated for at least one condition, and the results show there are no violations present. Green / Red Gray Possible explanations: The last condition associated to the entity has been deleted and therefore there's no status to report. The last condition associated to the entity has been disabled and therefore there's no status to report. The entity has stopped reporting data. There's a New Relic platform issue. Check the New Relic status page for updates. Green Yellow / Red There's at least one open violation at the time the entity is undergoing the evaluation. Yellow / Red Green The last open violation associated to the entity has been closed. Example: App without conditions Here's an example of an app listed on the APM index that is not associated with any conditions. Its color-coded health status is light grey, which indicates no alert conditions are set up for that entity. Go to one.newrelic.com, then click Explorer: This example shows an app that currently isn't associated with any alerts conditions. Its grey status icon means it doesn't have any conditions. Follow standard procedures to add it to an existing condition or to create a new condition for it. Example: App with conditions Here's an example of an app listed on the APM index that is associated with one or more conditions. Its color-coded health status is green, because we are collecting data for it, and currently there are no Warning (yellow) or Critical (red) violations. Go to one.newrelic.com, then click Explorer: This example shows an app that has one or more conditions. Its color-coded health status (green) shows the app hasn't reached any threshold violations. Tip To view the index listing currently open incidents across all products, not just this entity, select View all violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.06387,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "sections": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>alerts</em> you can easily tell whether an entity (the target for the notification) has one or more <em>conditions</em> associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current <em>alert</em> violations"
      },
      "id": "6130c01e196a679fa84948f5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/monitor-scheduled-jobs": [
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-12T21:53:32Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.25528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.68542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "View entity health status and find entities without alert conditions",
        "Important",
        "Exceptions",
        "Color-coded health status",
        "Health status transitions",
        "Example: App without conditions",
        "Example: App with conditions",
        "Tip"
      ],
      "title": "View entity health status and find entities without alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "b2826e95805df46a371e48e17c2439cf566240e8",
      "image": "https://docs.newrelic.com/static/e9ca85d8e1b3cf5d1ab549e0a3955990/38cea/032715crop-events-no-v3_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions/",
      "published_at": "2021-10-13T02:02:28Z",
      "updated_at": "2021-10-13T02:02:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With alerts you can easily tell whether an entity (the target for the notification) has one or more conditions associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current alert violations, mouse over its health status indicator. If no, its health status indicator on the selected index will appear grey. Important To learn more about how conditions and policies work together, see Introduction to important concepts. Exceptions The health status indicator doesn't apply for: Infrastructure entities Dashboards Entities targeted by labels Color-coded health status The index automatically appears when you select the product from the New Relic menu bar. For example, to view the index of APM apps, go to one.newrelic.com, then click APM. The Applications index lists all APM product entities and their current health status. Color Health status Green The entity is operational. We are collecting data that you can view in the appropriate UI. No alert violations are currently reported for it. Yellow The entity is degraded. A warning threshold has been violated. Red A critical threshold has been violated: Notifications have been sent based on the selected incident rollup preference. The incident appears in the Incidents index. Gray The entity's status is unknown. We're not receiving alerts data for the entity. This could mean alerts are muted, not set up, or the reporting system is down. Health status transitions The following table describes the different health status transitions an entity can endure: From... To... Transition explanation Gray Green The entity is evaluated for at least one condition, and the results show there are no violations present. Green / Red Gray Possible explanations: The last condition associated to the entity has been deleted and therefore there's no status to report. The last condition associated to the entity has been disabled and therefore there's no status to report. The entity has stopped reporting data. There's a New Relic platform issue. Check the New Relic status page for updates. Green Yellow / Red There's at least one open violation at the time the entity is undergoing the evaluation. Yellow / Red Green The last open violation associated to the entity has been closed. Example: App without conditions Here's an example of an app listed on the APM index that is not associated with any conditions. Its color-coded health status is light grey, which indicates no alert conditions are set up for that entity. Go to one.newrelic.com, then click Explorer: This example shows an app that currently isn't associated with any alerts conditions. Its grey status icon means it doesn't have any conditions. Follow standard procedures to add it to an existing condition or to create a new condition for it. Example: App with conditions Here's an example of an app listed on the APM index that is associated with one or more conditions. Its color-coded health status is green, because we are collecting data for it, and currently there are no Warning (yellow) or Critical (red) violations. Go to one.newrelic.com, then click Explorer: This example shows an app that has one or more conditions. Its color-coded health status (green) shows the app hasn't reached any threshold violations. Tip To view the index listing currently open incidents across all products, not just this entity, select View all violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.06378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "sections": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>alerts</em> you can easily tell whether an entity (the target for the notification) has one or more <em>conditions</em> associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current <em>alert</em> violations"
      },
      "id": "6130c01e196a679fa84948f5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/multi-location-synthetic-monitoring-alert-conditions": [
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-12T21:53:32Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.25516,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.6853,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "View entity health status and find entities without alert conditions",
        "Important",
        "Exceptions",
        "Color-coded health status",
        "Health status transitions",
        "Example: App without conditions",
        "Example: App with conditions",
        "Tip"
      ],
      "title": "View entity health status and find entities without alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "b2826e95805df46a371e48e17c2439cf566240e8",
      "image": "https://docs.newrelic.com/static/e9ca85d8e1b3cf5d1ab549e0a3955990/38cea/032715crop-events-no-v3_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions/",
      "published_at": "2021-10-13T02:02:28Z",
      "updated_at": "2021-10-13T02:02:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With alerts you can easily tell whether an entity (the target for the notification) has one or more conditions associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current alert violations, mouse over its health status indicator. If no, its health status indicator on the selected index will appear grey. Important To learn more about how conditions and policies work together, see Introduction to important concepts. Exceptions The health status indicator doesn't apply for: Infrastructure entities Dashboards Entities targeted by labels Color-coded health status The index automatically appears when you select the product from the New Relic menu bar. For example, to view the index of APM apps, go to one.newrelic.com, then click APM. The Applications index lists all APM product entities and their current health status. Color Health status Green The entity is operational. We are collecting data that you can view in the appropriate UI. No alert violations are currently reported for it. Yellow The entity is degraded. A warning threshold has been violated. Red A critical threshold has been violated: Notifications have been sent based on the selected incident rollup preference. The incident appears in the Incidents index. Gray The entity's status is unknown. We're not receiving alerts data for the entity. This could mean alerts are muted, not set up, or the reporting system is down. Health status transitions The following table describes the different health status transitions an entity can endure: From... To... Transition explanation Gray Green The entity is evaluated for at least one condition, and the results show there are no violations present. Green / Red Gray Possible explanations: The last condition associated to the entity has been deleted and therefore there's no status to report. The last condition associated to the entity has been disabled and therefore there's no status to report. The entity has stopped reporting data. There's a New Relic platform issue. Check the New Relic status page for updates. Green Yellow / Red There's at least one open violation at the time the entity is undergoing the evaluation. Yellow / Red Green The last open violation associated to the entity has been closed. Example: App without conditions Here's an example of an app listed on the APM index that is not associated with any conditions. Its color-coded health status is light grey, which indicates no alert conditions are set up for that entity. Go to one.newrelic.com, then click Explorer: This example shows an app that currently isn't associated with any alerts conditions. Its grey status icon means it doesn't have any conditions. Follow standard procedures to add it to an existing condition or to create a new condition for it. Example: App with conditions Here's an example of an app listed on the APM index that is associated with one or more conditions. Its color-coded health status is green, because we are collecting data for it, and currently there are no Warning (yellow) or Critical (red) violations. Go to one.newrelic.com, then click Explorer: This example shows an app that has one or more conditions. Its color-coded health status (green) shows the app hasn't reached any threshold violations. Tip To view the index listing currently open incidents across all products, not just this entity, select View all violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.06366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "sections": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>alerts</em> you can easily tell whether an entity (the target for the notification) has one or more <em>conditions</em> associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current <em>alert</em> violations"
      },
      "id": "6130c01e196a679fa84948f5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/outlier-detection-nrql-alert": [
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-12T21:53:32Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.25516,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.6853,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "View entity health status and find entities without alert conditions",
        "Important",
        "Exceptions",
        "Color-coded health status",
        "Health status transitions",
        "Example: App without conditions",
        "Example: App with conditions",
        "Tip"
      ],
      "title": "View entity health status and find entities without alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "b2826e95805df46a371e48e17c2439cf566240e8",
      "image": "https://docs.newrelic.com/static/e9ca85d8e1b3cf5d1ab549e0a3955990/38cea/032715crop-events-no-v3_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions/",
      "published_at": "2021-10-13T02:02:28Z",
      "updated_at": "2021-10-13T02:02:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With alerts you can easily tell whether an entity (the target for the notification) has one or more conditions associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current alert violations, mouse over its health status indicator. If no, its health status indicator on the selected index will appear grey. Important To learn more about how conditions and policies work together, see Introduction to important concepts. Exceptions The health status indicator doesn't apply for: Infrastructure entities Dashboards Entities targeted by labels Color-coded health status The index automatically appears when you select the product from the New Relic menu bar. For example, to view the index of APM apps, go to one.newrelic.com, then click APM. The Applications index lists all APM product entities and their current health status. Color Health status Green The entity is operational. We are collecting data that you can view in the appropriate UI. No alert violations are currently reported for it. Yellow The entity is degraded. A warning threshold has been violated. Red A critical threshold has been violated: Notifications have been sent based on the selected incident rollup preference. The incident appears in the Incidents index. Gray The entity's status is unknown. We're not receiving alerts data for the entity. This could mean alerts are muted, not set up, or the reporting system is down. Health status transitions The following table describes the different health status transitions an entity can endure: From... To... Transition explanation Gray Green The entity is evaluated for at least one condition, and the results show there are no violations present. Green / Red Gray Possible explanations: The last condition associated to the entity has been deleted and therefore there's no status to report. The last condition associated to the entity has been disabled and therefore there's no status to report. The entity has stopped reporting data. There's a New Relic platform issue. Check the New Relic status page for updates. Green Yellow / Red There's at least one open violation at the time the entity is undergoing the evaluation. Yellow / Red Green The last open violation associated to the entity has been closed. Example: App without conditions Here's an example of an app listed on the APM index that is not associated with any conditions. Its color-coded health status is light grey, which indicates no alert conditions are set up for that entity. Go to one.newrelic.com, then click Explorer: This example shows an app that currently isn't associated with any alerts conditions. Its grey status icon means it doesn't have any conditions. Follow standard procedures to add it to an existing condition or to create a new condition for it. Example: App with conditions Here's an example of an app listed on the APM index that is associated with one or more conditions. Its color-coded health status is green, because we are collecting data for it, and currently there are no Warning (yellow) or Critical (red) violations. Go to one.newrelic.com, then click Explorer: This example shows an app that has one or more conditions. Its color-coded health status (green) shows the app hasn't reached any threshold violations. Tip To view the index listing currently open incidents across all products, not just this entity, select View all violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.06366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "sections": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>alerts</em> you can easily tell whether an entity (the target for the notification) has one or more <em>conditions</em> associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current <em>alert</em> violations"
      },
      "id": "6130c01e196a679fa84948f5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/scope-alert-thresholds-specific-instances": [
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-12T21:53:32Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.25507,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.68518,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "View entity health status and find entities without alert conditions",
        "Important",
        "Exceptions",
        "Color-coded health status",
        "Health status transitions",
        "Example: App without conditions",
        "Example: App with conditions",
        "Tip"
      ],
      "title": "View entity health status and find entities without alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "b2826e95805df46a371e48e17c2439cf566240e8",
      "image": "https://docs.newrelic.com/static/e9ca85d8e1b3cf5d1ab549e0a3955990/38cea/032715crop-events-no-v3_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions/",
      "published_at": "2021-10-13T02:02:28Z",
      "updated_at": "2021-10-13T02:02:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With alerts you can easily tell whether an entity (the target for the notification) has one or more conditions associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current alert violations, mouse over its health status indicator. If no, its health status indicator on the selected index will appear grey. Important To learn more about how conditions and policies work together, see Introduction to important concepts. Exceptions The health status indicator doesn't apply for: Infrastructure entities Dashboards Entities targeted by labels Color-coded health status The index automatically appears when you select the product from the New Relic menu bar. For example, to view the index of APM apps, go to one.newrelic.com, then click APM. The Applications index lists all APM product entities and their current health status. Color Health status Green The entity is operational. We are collecting data that you can view in the appropriate UI. No alert violations are currently reported for it. Yellow The entity is degraded. A warning threshold has been violated. Red A critical threshold has been violated: Notifications have been sent based on the selected incident rollup preference. The incident appears in the Incidents index. Gray The entity's status is unknown. We're not receiving alerts data for the entity. This could mean alerts are muted, not set up, or the reporting system is down. Health status transitions The following table describes the different health status transitions an entity can endure: From... To... Transition explanation Gray Green The entity is evaluated for at least one condition, and the results show there are no violations present. Green / Red Gray Possible explanations: The last condition associated to the entity has been deleted and therefore there's no status to report. The last condition associated to the entity has been disabled and therefore there's no status to report. The entity has stopped reporting data. There's a New Relic platform issue. Check the New Relic status page for updates. Green Yellow / Red There's at least one open violation at the time the entity is undergoing the evaluation. Yellow / Red Green The last open violation associated to the entity has been closed. Example: App without conditions Here's an example of an app listed on the APM index that is not associated with any conditions. Its color-coded health status is light grey, which indicates no alert conditions are set up for that entity. Go to one.newrelic.com, then click Explorer: This example shows an app that currently isn't associated with any alerts conditions. Its grey status icon means it doesn't have any conditions. Follow standard procedures to add it to an existing condition or to create a new condition for it. Example: App with conditions Here's an example of an app listed on the APM index that is associated with one or more conditions. Its color-coded health status is green, because we are collecting data for it, and currently there are no Warning (yellow) or Critical (red) violations. Go to one.newrelic.com, then click Explorer: This example shows an app that has one or more conditions. Its color-coded health status (green) shows the app hasn't reached any threshold violations. Tip To view the index listing currently open incidents across all products, not just this entity, select View all violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.06354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "sections": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>alerts</em> you can easily tell whether an entity (the target for the notification) has one or more <em>conditions</em> associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current <em>alert</em> violations"
      },
      "id": "6130c01e196a679fa84948f5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/select-product-targets-alert-condition": [
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-12T21:53:32Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.25507,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.68518,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "View entity health status and find entities without alert conditions",
        "Important",
        "Exceptions",
        "Color-coded health status",
        "Health status transitions",
        "Example: App without conditions",
        "Example: App with conditions",
        "Tip"
      ],
      "title": "View entity health status and find entities without alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "b2826e95805df46a371e48e17c2439cf566240e8",
      "image": "https://docs.newrelic.com/static/e9ca85d8e1b3cf5d1ab549e0a3955990/38cea/032715crop-events-no-v3_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions/",
      "published_at": "2021-10-13T02:02:28Z",
      "updated_at": "2021-10-13T02:02:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With alerts you can easily tell whether an entity (the target for the notification) has one or more conditions associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current alert violations, mouse over its health status indicator. If no, its health status indicator on the selected index will appear grey. Important To learn more about how conditions and policies work together, see Introduction to important concepts. Exceptions The health status indicator doesn't apply for: Infrastructure entities Dashboards Entities targeted by labels Color-coded health status The index automatically appears when you select the product from the New Relic menu bar. For example, to view the index of APM apps, go to one.newrelic.com, then click APM. The Applications index lists all APM product entities and their current health status. Color Health status Green The entity is operational. We are collecting data that you can view in the appropriate UI. No alert violations are currently reported for it. Yellow The entity is degraded. A warning threshold has been violated. Red A critical threshold has been violated: Notifications have been sent based on the selected incident rollup preference. The incident appears in the Incidents index. Gray The entity's status is unknown. We're not receiving alerts data for the entity. This could mean alerts are muted, not set up, or the reporting system is down. Health status transitions The following table describes the different health status transitions an entity can endure: From... To... Transition explanation Gray Green The entity is evaluated for at least one condition, and the results show there are no violations present. Green / Red Gray Possible explanations: The last condition associated to the entity has been deleted and therefore there's no status to report. The last condition associated to the entity has been disabled and therefore there's no status to report. The entity has stopped reporting data. There's a New Relic platform issue. Check the New Relic status page for updates. Green Yellow / Red There's at least one open violation at the time the entity is undergoing the evaluation. Yellow / Red Green The last open violation associated to the entity has been closed. Example: App without conditions Here's an example of an app listed on the APM index that is not associated with any conditions. Its color-coded health status is light grey, which indicates no alert conditions are set up for that entity. Go to one.newrelic.com, then click Explorer: This example shows an app that currently isn't associated with any alerts conditions. Its grey status icon means it doesn't have any conditions. Follow standard procedures to add it to an existing condition or to create a new condition for it. Example: App with conditions Here's an example of an app listed on the APM index that is associated with one or more conditions. Its color-coded health status is green, because we are collecting data for it, and currently there are no Warning (yellow) or Critical (red) violations. Go to one.newrelic.com, then click Explorer: This example shows an app that has one or more conditions. Its color-coded health status (green) shows the app hasn't reached any threshold violations. Tip To view the index listing currently open incidents across all products, not just this entity, select View all violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.06354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "sections": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>alerts</em> you can easily tell whether an entity (the target for the notification) has one or more <em>conditions</em> associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current <em>alert</em> violations"
      },
      "id": "6130c01e196a679fa84948f5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition": [
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-12T21:53:32Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.25494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.68506,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "View entity health status and find entities without alert conditions",
        "Important",
        "Exceptions",
        "Color-coded health status",
        "Health status transitions",
        "Example: App without conditions",
        "Example: App with conditions",
        "Tip"
      ],
      "title": "View entity health status and find entities without alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "b2826e95805df46a371e48e17c2439cf566240e8",
      "image": "https://docs.newrelic.com/static/e9ca85d8e1b3cf5d1ab549e0a3955990/38cea/032715crop-events-no-v3_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions/",
      "published_at": "2021-10-13T02:02:28Z",
      "updated_at": "2021-10-13T02:02:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With alerts you can easily tell whether an entity (the target for the notification) has one or more conditions associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current alert violations, mouse over its health status indicator. If no, its health status indicator on the selected index will appear grey. Important To learn more about how conditions and policies work together, see Introduction to important concepts. Exceptions The health status indicator doesn't apply for: Infrastructure entities Dashboards Entities targeted by labels Color-coded health status The index automatically appears when you select the product from the New Relic menu bar. For example, to view the index of APM apps, go to one.newrelic.com, then click APM. The Applications index lists all APM product entities and their current health status. Color Health status Green The entity is operational. We are collecting data that you can view in the appropriate UI. No alert violations are currently reported for it. Yellow The entity is degraded. A warning threshold has been violated. Red A critical threshold has been violated: Notifications have been sent based on the selected incident rollup preference. The incident appears in the Incidents index. Gray The entity's status is unknown. We're not receiving alerts data for the entity. This could mean alerts are muted, not set up, or the reporting system is down. Health status transitions The following table describes the different health status transitions an entity can endure: From... To... Transition explanation Gray Green The entity is evaluated for at least one condition, and the results show there are no violations present. Green / Red Gray Possible explanations: The last condition associated to the entity has been deleted and therefore there's no status to report. The last condition associated to the entity has been disabled and therefore there's no status to report. The entity has stopped reporting data. There's a New Relic platform issue. Check the New Relic status page for updates. Green Yellow / Red There's at least one open violation at the time the entity is undergoing the evaluation. Yellow / Red Green The last open violation associated to the entity has been closed. Example: App without conditions Here's an example of an app listed on the APM index that is not associated with any conditions. Its color-coded health status is light grey, which indicates no alert conditions are set up for that entity. Go to one.newrelic.com, then click Explorer: This example shows an app that currently isn't associated with any alerts conditions. Its grey status icon means it doesn't have any conditions. Follow standard procedures to add it to an existing condition or to create a new condition for it. Example: App with conditions Here's an example of an app listed on the APM index that is associated with one or more conditions. Its color-coded health status is green, because we are collecting data for it, and currently there are no Warning (yellow) or Critical (red) violations. Go to one.newrelic.com, then click Explorer: This example shows an app that has one or more conditions. Its color-coded health status (green) shows the app hasn't reached any threshold violations. Tip To view the index listing currently open incidents across all products, not just this entity, select View all violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.06342,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "sections": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>alerts</em> you can easily tell whether an entity (the target for the notification) has one or more <em>conditions</em> associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current <em>alert</em> violations"
      },
      "id": "6130c01e196a679fa84948f5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/view-events-their-products": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.75536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-13T02:49:42Z",
      "updated_at": "2021-10-13T02:49:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) FROM Transaction WHERE appName='my-app-name'\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } } } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: { description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"} ) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.5495,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NerdGraph tutorial: NRQL condition <em>alerts</em>",
        "sections": "NerdGraph tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on <em>Alerts</em>NrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL <em>alert</em> condition. Get all the conditions for a policy: { actor { account(id"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "List notification channels with their associated policies",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-10-13T02:03:21Z",
      "updated_at": "2021-10-13T02:03:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy List notification channels with their associated policies This example returns the ID, name, and type for every notification channel on the supplied account ID, as well as a list of every policy that is associated with that channel. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type associatedPolicies { policies { id name } totalCount } } nextCursor totalCount } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the channel because it might be used by other policies. On the other hand, deleting a channel will cause all associated policies to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.32596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " { <em>alerts</em>NotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: &quot;https:&#x2F;&#x2F;example.com&#x2F;webhook&quot;, basicAuth: { password: &quot;t0t4lly-s3cr3t-p455w0rd&quot;, username: &quot;webhook-user&quot; }, customHttpHeaders: [ {name: &quot;X-Api-Key&quot;, value: &quot;100%-real-api-key&quot;}, {name: &quot;X-Calling-Service&quot;, value: &quot;<em>New</em>"
      },
      "id": "6130bf9c28ccbc027d56a863"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-alerts-policies": [
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-13T02:49:42Z",
      "updated_at": "2021-10-13T02:49:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) FROM Transaction WHERE appName='my-app-name'\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } } } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: { description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"} ) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.5807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "sections": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage <em>alerts</em> conditions using our GraphQL <em>NerdGraph</em> API. Here are some conditions queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. This document covers the following: Steps"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "List notification channels with their associated policies",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-10-13T02:03:21Z",
      "updated_at": "2021-10-13T02:03:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy List notification channels with their associated policies This example returns the ID, name, and type for every notification channel on the supplied account ID, as well as a list of every policy that is associated with that channel. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type associatedPolicies { policies { id name } totalCount } } nextCursor totalCount } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the channel because it might be used by other policies. On the other hand, deleting a channel will cause all associated policies to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.23132,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Notification channels",
        "sections": "<em>NerdGraph</em> tutorial: Notification channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your <em>alert</em> notification channels using our GraphQL <em>NerdGraph</em> API. Here are some queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. Get notification channels"
      },
      "id": "6130bf9c28ccbc027d56a863"
    },
    {
      "sections": [
        "NerdGraph tutorial: Loss of signal and gap filling",
        "Tip",
        "Customize your loss of signal detection",
        "View loss of signal settings for an existing condition",
        "Create a new condition with loss of signal settings",
        "Update the loss of signal settings of a condition",
        "Customize gap filling",
        "Important"
      ],
      "title": "NerdGraph tutorial: Loss of signal and gap filling",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "2389c7a91a09c2175c1f13c3cad5962389571b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling/",
      "published_at": "2021-10-13T01:26:27Z",
      "updated_at": "2021-10-13T01:26:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. Gap filling can help you solve issues caused by lost data points. When gaps are detected between valid data points, we automatically fill those gaps with replacement values, such as the last known values or a static value. Gap filling can prevent alerts from triggering or resolving when they shouldn't. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. You can customize loss of signal detection and gap filling using NerdGraph. For example, you can configure how long to wait before considering the signal lost, or what value should be used for filling gaps in the time series. Here are some queries and examples you can use in our NerdGraph API explorer. In this guide we cover the following: Customize loss of signal detection Customize gap filling Customize your loss of signal detection Loss of signal detection opens or closes violations if no data is received after a certain amount of time. For example, if you set the duration of the expiration period to 60 seconds and an integration doesn't seem to send data for more than a minute, a loss of signal violation would be triggered. You can configure the duration of the signal loss and whether to open a violation or close it by using these three fields in NerdGraph: expiration.expirationDuration: How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives at our platform and not on data timestamps. The default is to leave this null, and therefore this wouldn't enable Loss of Signal Detection. expiration.openViolationOnExpiration: If true, a new violation is opened when a signal is lost. Default is false. To use this field, a duration must be specified. expiration.closeViolationsOnExpiration: If true, open violations related to the signal are closed on expiration. Default is false. To use this field, a duration must be specified. View loss of signal settings for an existing condition Existing NRQL conditions may have their loss of signal settings already configured. To view the existing condition settings, select the fields under nrqlCondition > expiration: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: NRQL_CONDITION_ID) { ... on AlertsNrqlStaticCondition { id name nrql { query } expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } } } } } Copy You should see a result like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlCondition\": { \"expiration\": { \" closeViolationsOnExpiration \": false, \" expirationDuration \": 300, \" openViolationOnExpiration \": true }, \"id\": \"YOUR_ACCOUNT_ID\", \"name\": \"Any less than - Extrapolation\", \"nrql\": { \"query\": \"SELECT average(value) FROM AlertsSmokeTestSignals WHERE wave_type IN ('min-max', 'single-gap') FACET wave_type\" } } } } } }, ... Copy Create a new condition with loss of signal settings Let's say that you want to create a new create a NRQL static condition that triggers a loss of signal violation after no data is received for two minutes. You would set expirationDuration to 120 seconds and set openViolationOnExpiration to true, like in the example below. mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: [{ threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL }] valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 expiration : { expirationDuration : 120 openViolationOnExpiration : true } } ) { id name } } Copy Update the loss of signal settings of a condition What if you want to update loss of signal parameters for an alert condition? The following mutation allows you to update a NRQL static condition with new expiration values. mutation { alertsNrqlConditionStaticUpdate( accountId: YOUR_ACCOUNT_ID id: YOUR_STATIC_CONDITION_ID condition: { expiration: { closeViolationsOnExpiration : BOOLEAN expirationDuration : DURATION_IN_SECONDS openViolationOnExpiration : BOOLEAN } } ) { id expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } Copy Customize gap filling Gap filling replaces gap values in a time series with either the last value found or a static, arbitrary value of your choice. We fill gaps only after another data point has been received after the gaps in signal (after data reception has been restored). You can configure both the type of filling and the value, if the type is set to static: signal.fillOption: Type of replacement value for lost data points. Values can be: NONE: Gap filling is disabled. LAST_VALUE: The last value seen in the time series. STATIC: An arbitrary value, defined in fillValue. signal.fillValue: Value to use for replacing lost data points when fillOption is set to STATIC. Important Gap filling is also affected by expiration.expirationDuration. When a gap is longer than the expiration duration, the signal is considered expired and the gap will no longer be filled. For example, here's how to create a static NRQL condition with gap filling configured: mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { enabled: true name: \"Example Gap Filling Condition\" nrql: { query: \"select count(*) from Transaction\" } terms: { operator: ABOVE priority: CRITICAL threshold: 1000 thresholdDuration: 300 thresholdOccurrences: ALL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 28800 signal: { aggregationWindow: 60, aggregationMethod: EVENT_FLOW, aggregationDelay: 120, fillOption: STATIC, fillValue: 1 } } ) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 279.95453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "sections": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Loss of signal occurs when <em>New</em> <em>Relic</em> stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up <em>alerts</em>"
      },
      "id": "6130bf9c196a676b034948b3"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-examples": [
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-13T02:49:42Z",
      "updated_at": "2021-10-13T02:49:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) FROM Transaction WHERE appName='my-app-name'\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } } } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: { description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"} ) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.5807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "sections": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage <em>alerts</em> conditions using our GraphQL <em>NerdGraph</em> API. Here are some conditions queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. This document covers the following: Steps"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "List notification channels with their associated policies",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-10-13T02:03:21Z",
      "updated_at": "2021-10-13T02:03:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy List notification channels with their associated policies This example returns the ID, name, and type for every notification channel on the supplied account ID, as well as a list of every policy that is associated with that channel. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type associatedPolicies { policies { id name } totalCount } } nextCursor totalCount } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the channel because it might be used by other policies. On the other hand, deleting a channel will cause all associated policies to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.23132,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Notification channels",
        "sections": "<em>NerdGraph</em> tutorial: Notification channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your <em>alert</em> notification channels using our GraphQL <em>NerdGraph</em> API. Here are some queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. Get notification channels"
      },
      "id": "6130bf9c28ccbc027d56a863"
    },
    {
      "sections": [
        "NerdGraph tutorial: Alerts policies",
        "Tip",
        "List and filter policies",
        "Listing all policies for an account",
        "Paginating through policies with cursor pagination",
        "Find all policies by selected ids",
        "Find all policies by name",
        "Find policy by id",
        "Create a policy",
        "Update a policy",
        "Delete a policy"
      ],
      "title": "NerdGraph tutorial: Alerts policies",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "6b4553ffff3b55e91abb519963337eade57ae64b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-alerts-policies/",
      "published_at": "2021-10-13T02:02:28Z",
      "updated_at": "2021-10-13T02:02:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alerts policies using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. List and filter policies The policiesSearch query allows you to paginate through all of your policies per account. It also allows some filtering functionality on the account policies. Listing all policies for an account Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch { policies { id name incidentPreference } } } } } } Copy Paginating through policies with cursor pagination In order to paginate through your policies, you must request the nextCursor field on your initial query. With cursor pagination, you continue to make a request through the result set until the nextCursor that is returned from the response comes back empty. This signifies that you reached the end of your results. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch { nextCursor policies { id name incidentPreference } totalCount } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"policiesSearch\": { \"nextCursor\": \"/8o0y2qiR54m6thkdgHgwg==:jZTXDFKbTkhKwvMx+CtsPVM=\", \"policies\": [ { \"id\": \"3455\", \"incidentPreference\": \"PER_POLICY\", \"name\": \"First Policy Name\" }, { \"id\": \"2123\", \"incidentPreference\": \"PER_POLICY\", \"name\": \"Another Policy\" }, // ... more policies here in reality ], \"totalCount\": 745 } } } } } } Copy So, in your subsequent request, provide the cursor like so, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch(cursor: \"/8o0y2qiR54m6thkdgHgwg==:jZTXDFKbTkhKwvMx+CtsPVM=\") { nextCursor policies { id name incidentPreference } totalCount } } } } } Copy Find all policies by selected ids The API allows policy queries by a sub-select of ids. This will only return the information for these policies that you provide. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch(searchCriteria: { ids: [A_POLICY_ID, ANOTHER_POLICY_ID] }) { policies { id name incidentPreference } } } } } } Copy Find all policies by name The API allows policy queries by name. Use name for matching by exact names or nameLike for a partial match. Both search criteria are case insensitive. This will only return the information for the policies that match the name supplied. In this example, we want to find policies with \"DevOps\" in the name: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch(searchCriteria: { nameLike: \"DevOps\" }) { policies { id name } } } } } } Copy Find policy by id The API lets you query by policy id: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policy(id: YOUR_POLICY_ID) { id name incidentPreference } } } } } Copy Create a policy In order to create a policy, supply a name and an incidentPreference. The incident preference will configure how incidents get created for each condition created in the policy. For more information, refer to the documentation about choosing your incident preference. mutation { alertsPolicyCreate(accountId: YOUR_ACCOUNT_ID, policy: { name: \"Your Policy Name\" incidentPreference: PER_CONDITION }) { id name incidentPreference } } Copy Update a policy When you update a policy, note that you don't need to supply all of the attributes on the policy. For example, you only need to supply the name if you only intend to update the name: mutation { alertsPolicyUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_POLICY_ID, policy: { name: \"Updated Policy Name\" }) { id name incidentPreference } } Copy Delete a policy You can delete policies via the NerdGraph API. Note that only the id may be requested back from a deleted resource: mutation { alertsPolicyDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_POLICY_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.2247,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: <em>Alerts</em> policies",
        "sections": "<em>NerdGraph</em> tutorial: <em>Alerts</em> policies",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your <em>alerts</em> policies using our GraphQL <em>NerdGraph</em> API. Here are some queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. List and filter policies The policiesSearch query allows"
      },
      "id": "6130bf66196a6751e34948a9"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling": [
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-13T02:49:42Z",
      "updated_at": "2021-10-13T02:49:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) FROM Transaction WHERE appName='my-app-name'\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } } } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: { description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"} ) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.58057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "sections": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage <em>alerts</em> conditions using our GraphQL <em>NerdGraph</em> API. Here are some conditions queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. This document covers the following: Steps"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "List notification channels with their associated policies",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-10-13T02:03:21Z",
      "updated_at": "2021-10-13T02:03:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy List notification channels with their associated policies This example returns the ID, name, and type for every notification channel on the supplied account ID, as well as a list of every policy that is associated with that channel. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type associatedPolicies { policies { id name } totalCount } } nextCursor totalCount } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the channel because it might be used by other policies. On the other hand, deleting a channel will cause all associated policies to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.2312,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Notification channels",
        "sections": "<em>NerdGraph</em> tutorial: Notification channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your <em>alert</em> notification channels using our GraphQL <em>NerdGraph</em> API. Here are some queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. Get notification channels"
      },
      "id": "6130bf9c28ccbc027d56a863"
    },
    {
      "sections": [
        "NerdGraph tutorial: Alerts policies",
        "Tip",
        "List and filter policies",
        "Listing all policies for an account",
        "Paginating through policies with cursor pagination",
        "Find all policies by selected ids",
        "Find all policies by name",
        "Find policy by id",
        "Create a policy",
        "Update a policy",
        "Delete a policy"
      ],
      "title": "NerdGraph tutorial: Alerts policies",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "6b4553ffff3b55e91abb519963337eade57ae64b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-alerts-policies/",
      "published_at": "2021-10-13T02:02:28Z",
      "updated_at": "2021-10-13T02:02:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alerts policies using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. List and filter policies The policiesSearch query allows you to paginate through all of your policies per account. It also allows some filtering functionality on the account policies. Listing all policies for an account Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch { policies { id name incidentPreference } } } } } } Copy Paginating through policies with cursor pagination In order to paginate through your policies, you must request the nextCursor field on your initial query. With cursor pagination, you continue to make a request through the result set until the nextCursor that is returned from the response comes back empty. This signifies that you reached the end of your results. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch { nextCursor policies { id name incidentPreference } totalCount } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"policiesSearch\": { \"nextCursor\": \"/8o0y2qiR54m6thkdgHgwg==:jZTXDFKbTkhKwvMx+CtsPVM=\", \"policies\": [ { \"id\": \"3455\", \"incidentPreference\": \"PER_POLICY\", \"name\": \"First Policy Name\" }, { \"id\": \"2123\", \"incidentPreference\": \"PER_POLICY\", \"name\": \"Another Policy\" }, // ... more policies here in reality ], \"totalCount\": 745 } } } } } } Copy So, in your subsequent request, provide the cursor like so, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch(cursor: \"/8o0y2qiR54m6thkdgHgwg==:jZTXDFKbTkhKwvMx+CtsPVM=\") { nextCursor policies { id name incidentPreference } totalCount } } } } } Copy Find all policies by selected ids The API allows policy queries by a sub-select of ids. This will only return the information for these policies that you provide. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch(searchCriteria: { ids: [A_POLICY_ID, ANOTHER_POLICY_ID] }) { policies { id name incidentPreference } } } } } } Copy Find all policies by name The API allows policy queries by name. Use name for matching by exact names or nameLike for a partial match. Both search criteria are case insensitive. This will only return the information for the policies that match the name supplied. In this example, we want to find policies with \"DevOps\" in the name: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch(searchCriteria: { nameLike: \"DevOps\" }) { policies { id name } } } } } } Copy Find policy by id The API lets you query by policy id: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policy(id: YOUR_POLICY_ID) { id name incidentPreference } } } } } Copy Create a policy In order to create a policy, supply a name and an incidentPreference. The incident preference will configure how incidents get created for each condition created in the policy. For more information, refer to the documentation about choosing your incident preference. mutation { alertsPolicyCreate(accountId: YOUR_ACCOUNT_ID, policy: { name: \"Your Policy Name\" incidentPreference: PER_CONDITION }) { id name incidentPreference } } Copy Update a policy When you update a policy, note that you don't need to supply all of the attributes on the policy. For example, you only need to supply the name if you only intend to update the name: mutation { alertsPolicyUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_POLICY_ID, policy: { name: \"Updated Policy Name\" }) { id name incidentPreference } } Copy Delete a policy You can delete policies via the NerdGraph API. Note that only the id may be requested back from a deleted resource: mutation { alertsPolicyDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_POLICY_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.22458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: <em>Alerts</em> policies",
        "sections": "<em>NerdGraph</em> tutorial: <em>Alerts</em> policies",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your <em>alerts</em> policies using our GraphQL <em>NerdGraph</em> API. Here are some queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. List and filter policies The policiesSearch query allows"
      },
      "id": "6130bf66196a6751e34948a9"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels": [
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-13T02:49:42Z",
      "updated_at": "2021-10-13T02:49:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) FROM Transaction WHERE appName='my-app-name'\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } } } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: { description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"} ) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.58057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "sections": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage <em>alerts</em> conditions using our <em>Graph</em>QL <em>NerdGraph</em> API. Here are some conditions queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. This document covers the following: Steps"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "NerdGraph tutorial: Alerts policies",
        "Tip",
        "List and filter policies",
        "Listing all policies for an account",
        "Paginating through policies with cursor pagination",
        "Find all policies by selected ids",
        "Find all policies by name",
        "Find policy by id",
        "Create a policy",
        "Update a policy",
        "Delete a policy"
      ],
      "title": "NerdGraph tutorial: Alerts policies",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "6b4553ffff3b55e91abb519963337eade57ae64b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-alerts-policies/",
      "published_at": "2021-10-13T02:02:28Z",
      "updated_at": "2021-10-13T02:02:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alerts policies using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. List and filter policies The policiesSearch query allows you to paginate through all of your policies per account. It also allows some filtering functionality on the account policies. Listing all policies for an account Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch { policies { id name incidentPreference } } } } } } Copy Paginating through policies with cursor pagination In order to paginate through your policies, you must request the nextCursor field on your initial query. With cursor pagination, you continue to make a request through the result set until the nextCursor that is returned from the response comes back empty. This signifies that you reached the end of your results. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch { nextCursor policies { id name incidentPreference } totalCount } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"policiesSearch\": { \"nextCursor\": \"/8o0y2qiR54m6thkdgHgwg==:jZTXDFKbTkhKwvMx+CtsPVM=\", \"policies\": [ { \"id\": \"3455\", \"incidentPreference\": \"PER_POLICY\", \"name\": \"First Policy Name\" }, { \"id\": \"2123\", \"incidentPreference\": \"PER_POLICY\", \"name\": \"Another Policy\" }, // ... more policies here in reality ], \"totalCount\": 745 } } } } } } Copy So, in your subsequent request, provide the cursor like so, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch(cursor: \"/8o0y2qiR54m6thkdgHgwg==:jZTXDFKbTkhKwvMx+CtsPVM=\") { nextCursor policies { id name incidentPreference } totalCount } } } } } Copy Find all policies by selected ids The API allows policy queries by a sub-select of ids. This will only return the information for these policies that you provide. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch(searchCriteria: { ids: [A_POLICY_ID, ANOTHER_POLICY_ID] }) { policies { id name incidentPreference } } } } } } Copy Find all policies by name The API allows policy queries by name. Use name for matching by exact names or nameLike for a partial match. Both search criteria are case insensitive. This will only return the information for the policies that match the name supplied. In this example, we want to find policies with \"DevOps\" in the name: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch(searchCriteria: { nameLike: \"DevOps\" }) { policies { id name } } } } } } Copy Find policy by id The API lets you query by policy id: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policy(id: YOUR_POLICY_ID) { id name incidentPreference } } } } } Copy Create a policy In order to create a policy, supply a name and an incidentPreference. The incident preference will configure how incidents get created for each condition created in the policy. For more information, refer to the documentation about choosing your incident preference. mutation { alertsPolicyCreate(accountId: YOUR_ACCOUNT_ID, policy: { name: \"Your Policy Name\" incidentPreference: PER_CONDITION }) { id name incidentPreference } } Copy Update a policy When you update a policy, note that you don't need to supply all of the attributes on the policy. For example, you only need to supply the name if you only intend to update the name: mutation { alertsPolicyUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_POLICY_ID, policy: { name: \"Updated Policy Name\" }) { id name incidentPreference } } Copy Delete a policy You can delete policies via the NerdGraph API. Note that only the id may be requested back from a deleted resource: mutation { alertsPolicyDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_POLICY_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.22458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: <em>Alerts</em> policies",
        "sections": "<em>NerdGraph</em> tutorial: <em>Alerts</em> policies",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your <em>alerts</em> policies using our <em>Graph</em>QL <em>NerdGraph</em> API. Here are some queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. List and filter policies The policiesSearch query allows"
      },
      "id": "6130bf66196a6751e34948a9"
    },
    {
      "sections": [
        "NerdGraph tutorial: Loss of signal and gap filling",
        "Tip",
        "Customize your loss of signal detection",
        "View loss of signal settings for an existing condition",
        "Create a new condition with loss of signal settings",
        "Update the loss of signal settings of a condition",
        "Customize gap filling",
        "Important"
      ],
      "title": "NerdGraph tutorial: Loss of signal and gap filling",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "2389c7a91a09c2175c1f13c3cad5962389571b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling/",
      "published_at": "2021-10-13T01:26:27Z",
      "updated_at": "2021-10-13T01:26:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. Gap filling can help you solve issues caused by lost data points. When gaps are detected between valid data points, we automatically fill those gaps with replacement values, such as the last known values or a static value. Gap filling can prevent alerts from triggering or resolving when they shouldn't. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. You can customize loss of signal detection and gap filling using NerdGraph. For example, you can configure how long to wait before considering the signal lost, or what value should be used for filling gaps in the time series. Here are some queries and examples you can use in our NerdGraph API explorer. In this guide we cover the following: Customize loss of signal detection Customize gap filling Customize your loss of signal detection Loss of signal detection opens or closes violations if no data is received after a certain amount of time. For example, if you set the duration of the expiration period to 60 seconds and an integration doesn't seem to send data for more than a minute, a loss of signal violation would be triggered. You can configure the duration of the signal loss and whether to open a violation or close it by using these three fields in NerdGraph: expiration.expirationDuration: How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives at our platform and not on data timestamps. The default is to leave this null, and therefore this wouldn't enable Loss of Signal Detection. expiration.openViolationOnExpiration: If true, a new violation is opened when a signal is lost. Default is false. To use this field, a duration must be specified. expiration.closeViolationsOnExpiration: If true, open violations related to the signal are closed on expiration. Default is false. To use this field, a duration must be specified. View loss of signal settings for an existing condition Existing NRQL conditions may have their loss of signal settings already configured. To view the existing condition settings, select the fields under nrqlCondition > expiration: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: NRQL_CONDITION_ID) { ... on AlertsNrqlStaticCondition { id name nrql { query } expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } } } } } Copy You should see a result like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlCondition\": { \"expiration\": { \" closeViolationsOnExpiration \": false, \" expirationDuration \": 300, \" openViolationOnExpiration \": true }, \"id\": \"YOUR_ACCOUNT_ID\", \"name\": \"Any less than - Extrapolation\", \"nrql\": { \"query\": \"SELECT average(value) FROM AlertsSmokeTestSignals WHERE wave_type IN ('min-max', 'single-gap') FACET wave_type\" } } } } } }, ... Copy Create a new condition with loss of signal settings Let's say that you want to create a new create a NRQL static condition that triggers a loss of signal violation after no data is received for two minutes. You would set expirationDuration to 120 seconds and set openViolationOnExpiration to true, like in the example below. mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: [{ threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL }] valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 expiration : { expirationDuration : 120 openViolationOnExpiration : true } } ) { id name } } Copy Update the loss of signal settings of a condition What if you want to update loss of signal parameters for an alert condition? The following mutation allows you to update a NRQL static condition with new expiration values. mutation { alertsNrqlConditionStaticUpdate( accountId: YOUR_ACCOUNT_ID id: YOUR_STATIC_CONDITION_ID condition: { expiration: { closeViolationsOnExpiration : BOOLEAN expirationDuration : DURATION_IN_SECONDS openViolationOnExpiration : BOOLEAN } } ) { id expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } Copy Customize gap filling Gap filling replaces gap values in a time series with either the last value found or a static, arbitrary value of your choice. We fill gaps only after another data point has been received after the gaps in signal (after data reception has been restored). You can configure both the type of filling and the value, if the type is set to static: signal.fillOption: Type of replacement value for lost data points. Values can be: NONE: Gap filling is disabled. LAST_VALUE: The last value seen in the time series. STATIC: An arbitrary value, defined in fillValue. signal.fillValue: Value to use for replacing lost data points when fillOption is set to STATIC. Important Gap filling is also affected by expiration.expirationDuration. When a gap is longer than the expiration duration, the signal is considered expired and the gap will no longer be filled. For example, here's how to create a static NRQL condition with gap filling configured: mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { enabled: true name: \"Example Gap Filling Condition\" nrql: { query: \"select count(*) from Transaction\" } terms: { operator: ABOVE priority: CRITICAL threshold: 1000 thresholdDuration: 300 thresholdOccurrences: ALL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 28800 signal: { aggregationWindow: 60, aggregationMethod: EVENT_FLOW, aggregationDelay: 120, fillOption: STATIC, fillValue: 1 } } ) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 279.9544,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "sections": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Loss of signal occurs when <em>New</em> <em>Relic</em> stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up <em>alerts</em>"
      },
      "id": "6130bf9c196a676b034948b3"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts": [
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "List notification channels with their associated policies",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-10-13T02:03:21Z",
      "updated_at": "2021-10-13T02:03:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy List notification channels with their associated policies This example returns the ID, name, and type for every notification channel on the supplied account ID, as well as a list of every policy that is associated with that channel. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type associatedPolicies { policies { id name } totalCount } } nextCursor totalCount } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the channel because it might be used by other policies. On the other hand, deleting a channel will cause all associated policies to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.23108,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Notification channels",
        "sections": "<em>NerdGraph</em> tutorial: Notification channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your <em>alert</em> notification channels using our GraphQL <em>NerdGraph</em> API. Here are some queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. Get notification channels"
      },
      "id": "6130bf9c28ccbc027d56a863"
    },
    {
      "sections": [
        "NerdGraph tutorial: Alerts policies",
        "Tip",
        "List and filter policies",
        "Listing all policies for an account",
        "Paginating through policies with cursor pagination",
        "Find all policies by selected ids",
        "Find all policies by name",
        "Find policy by id",
        "Create a policy",
        "Update a policy",
        "Delete a policy"
      ],
      "title": "NerdGraph tutorial: Alerts policies",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "6b4553ffff3b55e91abb519963337eade57ae64b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-alerts-policies/",
      "published_at": "2021-10-13T02:02:28Z",
      "updated_at": "2021-10-13T02:02:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alerts policies using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. List and filter policies The policiesSearch query allows you to paginate through all of your policies per account. It also allows some filtering functionality on the account policies. Listing all policies for an account Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch { policies { id name incidentPreference } } } } } } Copy Paginating through policies with cursor pagination In order to paginate through your policies, you must request the nextCursor field on your initial query. With cursor pagination, you continue to make a request through the result set until the nextCursor that is returned from the response comes back empty. This signifies that you reached the end of your results. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch { nextCursor policies { id name incidentPreference } totalCount } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"policiesSearch\": { \"nextCursor\": \"/8o0y2qiR54m6thkdgHgwg==:jZTXDFKbTkhKwvMx+CtsPVM=\", \"policies\": [ { \"id\": \"3455\", \"incidentPreference\": \"PER_POLICY\", \"name\": \"First Policy Name\" }, { \"id\": \"2123\", \"incidentPreference\": \"PER_POLICY\", \"name\": \"Another Policy\" }, // ... more policies here in reality ], \"totalCount\": 745 } } } } } } Copy So, in your subsequent request, provide the cursor like so, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch(cursor: \"/8o0y2qiR54m6thkdgHgwg==:jZTXDFKbTkhKwvMx+CtsPVM=\") { nextCursor policies { id name incidentPreference } totalCount } } } } } Copy Find all policies by selected ids The API allows policy queries by a sub-select of ids. This will only return the information for these policies that you provide. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch(searchCriteria: { ids: [A_POLICY_ID, ANOTHER_POLICY_ID] }) { policies { id name incidentPreference } } } } } } Copy Find all policies by name The API allows policy queries by name. Use name for matching by exact names or nameLike for a partial match. Both search criteria are case insensitive. This will only return the information for the policies that match the name supplied. In this example, we want to find policies with \"DevOps\" in the name: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policiesSearch(searchCriteria: { nameLike: \"DevOps\" }) { policies { id name } } } } } } Copy Find policy by id The API lets you query by policy id: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { policy(id: YOUR_POLICY_ID) { id name incidentPreference } } } } } Copy Create a policy In order to create a policy, supply a name and an incidentPreference. The incident preference will configure how incidents get created for each condition created in the policy. For more information, refer to the documentation about choosing your incident preference. mutation { alertsPolicyCreate(accountId: YOUR_ACCOUNT_ID, policy: { name: \"Your Policy Name\" incidentPreference: PER_CONDITION }) { id name incidentPreference } } Copy Update a policy When you update a policy, note that you don't need to supply all of the attributes on the policy. For example, you only need to supply the name if you only intend to update the name: mutation { alertsPolicyUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_POLICY_ID, policy: { name: \"Updated Policy Name\" }) { id name incidentPreference } } Copy Delete a policy You can delete policies via the NerdGraph API. Note that only the id may be requested back from a deleted resource: mutation { alertsPolicyDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_POLICY_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.22443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: <em>Alerts</em> policies",
        "sections": "<em>NerdGraph</em> tutorial: <em>Alerts</em> policies",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your <em>alerts</em> policies using our GraphQL <em>NerdGraph</em> API. Here are some queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. List and filter policies The policiesSearch query allows"
      },
      "id": "6130bf66196a6751e34948a9"
    },
    {
      "sections": [
        "NerdGraph tutorial: Loss of signal and gap filling",
        "Tip",
        "Customize your loss of signal detection",
        "View loss of signal settings for an existing condition",
        "Create a new condition with loss of signal settings",
        "Update the loss of signal settings of a condition",
        "Customize gap filling",
        "Important"
      ],
      "title": "NerdGraph tutorial: Loss of signal and gap filling",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "2389c7a91a09c2175c1f13c3cad5962389571b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling/",
      "published_at": "2021-10-13T01:26:27Z",
      "updated_at": "2021-10-13T01:26:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. Gap filling can help you solve issues caused by lost data points. When gaps are detected between valid data points, we automatically fill those gaps with replacement values, such as the last known values or a static value. Gap filling can prevent alerts from triggering or resolving when they shouldn't. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. You can customize loss of signal detection and gap filling using NerdGraph. For example, you can configure how long to wait before considering the signal lost, or what value should be used for filling gaps in the time series. Here are some queries and examples you can use in our NerdGraph API explorer. In this guide we cover the following: Customize loss of signal detection Customize gap filling Customize your loss of signal detection Loss of signal detection opens or closes violations if no data is received after a certain amount of time. For example, if you set the duration of the expiration period to 60 seconds and an integration doesn't seem to send data for more than a minute, a loss of signal violation would be triggered. You can configure the duration of the signal loss and whether to open a violation or close it by using these three fields in NerdGraph: expiration.expirationDuration: How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives at our platform and not on data timestamps. The default is to leave this null, and therefore this wouldn't enable Loss of Signal Detection. expiration.openViolationOnExpiration: If true, a new violation is opened when a signal is lost. Default is false. To use this field, a duration must be specified. expiration.closeViolationsOnExpiration: If true, open violations related to the signal are closed on expiration. Default is false. To use this field, a duration must be specified. View loss of signal settings for an existing condition Existing NRQL conditions may have their loss of signal settings already configured. To view the existing condition settings, select the fields under nrqlCondition > expiration: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: NRQL_CONDITION_ID) { ... on AlertsNrqlStaticCondition { id name nrql { query } expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } } } } } Copy You should see a result like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlCondition\": { \"expiration\": { \" closeViolationsOnExpiration \": false, \" expirationDuration \": 300, \" openViolationOnExpiration \": true }, \"id\": \"YOUR_ACCOUNT_ID\", \"name\": \"Any less than - Extrapolation\", \"nrql\": { \"query\": \"SELECT average(value) FROM AlertsSmokeTestSignals WHERE wave_type IN ('min-max', 'single-gap') FACET wave_type\" } } } } } }, ... Copy Create a new condition with loss of signal settings Let's say that you want to create a new create a NRQL static condition that triggers a loss of signal violation after no data is received for two minutes. You would set expirationDuration to 120 seconds and set openViolationOnExpiration to true, like in the example below. mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: [{ threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL }] valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 expiration : { expirationDuration : 120 openViolationOnExpiration : true } } ) { id name } } Copy Update the loss of signal settings of a condition What if you want to update loss of signal parameters for an alert condition? The following mutation allows you to update a NRQL static condition with new expiration values. mutation { alertsNrqlConditionStaticUpdate( accountId: YOUR_ACCOUNT_ID id: YOUR_STATIC_CONDITION_ID condition: { expiration: { closeViolationsOnExpiration : BOOLEAN expirationDuration : DURATION_IN_SECONDS openViolationOnExpiration : BOOLEAN } } ) { id expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } Copy Customize gap filling Gap filling replaces gap values in a time series with either the last value found or a static, arbitrary value of your choice. We fill gaps only after another data point has been received after the gaps in signal (after data reception has been restored). You can configure both the type of filling and the value, if the type is set to static: signal.fillOption: Type of replacement value for lost data points. Values can be: NONE: Gap filling is disabled. LAST_VALUE: The last value seen in the time series. STATIC: An arbitrary value, defined in fillValue. signal.fillValue: Value to use for replacing lost data points when fillOption is set to STATIC. Important Gap filling is also affected by expiration.expirationDuration. When a gap is longer than the expiration duration, the signal is considered expired and the gap will no longer be filled. For example, here's how to create a static NRQL condition with gap filling configured: mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { enabled: true name: \"Example Gap Filling Condition\" nrql: { query: \"select count(*) from Transaction\" } terms: { operator: ABOVE priority: CRITICAL threshold: 1000 thresholdDuration: 300 thresholdOccurrences: ALL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 28800 signal: { aggregationWindow: 60, aggregationMethod: EVENT_FLOW, aggregationDelay: 120, fillOption: STATIC, fillValue: 1 } } ) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 279.95428,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "sections": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Loss of signal occurs when <em>New</em> <em>Relic</em> stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up <em>alerts</em>"
      },
      "id": "6130bf9c196a676b034948b3"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/apm-metric-alert-conditions": [
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-12T21:53:32Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.25458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.68472,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "View entity health status and find entities without alert conditions",
        "Important",
        "Exceptions",
        "Color-coded health status",
        "Health status transitions",
        "Example: App without conditions",
        "Example: App with conditions",
        "Tip"
      ],
      "title": "View entity health status and find entities without alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "b2826e95805df46a371e48e17c2439cf566240e8",
      "image": "https://docs.newrelic.com/static/e9ca85d8e1b3cf5d1ab549e0a3955990/38cea/032715crop-events-no-v3_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions/",
      "published_at": "2021-10-13T02:02:28Z",
      "updated_at": "2021-10-13T02:02:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With alerts you can easily tell whether an entity (the target for the notification) has one or more conditions associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current alert violations, mouse over its health status indicator. If no, its health status indicator on the selected index will appear grey. Important To learn more about how conditions and policies work together, see Introduction to important concepts. Exceptions The health status indicator doesn't apply for: Infrastructure entities Dashboards Entities targeted by labels Color-coded health status The index automatically appears when you select the product from the New Relic menu bar. For example, to view the index of APM apps, go to one.newrelic.com, then click APM. The Applications index lists all APM product entities and their current health status. Color Health status Green The entity is operational. We are collecting data that you can view in the appropriate UI. No alert violations are currently reported for it. Yellow The entity is degraded. A warning threshold has been violated. Red A critical threshold has been violated: Notifications have been sent based on the selected incident rollup preference. The incident appears in the Incidents index. Gray The entity's status is unknown. We're not receiving alerts data for the entity. This could mean alerts are muted, not set up, or the reporting system is down. Health status transitions The following table describes the different health status transitions an entity can endure: From... To... Transition explanation Gray Green The entity is evaluated for at least one condition, and the results show there are no violations present. Green / Red Gray Possible explanations: The last condition associated to the entity has been deleted and therefore there's no status to report. The last condition associated to the entity has been disabled and therefore there's no status to report. The entity has stopped reporting data. There's a New Relic platform issue. Check the New Relic status page for updates. Green Yellow / Red There's at least one open violation at the time the entity is undergoing the evaluation. Yellow / Red Green The last open violation associated to the entity has been closed. Example: App without conditions Here's an example of an app listed on the APM index that is not associated with any conditions. Its color-coded health status is light grey, which indicates no alert conditions are set up for that entity. Go to one.newrelic.com, then click Explorer: This example shows an app that currently isn't associated with any alerts conditions. Its grey status icon means it doesn't have any conditions. Follow standard procedures to add it to an existing condition or to create a new condition for it. Example: App with conditions Here's an example of an app listed on the APM index that is associated with one or more conditions. Its color-coded health status is green, because we are collecting data for it, and currently there are no Warning (yellow) or Critical (red) violations. Go to one.newrelic.com, then click Explorer: This example shows an app that has one or more conditions. Its color-coded health status (green) shows the app hasn't reached any threshold violations. Tip To view the index listing currently open incidents across all products, not just this entity, select View all violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.06308,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "sections": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>alerts</em> you can easily tell whether an entity (the target for the notification) has one or more <em>conditions</em> associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current <em>alert</em> violations"
      },
      "id": "6130c01e196a679fa84948f5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions": [
    {
      "sections": [
        "Update or disable conditions",
        "Condition maintenance quick reference",
        "Add more conditions",
        "Copy a condition",
        "Change a condition",
        "Disable or delete conditions",
        "Disable or re-enable a condition",
        "Tip",
        "Delete conditions"
      ],
      "title": "Update or disable conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert policies"
      ],
      "external_id": "4a6c5107cd6af696df6a3fb0651c6a1bde7daf36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions/",
      "published_at": "2021-10-12T21:53:32Z",
      "updated_at": "2021-10-12T21:53:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here's a quick reference for maintaining conditions. This includes the condition's entities (targets), Warning (yellow) and Critical (red) thresholds, and runbook URL. Condition maintenance quick reference Add more conditions To add more conditions to a policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Add a condition. OR To copy a condition from any policy and add it to another policy: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, select a policy, then click Copy. Copy a condition To copy an existing condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the policy's list of one or more Alert conditions, click Copy. From the Copy alert condition list, search or scroll the list to select the policy where you want to add this condition. Optional: Change the condition's name if necessary. Select Save. By default, the copied condition will be added to the selected alert policy in a Disabled state. Follow standard procedures to add or copy additional conditions to the alert policy, and then Enable the condition as needed. Change a condition To change a policy condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions for the selected policy: To change the condition's name, click Edit. To add, change, or remove targets (entities), select the name or number of targets for the condition, and then select Browse and select targets. To update the values for the required Critical (red) or optional Warning (yellow) thresholds, select the existing value. To update the condition's runbook URL, select the condition's Thresholds. Disable or delete conditions Disable or re-enable a condition You can enable or disable any policy conditions, and the policy will continue to apply. To disable or re-enable a condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. Then, from the list of Alert conditions select a condition). Click the On/Off switch to toggle it. Tip For Infrastructure conditions, use the checkbox at the bottom of the condition edit screen, then save the condition. If you copy a condition, it is automatically saved in the new policy as disabled (Off), even if the condition was enabled (On) in the original policy. Delete conditions If a policy has multiple conditions, you can delete any or all of them, and the remaining conditions for the policy will continue to apply. To turn a condition off but keep it with the policy, disable it. To delete one or more conditions: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then select a policy. From the list of Alert conditions, select a condition, then click Delete. Tip If you don't see the delete button, your account admin may have disabled condition deletion for your organization.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.25446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update or disable <em>conditions</em>",
        "sections": "Update or disable <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " condition, including its targets and thresholds, and add it to another policy for the selected account: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then select a policy. From the policy&#x27;s list of one or more <em>Alert</em> <em>conditions</em>, click Copy. From the Copy <em>alert</em> condition list"
      },
      "id": "604404ec28ccbc62492c6098"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.6846,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "View entity health status and find entities without alert conditions",
        "Important",
        "Exceptions",
        "Color-coded health status",
        "Health status transitions",
        "Example: App without conditions",
        "Example: App with conditions",
        "Tip"
      ],
      "title": "View entity health status and find entities without alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "b2826e95805df46a371e48e17c2439cf566240e8",
      "image": "https://docs.newrelic.com/static/e9ca85d8e1b3cf5d1ab549e0a3955990/38cea/032715crop-events-no-v3_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions/",
      "published_at": "2021-10-13T02:02:28Z",
      "updated_at": "2021-10-13T02:02:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With alerts you can easily tell whether an entity (the target for the notification) has one or more conditions associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current alert violations, mouse over its health status indicator. If no, its health status indicator on the selected index will appear grey. Important To learn more about how conditions and policies work together, see Introduction to important concepts. Exceptions The health status indicator doesn't apply for: Infrastructure entities Dashboards Entities targeted by labels Color-coded health status The index automatically appears when you select the product from the New Relic menu bar. For example, to view the index of APM apps, go to one.newrelic.com, then click APM. The Applications index lists all APM product entities and their current health status. Color Health status Green The entity is operational. We are collecting data that you can view in the appropriate UI. No alert violations are currently reported for it. Yellow The entity is degraded. A warning threshold has been violated. Red A critical threshold has been violated: Notifications have been sent based on the selected incident rollup preference. The incident appears in the Incidents index. Gray The entity's status is unknown. We're not receiving alerts data for the entity. This could mean alerts are muted, not set up, or the reporting system is down. Health status transitions The following table describes the different health status transitions an entity can endure: From... To... Transition explanation Gray Green The entity is evaluated for at least one condition, and the results show there are no violations present. Green / Red Gray Possible explanations: The last condition associated to the entity has been deleted and therefore there's no status to report. The last condition associated to the entity has been disabled and therefore there's no status to report. The entity has stopped reporting data. There's a New Relic platform issue. Check the New Relic status page for updates. Green Yellow / Red There's at least one open violation at the time the entity is undergoing the evaluation. Yellow / Red Green The last open violation associated to the entity has been closed. Example: App without conditions Here's an example of an app listed on the APM index that is not associated with any conditions. Its color-coded health status is light grey, which indicates no alert conditions are set up for that entity. Go to one.newrelic.com, then click Explorer: This example shows an app that currently isn't associated with any alerts conditions. Its grey status icon means it doesn't have any conditions. Follow standard procedures to add it to an existing condition or to create a new condition for it. Example: App with conditions Here's an example of an app listed on the APM index that is associated with one or more conditions. Its color-coded health status is green, because we are collecting data for it, and currently there are no Warning (yellow) or Critical (red) violations. Go to one.newrelic.com, then click Explorer: This example shows an app that has one or more conditions. Its color-coded health status (green) shows the app hasn't reached any threshold violations. Tip To view the index listing currently open incidents across all products, not just this entity, select View all violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.06296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "sections": "View entity health status <em>and</em> find entities without <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>alerts</em> you can easily tell whether an entity (the target for the notification) has one or more <em>conditions</em> associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current <em>alert</em> violations"
      },
      "id": "6130c01e196a679fa84948f5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-13T01:49:31Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.82474,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "sections": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Our <em>REST</em> <em>API</em> (v2) allows you to configure settings for <em>alerts</em>. The <em>API</em> Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available <em>API</em> calls. You can also create <em>alert</em> conditions in the UI. Important"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.5168,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-13T02:49:42Z",
      "updated_at": "2021-10-13T02:49:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) FROM Transaction WHERE appName='my-app-name'\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } } } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: { description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"} ) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.30435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NerdGraph tutorial: NRQL condition <em>alerts</em>",
        "sections": "NerdGraph tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage <em>alerts</em> conditions using our GraphQL NerdGraph <em>API</em>. Here are some conditions queries and mutations you can develop in our NerdGraph <em>API</em> explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph <em>API</em> explorer. This document covers the following: Steps"
      },
      "id": "6130bf6528ccbcb0d856a821"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/disable-enable-alerts-conditions-using-api": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "condition_scope",
        "enabled",
        "entities",
        "expected_groups",
        "expiration[expiration_duration]",
        "expiration[close_violations_on_expiration]",
        "expiration[open_violation_on_expiration]",
        "external_service_url",
        "ignore_overlap",
        "metric",
        "Alerts conditions",
        "Alerts external service conditions",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "runbook_url",
        "signal[aggregation_delay]",
        "signal[aggregation_method]",
        "signal[aggregation_timer]",
        "signal[aggregation_window]",
        "signal[evaluation_offset]",
        "signal[fill_option]",
        "signal[fill_value]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-13T01:51:20Z",
      "updated_at": "2021-10-13T01:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes four types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions NRQL conditions Synthetic monitoring conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration[expiration_duration] How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. Used for: NRQL conditions expiration[close_violations_on_expiration] When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. Used for: NRQL conditions expiration[open_violation_on_expiration] When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is false. Used for: NRQL conditions external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions NRQL conditions Synthetic monitoring conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] Deprecated in favor of an aggregation_method with either an aggregation_delay or aggregation_timer. This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions NRQL conditions Synthetic monitoring conditions signal[aggregation_delay] The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggregation_method types. Default is 120 seconds. Used with event flow and cadence aggregation methods. Used for: NRQL conditions signal[aggregation_method] New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data pointâ€™s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. The default is Event flow. Used for: NRQL conditions signal[aggregation_timer] The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Default is 60 seconds. Used for: NRQL conditions signal[aggregation_window] Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. Default is 60 seconds. Maximum is 15 minutes. Used for: NRQL conditions signal[evaluation_offset] Deprecated in favor of an aggregation_method with either an aggregation_delay or aggregation_timer. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 aggregation windows. Used for: NRQL conditions signal[fill_option] For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you donâ€™t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition wonâ€™t be in violation. static: Use this if youâ€™d like to insert a custom static value into the empty aggregation windows before theyâ€™re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. Used for: NRQL conditions signal[fill_value] This is the value used by the fill_option custom value. The default is 0. Used for: NRQL conditions terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions NRQL conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions NRQL conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions NRQL conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions NRQL conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions NRQL conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Default is 259,200 seconds (3 days). Maximum is 30 days. Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.67697,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions <em>API</em> field names",
        "sections": "<em>Alerts</em> conditions <em>API</em> field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The <em>REST</em> <em>API</em> endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The <em>API</em> includes four types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-13T01:49:31Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.82474,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "sections": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Our <em>REST</em> <em>API</em> (v2) allows you to configure settings for <em>alerts</em>. The <em>API</em> Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available <em>API</em> calls. You can also create <em>alert</em> conditions in the UI. Important"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.5168,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/manage-entities-alerts-conditions": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "condition_scope",
        "enabled",
        "entities",
        "expected_groups",
        "expiration[expiration_duration]",
        "expiration[close_violations_on_expiration]",
        "expiration[open_violation_on_expiration]",
        "external_service_url",
        "ignore_overlap",
        "metric",
        "Alerts conditions",
        "Alerts external service conditions",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "runbook_url",
        "signal[aggregation_delay]",
        "signal[aggregation_method]",
        "signal[aggregation_timer]",
        "signal[aggregation_window]",
        "signal[evaluation_offset]",
        "signal[fill_option]",
        "signal[fill_value]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-13T01:51:20Z",
      "updated_at": "2021-10-13T01:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes four types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions NRQL conditions Synthetic monitoring conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration[expiration_duration] How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. Used for: NRQL conditions expiration[close_violations_on_expiration] When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. Used for: NRQL conditions expiration[open_violation_on_expiration] When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is false. Used for: NRQL conditions external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions NRQL conditions Synthetic monitoring conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] Deprecated in favor of an aggregation_method with either an aggregation_delay or aggregation_timer. This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions NRQL conditions Synthetic monitoring conditions signal[aggregation_delay] The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggregation_method types. Default is 120 seconds. Used with event flow and cadence aggregation methods. Used for: NRQL conditions signal[aggregation_method] New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data pointâ€™s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. The default is Event flow. Used for: NRQL conditions signal[aggregation_timer] The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Default is 60 seconds. Used for: NRQL conditions signal[aggregation_window] Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. Default is 60 seconds. Maximum is 15 minutes. Used for: NRQL conditions signal[evaluation_offset] Deprecated in favor of an aggregation_method with either an aggregation_delay or aggregation_timer. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 aggregation windows. Used for: NRQL conditions signal[fill_option] For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you donâ€™t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition wonâ€™t be in violation. static: Use this if youâ€™d like to insert a custom static value into the empty aggregation windows before theyâ€™re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. Used for: NRQL conditions signal[fill_value] This is the value used by the fill_option custom value. The default is 0. Used for: NRQL conditions terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions NRQL conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions NRQL conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions NRQL conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions NRQL conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions NRQL conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Default is 259,200 seconds (3 days). Maximum is 30 days. Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.67685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions <em>API</em> field names",
        "sections": "<em>Alerts</em> conditions <em>API</em> field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The <em>REST</em> <em>API</em> endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The <em>API</em> includes four types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-13T01:49:31Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.82468,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "sections": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Our <em>REST</em> <em>API</em> (v2) allows you to configure settings for <em>alerts</em>. The <em>API</em> Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available <em>API</em> calls. You can also create <em>alert</em> conditions in the UI. Important"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.51672,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "condition_scope",
        "enabled",
        "entities",
        "expected_groups",
        "expiration[expiration_duration]",
        "expiration[close_violations_on_expiration]",
        "expiration[open_violation_on_expiration]",
        "external_service_url",
        "ignore_overlap",
        "metric",
        "Alerts conditions",
        "Alerts external service conditions",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "runbook_url",
        "signal[aggregation_delay]",
        "signal[aggregation_method]",
        "signal[aggregation_timer]",
        "signal[aggregation_window]",
        "signal[evaluation_offset]",
        "signal[fill_option]",
        "signal[fill_value]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-13T01:51:20Z",
      "updated_at": "2021-10-13T01:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes four types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions NRQL conditions Synthetic monitoring conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration[expiration_duration] How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. Used for: NRQL conditions expiration[close_violations_on_expiration] When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. Used for: NRQL conditions expiration[open_violation_on_expiration] When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is false. Used for: NRQL conditions external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions NRQL conditions Synthetic monitoring conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] Deprecated in favor of an aggregation_method with either an aggregation_delay or aggregation_timer. This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions NRQL conditions Synthetic monitoring conditions signal[aggregation_delay] The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggregation_method types. Default is 120 seconds. Used with event flow and cadence aggregation methods. Used for: NRQL conditions signal[aggregation_method] New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data pointâ€™s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. The default is Event flow. Used for: NRQL conditions signal[aggregation_timer] The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Default is 60 seconds. Used for: NRQL conditions signal[aggregation_window] Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. Default is 60 seconds. Maximum is 15 minutes. Used for: NRQL conditions signal[evaluation_offset] Deprecated in favor of an aggregation_method with either an aggregation_delay or aggregation_timer. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 aggregation windows. Used for: NRQL conditions signal[fill_option] For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you donâ€™t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition wonâ€™t be in violation. static: Use this if youâ€™d like to insert a custom static value into the empty aggregation windows before theyâ€™re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. Used for: NRQL conditions signal[fill_value] This is the value used by the fill_option custom value. The default is 0. Used for: NRQL conditions terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions NRQL conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions NRQL conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions NRQL conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions NRQL conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions NRQL conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Default is 259,200 seconds (3 days). Maximum is 30 days. Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.67685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions <em>API</em> field names",
        "sections": "<em>Alerts</em> conditions <em>API</em> field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The <em>REST</em> <em>API</em> endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The <em>API</em> includes four types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.51672,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-13T02:49:42Z",
      "updated_at": "2021-10-13T02:49:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) FROM Transaction WHERE appName='my-app-name'\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } } } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: { description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"} ) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.30426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NerdGraph tutorial: NRQL condition <em>alerts</em>",
        "sections": "NerdGraph tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage <em>alerts</em> conditions using our GraphQL NerdGraph <em>API</em>. Here are some conditions queries and mutations you can develop in our NerdGraph <em>API</em> explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph <em>API</em> explorer. This document covers the following: Steps"
      },
      "id": "6130bf6528ccbcb0d856a821"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/troubleshooting/missing-alert-notifications": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.14249,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-13T02:49:42Z",
      "updated_at": "2021-10-13T02:49:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) FROM Transaction WHERE appName='my-app-name'\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } } } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: { description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"} ) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.54893,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NerdGraph tutorial: NRQL condition <em>alerts</em>",
        "sections": "NerdGraph tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on <em>Alerts</em>NrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL <em>alert</em> condition. Get all the conditions for a policy: { actor { account(id"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "List notification channels with their associated policies",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-10-13T02:03:21Z",
      "updated_at": "2021-10-13T02:03:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy List notification channels with their associated policies This example returns the ID, name, and type for every notification channel on the supplied account ID, as well as a list of every policy that is associated with that channel. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type associatedPolicies { policies { id name } totalCount } } nextCursor totalCount } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the channel because it might be used by other policies. On the other hand, deleting a channel will cause all associated policies to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.3254,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " { <em>alerts</em>NotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: &quot;https:&#x2F;&#x2F;example.com&#x2F;webhook&quot;, basicAuth: { password: &quot;t0t4lly-s3cr3t-p455w0rd&quot;, username: &quot;webhook-user&quot; }, customHttpHeaders: [ {name: &quot;X-Api-Key&quot;, value: &quot;100%-real-api-key&quot;}, {name: &quot;X-Calling-Service&quot;, value: &quot;<em>New</em>"
      },
      "id": "6130bf9c28ccbc027d56a863"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/troubleshooting/tag-information-not-showing-entity-infra-alert-condition": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-13T03:32:10Z",
      "updated_at": "2021-10-13T03:32:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts donâ€™t make sense in the streaming context of alerts. Hereâ€™s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, youâ€™ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL conditionâ€™s query. The query is parsed and executed by our systems in the following order: FROM clause â€“ which event type needs to be grabbed? WHERE clause â€“ what can be filtered out? SELECT clause â€“ what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) â€‹â€‹â€‹â€‹â€‹ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)â€‹â€‹ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.14241,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-13T02:49:42Z",
      "updated_at": "2021-10-13T02:49:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) FROM Transaction WHERE appName='my-app-name'\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 aggregationMethod: EVENT_FLOW aggregationDelay: 120 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } } } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow aggregationMethod aggregationDelay aggregationTimer } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: { description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"} ) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.54886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NerdGraph tutorial: NRQL condition <em>alerts</em>",
        "sections": "NerdGraph tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on <em>Alerts</em>NrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL <em>alert</em> condition. Get all the conditions for a policy: { actor { account(id"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "List notification channels with their associated policies",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-10-13T02:03:21Z",
      "updated_at": "2021-10-13T02:03:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy List notification channels with their associated policies This example returns the ID, name, and type for every notification channel on the supplied account ID, as well as a list of every policy that is associated with that channel. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type associatedPolicies { policies { id name } totalCount } } nextCursor totalCount } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the channel because it might be used by other policies. On the other hand, deleting a channel will cause all associated policies to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.32532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " { <em>alerts</em>NotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: &quot;https:&#x2F;&#x2F;example.com&#x2F;webhook&quot;, basicAuth: { password: &quot;t0t4lly-s3cr3t-p455w0rd&quot;, username: &quot;webhook-user&quot; }, customHttpHeaders: [ {name: &quot;X-Api-Key&quot;, value: &quot;100%-real-api-key&quot;}, {name: &quot;X-Calling-Service&quot;, value: &quot;<em>New</em>"
      },
      "id": "6130bf9c28ccbc027d56a863"
    }
  ]
}